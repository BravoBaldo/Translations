<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Classificazione delle Immagini – Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" rel="next">
<link href="../../../../contents/labs/raspi/setup/setup.it.html" rel="prev">
<link href="../../../../favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script src="../../../../scripts/ai_menu/dist/bundle.js" defer=""></script>


</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalità oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalità lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/raspi.it.html">Raspberry Pi</a></li><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html">Classificazione delle Immagini</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/copyright.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/dedication.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedica</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/contributors.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collaboratori e Ringraziamenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell’IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell’IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell’IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/core/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LABORATORI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/part_LABS.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">LABORATORI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/overview.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/part_nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">part_nicla_vision.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/part_xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">part_xiao_esp32s3.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/part_raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">part_raspi.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/shared/part_shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">part_shared.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a>
  <ul>
  <li><a href="#applicazioni-in-scenari-del-mondo-reale" id="toc-applicazioni-in-scenari-del-mondo-reale" class="nav-link" data-scroll-target="#applicazioni-in-scenari-del-mondo-reale">Applicazioni in Scenari del Mondo Reale</a></li>
  <li><a href="#vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" id="toc-vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" class="nav-link" data-scroll-target="#vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi">Vantaggi dell’Esecuzione della Classificazione su Dispositivi Edge come Raspberry Pi</a></li>
  </ul></li>
  <li><a href="#impostazione-dellambiente" id="toc-impostazione-dellambiente" class="nav-link" data-scroll-target="#impostazione-dellambiente">Impostazione dell’Ambiente</a>
  <ul>
  <li><a href="#aggiornamento-di-raspberry-pi" id="toc-aggiornamento-di-raspberry-pi" class="nav-link" data-scroll-target="#aggiornamento-di-raspberry-pi">Aggiornamento di Raspberry Pi</a></li>
  <li><a href="#installazione-delle-librerie-richieste" id="toc-installazione-delle-librerie-richieste" class="nav-link" data-scroll-target="#installazione-delle-librerie-richieste">Installazione delle Librerie Richieste</a></li>
  <li><a href="#impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" id="toc-impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" class="nav-link" data-scroll-target="#impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato">Impostazione di un Ambiente Virtuale (Facoltativo ma Consigliato)</a></li>
  <li><a href="#installazione-di-tensorflow-lite" id="toc-installazione-di-tensorflow-lite" class="nav-link" data-scroll-target="#installazione-di-tensorflow-lite">Installazione di TensorFlow Lite</a></li>
  <li><a href="#installazione-di-librerie-python-aggiuntive" id="toc-installazione-di-librerie-python-aggiuntive" class="nav-link" data-scroll-target="#installazione-di-librerie-python-aggiuntive">Installazione di Librerie Python Aggiuntive</a></li>
  <li><a href="#creazione-di-una-directory-di-lavoro" id="toc-creazione-di-una-directory-di-lavoro" class="nav-link" data-scroll-target="#creazione-di-una-directory-di-lavoro">Creazione di una directory di lavoro:</a></li>
  <li><a href="#impostazione-di-jupyter-notebook-facoltativo" id="toc-impostazione-di-jupyter-notebook-facoltativo" class="nav-link" data-scroll-target="#impostazione-di-jupyter-notebook-facoltativo">Impostazione di Jupyter Notebook (Facoltativo)</a></li>
  <li><a href="#verifica-della-configurazione" id="toc-verifica-della-configurazione" class="nav-link" data-scroll-target="#verifica-della-configurazione">Verifica della Configurazione</a></li>
  </ul></li>
  <li><a href="#fare-inferenze-con-mobilenet-v2" id="toc-fare-inferenze-con-mobilenet-v2" class="nav-link" data-scroll-target="#fare-inferenze-con-mobilenet-v2">Fare inferenze con Mobilenet V2</a>
  <ul>
  <li><a href="#definire-una-funzione-generale-di-classificazione-delle-immagini" id="toc-definire-una-funzione-generale-di-classificazione-delle-immagini" class="nav-link" data-scroll-target="#definire-una-funzione-generale-di-classificazione-delle-immagini">Definire una funzione generale di Classificazione delle Immagini</a></li>
  <li><a href="#test-con-un-modello-addestrato-da-zero" id="toc-test-con-un-modello-addestrato-da-zero" class="nav-link" data-scroll-target="#test-con-un-modello-addestrato-da-zero">Test con un modello addestrato da zero</a></li>
  <li><a href="#installing-picamera2" id="toc-installing-picamera2" class="nav-link" data-scroll-target="#installing-picamera2">Installing Picamera2</a></li>
  </ul></li>
  <li><a href="#progetto-di-classificazione-delle-immagini" id="toc-progetto-di-classificazione-delle-immagini" class="nav-link" data-scroll-target="#progetto-di-classificazione-delle-immagini">Progetto di Classificazione delle Immagini</a>
  <ul>
  <li><a href="#lobiettivo" id="toc-lobiettivo" class="nav-link" data-scroll-target="#lobiettivo">L’Obiettivo</a></li>
  <li><a href="#raccolta-dati" id="toc-raccolta-dati" class="nav-link" data-scroll-target="#raccolta-dati">Raccolta Dati</a></li>
  <li><a href="#compromesso-accuratezza-contro-velocità" id="toc-compromesso-accuratezza-contro-velocità" class="nav-link" data-scroll-target="#compromesso-accuratezza-contro-velocità">Compromesso: Accuratezza contro Velocità</a></li>
  <li><a href="#test-del-modello" id="toc-test-del-modello" class="nav-link" data-scroll-target="#test-del-modello">Test del Modello</a></li>
  <li><a href="#distribuzione-del-modello" id="toc-distribuzione-del-modello" class="nav-link" data-scroll-target="#distribuzione-del-modello">Distribuzione del modello</a></li>
  </ul></li>
  <li><a href="#classificazione-delle-immagini-in-tempo-reale" id="toc-classificazione-delle-immagini-in-tempo-reale" class="nav-link" data-scroll-target="#classificazione-delle-immagini-in-tempo-reale">Classificazione delle Immagini in Tempo Reale</a>
  <ul>
  <li><a href="#componenti-chiave" id="toc-componenti-chiave" class="nav-link" data-scroll-target="#componenti-chiave">Componenti Chiave:</a></li>
  <li><a href="#caratteristiche-principali" id="toc-caratteristiche-principali" class="nav-link" data-scroll-target="#caratteristiche-principali">Caratteristiche Principali:</a></li>
  <li><a href="#struttura-del-codice" id="toc-struttura-del-codice" class="nav-link" data-scroll-target="#struttura-del-codice">Struttura del Codice:</a></li>
  <li><a href="#concetti-chiave" id="toc-concetti-chiave" class="nav-link" data-scroll-target="#concetti-chiave">Concetti Chiave:</a></li>
  <li><a href="#uso" id="toc-uso" class="nav-link" data-scroll-target="#uso">Uso:</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione">Conclusione:</a></li>
  <li><a href="#risorse" id="toc-risorse" class="nav-link" data-scroll-target="#risorse">Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/raspi.it.html">Raspberry Pi</a></li><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html">Classificazione delle Immagini</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Classificazione delle Immagini</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/jpeg/img_class_cover.jpg" class="img-fluid figure-img"></p>
<figcaption><em>DALL·E prompt - Un’immagine di copertina per un capitolo “Classificazione delle immagini” in un tutorial Raspberry Pi, progettata nello stesso stile vintage da laboratorio di elettronica anni ’50 delle copertine precedenti. La scena dovrebbe presentare un Raspberry Pi collegato a un modulo fotocamera, con la fotocamera che cattura una foto del piccolo robot blu fornito dall’utente. Il robot dovrebbe essere posizionato su un banco da lavoro, circondato da classici strumenti da laboratorio come saldatori, resistenze e fili. Lo sfondo del laboratorio dovrebbe includere apparecchiature d’epoca come oscilloscopi e radio a valvole, mantenendo il tocco dettagliato e nostalgico dell’epoca. Non dovrebbero essere inclusi testo o loghi.</em></figcaption>
</figure>
</div>
<section id="introduzione" class="level2">
<h2 class="anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>La classificazione delle immagini è un’attività fondamentale nella visione artificiale che comporta la categorizzazione di un’immagine in una delle diverse classi predefinite. È una pietra angolare dell’intelligenza artificiale, che consente alle macchine di interpretare e comprendere le informazioni visive in un modo che imita la percezione umana.</p>
<p>La classificazione delle immagini si riferisce all’assegnazione di un’etichetta o di una categoria a un’intera immagine in base al suo contenuto visivo. Questa attività è fondamentale nella visione artificiale e ha numerose applicazioni in vari settori. L’importanza della classificazione delle immagini risiede nella sua capacità di automatizzare le attività di comprensione visiva che altrimenti richiederebbero l’intervento umano.</p>
<section id="applicazioni-in-scenari-del-mondo-reale" class="level3">
<h3 class="anchored" data-anchor-id="applicazioni-in-scenari-del-mondo-reale">Applicazioni in Scenari del Mondo Reale</h3>
<p>La classificazione delle immagini ha trovato la sua strada in numerose applicazioni del mondo reale, rivoluzionando vari settori:</p>
<ul>
<li>Sanità: Assistenza nell’analisi delle immagini mediche, come l’identificazione di anomalie nelle radiografie o nelle risonanze magnetiche.</li>
<li>Agricoltura: Monitoraggio della salute delle colture e rilevamento delle malattie delle piante tramite immagini aeree.</li>
<li>Automotive: Abilitazione di sistemi avanzati di assistenza alla guida e veicoli autonomi per riconoscere segnali stradali, pedoni e altri veicoli.</li>
<li>Vendita al Dettaglio: Potenziamento delle capacità di ricerca visiva e sistemi di gestione automatizzata dell’inventario.</li>
<li>Sicurezza e Sorveglianza: Potenziamento dei sistemi di rilevamento delle minacce e riconoscimento facciale.</li>
<li>Monitoraggio Ambientale: Analisi delle immagini satellitari per studi su deforestazione, pianificazione urbana e cambiamenti climatici.</li>
</ul>
</section>
<section id="vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi">Vantaggi dell’Esecuzione della Classificazione su Dispositivi Edge come Raspberry Pi</h3>
<p>L’implementazione della classificazione delle immagini su dispositivi edge come Raspberry Pi offre diversi vantaggi interessanti:</p>
<ol type="1">
<li><p>Bassa latenza: L’elaborazione delle immagini in locale elimina la necessità di inviare dati ai server cloud, riducendo significativamente i tempi di risposta.</p></li>
<li><p>Funzionalità Offline: La classificazione può essere eseguita senza una connessione Internet, rendendola adatta ad ambienti remoti o con problemi di connettività.</p></li>
<li><p>Privacy e Sicurezza: I dati sensibili delle immagini rimangono sul dispositivo locale, affrontando i problemi di privacy dei dati e i requisiti di conformità.</p></li>
<li><p>Efficacia in Termini di Costi: Elimina la necessità di costose risorse di cloud computing, in particolare per attività di classificazione continue o ad alto volume.</p></li>
<li><p>Scalabilità: Consente architetture di elaborazione distribuite in cui più dispositivi possono funzionare in modo indipendente o in una rete.</p></li>
<li><p>Efficienza Energetica: I modelli ottimizzati su hardware dedicato possono essere più efficienti dal punto di vista energetico rispetto alle soluzioni basate su cloud, il che è fondamentale per applicazioni alimentate a batteria o remote.</p></li>
<li><p>Personalizzazione: L’implementazione di modelli specializzati o aggiornati di frequente, su misura per casi d’uso specifici, è più gestibile.</p></li>
</ol>
<p>Possiamo creare soluzioni di visione artificiale più reattive, sicure ed efficienti sfruttando la potenza di dispositivi edge come Raspberry Pi per la classificazione delle immagini. Questo approccio apre nuove possibilità per integrare l’elaborazione visiva intelligente in varie applicazioni e ambienti.</p>
<p>Nelle sezioni seguenti, esploreremo come implementare e ottimizzare la classificazione delle immagini su Raspberry Pi, sfruttando questi vantaggi per creare sistemi di visione artificiale potenti ed efficienti.</p>
</section>
</section>
<section id="impostazione-dellambiente" class="level2">
<h2 class="anchored" data-anchor-id="impostazione-dellambiente">Impostazione dell’Ambiente</h2>
<section id="aggiornamento-di-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="aggiornamento-di-raspberry-pi">Aggiornamento di Raspberry Pi</h3>
<p>Innanzitutto, assicurarsi che il Raspberry Pi sia aggiornato:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt upgrade <span class="at">-y</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installazione-delle-librerie-richieste" class="level3">
<h3 class="anchored" data-anchor-id="installazione-delle-librerie-richieste">Installazione delle Librerie Richieste</h3>
<p>Installare le librerie necessarie per l’elaborazione delle immagini e l’apprendimento automatico:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install python3-pip</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> rm /usr/lib/python3.11/EXTERNALLY-MANAGED</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install <span class="at">--upgrade</span> pip</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" class="level3">
<h3 class="anchored" data-anchor-id="impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato">Impostazione di un Ambiente Virtuale (Facoltativo ma Consigliato)</h3>
<p>Creare un ambiente virtuale per gestire le dipendenze:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv ~/tflite</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installazione-di-tensorflow-lite" class="level3">
<h3 class="anchored" data-anchor-id="installazione-di-tensorflow-lite">Installazione di TensorFlow Lite</h3>
<p>Siamo interessati a eseguire <strong>inferenza</strong>, ovvero l’esecuzione di un modello TensorFlow Lite su un dispositivo per effettuare previsioni basate sui dati di input. Per eseguire un’inferenza con un modello TensorFlow Lite, dobbiamo eseguirla tramite un <strong>interprete</strong>. L’interprete TensorFlow Lite è progettato per essere snello e veloce. L’interprete utilizza un ordinamento grafico statico e un allocatore di memoria personalizzato (meno dinamico) per garantire un carico, inizializzazione ed esecuzione latenza minimi.</p>
<p>Utilizzeremo il <a href="https://pypi.org/project/tflite-runtime/">runtime TensorFlow Lite</a> per Raspberry Pi, una libreria semplificata per l’esecuzione di modelli di apprendimento automatico su dispositivi mobili e embedded, senza includere tutti i pacchetti TensorFlow.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tflite_runtime <span class="at">--no-deps</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>La wheel installata: <code>tflite_runtime-2.14.0-cp311-cp311-manylinux_2_34_aarch64.whl</code></p>
</blockquote>
</section>
<section id="installazione-di-librerie-python-aggiuntive" class="level3">
<h3 class="anchored" data-anchor-id="installazione-di-librerie-python-aggiuntive">Installazione di Librerie Python Aggiuntive</h3>
<p>Installare le librerie Python richieste per l’uso con Image Classification:</p>
<p>Se è installata un’altra versione di Numpy, disinstallarla prima.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> uninstall numpy</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Installare la <code>versione 1.23.2</code>, che è compatibile con tflite_runtime.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install numpy==1.23.2</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install Pillow matplotlib</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="creazione-di-una-directory-di-lavoro" class="level3">
<h3 class="anchored" data-anchor-id="creazione-di-una-directory-di-lavoro">Creazione di una directory di lavoro:</h3>
<p>Se si lavora su Raspi-Zero con il sistema operativo minimo (No Desktop), non si ha un albero di directory user-pre-defined (lo si può verificare con <code>ls</code>. Quindi, creiamone uno:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> Documents</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> Documents/</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> TFLITE</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> TFLITE/</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> IMG_CLASS</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> IMG_CLASS</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> models</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> models</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Su Raspi-5, /Documents dovrebbe esserci.</p>
</blockquote>
<p><strong>Ottenere un Modello di Classificazione delle Immagini Pre-addestrato</strong>:</p>
<p>Un modello pre-addestrato appropriato è fondamentale per una classificazione delle immagini di successo su dispositivi con risorse limitate come Raspberry Pi. <strong>MobileNet</strong> è progettato per applicazioni di visione mobile e embedded con un buon equilibrio tra accuratezza e velocità. Versioni: MobileNetV1, MobileNetV2, MobileNetV3. Scarichiamo la V2:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://storage.googleapis.com/download.tensorflow.org/models/</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tar</span> xzf mobilenet_v2_1.0_224_quant.tgz</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Prelevarne le <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/models/labels.txt">etichette</a>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/models/labels.txt</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Alla fine, si dovrebbero avere i modelli nella sua directory:</p>
<p><img src="images/png/models_dir.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Ci serviranno solo il modello <code>mobilenet_v2_1.0_224_quant.tflite</code> e <code>labels.txt</code>. Si possono eliminare gli altri file.</p>
</blockquote>
</section>
<section id="impostazione-di-jupyter-notebook-facoltativo" class="level3">
<h3 class="anchored" data-anchor-id="impostazione-di-jupyter-notebook-facoltativo">Impostazione di Jupyter Notebook (Facoltativo)</h3>
<p>Se si preferisce usare Jupyter Notebook per lo sviluppo:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install jupyter</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--generate-config</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Per eseguire Jupyter Notebook, si lancia il comando (cambiare l’indirizzo IP per il proprio):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--ip</span><span class="op">=</span>192.168.4.210 <span class="at">--no-browser</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Sul terminale, si può vedere l’indirizzo URL locale per aprire il notebook:</p>
<p><img src="images/png/notebook_token.png" class="img-fluid"></p>
<p>Vi si può accedere da un altro dispositivo inserendo l’indirizzo IP del Raspberry Pi e il token fornito in un browser Web (il token lo si può copiare dal terminale).</p>
<p><img src="images/png/image-20240823145059675.png" class="img-fluid"></p>
<p>Definire la directory di lavoro nel Raspi e creare un nuovo notebook Python 3.</p>
</section>
<section id="verifica-della-configurazione" class="level3">
<h3 class="anchored" data-anchor-id="verifica-della-configurazione">Verifica della Configurazione</h3>
<p>Testare la configurazione eseguendo un semplice script Python:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy:"</span>, np.__version__)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pillow:"</span>, Image.__version__)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to create a TFLite Interpreter</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TFLite Interpreter created successfully!"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Si può creare lo script Python usando nano sul terminale, salvandolo con <code>CTRL+0</code> + <code>ENTER</code> + <code>CTRL+X</code></p>
<p><img src="images/png/nano.png" class="img-fluid"></p>
<p>Ed eseguirlo col comando:</p>
<p><img src="images/png/test_result.png" class="img-fluid"></p>
<p>Oppure lo si può lanciare direttamente sul <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Notebook</a>:</p>
<p><img src="images/png/notebook_test.png" class="img-fluid"></p>
</section>
</section>
<section id="fare-inferenze-con-mobilenet-v2" class="level2">
<h2 class="anchored" data-anchor-id="fare-inferenze-con-mobilenet-v2">Fare inferenze con Mobilenet V2</h2>
<p>Nell’ultima sezione, abbiamo impostato l’ambiente, incluso il download di un modello pre-addestrato popolare, Mobilenet V2, addestrato sulle immagini 224x224 di ImageNet (1,2 milioni) per 1.001 classi (1.000 categorie di oggetti più 1 sfondo). Il modello è stato convertito in un formato TensorFlow Lite compatto da 3,5 MB, rendendolo adatto allo spazio di archiviazione e alla memoria limitati di un Raspberry Pi.</p>
<p><img src="images/png/mobilinet_zero.png" class="img-fluid"></p>
<p>Apriamo un nuovo <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">notebook</a> per seguire tutti i passaggi per classificare un’immagine:</p>
<p>Importare le librerie necessarie:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Caricare il modello TFLite e allocare i tensori:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ottenere i tensori di input e output.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Input details</strong> ci daranno informazioni su come il modello dovrebbe essere alimentato con un’immagine. Il profilo di (1, 224, 224, 3) ci informa che un’immagine con dimensioni (224x224x3) dovrebbe essere inserita una alla volta (Batch Dimension: 1).</p>
<p><img src="images/png/input_details.png" class="img-fluid"></p>
<p>Gli <strong>output details</strong> mostrano che l’inferenza risulterà in un array di 1.001 valori interi. Tali valori derivano dalla classificazione dell’immagine, dove ogni valore è la probabilità che quella specifica etichetta sia correlata all’immagine.</p>
<p><img src="images/png/output_details.png" class="img-fluid"></p>
<p>Esaminiamo anche il dtype dei dettagli di input del modello</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>Questo mostra che l’immagine di input dovrebbe essere composta da pixel grezzi (0 - 255).</p>
<p>Prendiamo un’immagine di prova. La si può trasferire dal computer o scaricarne una per testarla. Per prima cosa creiamo una cartella nella nostra directory di lavoro:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> images</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> images</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Carichiamo e visualizziamo l’immagine:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load he image</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/Cat03.jpg"</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Image"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/cat_original.png" class="img-fluid"></p>
<p>Possiamo vedere la dimensione dell’immagine eseguendo il comando:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Questo ci mostra che l’immagine è RGB con una larghezza di 1600 e un’altezza di 1600 pixel. Quindi, per usare il nostro modello, dovremmo rimodellarlo in (224, 224, 3) e aggiungere una dimensione batch di 1, come definito nei dettagli di input: (1, 224, 224, 3). Il risultato dell’inferenza, come mostrato nei dettagli di output, sarà un array con una dimensione di 1001, come mostrato di seguito:</p>
<p><img src="images/png/process_img.png" class="img-fluid"></p>
<p>Quindi, rimodelliamo l’immagine, aggiungiamo la dimensione batch e vediamo il risultato:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>input_data.shape</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>La forma di input_data è come previsto: (1, 224, 224, 3)</p>
<p>Confermiamo il dtype dei dati di input:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>input_data.dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>Il dtype dei dati di input è ‘uint8’, che è compatibile con il dtype previsto per il modello.</p>
<p>Utilizzando input_data, eseguiamo l’interprete e otteniamo le previsioni (output):</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>La previsione è un array con 1001 elementi. Otteniamo i primi 5 indici in cui i loro elementi hanno valori elevati:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>top_k_results <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>top_k_indices</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>top_k_indices è un array con 5 elementi: <code>array([283, 286, 282])</code></p>
<p>Quindi, 283, 286, 282, 288 e 479 sono le classi più probabili dell’immagine. Avendo l’indice, dobbiamo trovare a quale classe è assegnato (ad esempio auto, gatto o cane). Il file di testo scaricato con il modello ha un’etichetta associata a ciascun indice da 0 a 1.000. Usiamo una funzione per caricare il file .txt come un elenco:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_labels(filename):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(filename, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [line.strip() <span class="cf">for</span> line <span class="kw">in</span> f.readlines()]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>E otteniamo l’elenco, stampando le etichette associate agli indici:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>labels_path <span class="op">=</span> <span class="st">"./models/labels.txt"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> load_labels(labels_path)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">286</span>])</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">283</span>])</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">282</span>])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">288</span>])</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">479</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Di conseguenza abbiamo:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Almeno i quattro indici principali sono correlati ai felini. Il contenuto di <strong>prediction</strong> è la probabilità associata a ciascuna delle etichette. Come abbiamo visto nei dettagli dell’output, quei valori sono quantizzati e dovrebbero essere dequantizzati e applicare la softmax.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Stampiamo le prime 5 probabilità:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">286</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">283</span>])</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">282</span>])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">288</span>])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">479</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">0.27741462</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="ex">0.3732285</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="ex">0.16919471</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.10319158</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="ex">0.023410844</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Per chiarezza, creiamo una funzione per mettere in relazione le etichette con le probabilità:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>        (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat           : 37%</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat        : 27%</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span>               : 16%</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span>                : 10%</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span>              : 2%</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="definire-una-funzione-generale-di-classificazione-delle-immagini" class="level3">
<h3 class="anchored" data-anchor-id="definire-una-funzione-generale-di-classificazione-delle-immagini">Definire una funzione generale di Classificazione delle Immagini</h3>
Creiamo una funzione generale per dare un’immagine come input e otteniamo le prime 5 classi possibili:
<div class="scroll-code-block">
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get quantization parameters</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dequantize the output and apply softmax</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>    dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>            (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>E caricando alcune immagini per i test, abbiamo:</p>
<p><img src="images/jpeg/img_class_func.jpg" class="img-fluid"></p>
</section>
<section id="test-con-un-modello-addestrato-da-zero" class="level3">
<h3 class="anchored" data-anchor-id="test-con-un-modello-addestrato-da-zero">Test con un modello addestrato da zero</h3>
<p>Addestriamo un modello TFLite da zero. Per questo, si può seguire il Notebook:</p>
<p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN to classify Cifar-10 dataset</a></p>
<p>Nel notebook, abbiamo addestrato un modello utilizzando il dataset CIFAR10, che contiene 60.000 immagini da 10 classi di CIFAR (<em>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck</em>). CIFAR ha immagini a colori 32x32 (3 canali colore) in cui gli oggetti non sono centrati e possono avere l’oggetto con uno sfondo, come gli aerei che potrebbero avere un cielo nuvoloso dietro di loro! In breve, immagini piccole ma reali.</p>
<p>Il modello addestrato dalla CNN (<em>cifar10_model.keras</em>) aveva una dimensione di 2,0 MB. Utilizzando <em>TFLite Converter</em>, il modello <em>cifar10.tflite</em> è diventato di 674 MB (circa 1/3 della dimensione originale).</p>
<p><img src="images/png/cifar10_model.png" class="img-fluid"></p>
<p>Sul notebook <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Image Classification on a Raspi with TFLite</a> (che può essere eseguito sul Raspi), possiamo seguire gli stessi passaggi che abbiamo fatto con <code>mobilenet_v2_1.0_224_quant.tflite</code>. Di seguito sono riportati esempi di immagini che utilizzano la <em>General Function for Image Classification</em> su un Raspi-Zero, come mostrato nell’ultima sezione.</p>
<p><img src="images/png/infer-cifar10.png" class="img-fluid"></p>
</section>
<section id="installing-picamera2" class="level3">
<h3 class="anchored" data-anchor-id="installing-picamera2">Installing Picamera2</h3>
<p><a href="https://github.com/raspberrypi/picamera2">Picamera2</a>, una libreria Python per interagire con la fotocamera del Raspberry Pi, è basata sullo stack della fotocamera <em>libcamera</em> e la Raspberry Pi Foundation la mantiene. La libreria Picamera2 è supportata su tutti i modelli Raspberry Pi, dal Pi Zero al RPi 5. È già installata in tutto il sistema Raspi, ma dovremmo renderla accessibile all’interno dell’ambiente virtuale.</p>
<ol type="1">
<li><p>Per prima cosa, attivare l’ambiente virtuale se non è già attivato:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Ora, creiamo un file .pth nelll’ambiente virtuale per aggiungere il percorso del sistema del pacchetto sul sito:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"/usr/lib/python3/dist-packages"</span> <span class="op">&gt;</span> <span class="va">$VIRTUAL_ENV</span>/lib/python3.11/</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="ex">site-packages/system_site_packages.pth</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Nota: Se la versione di Python è diversa, sostituire <code>python3.11</code> con la versione appropriata.</p>
</blockquote></li>
<li><p>Dopo aver creato questo file, provare a importare picamera2 in Python:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">picamera2</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> print<span class="kw">(</span><span class="ex">picamera2.__file__</span><span class="kw">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p>Il codice sopra mostrerà la posizione del file del modulo <code>picamera2</code> stesso, dimostrando che la libreria è accessibile dall’ambiente.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>home<span class="op">/</span>mjrovai<span class="op">/</span>tflite<span class="op">/</span>lib<span class="op">/</span>python3<span class="fl">.11</span><span class="op">/</span>site<span class="op">-</span>packages<span class="op">/</span>picamera2<span class="op">/</span><span class="fu">__init__</span>.py</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>È anche possibile elencare le telecamere disponibili nel sistema:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(Picamera2.global_camera_info())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Nel nostro caso, con una USB installata, si è ottenuto:</p>
<p><img src="images/png/cam_installed.png" class="img-fluid"></p>
<p>Ora che abbiamo confermato che picamera2 funziona nell’ambiente con un <code>indice 0</code>, proviamo un semplice script Python per catturare un’immagine dalla fotocamera USB:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the camera</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2() <span class="co"># default is index 0</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the camera</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_still_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">640</span>, <span class="dv">480</span>)})</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the camera</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait for the camera to warm up</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Capture an image</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>picam2.capture_file(<span class="st">"usb_camera_image.jpg"</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image captured and saved as 'usb_camera_image.jpg'"</span>)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the camera</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>picam2.stop()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Utilizzare l’editor di testo Nano, Jupyter Notebook o qualsiasi altro editor. Salvarlo come script Python (ad esempio, <code>capture_image.py</code>) ed eseguilo. Questo dovrebbe catturare un’immagine dalla fotocamera e salvarla come “usb_camera_image.jpg” nella stessa directory dello script.</p>
<p><img src="images/png/capture_test.png" class="img-fluid"></p>
<p>Se Jupyter è aperto, si può vedere l’immagine catturata sul computer. Altrimenti, si trasferisce il file dal Raspi al computer.</p>
<p><img src="images/png/img_test_result.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Se si sta lavorando con un Raspi-5 con un intero desktop, si può aprire il file direttamente sul dispositivo.</p>
</blockquote>
</section>
</section>
<section id="progetto-di-classificazione-delle-immagini" class="level2">
<h2 class="anchored" data-anchor-id="progetto-di-classificazione-delle-immagini">Progetto di Classificazione delle Immagini</h2>
<p>Ora, svilupperemo un progetto completo di Classificazione delle Immagini utilizzando Edge Impulse Studio. Come abbiamo fatto con Movilinet V2, il modello TFLite addestrato e convertito verrà utilizzato per l’inferenza.</p>
<section id="lobiettivo" class="level3">
<h3 class="anchored" data-anchor-id="lobiettivo">L’Obiettivo</h3>
<p>Il primo passo in qualsiasi progetto ML è definire il suo obiettivo. In questo caso, è rilevare e classificare due oggetti specifici presenti in un’immagine. Per questo progetto, utilizzeremo due piccoli giocattoli: un robot e un piccolo pappagallo brasiliano (chiamato Periquito). Raccoglieremo anche immagini di un <em>background</em> in cui questi due oggetti sono assenti.</p>
<p><img src="images/jpeg/project_goal.jpg" class="img-fluid"></p>
</section>
<section id="raccolta-dati" class="level3">
<h3 class="anchored" data-anchor-id="raccolta-dati">Raccolta Dati</h3>
<p>Una volta definito l’obiettivo del nostro progetto di apprendimento automatico, il passaggio successivo, e più cruciale, è la raccolta del dataset. Possiamo utilizzare un telefono per l’acquisizione delle immagini, ma qui utilizzeremo il Raspi. Impostiamo un semplice server Web sul nostro Raspberry Pi per visualizzare le immagini <code>QVGA (320 x 240)</code> acquisite in un browser.</p>
<ol type="1">
<li><p>Per prima cosa, installiamo Flask, un framework Web leggero per Python:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install flask</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Creiamo un nuovo script Python che combina l’acquisizione delle immagini con un server Web. Lo chiameremo <code>get_img_data.py</code>:</p></li>
</ol>
<div class="scroll-code-block">
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, redirect, url_for</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> signal</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>base_dir <span class="op">=</span> <span class="st">"dataset"</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>capture_counts <span class="op">=</span> {}</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>current_label <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>shutdown_event <span class="op">=</span> threading.Event()</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth preview</span></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth streaming</span></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shutdown_server():</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>    shutdown_event.<span class="bu">set</span>()</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> picam2:</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>        picam2.stop()</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Give some time for other threads to finish</span></span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Send SIGINT to the main process</span></span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>    os.kill(os.getpid(), signal.SIGINT)</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>, methods<span class="op">=</span>[<span class="st">'GET'</span>, <span class="st">'POST'</span>])</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> current_label</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> request.method <span class="op">==</span> <span class="st">'POST'</span>:</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a>        current_label <span class="op">=</span> request.form[<span class="st">'label'</span>]</span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> current_label <span class="kw">not</span> <span class="kw">in</span> capture_counts:</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>            capture_counts[current_label] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>        os.makedirs(os.path.join(base_dir, current_label), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Label Entry&lt;/title&gt;</span></span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Enter Label for Dataset&lt;/h1&gt;</span></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form method="post"&gt;</span></span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="text" name="label" required&gt;</span></span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Start Capture"&gt;</span></span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture'</span>)</span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_page():</span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture&lt;/title&gt;</span></span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a><span class="st">                var shutdownInitiated = false;</span></span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a><span class="st">                function checkShutdown() {</span></span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a><span class="st">                    if (!shutdownInitiated) {</span></span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a><span class="st">                        fetch('/check_shutdown')</span></span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(response =&gt; response.json())</span></span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a><span class="st">                            .then(data =&gt; {</span></span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a><span class="st">                                if (data.shutdown) {</span></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a><span class="st">                                    shutdownInitiated = true;</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('video-feed').src = '';</span></span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a><span class="st">                                    document.getElementById('shutdown-message')</span></span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a><span class="st">                                    .style.display = 'block';</span></span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a><span class="st">                                }</span></span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a><span class="st">                            });</span></span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a><span class="st">                    }</span></span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a><span class="st">                setInterval(checkShutdown, 1000);  // Check every second</span></span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture&lt;/h1&gt;</span></span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Current Label: </span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-111"><a href="#cb43-111" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Images captured for this label: </span><span class="sc">{{</span><span class="st"> capture_count </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img id="video-feed" src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" </span></span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a><span class="st">            height="480" /&gt;</span></span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="shutdown-message" style="display: none; color: red;"&gt;</span></span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a><span class="st">                Capture process has been stopped. You can close this window.</span></span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/div&gt;</span></span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/capture_image" method="post"&gt;</span></span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Capture Image"&gt;</span></span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/stop" method="post"&gt;</span></span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Stop Capture" </span></span>
<span id="cb43-122"><a href="#cb43-122" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ff6666;"&gt;</span></span>
<span id="cb43-123"><a href="#cb43-123" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;form action="/" method="get"&gt;</span></span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;input type="submit" value="Change Label" </span></span>
<span id="cb43-126"><a href="#cb43-126" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ffff66;"&gt;</span></span>
<span id="cb43-127"><a href="#cb43-127" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/form&gt;</span></span>
<span id="cb43-128"><a href="#cb43-128" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-129"><a href="#cb43-129" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-130"><a href="#cb43-130" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, label<span class="op">=</span>current_label, capture_count<span class="op">=</span>capture_counts.get(current_label, <span class="dv">0</span>))</span>
<span id="cb43-131"><a href="#cb43-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-132"><a href="#cb43-132" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb43-133"><a href="#cb43-133" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb43-134"><a href="#cb43-134" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb43-135"><a href="#cb43-135" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb43-136"><a href="#cb43-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-137"><a href="#cb43-137" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture_image'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-138"><a href="#cb43-138" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_image():</span>
<span id="cb43-139"><a href="#cb43-139" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> capture_counts</span>
<span id="cb43-140"><a href="#cb43-140" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> current_label <span class="kw">and</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-141"><a href="#cb43-141" aria-hidden="true" tabindex="-1"></a>        capture_counts[current_label] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb43-142"><a href="#cb43-142" aria-hidden="true" tabindex="-1"></a>        timestamp <span class="op">=</span> time.strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb43-143"><a href="#cb43-143" aria-hidden="true" tabindex="-1"></a>        filename <span class="op">=</span> <span class="ss">f"image_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">.jpg"</span></span>
<span id="cb43-144"><a href="#cb43-144" aria-hidden="true" tabindex="-1"></a>        full_path <span class="op">=</span> os.path.join(base_dir, current_label, filename)</span>
<span id="cb43-145"><a href="#cb43-145" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-146"><a href="#cb43-146" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(full_path)</span>
<span id="cb43-147"><a href="#cb43-147" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-148"><a href="#cb43-148" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-149"><a href="#cb43-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-150"><a href="#cb43-150" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-151"><a href="#cb43-151" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop():</span>
<span id="cb43-152"><a href="#cb43-152" aria-hidden="true" tabindex="-1"></a>    summary <span class="op">=</span> render_template_string(<span class="st">'''</span></span>
<span id="cb43-153"><a href="#cb43-153" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-154"><a href="#cb43-154" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb43-155"><a href="#cb43-155" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb43-156"><a href="#cb43-156" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Dataset Capture - Stopped&lt;/title&gt;</span></span>
<span id="cb43-157"><a href="#cb43-157" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb43-158"><a href="#cb43-158" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb43-159"><a href="#cb43-159" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Dataset Capture Stopped&lt;/h1&gt;</span></span>
<span id="cb43-160"><a href="#cb43-160" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;The capture process has been stopped. You can close this window.&lt;/p&gt;</span></span>
<span id="cb43-161"><a href="#cb43-161" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;p&gt;Summary of captures:&lt;/p&gt;</span></span>
<span id="cb43-162"><a href="#cb43-162" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;ul&gt;</span></span>
<span id="cb43-163"><a href="#cb43-163" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% f</span><span class="st">or label, count in capture_counts.items() %}</span></span>
<span id="cb43-164"><a href="#cb43-164" aria-hidden="true" tabindex="-1"></a><span class="st">                &lt;li&gt;</span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">: </span><span class="sc">{{</span><span class="st"> count </span><span class="sc">}}</span><span class="st"> images&lt;/li&gt;</span></span>
<span id="cb43-165"><a href="#cb43-165" aria-hidden="true" tabindex="-1"></a><span class="st">            {</span><span class="sc">% e</span><span class="st">ndfor %}</span></span>
<span id="cb43-166"><a href="#cb43-166" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/ul&gt;</span></span>
<span id="cb43-167"><a href="#cb43-167" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb43-168"><a href="#cb43-168" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb43-169"><a href="#cb43-169" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>, capture_counts<span class="op">=</span>capture_counts)</span>
<span id="cb43-170"><a href="#cb43-170" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-171"><a href="#cb43-171" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start a new thread to shutdown the server</span></span>
<span id="cb43-172"><a href="#cb43-172" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>shutdown_server).start()</span>
<span id="cb43-173"><a href="#cb43-173" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-174"><a href="#cb43-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb43-175"><a href="#cb43-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-176"><a href="#cb43-176" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/check_shutdown'</span>)</span>
<span id="cb43-177"><a href="#cb43-177" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_shutdown():</span>
<span id="cb43-178"><a href="#cb43-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'shutdown'</span>: shutdown_event.is_set()}</span>
<span id="cb43-179"><a href="#cb43-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-180"><a href="#cb43-180" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb43-181"><a href="#cb43-181" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb43-182"><a href="#cb43-182" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb43-183"><a href="#cb43-183" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li><p>Eseguire questo script:</p>
<p>```bash python3 get_img_data.py</p></li>
</ol>
<pre><code>4. Accedere all'interfaccia web:

    - Sul Raspberry Pi stesso (se si ha una GUI): Aprire un browser web e andare su `http://localhost:5000`
    - Da un altro dispositivo sulla stessa rete: Aprire un browser web e andare su `http://&lt;raspberry_pi_ip&gt;:5000` (Sostituire `&lt;raspberry_pi_ip&gt;` con l'indirizzo IP del Raspberry Pi). Per esempio: `http://192.168.4.210:5000/`

Questo script Python crea un'interfaccia basata sul web per catturare e organizzare set di dati di immagini usando un Raspberry Pi e la sua fotocamera. È utile per progetti di apprendimento automatico che richiedono dati di immagini etichettati.

#### Caratteristiche Principali:

1. **Interfaccia Web**: Accessibile da qualsiasi dispositivo sulla stessa rete del Raspberry Pi.
2. **Anteprima Telecamera in Tempo Reale**: Mostra un feed in tempo reale dalla telecamera.
3. **Sistema di Etichettatura**: Consente agli utenti di immettere etichette per diverse categorie di immagini.
4. **Archiviazione Organizzata**: Salva automaticamente le immagini in sottodirectory specifiche per etichetta.
5. **Contatori per Etichetta**: Tiene traccia di quante immagini vengono acquisite per ogni etichetta.
6. **Statistiche di Riepilogo**: Fornisce un riepilogo delle immagini acquisite quando si interrompe il processo di acquisizione.

#### Componenti Principali:

1. **Applicazione Web Flask**: Gestisce il routing e serve l'interfaccia Web.
2. **Integrazione di Picamera2**: Controlla la telecamera Raspberry Pi.
3. **Threaded Frame Capture**: Assicura un'anteprima live fluida.
4. **File Management**: Organizza le immagini catturate in directory etichettate.

#### Funzioni Chiave:

- `initialize_camera()`: Imposta l'istanza Picamera2.
- `get_frame()`: Cattura continuamente i frame per l'anteprima live.
- `generate_frames()`: Genera i frame per il feed video live.
- `shutdown_server()`: Imposta l'evento di arresto, arresta la telecamera e arresta il server Flask
- `index()`: Gestisce la pagina di input dell'etichetta.
- `capture_page()`: Visualizza l'interfaccia di acquisizione principale.
- `video_feed()`: Mostra un'anteprima live per posizionare la telecamera
- `capture_image()`: Salva un'immagine con l'etichetta corrente.
- `stop()`: Arresta il processo di acquisizione e visualizza un riepilogo.

#### Flusso di Utilizzo:

1. Avviare lo script sul Raspberry Pi.
2. Accedere all'interfaccia web da un browser.
3. Inserire un'etichetta per le immagini da catturare e premere `Start Capture`.

![](images/png/enter_label.png)

4. Utilizzare l'anteprima live per posizionare la telecamera.
5. Cliccare `Capture Image` per salvare le immagini sotto l'etichetta corrente.

![](images/png/capture.png)

6. Cambiare le etichette come necessario per le diverse categorie, selezionando `Change Label`.
7. Cliccare `Stop Capture` al termine per vedere un riepilogo.

![](images/png/stop.png)

#### Note Tecniche:

- Lo script usa il threading per gestire la cattura di frame e il web serving simultanei.
- Le immagini vengono salvate con timestamp nei nomi dei file per renderle uniche.
- L'interfaccia web è reattiva e accessibile da dispositivi mobili.

#### Possibilità di Personalizzazione:

- Regolare la risoluzione dell'immagine nella funzione `initialize_camera()`. Qui abbiamo utilizzato QVGA (320X240).
- Modificare i modelli HTML per un aspetto diverso.
- Aggiungere ulteriori passaggi di elaborazione o analisi delle immagini nella funzione `capture_image()`.

#### Numero di campioni sul Dataset:

Si ottengono circa 60 immagini da ciascuna categoria (`periquito`, `robot` e `background`). Provare ad acquisire con diverse angolazioni, sfondi e condizioni di luce. Sul Raspi, finiremo con una cartella denominata `dataset`, che contiene 3 sottocartelle *periquito*, *robot* e *background*. una per ogni classe di immagini.

Si può usare `Filezilla` per trasferire il dataset creato sul computer principale. 

## Addestramento del modello con Edge Impulse

Useremo Edge Impulse Studio per addestrare il modello.  Si va nella [Pagina di Edge Impulse](https://edgeimpulse.com/), si inseriscono le credenziali e si crea un nuovo progetto:

![](images/png/new-proj-ei.png)

&gt; Qui si può clonare un progetto simile: [Raspi - Img Class](https://studio.edgeimpulse.com/public/510251/live).

### Dataset

Esamineremo quattro passaggi principali usando EI Studio (o Studio). Questi passaggi sono fondamentali per preparare il nostro modello per l'uso sul Raspi: Dataset, Impulse, Test e Deploy (sul dispositivo Edge, in questo caso, il Raspi).

&gt; Per quanto riguarda il Dataset, è essenziale sottolineare che il nostro Dataset originale, acquisito con il Raspi, sarà suddiviso in *Training*, *Validation* e *Test*. Il Test Set sarà separato dall'inizio e riservato per l'uso solo nella fase di Test dopo l'addestramento. Il Validation Set sarà utilizzato durante l'addestramento.

Su Studio, seguire i passaggi per caricare i dati acquisiti:

1. Si va nella scheda `Data acquisition` e nella sezione `UPLOAD DATA`, si caricano i file dal computer nelle categorie scelte.
2. Lasciare a Studio la suddivisione del dataset originale in *train and test* e scegliere l'etichetta a riguardo
3. Ripetere la procedura per tutte e tre le classi. Alla fine, si vedranno i "raw data" in Studio:

![](images/png/data-Aquisition.png)

Studio consente di esplorare i dati, mostrando una vista completa di tutti i quelli nel progetto. Si possono cancellare, ispezionare o modificare le etichette cliccando sui singoli elementi di dati. Nel nostro caso, un progetto semplice, i dati sembrano OK.

![](images/png/data-esplorer.png)

## Il Progetto Impulse

In questa fase, dovremmo definire come:

- Pre-elaborare i nostri dati, il che consiste nel ridimensionare le singole immagini e determinare la `color depth` [profondità di colore] da utilizzare (sia RGB che in scala di grigi) e

- Specificare un Modello. In questo caso, sarà `Transfer Learning (Images)` a mettere a punto un modello di classificazione delle immagini MobileNet V2 pre-addestrato sui nostri dati. Questo metodo funziona bene anche con set di dati di immagini relativamente piccoli (circa 180 immagini nel nostro caso).

Transfer Learning con MobileNet offre un approccio semplificato all'addestramento del modello, che è particolarmente utile per ambienti con risorse limitate e progetti con dati etichettati limitati. MobileNet, noto per la sua architettura leggera, è un modello pre-addestrato che ha già appreso funzionalità preziose da un ampio set di dati (ImageNet).

![](images/jpeg/model_1.jpg)

Sfruttando queste funzionalità apprese, possiamo addestrare un nuovo modello per il compito specifico con meno dati e risorse computazionali e raggiungere un'accuratezza competitiva.

![](images/jpeg/model_2.jpg)

Questo approccio riduce significativamente i tempi di addestramento e i costi computazionali, rendendolo ideale per la prototipazione rapida e l'implementazione su dispositivi embedded in cui l'efficienza è fondamentale.

Si va alla scheda Impulse Design e si crea l'*impulse*, definendo una dimensione dell'immagine di 160x160 e schiacciandola (forma quadrata, senza ritaglio). Si seleziona Image e i blocchi Transfer Learning. Si salva l'Impulse.

![](images/png/impulse.png)

### Pre-elaborazione delle immagini

Tutte le immagini QVGA/RGB565 in ingresso verranno convertite in 76.800 feature (160x160x3).

![](images/png/preproc.png)

Premere `Save parameters` e selezionare `Generate features` nella scheda successiva.

### Progettazione del modello

MobileNet è una famiglia di reti neurali convoluzionali efficienti progettate per applicazioni di visione mobile e embedded. Le caratteristiche principali di MobileNet sono:

1. Leggero: Ottimizzato per dispositivi mobili e sistemi embedded con risorse di calcolo limitate.
2. Velocità: Tempi di inferenza rapidi, adatti per applicazioni in tempo reale.
3. Precisione: Mantiene una buona accuratezza nonostante le dimensioni compatte.

[MobileNetV2](https://arxiv.org/abs/1801.04381), introdotto nel 2018, migliora l'architettura MobileNet originale. Le caratteristiche principali includono:

1. Residui Invertiti: Le strutture residue invertite vengono utilizzate quando vengono create connessioni di scelta rapida tra layer di colli di bottiglia sottili.
2. Colli di Bottiglia Lineari: Rimuove le non linearità nei layer stretti per impedire la distruzione delle informazioni.
3. Convoluzioni Separabili in Profondità: Continua a utilizzare questa efficiente operazione da MobileNetV1.

Nel nostro progetto, faremo un `Transfer Learning` con `MobileNetV2 160x160 1.0`, il che significa che le immagini utilizzate per l'addestramento (e l'inferenza futura) dovrebbero avere una *input Size* [dimensione di input] di 160x160 pixel e un *Width Multiplier* [moltiplicatore di larghezza] di 1.0 (larghezza completa, non ridotta). Questa configurazione bilancia tra dimensione del modello, velocità e accuratezza.

### Training del Modello

Un'altra preziosa tecnica di apprendimento profondo è il **Data Augmentation**. Il "data augmentation" migliora l'accuratezza dei modelli di apprendimento automatico creando dati artificiali aggiuntivi. Un sistema di data augmentation apporta piccole modifiche casuali ai dati di training durante l'addestramento (ad esempio capovolgendo, ritagliando o ruotando le immagini).

Guardando internamente, qui si può vedere come Edge Impulse implementa una policy di data Augmentation sui dati:

``` python
# Implements the data augmentation policy
def augment_image(image, label):
    # Flips the image randomly
    image = tf.image.random_flip_left_right(image)

    # Increase the image size, then randomly crop it down to
    # the original dimensions
    resize_factor = random.uniform(1, 1.2)
    new_height = math.floor(resize_factor * INPUT_SHAPE[0])
    new_width = math.floor(resize_factor * INPUT_SHAPE[1])
    image = tf.image.resize_with_crop_or_pad(image, new_height, new_width)
    image = tf.image.random_crop(image, size=INPUT_SHAPE)

    # Vary the brightness of the image
    image = tf.image.random_brightness(image, max_delta=0.2)

    return image, label</code></pre>
<p>L’esposizione a queste variazioni durante l’addestramento può aiutare a impedire al modello di prendere scorciatoie “memorizzando” indizi superficiali nei dati di addestramento, il che significa che potrebbe riflettere meglio i pattern profondi in esame nel set di dati.</p>
<p>L’ultimo layer denso del nostro modello avrà 0 neuroni con un dropout del 10% per prevenire il sovradattamento. Ecco il risultato del Training:</p>
<p><img src="images/png/result-train.png" class="img-fluid"></p>
<p>Il risultato è eccellente, con una latenza ragionevole di 35 ms (per un Raspi-4), che dovrebbe tradursi in circa 30 fps (fotogrammi al secondo) durante l’inferenza. Un Raspi-Zero dovrebbe essere più lento e il Raspi-5 più veloce.</p>
</section>
<section id="compromesso-accuratezza-contro-velocità" class="level3">
<h3 class="anchored" data-anchor-id="compromesso-accuratezza-contro-velocità">Compromesso: Accuratezza contro Velocità</h3>
<p>Se è necessaria un’inferenza più rapida, dovremmo addestrare il modello usando alfa più piccoli (0.35, 0.5 e 0.75) o persino ridurre le dimensioni dell’immagine in ingresso, a discapito dell’accuratezza. Tuttavia, ridurre le dimensioni dell’immagine in ingresso e diminuire l’alfa (moltiplicatore di larghezza) può accelerare l’inferenza per MobileNet V2, ma hanno compromessi diversi. Confrontiamoli:</p>
<ol type="1">
<li>Riduzione delle Dimensioni dell’Immagine in Ingresso:</li>
</ol>
<p>Pro:</p>
<ul>
<li>Riduce significativamente il costo computazionale su tutti i layer.</li>
<li>Riduce l’utilizzo della memoria.</li>
<li>Spesso fornisce un aumento sostanziale della velocità.</li>
</ul>
<p>Contro:</p>
<ul>
<li>Potrebbe ridurre la capacità del modello di rilevare piccole caratteristiche o dettagli fini.</li>
<li>Può avere un impatto significativo sulla precisione, specialmente per le attività che richiedono un riconoscimento a grana fine.</li>
</ul>
<ol start="2" type="1">
<li>Riduzione di Alpha (Moltiplicatore di Larghezza):</li>
</ol>
<p>Pro:</p>
<ul>
<li>Riduce il numero di parametri e calcoli nel modello.</li>
<li>Mantiene la risoluzione di input originale, preservando potenzialmente più dettagli.</li>
<li>Può fornire un buon equilibrio tra velocità e precisione.</li>
</ul>
<p>Contro:</p>
<ul>
<li>Potrebbe non accelerare l’inferenza in modo così drastico come la riduzione delle dimensioni di input.</li>
<li>Può ridurre la capacità del modello di apprendere caratteristiche complesse.</li>
</ul>
<p>Confronto:</p>
<ol type="1">
<li>Impatto sulla Velocità:
<ul>
<li>La riduzione delle dimensioni di input spesso fornisce un aumento di velocità più sostanziale perché riduce i calcoli in modo quadratico (dimezzando sia la larghezza che l’altezza si riducono i calcoli di circa il 75%).</li>
<li>La riduzione di Alpha fornisce una riduzione più lineare nei calcoli.</li>
</ul></li>
<li>Impatto sulla Precisione:
<ul>
<li>La riduzione delle dimensioni di input può avere un impatto significativo sulla precisione, specialmente quando si rilevano piccoli oggetti o dettagli fini.</li>
<li>La riduzione di alpha tende ad avere un impatto più graduale sulla precisione.</li>
</ul></li>
<li>Architettura del Modello:
<ul>
<li>La modifica delle dimensioni di input non altera l’architettura del modello.</li>
<li>La modifica di alpha modifica la struttura del modello riducendo il numero di canali in ogni layer.</li>
</ul></li>
</ol>
<p>Raccomandazione:</p>
<ol type="1">
<li>Se l’applicazione non richiede il rilevamento di piccoli dettagli e può tollerare una certa perdita di accuratezza, ridurre le dimensioni di input è spesso il modo più efficace per accelerare l’inferenza.</li>
<li>Ridurre l’alfa potrebbe essere preferibile se mantenere la capacità di rilevare dettagli fini è fondamentale o se c’è bisogno di un compromesso più equilibrato tra velocità e accuratezza.</li>
<li>Per ottenere risultati migliori, si devono sperimentare entrambi:
<ul>
<li>Provare MobileNet V2 con dimensioni di input come 160x160 o 92x92</li>
<li>Sperimentare con valori alfa come 1.0, 0.75, 0.5 o 0.35.</li>
</ul></li>
<li>Eseguire sempre il benchmark delle diverse configurazioni sull’hardware specifico e con il particolare set di dati per trovare l’equilibrio ottimale per il caso d’uso.</li>
</ol>
<blockquote class="blockquote">
<p>Ricordarsi che la scelta migliore dipende dai requisiti specifici di accuratezza, velocità e dalla natura delle immagini con cui si sta lavorando. Spesso vale la pena sperimentare combinazioni per trovare la configurazione ottimale per il particolare caso d’uso.</p>
</blockquote>
</section>
<section id="test-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="test-del-modello">Test del Modello</h3>
<p>Ora, si deve prendere il set di dati all’inizio del progetto ed eseguire il modello addestrato usandolo come input. Di nuovo, il risultato è eccellente (92,22%).</p>
</section>
<section id="distribuzione-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="distribuzione-del-modello">Distribuzione del modello</h3>
<p>Come abbiamo fatto nella sezione precedente, possiamo distribuire il modello addestrato come .tflite e usare Raspi per eseguirlo usando Python.</p>
<p>Nella scheda <code>Dashboard</code>, si va su Transfer learning model (int8 quantized) e si clicca sull’icona di download:</p>
<p><img src="images/png/model.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Scarichiamo anche la versione float32 per il confronto</p>
</blockquote>
<p>Trasferire il modello dal computer al Raspi (./models), ad esempio, usando FileZilla. Catturare, inoltre, alcune immagini per l’inferenza (./images).</p>
<p>Importare le librerie necessarie:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Definire i path e le etichette:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/robot.jpg"</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Notare che i modelli addestrati su Edge Impulse Studio produrranno valori con indice 0, 1, 2, ecc., dove le etichette effettive seguiranno un ordine alfabetico.</p>
</blockquote>
<p>Caricare il modello, allocare i tensori e ottenere i dettagli dei tensori di input e output:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the TFLite model</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output tensors</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Una differenza importante da notare è che il <code>dtype</code> dei dettagli di input del modello è ora <code>int8</code>, il che significa che i valori di input vanno da -128 a +127, mentre ogni pixel della nostra immagine va da 0 a 255. Ciò significa che dovremmo pre-elaborare l’immagine per farla corrispondere. Possiamo controllare qui:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>numpy.int8</code></pre>
<p>Quindi, apriamo l’immagine e mostriamola:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer_robot.png" class="img-fluid"></p>
<p>Ed eseguiamo la pre-elaborazione:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>                  input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Controllando i dati di input, possiamo verificare che il tensore di input è compatibile con quanto previsto dal modello:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>input_data.shape, input_data.dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>((1, 160, 160, 3), dtype('int8'))</code></pre>
<p>Adesso è il momento di effettuare l’inferenza. Calcoliamo anche la latenza del modello:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Il modello impiegherà circa 125 ms per eseguire l’inferenza nel Raspi-Zero, che dura 3 o 4 volte più a lungo di un Raspi-5.</p>
<p>Ora possiamo ottenere le etichette di output e le probabilità. È anche importante notare che il modello addestrato su Edge Impulse Studio ha un softmax nel suo output (diverso dal Movilenet V2 originale) e dovremmo usare l’output grezzo del modello come “probabilità”.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get indices of the top k results</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>top_k_results<span class="op">=</span><span class="dv">3</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get quantization parameters</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Dequantize the output</span></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> dequantized_output</span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb55-19"><a href="#cb55-19" aria-hidden="true" tabindex="-1"></a>        probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer-result.png" class="img-fluid"></p>
<p>Modifichiamo la funzione creata in precedenza in modo da poter gestire diversi tipi di modelli:</p>
<div class="scroll-code-block">
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>                         apply_softmax<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the image</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb56-20"><a href="#cb56-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-21"><a href="#cb56-21" aria-hidden="true" tabindex="-1"></a>    input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb56-22"><a href="#cb56-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-23"><a href="#cb56-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> input_dtype <span class="op">==</span> np.uint8:</span>
<span id="cb56-24"><a href="#cb56-24" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb56-25"><a href="#cb56-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> input_dtype <span class="op">==</span> np.int8:</span>
<span id="cb56-26"><a href="#cb56-26" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb56-27"><a href="#cb56-27" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb56-28"><a href="#cb56-28" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb56-29"><a href="#cb56-29" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb56-30"><a href="#cb56-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># float32</span></span>
<span id="cb56-31"><a href="#cb56-31" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img, dtype<span class="op">=</span>np.float32), axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb56-32"><a href="#cb56-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-33"><a href="#cb56-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb56-34"><a href="#cb56-34" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb56-35"><a href="#cb56-35" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb56-36"><a href="#cb56-36" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb56-37"><a href="#cb56-37" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb56-38"><a href="#cb56-38" aria-hidden="true" tabindex="-1"></a>    inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb56-39"><a href="#cb56-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-40"><a href="#cb56-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results</span></span>
<span id="cb56-41"><a href="#cb56-41" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb56-42"><a href="#cb56-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-43"><a href="#cb56-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb56-44"><a href="#cb56-44" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb56-45"><a href="#cb56-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-46"><a href="#cb56-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb56-47"><a href="#cb56-47" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb56-48"><a href="#cb56-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb56-49"><a href="#cb56-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb56-50"><a href="#cb56-50" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb56-51"><a href="#cb56-51" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb56-52"><a href="#cb56-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-53"><a href="#cb56-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> apply_softmax:</span>
<span id="cb56-54"><a href="#cb56-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax</span></span>
<span id="cb56-55"><a href="#cb56-55" aria-hidden="true" tabindex="-1"></a>        exp_preds <span class="op">=</span> np.exp(predictions <span class="op">-</span> np.<span class="bu">max</span>(predictions))</span>
<span id="cb56-56"><a href="#cb56-56" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> exp_preds <span class="op">/</span> np.<span class="bu">sum</span>(exp_preds)</span>
<span id="cb56-57"><a href="#cb56-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb56-58"><a href="#cb56-58" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> predictions</span>
<span id="cb56-59"><a href="#cb56-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb56-60"><a href="#cb56-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb56-61"><a href="#cb56-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb56-62"><a href="#cb56-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb56-63"><a href="#cb56-63" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb56-64"><a href="#cb56-64" aria-hidden="true" tabindex="-1"></a>            probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb56-65"><a href="#cb56-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">"</span><span class="ch">\n\t</span><span class="st">Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>E lo si testa con immagini diverse e con il modello quantizzato int8 (<strong>160x160 alpha =1.0</strong>).</p>
<p><img src="images/png/infer-int8-160.png" class="img-fluid"></p>
<p>Scarichiamo un modello più piccolo, come quello addestrato per il <a href="https://studio.edgeimpulse.com/public/353482/live">Nicla Vision Lab</a> (int8 quantized model, 96x96, alpha = 0.1), come test. Possiamo usare la stessa funzione:</p>
<p><img src="images/png/infer-int8-96.png" class="img-fluid"></p>
<p>Il modello ha perso un po’ di accuratezza, ma è ancora OK dato che non cerca molti dettagli. Per quanto riguarda la latenza, siamo circa <strong>dieci volte più veloci</strong> su Raspi-Zero.</p>
</section>
</section>
<section id="classificazione-delle-immagini-in-tempo-reale" class="level2">
<h2 class="anchored" data-anchor-id="classificazione-delle-immagini-in-tempo-reale">Classificazione delle Immagini in Tempo Reale</h2>
<p>Sviluppiamo un’app per catturare immagini con la fotocamera USB in tempo reale, mostrandone la classificazione.</p>
Utilizzando nano sul terminale, salvare il codice sottostante, come <code>img_class_live_infer.py</code>.
<div class="scroll-code-block">
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, jsonify</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> queue <span class="im">import</span> Queue</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>confidence_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> <span class="va">None</span></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>classification_queue <span class="op">=</span> Queue(maxsize<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Capture frames more frequently</span></span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)</span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_model():</span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> interpreter</span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> interpreter <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a>        interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a>        interpreter.allocate_tensors()</span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> interpreter</span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img, interpreter):</span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)<span class="op">\</span></span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a>                             .astype(input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>])</span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb57-66"><a href="#cb57-66" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb57-67"><a href="#cb57-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-68"><a href="#cb57-68" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb57-69"><a href="#cb57-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb57-70"><a href="#cb57-70" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb57-71"><a href="#cb57-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb57-72"><a href="#cb57-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb57-73"><a href="#cb57-73" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb57-74"><a href="#cb57-74" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb57-75"><a href="#cb57-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb57-76"><a href="#cb57-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-77"><a href="#cb57-77" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classification_worker():</span>
<span id="cb57-78"><a href="#cb57-78" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> load_model()</span>
<span id="cb57-79"><a href="#cb57-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb57-80"><a href="#cb57-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> is_classifying:</span>
<span id="cb57-81"><a href="#cb57-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> frame_lock:</span>
<span id="cb57-82"><a href="#cb57-82" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb57-83"><a href="#cb57-83" aria-hidden="true" tabindex="-1"></a>                    img <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(frame))</span>
<span id="cb57-84"><a href="#cb57-84" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> classify_image(img, interpreter)</span>
<span id="cb57-85"><a href="#cb57-85" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> np.<span class="bu">max</span>(predictions)</span>
<span id="cb57-86"><a href="#cb57-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> max_prob <span class="op">&gt;=</span> confidence_threshold:</span>
<span id="cb57-87"><a href="#cb57-87" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> labels[np.argmax(predictions)]</span>
<span id="cb57-88"><a href="#cb57-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb57-89"><a href="#cb57-89" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> <span class="st">'Uncertain'</span></span>
<span id="cb57-90"><a href="#cb57-90" aria-hidden="true" tabindex="-1"></a>            classification_queue.put({<span class="st">'label'</span>: label, </span>
<span id="cb57-91"><a href="#cb57-91" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">'probability'</span>: <span class="bu">float</span>(max_prob)})</span>
<span id="cb57-92"><a href="#cb57-92" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust based on your needs</span></span>
<span id="cb57-93"><a href="#cb57-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-94"><a href="#cb57-94" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>)</span>
<span id="cb57-95"><a href="#cb57-95" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb57-96"><a href="#cb57-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb57-97"><a href="#cb57-97" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb57-98"><a href="#cb57-98" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb57-99"><a href="#cb57-99" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb57-100"><a href="#cb57-100" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Image Classification&lt;/title&gt;</span></span>
<span id="cb57-101"><a href="#cb57-101" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script </span></span>
<span id="cb57-102"><a href="#cb57-102" aria-hidden="true" tabindex="-1"></a><span class="st">                src="https://code.jquery.com/jquery-3.6.0.min.js"&gt;</span></span>
<span id="cb57-103"><a href="#cb57-103" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb57-104"><a href="#cb57-104" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb57-105"><a href="#cb57-105" aria-hidden="true" tabindex="-1"></a><span class="st">                function startClassification() {</span></span>
<span id="cb57-106"><a href="#cb57-106" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/start');</span></span>
<span id="cb57-107"><a href="#cb57-107" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', true);</span></span>
<span id="cb57-108"><a href="#cb57-108" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', false);</span></span>
<span id="cb57-109"><a href="#cb57-109" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb57-110"><a href="#cb57-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-111"><a href="#cb57-111" aria-hidden="true" tabindex="-1"></a><span class="st">                function stopClassification() {</span></span>
<span id="cb57-112"><a href="#cb57-112" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/stop');</span></span>
<span id="cb57-113"><a href="#cb57-113" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', false);</span></span>
<span id="cb57-114"><a href="#cb57-114" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', true);</span></span>
<span id="cb57-115"><a href="#cb57-115" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb57-116"><a href="#cb57-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-117"><a href="#cb57-117" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateConfidence() {</span></span>
<span id="cb57-118"><a href="#cb57-118" aria-hidden="true" tabindex="-1"></a><span class="st">                    var confidence = $('#confidence').val();</span></span>
<span id="cb57-119"><a href="#cb57-119" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/update_confidence', {confidence: confidence});</span></span>
<span id="cb57-120"><a href="#cb57-120" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb57-121"><a href="#cb57-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-122"><a href="#cb57-122" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateClassification() {</span></span>
<span id="cb57-123"><a href="#cb57-123" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.get('/get_classification', function(data) {</span></span>
<span id="cb57-124"><a href="#cb57-124" aria-hidden="true" tabindex="-1"></a><span class="st">                        $('#classification').text(data.label + ': ' </span></span>
<span id="cb57-125"><a href="#cb57-125" aria-hidden="true" tabindex="-1"></a><span class="st">                        + data.probability.toFixed(2));</span></span>
<span id="cb57-126"><a href="#cb57-126" aria-hidden="true" tabindex="-1"></a><span class="st">                    });</span></span>
<span id="cb57-127"><a href="#cb57-127" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb57-128"><a href="#cb57-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-129"><a href="#cb57-129" aria-hidden="true" tabindex="-1"></a><span class="st">                $(document).ready(function() {</span></span>
<span id="cb57-130"><a href="#cb57-130" aria-hidden="true" tabindex="-1"></a><span class="st">                    setInterval(updateClassification, 100);  </span></span>
<span id="cb57-131"><a href="#cb57-131" aria-hidden="true" tabindex="-1"></a><span class="st">                    // Update every 100ms</span></span>
<span id="cb57-132"><a href="#cb57-132" aria-hidden="true" tabindex="-1"></a><span class="st">                });</span></span>
<span id="cb57-133"><a href="#cb57-133" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb57-134"><a href="#cb57-134" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb57-135"><a href="#cb57-135" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb57-136"><a href="#cb57-136" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Image Classification&lt;/h1&gt;</span></span>
<span id="cb57-137"><a href="#cb57-137" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" height="480" /&gt;</span></span>
<span id="cb57-138"><a href="#cb57-138" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb57-139"><a href="#cb57-139" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="startBtn" onclick="startClassification()"&gt;</span></span>
<span id="cb57-140"><a href="#cb57-140" aria-hidden="true" tabindex="-1"></a><span class="st">            Start Classification&lt;/button&gt;</span></span>
<span id="cb57-141"><a href="#cb57-141" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="stopBtn" onclick="stopClassification()" disabled&gt;</span></span>
<span id="cb57-142"><a href="#cb57-142" aria-hidden="true" tabindex="-1"></a><span class="st">            Stop Classification&lt;/button&gt;</span></span>
<span id="cb57-143"><a href="#cb57-143" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb57-144"><a href="#cb57-144" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;label for="confidence"&gt;Confidence Threshold:&lt;/label&gt;</span></span>
<span id="cb57-145"><a href="#cb57-145" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;input type="number" id="confidence" name="confidence" min="0" </span></span>
<span id="cb57-146"><a href="#cb57-146" aria-hidden="true" tabindex="-1"></a><span class="st">            max="1" step="0.1" value="0.8" onchange="updateConfidence()"&gt;</span></span>
<span id="cb57-147"><a href="#cb57-147" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb57-148"><a href="#cb57-148" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="classification"&gt;Waiting for classification...&lt;/div&gt;</span></span>
<span id="cb57-149"><a href="#cb57-149" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb57-150"><a href="#cb57-150" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb57-151"><a href="#cb57-151" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb57-152"><a href="#cb57-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-153"><a href="#cb57-153" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb57-154"><a href="#cb57-154" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb57-155"><a href="#cb57-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb57-156"><a href="#cb57-156" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb57-157"><a href="#cb57-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-158"><a href="#cb57-158" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/start'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb57-159"><a href="#cb57-159" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> start_classification():</span>
<span id="cb57-160"><a href="#cb57-160" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb57-161"><a href="#cb57-161" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">True</span></span>
<span id="cb57-162"><a href="#cb57-162" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb57-163"><a href="#cb57-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-164"><a href="#cb57-164" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb57-165"><a href="#cb57-165" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop_classification():</span>
<span id="cb57-166"><a href="#cb57-166" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb57-167"><a href="#cb57-167" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb57-168"><a href="#cb57-168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb57-169"><a href="#cb57-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-170"><a href="#cb57-170" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/update_confidence'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb57-171"><a href="#cb57-171" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_confidence():</span>
<span id="cb57-172"><a href="#cb57-172" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> confidence_threshold</span>
<span id="cb57-173"><a href="#cb57-173" aria-hidden="true" tabindex="-1"></a>    confidence_threshold <span class="op">=</span> <span class="bu">float</span>(request.form[<span class="st">'confidence'</span>])</span>
<span id="cb57-174"><a href="#cb57-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb57-175"><a href="#cb57-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-176"><a href="#cb57-176" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/get_classification'</span>)</span>
<span id="cb57-177"><a href="#cb57-177" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classification():</span>
<span id="cb57-178"><a href="#cb57-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> is_classifying:</span>
<span id="cb57-179"><a href="#cb57-179" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> jsonify({<span class="st">'label'</span>: <span class="st">'Not classifying'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>})</span>
<span id="cb57-180"><a href="#cb57-180" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb57-181"><a href="#cb57-181" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> classification_queue.get_nowait()</span>
<span id="cb57-182"><a href="#cb57-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> Queue.Empty:</span>
<span id="cb57-183"><a href="#cb57-183" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {<span class="st">'label'</span>: <span class="st">'Processing'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>}</span>
<span id="cb57-184"><a href="#cb57-184" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jsonify(result)</span>
<span id="cb57-185"><a href="#cb57-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-186"><a href="#cb57-186" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb57-187"><a href="#cb57-187" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb57-188"><a href="#cb57-188" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb57-189"><a href="#cb57-189" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>classification_worker, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb57-190"><a href="#cb57-190" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sul terminale lanciare:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> img_class_live_infer.py</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>E accedere all’interfaccia web:</p>
<ul>
<li>Sul Raspberry Pi stesso (se si ha una GUI): si apre un browser web e si va su<code>http://localhost:5000</code></li>
<li>Da un altro dispositivo sulla stessa rete: aprire un browser web e andare su <code>http://&lt;raspberry_pi_ip&gt;:5000</code> (Sostituire <code>&lt;raspberry_pi_ip&gt;</code> con l’indirizzo IP del Raspberry Pi). Per esempio: <code>http://192.168.4.210:5000/</code></li>
</ul>
<p>Ecco alcuni screenshot dell’app in esecuzione su un desktop esterno</p>
<p><img src="images/png/app-inference.png" class="img-fluid"></p>
<p>Qui si può vedere l’app in esecuzione su YouTube:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/o1QsQrpCMw4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Il codice crea un’applicazione web per la classificazione delle immagini in tempo reale utilizzando un Raspberry Pi, il suo modulo fotocamera e un modello TensorFlow Lite. L’applicazione utilizza Flask per fornire un’interfaccia web in cui è possibile visualizzare il feed della fotocamera e vedere i risultati della classificazione in tempo reale.</p>
<section id="componenti-chiave" class="level4">
<h4 class="anchored" data-anchor-id="componenti-chiave">Componenti Chiave:</h4>
<ol type="1">
<li><strong>Applicazione Web Flask</strong>: Fornisce l’interfaccia utente e gestisce le richieste.</li>
<li><strong>PiCamera2</strong>: Cattura le immagini dal modulo fotocamera Raspberry Pi.</li>
<li><strong>TensorFlow Lite</strong>: Esegue il modello di classificazione delle immagini.</li>
<li><strong>Threading</strong>: Gestisce le operazioni simultanee per prestazioni fluide.</li>
</ol>
</section>
<section id="caratteristiche-principali" class="level4">
<h4 class="anchored" data-anchor-id="caratteristiche-principali">Caratteristiche Principali:</h4>
<ul>
<li>Visualizzazione feed telecamera live</li>
<li>Classificazione immagini in tempo reale</li>
<li>Soglia di confidenza regolabile</li>
<li>Avvia/Arresta classificazione su richiesta</li>
</ul>
</section>
<section id="struttura-del-codice" class="level4">
<h4 class="anchored" data-anchor-id="struttura-del-codice">Struttura del Codice:</h4>
<ol type="1">
<li><strong>Importazioni e Setup</strong>:
<ul>
<li>Flask per applicazione web</li>
<li>PiCamera2 per controllo telecamera</li>
<li>TensorFlow Lite per l’inferenza</li>
<li>Threading e Queue per operazioni concorrenti</li>
</ul></li>
<li><strong>Variabili Globali</strong>:
<ul>
<li>Gestione telecamera e frame</li>
<li>Controllo classificazione</li>
<li>Informazioni modello ed etichetta</li>
</ul></li>
<li><strong>Funzioni della Telecamera</strong>:
<ul>
<li><code>initialize_camera()</code>: Imposta PiCamera2</li>
<li><code>get_frame()</code>: Cattura continuamente frame</li>
<li><code>generate_frames()</code>: Genera frame per il feed web</li>
</ul></li>
<li><strong>Funzioni del Modello</strong>:
<ul>
<li><code>load_model()</code>: Carica il modello TFLite</li>
<li><code>classify_image()</code>: Esegue l’inferenza su una singola immagine</li>
</ul></li>
<li><strong>Worker per la Classificazione</strong>:
<ul>
<li>Gira in un thread separato</li>
<li>Classifica continuamente i frame quando è attivo</li>
<li>Aaggiorna una coda con i risultati più recenti</li>
</ul></li>
<li><strong>Route di Flask</strong>:
<ul>
<li><code>/</code>: Serve la pagina HTML principale</li>
<li><code>/video_feed</code>: Trasmette il feed della telecamera</li>
<li><code>/start</code> and <code>/stop</code>: Controlla la classificazione</li>
<li><code>/update_confidence</code>: Regola la soglia di confidenza</li>
<li><code>/get_classification</code>: Restituisce l’ultimo risultato di classificazione</li>
</ul></li>
<li><strong>Template HTML</strong>:
<ul>
<li>Visualizza il feed della telecamera e la classificazione dei risultati</li>
<li>Fornisce controlli per avviare/arrestare e regolare le impostazioni</li>
</ul></li>
<li><strong>Esecuzione Principale</strong>:
<ul>
<li>Inizializza la fotocamera e avvia i thread necessari</li>
<li>Esegue l’applicazione Flask</li>
</ul></li>
</ol>
</section>
<section id="concetti-chiave" class="level4">
<h4 class="anchored" data-anchor-id="concetti-chiave">Concetti Chiave:</h4>
<ol type="1">
<li><strong>Operazioni Concorrenti</strong>: Utilizzo di thread per gestire l’acquisizione e la classificazione della telecamera separatamente dal server Web.</li>
<li><strong>Aggiornamenti in Tempo Reale</strong>: Aggiornamenti frequenti dei risultati della classificazione senza ricaricare la pagina.</li>
<li><strong>Riutilizzo del Modello</strong>: Caricamento del modello TFLite una volta e il riutilizzo per l’efficienza.</li>
<li><strong>Configurazione Flessibile</strong>: Consente agli utenti di regolare la soglia di confidenza al volo.</li>
</ol>
</section>
<section id="uso" class="level4">
<h4 class="anchored" data-anchor-id="uso">Uso:</h4>
<ol type="1">
<li>Assicurarsi che tutte le dipendenze siano installate.</li>
<li>Eseguire lo script su un Raspberry Pi con un modulo telecamera.</li>
<li>Accedere all’interfaccia Web da un browser utilizzando l’indirizzo IP del Raspberry Pi.</li>
<li>Avviare la classificazione e regolare le impostazioni in base alle esigenze.</li>
</ol>
</section>
</section>
<section id="conclusione" class="level2">
<h2 class="anchored" data-anchor-id="conclusione">Conclusione:</h2>
<p>La classificazione delle immagini è emersa come un’applicazione potente e versatile dell’apprendimento automatico, con implicazioni significative per vari campi, dall’assistenza sanitaria al monitoraggio ambientale. Questo capitolo ha dimostrato come implementare un sistema di classificazione delle immagini robusto su dispositivi edge come Raspi-Zero e Raspi-5, mostrando il potenziale per l’intelligenza in tempo reale sul dispositivo.</p>
<p>Abbiamo esplorato l’intera pipeline di un progetto di classificazione delle immagini, dalla raccolta dati e dall’addestramento del modello tramite Edge Impulse Studio all’implementazione e all’esecuzione di inferenze su un Raspi. Il processo ha evidenziato diversi punti chiave:</p>
<ol type="1">
<li>L’importanza di una corretta raccolta dati e pre-elaborazione per l’addestramento efficace dei modelli.</li>
<li>La potenza dell’apprendimento tramite trasferimento, che ci consente di sfruttare modelli pre-addestrati come MobileNet V2 per un addestramento efficiente con dati limitati.</li>
<li>I compromessi tra accuratezza del modello e velocità di inferenza, particolarmente cruciali per i dispositivi edge.</li>
<li>L’implementazione della classificazione in tempo reale tramite un’interfaccia basata sul Web, che dimostra applicazioni pratiche.</li>
</ol>
<p>La capacità di eseguire questi modelli su dispositivi edge come Raspi apre numerose possibilità per applicazioni IoT, sistemi autonomi e soluzioni di monitoraggio in tempo reale. Consente una latenza ridotta, una migliore privacy e il funzionamento in ambienti con connettività limitata.</p>
<p>Come abbiamo visto, anche con i vincoli computazionali dei dispositivi edge, è possibile ottenere risultati impressionanti in termini di accuratezza e velocità. La flessibilità di regolare i parametri del modello, come le dimensioni di input e i valori alfa, consente una messa a punto precisa per soddisfare requisiti di progetto specifici.</p>
<p>Guardando al futuro, il campo dell’intelligenza artificiale edge e della classificazione delle immagini continua a evolversi rapidamente. I progressi nelle tecniche di compressione dei modelli, nell’accelerazione hardware e nelle architetture di reti neurali più efficienti promettono di espandere ulteriormente le capacità dei dispositivi edge nelle attività di visione artificiale.</p>
<p>Questo progetto funge da base per applicazioni di visione artificiale più complesse e incoraggia un’ulteriore esplorazione nell’entusiasmante mondo dell’intelligenza artificiale edge e dell’IoT. Che si tratti di automazione industriale, applicazioni per la casa intelligente o monitoraggio ambientale, le competenze e i concetti trattati qui forniscono un solido punto di partenza per un’ampia gamma di progetti innovativi.</p>
</section>
<section id="risorse" class="level2">
<h2 class="anchored" data-anchor-id="risorse">Risorse</h2>
<ul>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/dataset">Esempio di Dataset</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Impostazione del Notebook di Prova su un Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">Notebook di Classificazione delle Immagini su un Raspi</a></p></li>
<li><p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN per classificare il dataset Cifar-10 su CoLab</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Classificazione delle Immagini su un Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/python_scripts">Script Python</a></p></li>
<li><p><a href="https://studio.edgeimpulse.com/public/510251/live">Progetto Edge Impulse</a></p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../../contents/labs/raspi/setup/setup.it.html" class="pagination-link" aria-label="Setup">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" class="pagination-link" aria-label="Rilevamento degli Oggetti">
        <span class="nav-page-text">Rilevamento degli Oggetti</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro è stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>