<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Classificazione delle Immagini ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" rel="next">
<link href="../../../../contents/labs/raspi/setup/setup.it.html" rel="prev">
<link href="../../../../favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>


</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/raspi.it.html">Raspberry Pi</a></li><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html">Classificazione delle Immagini</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2d6cdf6fc58f1105ce2a5c5c28a11153" class="alert alert-info hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>üåü Aiutaci a raggiungere 1.000 stelle GitHub! üåü Per ogni 25 stelle, Arduino e SEEED doneranno una NiclaVision o una XIAO ESP32S3 per l‚Äôistruzione sull‚Äôintelligenza artificiale. <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per una ‚≠ê</a></p>
</div></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">PREFAZIONE</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/dedication.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/contributors.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collaboratori e Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/copyright.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">PARTE PRINCIPALE</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Nozioni Fondamentali</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Workflow</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Training</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Argomenti Avanzati</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Impatto Sociale</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Chiusura</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">LABS</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/tools.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tool</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/zoo_datasets.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Dataset</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/zoo_models.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/learning_resources.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Risorse</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/community.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Le Community</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../contents/case_studies.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Casi di Studio</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione">Introduzione</a>
  <ul>
  <li><a href="#applicazioni-in-scenari-del-mondo-reale" id="toc-applicazioni-in-scenari-del-mondo-reale" class="nav-link" data-scroll-target="#applicazioni-in-scenari-del-mondo-reale">Applicazioni in Scenari del Mondo Reale</a></li>
  <li><a href="#vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" id="toc-vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" class="nav-link" data-scroll-target="#vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi">Vantaggi dell‚ÄôEsecuzione della Classificazione su Dispositivi Edge come Raspberry Pi</a></li>
  </ul></li>
  <li><a href="#impostazione-dellambiente" id="toc-impostazione-dellambiente" class="nav-link" data-scroll-target="#impostazione-dellambiente">Impostazione dell‚ÄôAmbiente</a>
  <ul>
  <li><a href="#aggiornamento-di-raspberry-pi" id="toc-aggiornamento-di-raspberry-pi" class="nav-link" data-scroll-target="#aggiornamento-di-raspberry-pi">Aggiornamento di Raspberry Pi</a></li>
  <li><a href="#installazione-delle-librerie-richieste" id="toc-installazione-delle-librerie-richieste" class="nav-link" data-scroll-target="#installazione-delle-librerie-richieste">Installazione delle Librerie Richieste</a></li>
  <li><a href="#impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" id="toc-impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" class="nav-link" data-scroll-target="#impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato">Impostazione di un Ambiente Virtuale (Facoltativo ma Consigliato)</a></li>
  <li><a href="#installazione-di-tensorflow-lite" id="toc-installazione-di-tensorflow-lite" class="nav-link" data-scroll-target="#installazione-di-tensorflow-lite">Installazione di TensorFlow Lite</a></li>
  <li><a href="#installazione-di-librerie-python-aggiuntive" id="toc-installazione-di-librerie-python-aggiuntive" class="nav-link" data-scroll-target="#installazione-di-librerie-python-aggiuntive">Installazione di Librerie Python Aggiuntive</a></li>
  <li><a href="#creazione-di-una-directory-di-lavoro" id="toc-creazione-di-una-directory-di-lavoro" class="nav-link" data-scroll-target="#creazione-di-una-directory-di-lavoro">Creazione di una directory di lavoro:</a></li>
  <li><a href="#impostazione-di-jupyter-notebook-facoltativo" id="toc-impostazione-di-jupyter-notebook-facoltativo" class="nav-link" data-scroll-target="#impostazione-di-jupyter-notebook-facoltativo">Impostazione di Jupyter Notebook (Facoltativo)</a></li>
  <li><a href="#verifica-della-configurazione" id="toc-verifica-della-configurazione" class="nav-link" data-scroll-target="#verifica-della-configurazione">Verifica della Configurazione</a></li>
  </ul></li>
  <li><a href="#fare-inferenze-con-mobilenet-v2" id="toc-fare-inferenze-con-mobilenet-v2" class="nav-link" data-scroll-target="#fare-inferenze-con-mobilenet-v2">Fare inferenze con Mobilenet V2</a>
  <ul>
  <li><a href="#definire-una-funzione-generale-di-classificazione-delle-immagini" id="toc-definire-una-funzione-generale-di-classificazione-delle-immagini" class="nav-link" data-scroll-target="#definire-una-funzione-generale-di-classificazione-delle-immagini">Definire una funzione generale di Classificazione delle Immagini</a></li>
  <li><a href="#test-con-un-modello-addestrato-da-zero" id="toc-test-con-un-modello-addestrato-da-zero" class="nav-link" data-scroll-target="#test-con-un-modello-addestrato-da-zero">Test con un modello addestrato da zero</a></li>
  <li><a href="#installing-picamera2" id="toc-installing-picamera2" class="nav-link" data-scroll-target="#installing-picamera2">Installing Picamera2</a></li>
  </ul></li>
  <li><a href="#progetto-di-classificazione-delle-immagini" id="toc-progetto-di-classificazione-delle-immagini" class="nav-link" data-scroll-target="#progetto-di-classificazione-delle-immagini">Progetto di Classificazione delle Immagini</a>
  <ul>
  <li><a href="#lobiettivo" id="toc-lobiettivo" class="nav-link" data-scroll-target="#lobiettivo">L‚ÄôObiettivo</a></li>
  <li><a href="#raccolta-dati" id="toc-raccolta-dati" class="nav-link" data-scroll-target="#raccolta-dati">Raccolta Dati</a>
  <ul class="collapse">
  <li><a href="#caratteristiche-principali" id="toc-caratteristiche-principali" class="nav-link" data-scroll-target="#caratteristiche-principali">Caratteristiche Principali:</a></li>
  <li><a href="#componenti-principali" id="toc-componenti-principali" class="nav-link" data-scroll-target="#componenti-principali">Componenti Principali:</a></li>
  <li><a href="#funzioni-chiave" id="toc-funzioni-chiave" class="nav-link" data-scroll-target="#funzioni-chiave">Funzioni Chiave:</a></li>
  <li><a href="#flusso-di-utilizzo" id="toc-flusso-di-utilizzo" class="nav-link" data-scroll-target="#flusso-di-utilizzo">Flusso di Utilizzo:</a></li>
  <li><a href="#note-tecniche" id="toc-note-tecniche" class="nav-link" data-scroll-target="#note-tecniche">Note Tecniche:</a></li>
  <li><a href="#possibilit√†-di-personalizzazione" id="toc-possibilit√†-di-personalizzazione" class="nav-link" data-scroll-target="#possibilit√†-di-personalizzazione">Possibilit√† di Personalizzazione:</a></li>
  <li><a href="#numero-di-campioni-sul-dataset" id="toc-numero-di-campioni-sul-dataset" class="nav-link" data-scroll-target="#numero-di-campioni-sul-dataset">Numero di campioni sul Dataset:</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#addestramento-del-modello-con-edge-impulse" id="toc-addestramento-del-modello-con-edge-impulse" class="nav-link" data-scroll-target="#addestramento-del-modello-con-edge-impulse">Addestramento del modello con Edge Impulse</a>
  <ul>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">Dataset</a></li>
  </ul></li>
  <li><a href="#il-progetto-impulse" id="toc-il-progetto-impulse" class="nav-link" data-scroll-target="#il-progetto-impulse">Il Progetto Impulse</a>
  <ul>
  <li><a href="#pre-elaborazione-delle-immagini" id="toc-pre-elaborazione-delle-immagini" class="nav-link" data-scroll-target="#pre-elaborazione-delle-immagini">Pre-elaborazione delle immagini</a></li>
  <li><a href="#progettazione-del-modello" id="toc-progettazione-del-modello" class="nav-link" data-scroll-target="#progettazione-del-modello">Progettazione del modello</a></li>
  <li><a href="#training-del-modello" id="toc-training-del-modello" class="nav-link" data-scroll-target="#training-del-modello">Training del Modello</a></li>
  <li><a href="#compromesso-accuratezza-contro-velocit√†" id="toc-compromesso-accuratezza-contro-velocit√†" class="nav-link" data-scroll-target="#compromesso-accuratezza-contro-velocit√†">Compromesso: Accuratezza contro Velocit√†</a></li>
  <li><a href="#test-del-modello" id="toc-test-del-modello" class="nav-link" data-scroll-target="#test-del-modello">Test del Modello</a></li>
  <li><a href="#distribuzione-del-modello" id="toc-distribuzione-del-modello" class="nav-link" data-scroll-target="#distribuzione-del-modello">Distribuzione del modello</a></li>
  </ul></li>
  <li><a href="#classificazione-delle-immagini-in-tempo-reale" id="toc-classificazione-delle-immagini-in-tempo-reale" class="nav-link" data-scroll-target="#classificazione-delle-immagini-in-tempo-reale">Classificazione delle Immagini in Tempo Reale</a>
  <ul>
  <li><a href="#componenti-chiave" id="toc-componenti-chiave" class="nav-link" data-scroll-target="#componenti-chiave">Componenti Chiave:</a></li>
  <li><a href="#caratteristiche-principali-1" id="toc-caratteristiche-principali-1" class="nav-link" data-scroll-target="#caratteristiche-principali-1">Caratteristiche Principali:</a></li>
  <li><a href="#struttura-del-codice" id="toc-struttura-del-codice" class="nav-link" data-scroll-target="#struttura-del-codice">Struttura del Codice:</a></li>
  <li><a href="#concetti-chiave" id="toc-concetti-chiave" class="nav-link" data-scroll-target="#concetti-chiave">Concetti Chiave:</a></li>
  <li><a href="#uso" id="toc-uso" class="nav-link" data-scroll-target="#uso">Uso:</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione">Conclusione:</a></li>
  <li><a href="#risorse" id="toc-risorse" class="nav-link" data-scroll-target="#risorse">Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/raspi.it.html">Raspberry Pi</a></li><li class="breadcrumb-item"><a href="../../../../contents/labs/raspi/image_classification/image_classification.it.html">Classificazione delle Immagini</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Classificazione delle Immagini</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/jpeg/img_class_cover.jpg" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E prompt - Un‚Äôimmagine di copertina per un capitolo ‚ÄúClassificazione delle immagini‚Äù in un tutorial Raspberry Pi, progettata nello stesso stile vintage da laboratorio di elettronica anni ‚Äô50 delle copertine precedenti. La scena dovrebbe presentare un Raspberry Pi collegato a un modulo fotocamera, con la fotocamera che cattura una foto del piccolo robot blu fornito dall‚Äôutente. Il robot dovrebbe essere posizionato su un banco da lavoro, circondato da classici strumenti da laboratorio come saldatori, resistenze e fili. Lo sfondo del laboratorio dovrebbe includere apparecchiature d‚Äôepoca come oscilloscopi e radio a valvole, mantenendo il tocco dettagliato e nostalgico dell‚Äôepoca. Non dovrebbero essere inclusi testo o loghi.</em></figcaption>
</figure>
</div>
<section id="introduzione" class="level2">
<h2 class="anchored" data-anchor-id="introduzione">Introduzione</h2>
<p>La classificazione delle immagini √® un‚Äôattivit√† fondamentale nella visione artificiale che comporta la categorizzazione di un‚Äôimmagine in una delle diverse classi predefinite. √à una pietra angolare dell‚Äôintelligenza artificiale, che consente alle macchine di interpretare e comprendere le informazioni visive in un modo che imita la percezione umana.</p>
<p>La classificazione delle immagini si riferisce all‚Äôassegnazione di un‚Äôetichetta o di una categoria a un‚Äôintera immagine in base al suo contenuto visivo. Questa attivit√† √® fondamentale nella visione artificiale e ha numerose applicazioni in vari settori. L‚Äôimportanza della classificazione delle immagini risiede nella sua capacit√† di automatizzare le attivit√† di comprensione visiva che altrimenti richiederebbero l‚Äôintervento umano.</p>
<section id="applicazioni-in-scenari-del-mondo-reale" class="level3">
<h3 class="anchored" data-anchor-id="applicazioni-in-scenari-del-mondo-reale">Applicazioni in Scenari del Mondo Reale</h3>
<p>La classificazione delle immagini ha trovato la sua strada in numerose applicazioni del mondo reale, rivoluzionando vari settori:</p>
<ul>
<li>Sanit√†: Assistenza nell‚Äôanalisi delle immagini mediche, come l‚Äôidentificazione di anomalie nelle radiografie o nelle risonanze magnetiche.</li>
<li>Agricoltura: Monitoraggio della salute delle colture e rilevamento delle malattie delle piante tramite immagini aeree.</li>
<li>Automotive: Abilitazione di sistemi avanzati di assistenza alla guida e veicoli autonomi per riconoscere segnali stradali, pedoni e altri veicoli.</li>
<li>Vendita al Dettaglio: Potenziamento delle capacit√† di ricerca visiva e sistemi di gestione automatizzata dell‚Äôinventario.</li>
<li>Sicurezza e Sorveglianza: Potenziamento dei sistemi di rilevamento delle minacce e riconoscimento facciale.</li>
<li>Monitoraggio Ambientale: Analisi delle immagini satellitari per studi su deforestazione, pianificazione urbana e cambiamenti climatici.</li>
</ul>
</section>
<section id="vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="vantaggi-dellesecuzione-della-classificazione-su-dispositivi-edge-come-raspberry-pi">Vantaggi dell‚ÄôEsecuzione della Classificazione su Dispositivi Edge come Raspberry Pi</h3>
<p>L‚Äôimplementazione della classificazione delle immagini su dispositivi edge come Raspberry Pi offre diversi vantaggi interessanti:</p>
<ol type="1">
<li><p>Bassa latenza: L‚Äôelaborazione delle immagini in locale elimina la necessit√† di inviare dati ai server cloud, riducendo significativamente i tempi di risposta.</p></li>
<li><p>Funzionalit√† Offline: La classificazione pu√≤ essere eseguita senza una connessione Internet, rendendola adatta ad ambienti remoti o con problemi di connettivit√†.</p></li>
<li><p>Privacy e Sicurezza: I dati sensibili delle immagini rimangono sul dispositivo locale, affrontando i problemi di privacy dei dati e i requisiti di conformit√†.</p></li>
<li><p>Efficacia in Termini di Costi: Elimina la necessit√† di costose risorse di cloud computing, in particolare per attivit√† di classificazione continue o ad alto volume.</p></li>
<li><p>Scalabilit√†: Consente architetture di elaborazione distribuite in cui pi√π dispositivi possono funzionare in modo indipendente o in una rete.</p></li>
<li><p>Efficienza Energetica: I modelli ottimizzati su hardware dedicato possono essere pi√π efficienti dal punto di vista energetico rispetto alle soluzioni basate su cloud, il che √® fondamentale per applicazioni alimentate a batteria o remote.</p></li>
<li><p>Personalizzazione: L‚Äôimplementazione di modelli specializzati o aggiornati di frequente, su misura per casi d‚Äôuso specifici, √® pi√π gestibile.</p></li>
</ol>
<p>Possiamo creare soluzioni di visione artificiale pi√π reattive, sicure ed efficienti sfruttando la potenza di dispositivi edge come Raspberry Pi per la classificazione delle immagini. Questo approccio apre nuove possibilit√† per integrare l‚Äôelaborazione visiva intelligente in varie applicazioni e ambienti.</p>
<p>Nelle sezioni seguenti, esploreremo come implementare e ottimizzare la classificazione delle immagini su Raspberry Pi, sfruttando questi vantaggi per creare sistemi di visione artificiale potenti ed efficienti.</p>
</section>
</section>
<section id="impostazione-dellambiente" class="level2">
<h2 class="anchored" data-anchor-id="impostazione-dellambiente">Impostazione dell‚ÄôAmbiente</h2>
<section id="aggiornamento-di-raspberry-pi" class="level3">
<h3 class="anchored" data-anchor-id="aggiornamento-di-raspberry-pi">Aggiornamento di Raspberry Pi</h3>
<p>Innanzitutto, assicurarsi che il Raspberry Pi sia aggiornato:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt update</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt upgrade <span class="at">-y</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installazione-delle-librerie-richieste" class="level3">
<h3 class="anchored" data-anchor-id="installazione-delle-librerie-richieste">Installazione delle Librerie Richieste</h3>
<p>Installare le librerie necessarie per l‚Äôelaborazione delle immagini e l‚Äôapprendimento automatico:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> apt install python3-pip</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sudo</span> rm /usr/lib/python3.11/EXTERNALLY-MANAGED</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install <span class="at">--upgrade</span> pip</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato" class="level3">
<h3 class="anchored" data-anchor-id="impostazione-di-un-ambiente-virtuale-facoltativo-ma-consigliato">Impostazione di un Ambiente Virtuale (Facoltativo ma Consigliato)</h3>
<p>Creare un ambiente virtuale per gestire le dipendenze:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> <span class="at">-m</span> venv ~/tflite</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="installazione-di-tensorflow-lite" class="level3">
<h3 class="anchored" data-anchor-id="installazione-di-tensorflow-lite">Installazione di TensorFlow Lite</h3>
<p>Siamo interessati a eseguire <strong>inferenza</strong>, ovvero l‚Äôesecuzione di un modello TensorFlow Lite su un dispositivo per effettuare previsioni basate sui dati di input. Per eseguire un‚Äôinferenza con un modello TensorFlow Lite, dobbiamo eseguirla tramite un <strong>interprete</strong>. L‚Äôinterprete TensorFlow Lite √® progettato per essere snello e veloce. L‚Äôinterprete utilizza un ordinamento grafico statico e un allocatore di memoria personalizzato (meno dinamico) per garantire un carico, inizializzazione ed esecuzione latenza minimi.</p>
<p>Utilizzeremo il <a href="https://pypi.org/project/tflite-runtime/">runtime TensorFlow Lite</a> per Raspberry Pi, una libreria semplificata per l‚Äôesecuzione di modelli di apprendimento automatico su dispositivi mobili e embedded, senza includere tutti i pacchetti TensorFlow.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install tflite_runtime <span class="at">--no-deps</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>La wheel installata: <code>tflite_runtime-2.14.0-cp311-cp311-manylinux_2_34_aarch64.whl</code></p>
</blockquote>
</section>
<section id="installazione-di-librerie-python-aggiuntive" class="level3">
<h3 class="anchored" data-anchor-id="installazione-di-librerie-python-aggiuntive">Installazione di Librerie Python Aggiuntive</h3>
<p>Installare le librerie Python richieste per l‚Äôuso con Image Classification:</p>
<p>Se √® installata un‚Äôaltra versione di Numpy, disinstallarla prima.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> uninstall numpy</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Installare la <code>versione 1.23.2</code>, che √® compatibile con tflite_runtime.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install numpy==1.23.2</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install Pillow matplotlib</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="creazione-di-una-directory-di-lavoro" class="level3">
<h3 class="anchored" data-anchor-id="creazione-di-una-directory-di-lavoro">Creazione di una directory di lavoro:</h3>
<p>Se si lavora su Raspi-Zero con il sistema operativo minimo (No Desktop), non si ha un albero di directory user-pre-defined (lo si pu√≤ verificare con <code>ls</code>. Quindi, creiamone uno:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> Documents</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> Documents/</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> TFLITE</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> TFLITE/</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> IMG_CLASS</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> IMG_CLASS</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> models</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> models</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Su Raspi-5, /Documents dovrebbe esserci.</p>
</blockquote>
<p><strong>Ottenere un Modello di Classificazione delle Immagini Pre-addestrato</strong>:</p>
<p>Un modello pre-addestrato appropriato √® fondamentale per una classificazione delle immagini di successo su dispositivi con risorse limitate come Raspberry Pi. <strong>MobileNet</strong> √® progettato per applicazioni di visione mobile e embedded con un buon equilibrio tra accuratezza e velocit√†. Versioni: MobileNetV1, MobileNetV2, MobileNetV3. Scarichiamo la V2:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://storage.googleapis.com/download.tensorflow.org/models/</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tar</span> xzf mobilenet_v2_1.0_224_quant.tgz</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Prelevarne le etichette:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">lite/java/demo/app/src/main/assets/labels_mobilenet_quant_v1_224.txt</span> <span class="at">-O</span> labels.txt</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Alla fine, si dovrebbero avere i modelli nella sua directory:</p>
<p><img src="images/png/models_dir.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Ci serviranno solo il modello <code>mobilenet_v2_1.0_224_quant.tflite</code> e <code>labels.txt</code>. Si possono eliminare gli altri file.</p>
</blockquote>
</section>
<section id="impostazione-di-jupyter-notebook-facoltativo" class="level3">
<h3 class="anchored" data-anchor-id="impostazione-di-jupyter-notebook-facoltativo">Impostazione di Jupyter Notebook (Facoltativo)</h3>
<p>Se si preferisce usare Jupyter Notebook per lo sviluppo:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install jupyter</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--generate-config</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Per eseguire Jupyter Notebook, si lancia il comando (cambiare l‚Äôindirizzo IP per il proprio):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">jupyter</span> notebook <span class="at">--ip</span><span class="op">=</span>192.168.4.210 <span class="at">--no-browser</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Sul terminale, si pu√≤ vedere l‚Äôindirizzo URL locale per aprire il notebook:</p>
<p><img src="images/png/notebook_token.png" class="img-fluid"></p>
<p>Vi si pu√≤ accedere da un altro dispositivo inserendo l‚Äôindirizzo IP del Raspberry Pi e il token fornito in un browser Web (il token lo si pu√≤ copiare dal terminale).</p>
<p><img src="images/png/image-20240823145059675.png" class="img-fluid"></p>
<p>Definire la directory di lavoro nel Raspi e creare un nuovo notebook Python 3.</p>
</section>
<section id="verifica-della-configurazione" class="level3">
<h3 class="anchored" data-anchor-id="verifica-della-configurazione">Verifica della Configurazione</h3>
<p>Testare la configurazione eseguendo un semplice script Python:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy:"</span>, np.__version__)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Pillow:"</span>, Image.__version__)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Try to create a TFLite Interpreter</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TFLite Interpreter created successfully!"</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Si pu√≤ creare lo script Python usando nano sul terminale, salvandolo con <code>CTRL+0</code> + <code>ENTER</code> + <code>CTRL+X</code></p>
<p><img src="images/png/nano.png" class="img-fluid"></p>
<p>Ed eseguirlo col comando:</p>
<p><img src="images/png/test_result.png" class="img-fluid"></p>
<p>Oppure lo si pu√≤ lanciare direttamente sul <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Notebook</a>:</p>
<p><img src="images/png/notebook_test.png" class="img-fluid"></p>
</section>
</section>
<section id="fare-inferenze-con-mobilenet-v2" class="level2">
<h2 class="anchored" data-anchor-id="fare-inferenze-con-mobilenet-v2">Fare inferenze con Mobilenet V2</h2>
<p>Nell‚Äôultima sezione, abbiamo impostato l‚Äôambiente, incluso il download di un modello pre-addestrato popolare, Mobilenet V2, addestrato sulle immagini 224x224 di ImageNet (1,2 milioni) per 1.001 classi (1.000 categorie di oggetti pi√π 1 sfondo). Il modello √® stato convertito in un formato TensorFlow Lite compatto da 3,5 MB, rendendolo adatto allo spazio di archiviazione e alla memoria limitati di un Raspberry Pi.</p>
<p><img src="images/png/mobilinet_zero.png" class="img-fluid"></p>
<p>Apriamo un nuovo <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">notebook</a> per seguire tutti i passaggi per classificare un‚Äôimmagine:</p>
<p>Importare le librerie necessarie:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Caricare il modello TFLite e allocare i tensori:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/mobilenet_v2_1.0_224_quant.tflite"</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ottenere i tensori di input e output.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Input details</strong> ci daranno informazioni su come il modello dovrebbe essere alimentato con un‚Äôimmagine. Il profilo di (1, 224, 224, 3) ci informa che un‚Äôimmagine con dimensioni (224x224x3) dovrebbe essere inserita una alla volta (Batch Dimension: 1).</p>
<p><img src="images/png/input_details.png" class="img-fluid"></p>
<p>Gli <strong>output details</strong> mostrano che l‚Äôinferenza risulter√† in un array di 1.001 valori interi. Tali valori derivano dalla classificazione dell‚Äôimmagine, dove ogni valore √® la probabilit√† che quella specifica etichetta sia correlata all‚Äôimmagine.</p>
<p><img src="images/png/output_details.png" class="img-fluid"></p>
<p>Esaminiamo anche il dtype dei dettagli di input del modello</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>Questo mostra che l‚Äôimmagine di input dovrebbe essere composta da pixel grezzi (0 - 255).</p>
<p>Prendiamo un‚Äôimmagine di prova. La si pu√≤ trasferire dal computer o scaricarne una per testarla. Per prima cosa creiamo una cartella nella nostra directory di lavoro:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> images</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> images</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> https://upload.wikimedia.org/wikipedia/commons/3/3a/Cat03.jpg</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Carichiamo e visualizziamo l‚Äôimmagine:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load he image</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/Cat03.jpg"</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the image</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Original Image"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/cat_original.png" class="img-fluid"></p>
<p>Possiamo vedere la dimensione dell‚Äôimmagine eseguendo il comando:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>width, height <span class="op">=</span> img.size</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Questo ci mostra che l‚Äôimmagine √® RGB con una larghezza di 1600 e un‚Äôaltezza di 1600 pixel. Quindi, per usare il nostro modello, dovremmo rimodellarlo in (224, 224, 3) e aggiungere una dimensione batch di 1, come definito nei dettagli di input: (1, 224, 224, 3). Il risultato dell‚Äôinferenza, come mostrato nei dettagli di output, sar√† un array con una dimensione di 1001, come mostrato di seguito:</p>
<p><img src="images/png/process_img.png" class="img-fluid"></p>
<p>Quindi, rimodelliamo l‚Äôimmagine, aggiungiamo la dimensione batch e vediamo il risultato:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>input_data.shape</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>La forma di input_data √® come previsto: (1, 224, 224, 3)</p>
<p>Confermiamo il dtype dei dati di input:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>input_data.dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>dtype('uint8')</code></pre>
<p>Il dtype dei dati di input √® ‚Äòuint8‚Äô, che √® compatibile con il dtype previsto per il modello.</p>
<p>Utilizzando input_data, eseguiamo l‚Äôinterprete e otteniamo le previsioni (output):</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>La previsione √® un array con 1001 elementi. Otteniamo i primi 5 indici in cui i loro elementi hanno valori elevati:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>top_k_results <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>top_k_indices</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>top_k_indices √® un array con 5 elementi: <code>array([283, 286, 282])</code></p>
<p>Quindi, 283, 286, 282, 288 e 479 sono le classi pi√π probabili dell‚Äôimmagine. Avendo l‚Äôindice, dobbiamo trovare a quale classe √® assegnato (ad esempio auto, gatto o cane). Il file di testo scaricato con il modello ha un‚Äôetichetta associata a ciascun indice da 0 a 1.000. Usiamo una funzione per caricare il file .txt come un elenco:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_labels(filename):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(filename, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [line.strip() <span class="cf">for</span> line <span class="kw">in</span> f.readlines()]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>E otteniamo l‚Äôelenco, stampando le etichette associate agli indici:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>labels_path <span class="op">=</span> <span class="st">"./models/labels.txt"</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> load_labels(labels_path)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">286</span>])</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">283</span>])</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">282</span>])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">288</span>])</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(labels[<span class="dv">479</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Di conseguenza abbiamo:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Almeno i quattro indici principali sono correlati ai felini. Il contenuto di <strong>prediction</strong> √® la probabilit√† associata a ciascuna delle etichette. Come abbiamo visto nei dettagli dell‚Äôoutput, quei valori sono quantizzati e dovrebbero essere dequantizzati e applicare la softmax.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Stampiamo le prime 5 probabilit√†:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">286</span>])</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">283</span>])</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">282</span>])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">288</span>])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (probabilities[<span class="dv">479</span>])</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">0.27741462</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="ex">0.3732285</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="ex">0.16919471</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0.10319158</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="ex">0.023410844</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Per chiarezza, creiamo una funzione per mettere in relazione le etichette con le probabilit√†:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>        (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">tiger</span> cat           : 37%</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Egyptian</span> cat        : 27%</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="ex">tabby</span>               : 16%</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lynx</span>                : 10%</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="ex">carton</span>              : 2%</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="definire-una-funzione-generale-di-classificazione-delle-immagini" class="level3">
<h3 class="anchored" data-anchor-id="definire-una-funzione-generale-di-classificazione-delle-immagini">Definire una funzione generale di Classificazione delle Immagini</h3>
Creiamo una funzione generale per dare un‚Äôimmagine come input e otteniamo le prime 5 classi possibili:
<div class="scroll-code-block">
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># load the image</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get quantization parameters</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dequantize the output and apply softmax</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>    dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    exp_output <span class="op">=</span> np.exp(dequantized_output <span class="op">-</span> np.<span class="bu">max</span>(dequantized_output))</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> exp_output <span class="op">/</span> np.<span class="bu">sum</span>(exp_output)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>            (<span class="bu">int</span>(probabilities[top_k_indices[i]]<span class="op">*</span><span class="dv">100</span>))))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>E caricando alcune immagini per i test, abbiamo:</p>
<p><img src="images/jpeg/img_class_func.jpg" class="img-fluid"></p>
</section>
<section id="test-con-un-modello-addestrato-da-zero" class="level3">
<h3 class="anchored" data-anchor-id="test-con-un-modello-addestrato-da-zero">Test con un modello addestrato da zero</h3>
<p>Addestriamo un modello TFLite da zero. Per questo, si pu√≤ seguire il Notebook:</p>
<p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN to classify Cifar-10 dataset</a></p>
<p>Nel notebook, abbiamo addestrato un modello utilizzando il dataset CIFAR10, che contiene 60.000 immagini da 10 classi di CIFAR (<em>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck</em>). CIFAR ha immagini a colori 32x32 (3 canali colore) in cui gli oggetti non sono centrati e possono avere l‚Äôoggetto con uno sfondo, come gli aerei che potrebbero avere un cielo nuvoloso dietro di loro! In breve, immagini piccole ma reali.</p>
<p>Il modello addestrato dalla CNN (<em>cifar10_model.keras</em>) aveva una dimensione di 2,0 MB. Utilizzando <em>TFLite Converter</em>, il modello <em>cifar10.tflite</em> √® diventato di 674 MB (circa 1/3 della dimensione originale).</p>
<p><img src="images/png/cifar10_model.png" class="img-fluid"></p>
<p>Sul notebook <a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Image Classification on a Raspi with TFLite</a> (che pu√≤ essere eseguito sul Raspi), possiamo seguire gli stessi passaggi che abbiamo fatto con <code>mobilenet_v2_1.0_224_quant.tflite</code>. Di seguito sono riportati esempi di immagini che utilizzano la <em>General Function for Image Classification</em> su un Raspi-Zero, come mostrato nell‚Äôultima sezione.</p>
<p><img src="images/png/infer-cifar10.png" class="img-fluid"></p>
</section>
<section id="installing-picamera2" class="level3">
<h3 class="anchored" data-anchor-id="installing-picamera2">Installing Picamera2</h3>
<p><a href="https://github.com/raspberrypi/picamera2">Picamera2</a>, una libreria Python per interagire con la fotocamera del Raspberry Pi, √® basata sullo stack della fotocamera <em>libcamera</em> e la Raspberry Pi Foundation la mantiene. La libreria Picamera2 √® supportata su tutti i modelli Raspberry Pi, dal Pi Zero al RPi 5. √à gi√† installata in tutto il sistema Raspi, ma dovremmo renderla accessibile all‚Äôinterno dell‚Äôambiente virtuale.</p>
<ol type="1">
<li><p>Per prima cosa, attivare l‚Äôambiente virtuale se non √® gi√† attivato:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">source</span> ~/tflite/bin/activate</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Ora, creiamo un file .pth nelll‚Äôambiente virtuale per aggiungere il percorso del sistema del pacchetto sul sito:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"/usr/lib/python3/dist-packages"</span> <span class="op">&gt;</span> <span class="va">$VIRTUAL_ENV</span>/lib/python3.11/</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="ex">site-packages/system_site_packages.pth</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Nota: se la versione di Python √® diversa, sostituire <code>python3.11</code> con la versione appropriata.</p>
</blockquote></li>
<li><p>Dopo aver creato questo file, provare a importare picamera2 in Python:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> import <span class="ex">picamera2</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> print<span class="kw">(</span><span class="ex">picamera2.__file__</span><span class="kw">)</span></span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
<p>Il codice sopra mostrer√† la posizione del file del modulo <code>picamera2</code> stesso, dimostrando che la libreria √® accessibile dall‚Äôambiente.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="op">/</span>home<span class="op">/</span>mjrovai<span class="op">/</span>tflite<span class="op">/</span>lib<span class="op">/</span>python3<span class="fl">.11</span><span class="op">/</span>site<span class="op">-</span>packages<span class="op">/</span>picamera2<span class="op">/</span><span class="fu">__init__</span>.py</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>√à anche possibile elencare le telecamere disponibili nel sistema:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="bu">print</span>(Picamera2.global_camera_info())</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Nel nostro caso, con una USB installata, si √® ottenuto:</p>
<p><img src="images/png/cam_installed.png" class="img-fluid"></p>
<p>Ora che abbiamo confermato che picamera2 funziona nell‚Äôambiente con un <code>indice 0</code>, proviamo un semplice script Python per catturare un‚Äôimmagine dalla fotocamera USB:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the camera</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2() <span class="co"># default is index 0</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure the camera</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_still_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">640</span>, <span class="dv">480</span>)})</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the camera</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Wait for the camera to warm up</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Capture an image</span></span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>picam2.capture_file(<span class="st">"usb_camera_image.jpg"</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Image captured and saved as 'usb_camera_image.jpg'"</span>)</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Stop the camera</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>picam2.stop()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Utilizzare l‚Äôeditor di testo Nano, Jupyter Notebook o qualsiasi altro editor. Salvarlo come script Python (ad esempio, <code>capture_image.py</code>) ed eseguilo. Questo dovrebbe catturare un‚Äôimmagine dalla fotocamera e salvarla come ‚Äúusb_camera_image.jpg‚Äù nella stessa directory dello script.</p>
<p><img src="images/png/capture_test.png" class="img-fluid"></p>
<p>Se Jupyter √® aperto, si pu√≤ vedere l‚Äôimmagine catturata sul computer. Altrimenti, si trasferisce il file dal Raspi al computer.</p>
<p><img src="images/png/img_test_result.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Se si sta lavorando con un Raspi-5 con un intero desktop, si pu√≤ aprire il file direttamente sul dispositivo.</p>
</blockquote>
</section>
</section>
<section id="progetto-di-classificazione-delle-immagini" class="level2">
<h2 class="anchored" data-anchor-id="progetto-di-classificazione-delle-immagini">Progetto di Classificazione delle Immagini</h2>
<p>Ora, svilupperemo un progetto completo di Classificazione delle Immagini utilizzando Edge Impulse Studio. Come abbiamo fatto con Movilinet V2, il modello TFLite addestrato e convertito verr√† utilizzato per l‚Äôinferenza.</p>
<section id="lobiettivo" class="level3">
<h3 class="anchored" data-anchor-id="lobiettivo">L‚ÄôObiettivo</h3>
<p>Il primo passo in qualsiasi progetto ML √® definire il suo obiettivo. In questo caso, √® rilevare e classificare due oggetti specifici presenti in un‚Äôimmagine. Per questo progetto, utilizzeremo due piccoli giocattoli: un robot e un piccolo pappagallo brasiliano (chiamato Periquito). Raccoglieremo anche immagini di un <em>background</em> in cui questi due oggetti sono assenti.</p>
<p><img src="images/jpeg/project_goal.jpg" class="img-fluid"></p>
</section>
<section id="raccolta-dati" class="level3">
<h3 class="anchored" data-anchor-id="raccolta-dati">Raccolta Dati</h3>
<p>Una volta definito l‚Äôobiettivo del nostro progetto di apprendimento automatico, il passaggio successivo, e pi√π cruciale, √® la raccolta del dataset. Possiamo utilizzare un telefono per l‚Äôacquisizione delle immagini, ma qui utilizzeremo il Raspi. Impostiamo un semplice server Web sul nostro Raspberry Pi per visualizzare le immagini <code>QVGA (320 x 240)</code> acquisite in un browser.</p>
<ol type="1">
<li><p>Per prima cosa, installiamo Flask, un framework Web leggero per Python:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip3</span> install flask</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Creiamo un nuovo script Python che combina l‚Äôacquisizione delle immagini con un server Web. Lo chiameremo <code>get_img_data.py</code>:</p></li>
</ol>
<div class="scroll-code-block">
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, redirect, url_for</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> signal</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>base_dir <span class="op">=</span> <span class="st">"dataset"</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>capture_counts <span class="op">=</span> {}</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>current_label <span class="op">=</span> <span class="va">None</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>shutdown_event <span class="op">=</span> threading.Event()</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a><span class="kw">global</span> picam2</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>picam2.configure(config)</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>picam2.start()</span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a><span class="kw">global</span> frame</span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> frame_lock:</span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth preview</span></span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> frame_lock:</span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a><span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a><span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust as needed for smooth streaming</span></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shutdown_server():</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a>shutdown_event.<span class="bu">set</span>()</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> picam2:</span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a>picam2.stop()</span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Give some time for other threads to finish</span></span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a>time.sleep(<span class="dv">2</span>)</span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Send SIGINT to the main process</span></span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a>os.kill(os.getpid(), signal.SIGINT)</span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>, methods<span class="op">=</span>[<span class="st">'GET'</span>, <span class="st">'POST'</span>])</span>
<span id="cb43-55"><a href="#cb43-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb43-56"><a href="#cb43-56" aria-hidden="true" tabindex="-1"></a><span class="kw">global</span> current_label</span>
<span id="cb43-57"><a href="#cb43-57" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> request.method <span class="op">==</span> <span class="st">'POST'</span>:</span>
<span id="cb43-58"><a href="#cb43-58" aria-hidden="true" tabindex="-1"></a>current_label <span class="op">=</span> request.form[<span class="st">'label'</span>]</span>
<span id="cb43-59"><a href="#cb43-59" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> current_label <span class="kw">not</span> <span class="kw">in</span> capture_counts:</span>
<span id="cb43-60"><a href="#cb43-60" aria-hidden="true" tabindex="-1"></a>capture_counts[current_label] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb43-61"><a href="#cb43-61" aria-hidden="true" tabindex="-1"></a>os.makedirs(os.path.join(base_dir, current_label), exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-62"><a href="#cb43-62" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-63"><a href="#cb43-63" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> render_template_string(<span class="st">'''&lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-64"><a href="#cb43-64" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;html&gt;</span></span>
<span id="cb43-65"><a href="#cb43-65" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;</span></span>
<span id="cb43-66"><a href="#cb43-66" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;title&gt;Dataset Capture - Label Entry&lt;/title&gt;</span></span>
<span id="cb43-67"><a href="#cb43-67" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/head&gt;</span></span>
<span id="cb43-68"><a href="#cb43-68" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;body&gt;</span></span>
<span id="cb43-69"><a href="#cb43-69" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;h1&gt;Enter Label for Dataset&lt;/h1&gt;</span></span>
<span id="cb43-70"><a href="#cb43-70" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;form method="post"&gt;&lt;input type="text" name="label" required&gt;</span></span>
<span id="cb43-71"><a href="#cb43-71" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;input type="submit" value="Start Capture"&gt;&lt;/form&gt;</span></span>
<span id="cb43-72"><a href="#cb43-72" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/body&gt;</span></span>
<span id="cb43-73"><a href="#cb43-73" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/html&gt;'''</span>)</span>
<span id="cb43-74"><a href="#cb43-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-75"><a href="#cb43-75" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture'</span>)</span>
<span id="cb43-76"><a href="#cb43-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_page():</span>
<span id="cb43-77"><a href="#cb43-77" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> render_template_string(<span class="st">'''&lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-78"><a href="#cb43-78" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;html&gt;</span></span>
<span id="cb43-79"><a href="#cb43-79" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;</span></span>
<span id="cb43-80"><a href="#cb43-80" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;title&gt;Dataset Capture&lt;/title&gt;</span></span>
<span id="cb43-81"><a href="#cb43-81" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;script&gt;var shutdownInitiated = false;</span></span>
<span id="cb43-82"><a href="#cb43-82" aria-hidden="true" tabindex="-1"></a><span class="st">function checkShutdown() {</span></span>
<span id="cb43-83"><a href="#cb43-83" aria-hidden="true" tabindex="-1"></a><span class="st">if (!shutdownInitiated) {</span></span>
<span id="cb43-84"><a href="#cb43-84" aria-hidden="true" tabindex="-1"></a><span class="st">fetch('/check_shutdown')</span></span>
<span id="cb43-85"><a href="#cb43-85" aria-hidden="true" tabindex="-1"></a><span class="st">.then(response =&gt; response.json())</span></span>
<span id="cb43-86"><a href="#cb43-86" aria-hidden="true" tabindex="-1"></a><span class="st">.then(data =&gt; {</span></span>
<span id="cb43-87"><a href="#cb43-87" aria-hidden="true" tabindex="-1"></a><span class="st">if (data.shutdown) {</span></span>
<span id="cb43-88"><a href="#cb43-88" aria-hidden="true" tabindex="-1"></a><span class="st">shutdownInitiated = true;</span></span>
<span id="cb43-89"><a href="#cb43-89" aria-hidden="true" tabindex="-1"></a><span class="st">document.getElementById('video-feed').src = '';</span></span>
<span id="cb43-90"><a href="#cb43-90" aria-hidden="true" tabindex="-1"></a><span class="st">document.getElementById('shutdown-message')</span></span>
<span id="cb43-91"><a href="#cb43-91" aria-hidden="true" tabindex="-1"></a><span class="st">.style.display = 'block';</span></span>
<span id="cb43-92"><a href="#cb43-92" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb43-93"><a href="#cb43-93" aria-hidden="true" tabindex="-1"></a><span class="st">});</span></span>
<span id="cb43-94"><a href="#cb43-94" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb43-95"><a href="#cb43-95" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb43-96"><a href="#cb43-96" aria-hidden="true" tabindex="-1"></a><span class="st">setInterval(checkShutdown, 1000);  // Check every second&lt;/script&gt;</span></span>
<span id="cb43-97"><a href="#cb43-97" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/head&gt;</span></span>
<span id="cb43-98"><a href="#cb43-98" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;body&gt;</span></span>
<span id="cb43-99"><a href="#cb43-99" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;h1&gt;Dataset Capture&lt;/h1&gt;</span></span>
<span id="cb43-100"><a href="#cb43-100" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;p&gt;Current Label: </span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-101"><a href="#cb43-101" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;p&gt;Images captured for this label: </span><span class="sc">{{</span><span class="st"> capture_count </span><span class="sc">}}</span><span class="st">&lt;/p&gt;</span></span>
<span id="cb43-102"><a href="#cb43-102" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;img id="video-feed" src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" </span></span>
<span id="cb43-103"><a href="#cb43-103" aria-hidden="true" tabindex="-1"></a><span class="st">            height="480" /&gt;&lt;div id="shutdown-message" style="display: none; color: red;"&gt;Capture process has been stopped. You can close this window.&lt;/div&gt;</span></span>
<span id="cb43-104"><a href="#cb43-104" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;form action="/capture_image" method="post"&gt;&lt;input type="submit" value="Capture Image"&gt;&lt;/form&gt;</span></span>
<span id="cb43-105"><a href="#cb43-105" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;form action="/stop" method="post"&gt;&lt;input type="submit" value="Stop Capture" </span></span>
<span id="cb43-106"><a href="#cb43-106" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ff6666;"&gt;&lt;/form&gt;</span></span>
<span id="cb43-107"><a href="#cb43-107" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;form action="/" method="get"&gt;&lt;input type="submit" value="Change Label" </span></span>
<span id="cb43-108"><a href="#cb43-108" aria-hidden="true" tabindex="-1"></a><span class="st">                style="background-color: #ffff66;"&gt;&lt;/form&gt;</span></span>
<span id="cb43-109"><a href="#cb43-109" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/body&gt;</span></span>
<span id="cb43-110"><a href="#cb43-110" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/html&gt;'''</span>, label<span class="op">=</span>current_label, capture_count<span class="op">=</span>capture_counts.get(current_label, <span class="dv">0</span>))</span>
<span id="cb43-111"><a href="#cb43-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-112"><a href="#cb43-112" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb43-113"><a href="#cb43-113" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb43-114"><a href="#cb43-114" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb43-115"><a href="#cb43-115" aria-hidden="true" tabindex="-1"></a>mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb43-116"><a href="#cb43-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-117"><a href="#cb43-117" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/capture_image'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-118"><a href="#cb43-118" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> capture_image():</span>
<span id="cb43-119"><a href="#cb43-119" aria-hidden="true" tabindex="-1"></a><span class="kw">global</span> capture_counts</span>
<span id="cb43-120"><a href="#cb43-120" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> current_label <span class="kw">and</span> <span class="kw">not</span> shutdown_event.is_set():</span>
<span id="cb43-121"><a href="#cb43-121" aria-hidden="true" tabindex="-1"></a>capture_counts[current_label] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb43-122"><a href="#cb43-122" aria-hidden="true" tabindex="-1"></a>timestamp <span class="op">=</span> time.strftime(<span class="st">"%Y%m</span><span class="sc">%d</span><span class="st">-%H%M%S"</span>)</span>
<span id="cb43-123"><a href="#cb43-123" aria-hidden="true" tabindex="-1"></a>filename <span class="op">=</span> <span class="ss">f"image_</span><span class="sc">{</span>timestamp<span class="sc">}</span><span class="ss">.jpg"</span></span>
<span id="cb43-124"><a href="#cb43-124" aria-hidden="true" tabindex="-1"></a>full_path <span class="op">=</span> os.path.join(base_dir, current_label, filename)</span>
<span id="cb43-125"><a href="#cb43-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-126"><a href="#cb43-126" aria-hidden="true" tabindex="-1"></a>    picam2.capture_file(full_path)</span>
<span id="cb43-127"><a href="#cb43-127" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-128"><a href="#cb43-128" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> redirect(url_for(<span class="st">'capture_page'</span>))</span>
<span id="cb43-129"><a href="#cb43-129" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb43-130"><a href="#cb43-130" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop():</span>
<span id="cb43-131"><a href="#cb43-131" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> render_template_string(<span class="st">'''&lt;!DOCTYPE html&gt;</span></span>
<span id="cb43-132"><a href="#cb43-132" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;html&gt;</span></span>
<span id="cb43-133"><a href="#cb43-133" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;head&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt;</span></span>
<span id="cb43-134"><a href="#cb43-134" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;title&gt;Dataset Capture - Stopped&lt;/title&gt;</span></span>
<span id="cb43-135"><a href="#cb43-135" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/head&gt;</span></span>
<span id="cb43-136"><a href="#cb43-136" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;body&gt;</span></span>
<span id="cb43-137"><a href="#cb43-137" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;h1&gt;Dataset Capture Stopped&lt;/h1&gt;</span></span>
<span id="cb43-138"><a href="#cb43-138" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;p&gt;The capture process has been stopped. You can close this window.&lt;/p&gt;</span></span>
<span id="cb43-139"><a href="#cb43-139" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;p&gt;Summary of captures:&lt;/p&gt;</span></span>
<span id="cb43-140"><a href="#cb43-140" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;ul&gt;{</span><span class="sc">% f</span><span class="st">or label, count in capture_counts.items() %}&lt;li&gt;</span><span class="sc">{{</span><span class="st"> label </span><span class="sc">}}</span><span class="st">: </span><span class="sc">{{</span><span class="st"> count </span><span class="sc">}}</span><span class="st"> images&lt;/li&gt;{</span><span class="sc">% e</span><span class="st">ndfor %}&lt;/ul&gt;</span></span>
<span id="cb43-141"><a href="#cb43-141" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/body&gt;</span></span>
<span id="cb43-142"><a href="#cb43-142" aria-hidden="true" tabindex="-1"></a><span class="st">&lt;/html&gt;'''</span>, capture_counts<span class="op">=</span>capture_counts)</span>
<span id="cb43-143"><a href="#cb43-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-144"><a href="#cb43-144" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Start a new thread to shutdown the server</span></span>
<span id="cb43-145"><a href="#cb43-145" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>shutdown_server).start()</span>
<span id="cb43-146"><a href="#cb43-146" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb43-147"><a href="#cb43-147" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> summary</span>
<span id="cb43-148"><a href="#cb43-148" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/check_shutdown'</span>)</span>
<span id="cb43-149"><a href="#cb43-149" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_shutdown():</span>
<span id="cb43-150"><a href="#cb43-150" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> {<span class="st">'shutdown'</span>: shutdown_event.is_set()}</span>
<span id="cb43-151"><a href="#cb43-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-152"><a href="#cb43-152" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb43-153"><a href="#cb43-153" aria-hidden="true" tabindex="-1"></a>initialize_camera()</span>
<span id="cb43-154"><a href="#cb43-154" aria-hidden="true" tabindex="-1"></a>threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb43-155"><a href="#cb43-155" aria-hidden="true" tabindex="-1"></a>app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="1">
<li><p>Eseguire questo script:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> get_img_data.py</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Accedere all‚Äôinterfaccia web:</p>
<ul>
<li>Sul Raspberry Pi stesso (se si ha una GUI): Aprire un browser web e andare su <code>http://localhost:5000</code></li>
<li>Da un altro dispositivo sulla stessa rete: Aprire un browser web e andare su <code>http://&lt;raspberry_pi_ip&gt;:5000</code> (Sostituire <code>&lt;raspberry_pi_ip&gt;</code> con l‚Äôindirizzo IP del Raspberry Pi). Per esempio: <code>http://192.168.4.210:5000/</code></li>
</ul></li>
</ol>
<p>Questo script Python crea un‚Äôinterfaccia basata sul web per catturare e organizzare set di dati di immagini usando un Raspberry Pi e la sua fotocamera. √à utile per progetti di apprendimento automatico che richiedono dati di immagini etichettati.</p>
<section id="caratteristiche-principali" class="level4">
<h4 class="anchored" data-anchor-id="caratteristiche-principali">Caratteristiche Principali:</h4>
<ol type="1">
<li>*Interfaccia Web**: Accessibile da qualsiasi dispositivo sulla stessa rete del Raspberry Pi.</li>
<li><strong>Anteprima Telecamera in Tempo Reale</strong>: Mostra un feed in tempo reale dalla telecamera.</li>
<li>*Sistema di Etichettatura**: Consente agli utenti di immettere etichette per diverse categorie di immagini.</li>
<li>*Archiviazione Organizzata**: Salva automaticamente le immagini in sottodirectory specifiche per etichetta..</li>
<li><strong>Contatori per Etichetta</strong>: Tiene traccia di quante immagini vengono acquisite per ogni etichetta.</li>
<li>*Statistiche di Riepilogo**: Fornisce un riepilogo delle immagini acquisite quando si interrompe il processo di acquisizione.</li>
</ol>
</section>
<section id="componenti-principali" class="level4">
<h4 class="anchored" data-anchor-id="componenti-principali">Componenti Principali:</h4>
<ol type="1">
<li>*Applicazione Web Flask**: Gestisce il routing e serve l‚Äôinterfaccia Web.</li>
<li><strong>Integrazione di Picamera2</strong>: Controlla la telecamera Raspberry Pi.</li>
<li><strong>Threaded Frame Capture</strong>: Assicura un‚Äôanteprima live fluida.</li>
<li><strong>File Management</strong>: Organizza le immagini catturate in directory etichettate.</li>
</ol>
</section>
<section id="funzioni-chiave" class="level4">
<h4 class="anchored" data-anchor-id="funzioni-chiave">Funzioni Chiave:</h4>
<ul>
<li><code>initialize_camera()</code>: Imposta l‚Äôistanza Picamera2.</li>
<li><code>get_frame()</code>: Cattura continuamente i frame per l‚Äôanteprima live.</li>
<li><code>generate_frames()</code>: Genera i frame per il feed video live.</li>
<li><code>shutdown_server()</code>: Imposta l‚Äôevento di arresto, arresta la telecamera e arresta il server Flask</li>
<li><code>index()</code>: Gestisce la pagina di input dell‚Äôetichetta.</li>
<li><code>capture_page()</code>: Visualizza l‚Äôinterfaccia di acquisizione principale.</li>
<li><code>video_feed()</code>: Mostra un‚Äôanteprima live per posizionare la telecamera</li>
<li><code>capture_image()</code>: Salva un‚Äôimmagine con l‚Äôetichetta corrente.</li>
<li><code>stop()</code>: Arresta il processo di acquisizione e visualizza un riepilogo.</li>
</ul>
</section>
<section id="flusso-di-utilizzo" class="level4">
<h4 class="anchored" data-anchor-id="flusso-di-utilizzo">Flusso di Utilizzo:</h4>
<ol type="1">
<li>Avviare lo script sul Raspberry Pi.</li>
<li>Accedere all‚Äôinterfaccia web da un browser.</li>
<li>Inserire un‚Äôetichetta per le immagini da catturare e premere <code>Start Capture</code>.</li>
</ol>
<p><img src="images/png/enter_label.png" class="img-fluid"></p>
<ol start="4" type="1">
<li>Utilizzare l‚Äôanteprima live per posizionare la telecamera.</li>
<li>Cliccare <code>Capture Image</code> per salvare le immagini sotto l‚Äôetichetta corrente.</li>
</ol>
<p><img src="images/png/capture.png" class="img-fluid"></p>
<ol start="6" type="1">
<li>Cambiare le etichette come necessario per le diverse categorie, selezionando <code>Change Label</code>.</li>
<li>Cliccare <code>Stop Capture</code> al termine per vedere un riepilogo.</li>
</ol>
<p><img src="images/png/stop.png" class="img-fluid"></p>
</section>
<section id="note-tecniche" class="level4">
<h4 class="anchored" data-anchor-id="note-tecniche">Note Tecniche:</h4>
<ul>
<li>Lo script usa il threading per gestire la cattura di frame e il web serving simultanei.</li>
<li>Le immagini vengono salvate con timestamp nei nomi dei file per renderle uniche.</li>
<li>L‚Äôinterfaccia web √® reattiva e accessibile da dispositivi mobili.</li>
</ul>
</section>
<section id="possibilit√†-di-personalizzazione" class="level4">
<h4 class="anchored" data-anchor-id="possibilit√†-di-personalizzazione">Possibilit√† di Personalizzazione:</h4>
<ul>
<li>Regolare la risoluzione dell‚Äôimmagine nella funzione <code>initialize_camera()</code>. Qui abbiamo utilizzato QVGA (320X240).</li>
<li>Modificare i modelli HTML per un aspetto diverso.</li>
<li>Aggiungere ulteriori passaggi di elaborazione o analisi delle immagini nella funzione <code>capture_image()</code>.</li>
</ul>
</section>
<section id="numero-di-campioni-sul-dataset" class="level4">
<h4 class="anchored" data-anchor-id="numero-di-campioni-sul-dataset">Numero di campioni sul Dataset:</h4>
<p>Si ottengono circa 60 immagini da ciascuna categoria (<code>periquito</code>, <code>robot</code> e <code>background</code>). Provare ad acquisire con diverse angolazioni, sfondi e condizioni di luce. Sul Raspi, finiremo con una cartella denominata <code>dataset</code>, che contiene 3 sottocartelle <em>periquito</em>, <em>robot</em> e <em>background</em>. una per ogni classe di immagini.</p>
<p>Si pu√≤ usare <code>Filezilla</code> per trasferire il dataset creato sul computer principale.</p>
</section>
</section>
</section>
<section id="addestramento-del-modello-con-edge-impulse" class="level2">
<h2 class="anchored" data-anchor-id="addestramento-del-modello-con-edge-impulse">Addestramento del modello con Edge Impulse</h2>
<p>Useremo Edge Impulse Studio per addestrare il modello. Si va nella <a href="https://edgeimpulse.com/">Pagina di Edge Impulse</a>, si inseriscono le credenziali e si crea un nuovo progetto:</p>
<p><img src="images/png/new-proj-ei.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Qui si pu√≤ clonare un progetto simile: <a href="https://studio.edgeimpulse.com/public/510251/live">Raspi - Img Class</a>.</p>
</blockquote>
<section id="dataset" class="level3">
<h3 class="anchored" data-anchor-id="dataset">Dataset</h3>
<p>Esamineremo quattro passaggi principali usando EI Studio (o Studio). Questi passaggi sono fondamentali per preparare il nostro modello per l‚Äôuso sul Raspi: Dataset, Impulse, Test e Deploy (sul dispositivo Edge, in questo caso, il Raspi).</p>
<blockquote class="blockquote">
<p>Per quanto riguarda il Dataset, √® essenziale sottolineare che il nostro Dataset originale, acquisito con il Raspi, sar√† suddiviso in <em>Training</em>, <em>Validation</em> e <em>Test</em>. Il Test Set sar√† separato dall‚Äôinizio e riservato per l‚Äôuso solo nella fase di Test dopo l‚Äôaddestramento. Il Validation Set sar√† utilizzato durante l‚Äôaddestramento.</p>
</blockquote>
<p>Su Studio, seguire i passaggi per caricare i dati acquisiti:</p>
<ol type="1">
<li>Si va nella scheda <code>Data acquisition</code> e nella sezione <code>UPLOAD DATA</code>, si caricano i file dal computer nelle categorie scelte.</li>
<li>Lasciare a Studio la suddivisione del dataset originale in <em>train and test</em> e scegliere l‚Äôetichetta a riguardo</li>
<li>Ripetere la procedura per tutte e tre le classi. Alla fine, si vedranno i ‚Äúraw data‚Äù in Studio:</li>
</ol>
<p><img src="images/png/data-Aquisition.png" class="img-fluid"></p>
<p>Studio consente di esplorare i dati, mostrando una vista completa di tutti i quelli nel progetto. Si possono cancellare, ispezionare o modificare le etichette cliccando sui singoli elementi di dati. Nel nostro caso, un progetto semplice, i dati sembrano OK.</p>
<p><img src="images/png/data-esplorer.png" class="img-fluid"></p>
</section>
</section>
<section id="il-progetto-impulse" class="level2">
<h2 class="anchored" data-anchor-id="il-progetto-impulse">Il Progetto Impulse</h2>
<p>In questa fase, dovremmo definire come:</p>
<ul>
<li><p>Pre-elaborare i nostri dati, il che consiste nel ridimensionare le singole immagini e determinare la <code>color depth</code> [profondit√† di colore] da utilizzare (sia RGB che in scala di grigi) e</p></li>
<li><p>Specificare un Modello. In questo caso, sar√† <code>Transfer Learning (Images)</code> a mettere a punto un modello di classificazione delle immagini MobileNet V2 pre-addestrato sui nostri dati. Questo metodo funziona bene anche con set di dati di immagini relativamente piccoli (circa 180 immagini nel nostro caso).</p></li>
</ul>
<p>Transfer Learning con MobileNet offre un approccio semplificato all‚Äôaddestramento del modello, che √® particolarmente utile per ambienti con risorse limitate e progetti con dati etichettati limitati. MobileNet, noto per la sua architettura leggera, √® un modello pre-addestrato che ha gi√† appreso funzionalit√† preziose da un ampio set di dati (ImageNet).</p>
<p><img src="images/jpeg/model_1.jpg" class="img-fluid"></p>
<p>Sfruttando queste funzionalit√† apprese, possiamo addestrare un nuovo modello per il compito specifico con meno dati e risorse computazionali e raggiungere un‚Äôaccuratezza competitiva.</p>
<p><img src="images/jpeg/model_2.jpg" class="img-fluid"></p>
<p>Questo approccio riduce significativamente i tempi di addestramento e i costi computazionali, rendendolo ideale per la prototipazione rapida e l‚Äôimplementazione su dispositivi embedded in cui l‚Äôefficienza √® fondamentale.</p>
<p>Si va alla scheda Impulse Design e si crea l‚Äô<em>impulse</em>, definendo una dimensione dell‚Äôimmagine di 160x160 e schiacciandola (forma quadrata, senza ritaglio). Si seleziona Image e i blocchi Transfer Learning. Si salva l‚ÄôImpulse.</p>
<p><img src="images/png/impulse.png" class="img-fluid"></p>
<section id="pre-elaborazione-delle-immagini" class="level3">
<h3 class="anchored" data-anchor-id="pre-elaborazione-delle-immagini">Pre-elaborazione delle immagini</h3>
<p>Tutte le immagini QVGA/RGB565 in ingresso verranno convertite in 76.800 feature (160x160x3).</p>
<p><img src="images/png/preproc.png" class="img-fluid"></p>
<p>Premere <code>Save parameters</code> e selezionare <code>Generate features</code> nella scheda successiva.</p>
</section>
<section id="progettazione-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="progettazione-del-modello">Progettazione del modello</h3>
<p>MobileNet √® una famiglia di reti neurali convoluzionali efficienti progettate per applicazioni di visione mobile e embedded. Le caratteristiche principali di MobileNet sono:</p>
<ol type="1">
<li>Leggero: Ottimizzato per dispositivi mobili e sistemi embedded con risorse di calcolo limitate.</li>
<li>Velocit√†: Tempi di inferenza rapidi, adatti per applicazioni in tempo reale.</li>
<li>Precisione: Mantiene una buona accuratezza nonostante le dimensioni compatte.</li>
</ol>
<p><a href="https://arxiv.org/abs/1801.04381">MobileNetV2</a>, introdotto nel 2018, migliora l‚Äôarchitettura MobileNet originale. Le caratteristiche principali includono:</p>
<ol type="1">
<li>Residui Invertiti: Le strutture residue invertite vengono utilizzate quando vengono create connessioni di scelta rapida tra layer di colli di bottiglia sottili.</li>
<li>Colli di Bottiglia Lineari: Rimuove le non linearit√† nei layer stretti per impedire la distruzione delle informazioni.</li>
<li>Convoluzioni Separabili in Profondit√†: Continua a utilizzare questa efficiente operazione da MobileNetV1.</li>
</ol>
<p>Nel nostro progetto, faremo un <code>Transfer Learning</code> con <code>MobileNetV2 160x160 1.0</code>, il che significa che le immagini utilizzate per l‚Äôaddestramento (e l‚Äôinferenza futura) dovrebbero avere una <em>input Size</em> [dimensione di input] di 160x160 pixel e un <em>Width Multiplier</em> [moltiplicatore di larghezza] di 1.0 (larghezza completa, non ridotta). Questa configurazione bilancia tra dimensione del modello, velocit√† e accuratezza.</p>
</section>
<section id="training-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="training-del-modello">Training del Modello</h3>
<p>Un‚Äôaltra preziosa tecnica di apprendimento profondo √® il <strong>Data Augmentation</strong>. Il ‚Äúdata augmentation‚Äù migliora l‚Äôaccuratezza dei modelli di apprendimento automatico creando dati artificiali aggiuntivi. Un sistema di data augmentation apporta piccole modifiche casuali ai dati di training durante l‚Äôaddestramento (ad esempio capovolgendo, ritagliando o ruotando le immagini).</p>
<p>Guardando internamente, qui si pu√≤ vedere come Edge Impulse implementa una policy di data Augmentation sui dati:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Implements the data augmentation policy</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> augment_image(image, label):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flips the image randomly</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_flip_left_right(image)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Increase the image size, then randomly crop it down to</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># the original dimensions</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>    resize_factor <span class="op">=</span> random.uniform(<span class="dv">1</span>, <span class="fl">1.2</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>    new_height <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">0</span>])</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>    new_width <span class="op">=</span> math.floor(resize_factor <span class="op">*</span> INPUT_SHAPE[<span class="dv">1</span>])</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize_with_crop_or_pad(image, new_height, new_width)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_crop(image, size<span class="op">=</span>INPUT_SHAPE)</span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Vary the brightness of the image</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> tf.image.random_brightness(image, max_delta<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> image, label</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>L‚Äôesposizione a queste variazioni durante l‚Äôaddestramento pu√≤ aiutare a impedire al modello di prendere scorciatoie ‚Äúmemorizzando‚Äù indizi superficiali nei dati di addestramento, il che significa che potrebbe riflettere meglio i pattern profondi in esame nel set di dati.</p>
<p>L‚Äôultimo layer denso del nostro modello avr√† 0 neuroni con un dropout del 10% per prevenire il sovradattamento. Ecco il risultato del Training:</p>
<p><img src="images/png/result-train.png" class="img-fluid"></p>
<p>Il risultato √® eccellente, con una latenza ragionevole di 35 ms (per un Raspi-4), che dovrebbe tradursi in circa 30 fps (fotogrammi al secondo) durante l‚Äôinferenza. Un Raspi-Zero dovrebbe essere pi√π lento e il Raspi-5 pi√π veloce.</p>
</section>
<section id="compromesso-accuratezza-contro-velocit√†" class="level3">
<h3 class="anchored" data-anchor-id="compromesso-accuratezza-contro-velocit√†">Compromesso: Accuratezza contro Velocit√†</h3>
<p>Se √® necessaria un‚Äôinferenza pi√π rapida, dovremmo addestrare il modello usando alfa pi√π piccoli (0.35, 0.5 e 0.75) o persino ridurre le dimensioni dell‚Äôimmagine in ingresso, a discapito dell‚Äôaccuratezza. Tuttavia, ridurre le dimensioni dell‚Äôimmagine in ingresso e diminuire l‚Äôalfa (moltiplicatore di larghezza) pu√≤ accelerare l‚Äôinferenza per MobileNet V2, ma hanno compromessi diversi. Confrontiamoli:</p>
<ol type="1">
<li>Riduzione delle Dimensioni dell‚ÄôImmagine in Ingresso:</li>
</ol>
<p>Pro:</p>
<ul>
<li>Riduce significativamente il costo computazionale su tutti i layer.</li>
<li>Riduce l‚Äôutilizzo della memoria.</li>
<li>Spesso fornisce un aumento sostanziale della velocit√†.</li>
</ul>
<p>Contro:</p>
<ul>
<li>Potrebbe ridurre la capacit√† del modello di rilevare piccole caratteristiche o dettagli fini.</li>
<li>Pu√≤ avere un impatto significativo sulla precisione, specialmente per le attivit√† che richiedono un riconoscimento a grana fine.</li>
</ul>
<ol start="2" type="1">
<li>Riduzione di Alpha (Moltiplicatore di Larghezza):</li>
</ol>
<p>Pro:</p>
<ul>
<li>Riduce il numero di parametri e calcoli nel modello.</li>
<li>Mantiene la risoluzione di input originale, preservando potenzialmente pi√π dettagli.</li>
<li>Pu√≤ fornire un buon equilibrio tra velocit√† e precisione.</li>
</ul>
<p>Contro:</p>
<ul>
<li>Potrebbe non accelerare l‚Äôinferenza in modo cos√¨ drastico come la riduzione delle dimensioni di input.</li>
<li>Pu√≤ ridurre la capacit√† del modello di apprendere caratteristiche complesse.</li>
</ul>
<p>Confronto:</p>
<ol type="1">
<li>Impatto sulla Velocit√†:
<ul>
<li>La riduzione delle dimensioni di input spesso fornisce un aumento di velocit√† pi√π sostanziale perch√© riduce i calcoli in modo quadratico (dimezzando sia la larghezza che l‚Äôaltezza si riducono i calcoli di circa il 75%).</li>
<li>La riduzione di Alpha fornisce una riduzione pi√π lineare nei calcoli.</li>
</ul></li>
<li>Impatto sulla Precisione:
<ul>
<li>La riduzione delle dimensioni di input pu√≤ avere un impatto significativo sulla precisione, specialmente quando si rilevano piccoli oggetti o dettagli fini.</li>
<li>La riduzione di alpha tende ad avere un impatto pi√π graduale sulla precisione.</li>
</ul></li>
<li>Architettura del Modello:
<ul>
<li>La modifica delle dimensioni di input non altera l‚Äôarchitettura del modello.</li>
<li>La modifica di alpha modifica la struttura del modello riducendo il numero di canali in ogni layer.</li>
</ul></li>
</ol>
<p>Raccomandazione:</p>
<ol type="1">
<li>Se l‚Äôapplicazione non richiede il rilevamento di piccoli dettagli e pu√≤ tollerare una certa perdita di accuratezza, ridurre le dimensioni di input √® spesso il modo pi√π efficace per accelerare l‚Äôinferenza.</li>
<li>Ridurre l‚Äôalfa potrebbe essere preferibile se mantenere la capacit√† di rilevare dettagli fini √® fondamentale o se c‚Äô√® bisogno di un compromesso pi√π equilibrato tra velocit√† e accuratezza.</li>
<li>Per ottenere risultati migliori, si devono sperimentare entrambi:
<ul>
<li>Provare MobileNet V2 con dimensioni di input come 160x160 o 92x92</li>
<li>Sperimentare con valori alfa come 1.0, 0.75, 0.5 o 0.35.</li>
</ul></li>
<li>Eseguire sempre il benchmark delle diverse configurazioni sull‚Äôhardware specifico e con il particolare set di dati per trovare l‚Äôequilibrio ottimale per il caso d‚Äôuso.</li>
</ol>
<blockquote class="blockquote">
<p>Ricordarsi che la scelta migliore dipende dai requisiti specifici di accuratezza, velocit√† e dalla natura delle immagini con cui si sta lavorando. Spesso vale la pena sperimentare combinazioni per trovare la configurazione ottimale per il particolare caso d‚Äôuso.</p>
</blockquote>
</section>
<section id="test-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="test-del-modello">Test del Modello</h3>
<p>Ora, si deve prendere il set di dati all‚Äôinizio del progetto ed eseguire il modello addestrato usandolo come input. Di nuovo, il risultato √® eccellente (92,22%).</p>
</section>
<section id="distribuzione-del-modello" class="level3">
<h3 class="anchored" data-anchor-id="distribuzione-del-modello">Distribuzione del modello</h3>
<p>Come abbiamo fatto nella sezione precedente, possiamo distribuire il modello addestrato come .tflite e usare Raspi per eseguirlo usando Python.</p>
<p>Nella scheda <code>Dashboard</code>, si va su Transfer learning model (int8 quantized) e si clicca sull‚Äôicona di download:</p>
<p><img src="images/png/model.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>Scarichiamo anche la versione float32 per il confronto</p>
</blockquote>
<p>Trasferire il modello dal computer al Raspi (./models), ad esempio, usando FileZilla. Catturare, inoltre, alcune immagini per l‚Äôinferenza (./images).</p>
<p>Importare le librerie necessarie:</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Definire i path e le etichette:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"./images/robot.jpg"</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<blockquote class="blockquote">
<p>Notare che i modelli addestrati su Edge Impulse Studio produrranno valori con indice 0, 1, 2, ecc., dove le etichette effettive seguiranno un ordine alfabetico.</p>
</blockquote>
<p>Caricare il modello, allocare i tensori e ottenere i dettagli dei tensori di input e output:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the TFLite model</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>interpreter.allocate_tensors()</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get input and output tensors</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>output_details <span class="op">=</span> interpreter.get_output_details()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Una differenza importante da notare √® che il <code>dtype</code> dei dettagli di input del modello √® ora <code>int8</code>, il che significa che i valori di input vanno da -128 a +127, mentre ogni pixel della nostra immagine va da 0 a 255. Ci√≤ significa che dovremmo pre-elaborare l‚Äôimmagine per farla corrispondere. Possiamo controllare qui:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>input_dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>numpy.int8</code></pre>
<p>Quindi, apriamo l‚Äôimmagine e mostriamola:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(img)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer_robot.png" class="img-fluid"></p>
<p>Ed eseguiamo la pre-elaborazione:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>                  input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Controllando i dati di input, possiamo verificare che il tensore di input √® compatibile con quanto previsto dal modello:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>input_data.shape, input_data.dtype</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>((1, 160, 160, 3), dtype('int8'))</code></pre>
<p>Adesso √® il momento di effettuare l‚Äôinferenza. Calcoliamo anche la latenza del modello:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>interpreter.invoke()</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">"Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Il modello impiegher√† circa 125 ms per eseguire l‚Äôinferenza nel Raspi-Zero, che dura 3 o 4 volte pi√π a lungo di un Raspi-5.</p>
<p>Ora possiamo ottenere le etichette di output e le probabilit√†. √à anche importante notare che il modello addestrato su Edge Impulse Studio ha un softmax nel suo output (diverso dal Movilenet V2 originale) e dovremmo usare l‚Äôoutput grezzo del modello come ‚Äúprobabilit√†‚Äù.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtain results and map them to the classes</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get indices of the top k results</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>top_k_results<span class="op">=</span><span class="dv">3</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Get quantization parameters</span></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Dequantize the output</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>dequantized_output <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> dequantized_output</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-15"><a href="#cb56-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb56-16"><a href="#cb56-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb56-17"><a href="#cb56-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb56-18"><a href="#cb56-18" aria-hidden="true" tabindex="-1"></a>        labels[top_k_indices[i]],</span>
<span id="cb56-19"><a href="#cb56-19" aria-hidden="true" tabindex="-1"></a>        probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><img src="images/png/infer-result.png" class="img-fluid"></p>
<p>Modifichiamo la funzione creata in precedenza in modo da poter gestire diversi tipi di modelli:</p>
<div class="scroll-code-block">
<div class="sourceCode" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> image_classification(img_path, model_path, labels, top_k_results<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>                         apply_softmax<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the image</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img)</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the TFLite model</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>    interpreter.allocate_tensors()</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get input and output tensors</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preprocess</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    input_dtype <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> input_dtype <span class="op">==</span> np.uint8:</span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> input_dtype <span class="op">==</span> np.int8:</span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> input_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> np.array(img, dtype<span class="op">=</span>np.float32) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a>        img_array <span class="op">=</span> (img_array <span class="op">/</span> scale <span class="op">+</span> zero_point).clip(<span class="op">-</span><span class="dv">128</span>, <span class="dv">127</span>).astype(np.int8)</span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(img_array, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:  <span class="co"># float32</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a>        input_data <span class="op">=</span> np.expand_dims(np.array(img, dtype<span class="op">=</span>np.float32), axis<span class="op">=</span><span class="dv">0</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-33"><a href="#cb57-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inference on Raspi-Zero</span></span>
<span id="cb57-34"><a href="#cb57-34" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb57-35"><a href="#cb57-35" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb57-36"><a href="#cb57-36" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb57-37"><a href="#cb57-37" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb57-38"><a href="#cb57-38" aria-hidden="true" tabindex="-1"></a>    inference_time <span class="op">=</span> (end_time <span class="op">-</span> start_time) <span class="op">*</span> <span class="dv">1000</span>  <span class="co"># Convert to milliseconds</span></span>
<span id="cb57-39"><a href="#cb57-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-40"><a href="#cb57-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Obtain results</span></span>
<span id="cb57-41"><a href="#cb57-41" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb57-42"><a href="#cb57-42" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-43"><a href="#cb57-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get indices of the top k results</span></span>
<span id="cb57-44"><a href="#cb57-44" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> np.argsort(predictions)[::<span class="op">-</span><span class="dv">1</span>][:top_k_results]</span>
<span id="cb57-45"><a href="#cb57-45" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-46"><a href="#cb57-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb57-47"><a href="#cb57-47" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb57-48"><a href="#cb57-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb57-49"><a href="#cb57-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb57-50"><a href="#cb57-50" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb57-51"><a href="#cb57-51" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb57-52"><a href="#cb57-52" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-53"><a href="#cb57-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> apply_softmax:</span>
<span id="cb57-54"><a href="#cb57-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply softmax</span></span>
<span id="cb57-55"><a href="#cb57-55" aria-hidden="true" tabindex="-1"></a>        exp_preds <span class="op">=</span> np.exp(predictions <span class="op">-</span> np.<span class="bu">max</span>(predictions))</span>
<span id="cb57-56"><a href="#cb57-56" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> exp_preds <span class="op">/</span> np.<span class="bu">sum</span>(exp_preds)</span>
<span id="cb57-57"><a href="#cb57-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb57-58"><a href="#cb57-58" aria-hidden="true" tabindex="-1"></a>        probabilities <span class="op">=</span> predictions</span>
<span id="cb57-59"><a href="#cb57-59" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb57-60"><a href="#cb57-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n\t</span><span class="st">[PREDICTION]        [Prob]</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb57-61"><a href="#cb57-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(top_k_results):</span>
<span id="cb57-62"><a href="#cb57-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\t</span><span class="sc">{:20}</span><span class="st">: </span><span class="sc">{:.1f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb57-63"><a href="#cb57-63" aria-hidden="true" tabindex="-1"></a>            labels[top_k_indices[i]],</span>
<span id="cb57-64"><a href="#cb57-64" aria-hidden="true" tabindex="-1"></a>            probabilities[top_k_indices[i]] <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb57-65"><a href="#cb57-65" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span> (<span class="st">"</span><span class="ch">\n\t</span><span class="st">Inference time: </span><span class="sc">{:.1f}</span><span class="st">ms"</span>.<span class="bu">format</span>(inference_time))</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>E lo si testa con immagini diverse e con il modello quantizzato int8 (<strong>160x160 alpha =1.0</strong>).</p>
<p><img src="images/png/infer-int8-160.png" class="img-fluid"></p>
<p>Scarichiamo un modello pi√π piccolo, come quello addestrato per il <a href="https://studio.edgeimpulse.com/public/353482/live">Nicla Vision Lab</a> (int8 quantized model, 96x96, alpha = 0.1), come test. Possiamo usare la stessa funzione:</p>
<p><img src="images/png/infer-int8-96.png" class="img-fluid"></p>
<p>Il modello ha perso un po‚Äô di accuratezza, ma √® ancora OK dato che non cerca molti dettagli. Per quanto riguarda la latenza, siamo circa <strong>dieci volte pi√π veloci</strong> su Raspi-Zero.</p>
</section>
</section>
<section id="classificazione-delle-immagini-in-tempo-reale" class="level2">
<h2 class="anchored" data-anchor-id="classificazione-delle-immagini-in-tempo-reale">Classificazione delle Immagini in Tempo Reale</h2>
<p>Sviluppiamo un‚Äôapp per catturare immagini con la fotocamera USB in tempo reale, mostrandone la classificazione.</p>
Utilizzando nano sul terminale, salvare il codice sottostante, come <code>img_class_live_infer.py</code>.
<div class="scroll-code-block">
<div class="sourceCode" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> flask <span class="im">import</span> Flask, Response, render_template_string, request, jsonify</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> picamera2 <span class="im">import</span> Picamera2</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> threading</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tflite_runtime.interpreter <span class="im">as</span> tflite</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> queue <span class="im">import</span> Queue</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> Flask(<span class="va">__name__</span>)</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>picam2 <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>frame <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>frame_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>confidence_threshold <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>model_path <span class="op">=</span> <span class="st">"./models/ei-raspi-img-class-int8-quantized-model.tflite"</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'background'</span>, <span class="st">'periquito'</span>, <span class="st">'robot'</span>]</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>interpreter <span class="op">=</span> <span class="va">None</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>classification_queue <span class="op">=</span> Queue(maxsize<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_camera():</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> picam2</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>    picam2 <span class="op">=</span> Picamera2()</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>    config <span class="op">=</span> picam2.create_preview_configuration(main<span class="op">=</span>{<span class="st">"size"</span>: (<span class="dv">320</span>, <span class="dv">240</span>)})</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>    picam2.configure(config)</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>    picam2.start()</span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">2</span>)  <span class="co"># Wait for camera to warm up</span></span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_frame():</span>
<span id="cb58-33"><a href="#cb58-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> frame</span>
<span id="cb58-34"><a href="#cb58-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-35"><a href="#cb58-35" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> io.BytesIO()</span>
<span id="cb58-36"><a href="#cb58-36" aria-hidden="true" tabindex="-1"></a>        picam2.capture_file(stream, <span class="bu">format</span><span class="op">=</span><span class="st">'jpeg'</span>)</span>
<span id="cb58-37"><a href="#cb58-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb58-38"><a href="#cb58-38" aria-hidden="true" tabindex="-1"></a>            frame <span class="op">=</span> stream.getvalue()</span>
<span id="cb58-39"><a href="#cb58-39" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Capture frames more frequently</span></span>
<span id="cb58-40"><a href="#cb58-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-41"><a href="#cb58-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_frames():</span>
<span id="cb58-42"><a href="#cb58-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-43"><a href="#cb58-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> frame_lock:</span>
<span id="cb58-44"><a href="#cb58-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-45"><a href="#cb58-45" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (<span class="st">b'--frame</span><span class="ch">\r\n</span><span class="st">'</span></span>
<span id="cb58-46"><a href="#cb58-46" aria-hidden="true" tabindex="-1"></a>                       <span class="st">b'Content-Type: image/jpeg</span><span class="ch">\r\n\r\n</span><span class="st">'</span> <span class="op">+</span> frame <span class="op">+</span> <span class="st">b'</span><span class="ch">\r\n</span><span class="st">'</span>)</span>
<span id="cb58-47"><a href="#cb58-47" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)</span>
<span id="cb58-48"><a href="#cb58-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-49"><a href="#cb58-49" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_model():</span>
<span id="cb58-50"><a href="#cb58-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> interpreter</span>
<span id="cb58-51"><a href="#cb58-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> interpreter <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb58-52"><a href="#cb58-52" aria-hidden="true" tabindex="-1"></a>        interpreter <span class="op">=</span> tflite.Interpreter(model_path<span class="op">=</span>model_path)</span>
<span id="cb58-53"><a href="#cb58-53" aria-hidden="true" tabindex="-1"></a>        interpreter.allocate_tensors()</span>
<span id="cb58-54"><a href="#cb58-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> interpreter</span>
<span id="cb58-55"><a href="#cb58-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-56"><a href="#cb58-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img, interpreter):</span>
<span id="cb58-57"><a href="#cb58-57" aria-hidden="true" tabindex="-1"></a>    input_details <span class="op">=</span> interpreter.get_input_details()</span>
<span id="cb58-58"><a href="#cb58-58" aria-hidden="true" tabindex="-1"></a>    output_details <span class="op">=</span> interpreter.get_output_details()</span>
<span id="cb58-59"><a href="#cb58-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-60"><a href="#cb58-60" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> img.resize((input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">1</span>], </span>
<span id="cb58-61"><a href="#cb58-61" aria-hidden="true" tabindex="-1"></a>                      input_details[<span class="dv">0</span>][<span class="st">'shape'</span>][<span class="dv">2</span>]))</span>
<span id="cb58-62"><a href="#cb58-62" aria-hidden="true" tabindex="-1"></a>    input_data <span class="op">=</span> np.expand_dims(np.array(img), axis<span class="op">=</span><span class="dv">0</span>)<span class="op">\</span></span>
<span id="cb58-63"><a href="#cb58-63" aria-hidden="true" tabindex="-1"></a>                             .astype(input_details[<span class="dv">0</span>][<span class="st">'dtype'</span>])</span>
<span id="cb58-64"><a href="#cb58-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-65"><a href="#cb58-65" aria-hidden="true" tabindex="-1"></a>    interpreter.set_tensor(input_details[<span class="dv">0</span>][<span class="st">'index'</span>], input_data)</span>
<span id="cb58-66"><a href="#cb58-66" aria-hidden="true" tabindex="-1"></a>    interpreter.invoke()</span>
<span id="cb58-67"><a href="#cb58-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-68"><a href="#cb58-68" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> interpreter.get_tensor(output_details[<span class="dv">0</span>][<span class="st">'index'</span>])[<span class="dv">0</span>]</span>
<span id="cb58-69"><a href="#cb58-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Handle output based on type</span></span>
<span id="cb58-70"><a href="#cb58-70" aria-hidden="true" tabindex="-1"></a>    output_dtype <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'dtype'</span>]</span>
<span id="cb58-71"><a href="#cb58-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> output_dtype <span class="kw">in</span> [np.int8, np.uint8]:</span>
<span id="cb58-72"><a href="#cb58-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Dequantize the output</span></span>
<span id="cb58-73"><a href="#cb58-73" aria-hidden="true" tabindex="-1"></a>        scale, zero_point <span class="op">=</span> output_details[<span class="dv">0</span>][<span class="st">'quantization'</span>]</span>
<span id="cb58-74"><a href="#cb58-74" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> (predictions.astype(np.float32) <span class="op">-</span> zero_point) <span class="op">*</span> scale</span>
<span id="cb58-75"><a href="#cb58-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predictions</span>
<span id="cb58-76"><a href="#cb58-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-77"><a href="#cb58-77" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classification_worker():</span>
<span id="cb58-78"><a href="#cb58-78" aria-hidden="true" tabindex="-1"></a>    interpreter <span class="op">=</span> load_model()</span>
<span id="cb58-79"><a href="#cb58-79" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb58-80"><a href="#cb58-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> is_classifying:</span>
<span id="cb58-81"><a href="#cb58-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> frame_lock:</span>
<span id="cb58-82"><a href="#cb58-82" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> frame <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb58-83"><a href="#cb58-83" aria-hidden="true" tabindex="-1"></a>                    img <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(frame))</span>
<span id="cb58-84"><a href="#cb58-84" aria-hidden="true" tabindex="-1"></a>            predictions <span class="op">=</span> classify_image(img, interpreter)</span>
<span id="cb58-85"><a href="#cb58-85" aria-hidden="true" tabindex="-1"></a>            max_prob <span class="op">=</span> np.<span class="bu">max</span>(predictions)</span>
<span id="cb58-86"><a href="#cb58-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> max_prob <span class="op">&gt;=</span> confidence_threshold:</span>
<span id="cb58-87"><a href="#cb58-87" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> labels[np.argmax(predictions)]</span>
<span id="cb58-88"><a href="#cb58-88" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb58-89"><a href="#cb58-89" aria-hidden="true" tabindex="-1"></a>                label <span class="op">=</span> <span class="st">'Uncertain'</span></span>
<span id="cb58-90"><a href="#cb58-90" aria-hidden="true" tabindex="-1"></a>            classification_queue.put({<span class="st">'label'</span>: label, </span>
<span id="cb58-91"><a href="#cb58-91" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">'probability'</span>: <span class="bu">float</span>(max_prob)})</span>
<span id="cb58-92"><a href="#cb58-92" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="fl">0.1</span>)  <span class="co"># Adjust based on your needs</span></span>
<span id="cb58-93"><a href="#cb58-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-94"><a href="#cb58-94" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/'</span>)</span>
<span id="cb58-95"><a href="#cb58-95" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> index():</span>
<span id="cb58-96"><a href="#cb58-96" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> render_template_string(<span class="st">'''</span></span>
<span id="cb58-97"><a href="#cb58-97" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;!DOCTYPE html&gt;</span></span>
<span id="cb58-98"><a href="#cb58-98" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;html&gt;</span></span>
<span id="cb58-99"><a href="#cb58-99" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;head&gt;</span></span>
<span id="cb58-100"><a href="#cb58-100" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;title&gt;Image Classification&lt;/title&gt;</span></span>
<span id="cb58-101"><a href="#cb58-101" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script </span></span>
<span id="cb58-102"><a href="#cb58-102" aria-hidden="true" tabindex="-1"></a><span class="st">                src="https://code.jquery.com/jquery-3.6.0.min.js"&gt;</span></span>
<span id="cb58-103"><a href="#cb58-103" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb58-104"><a href="#cb58-104" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;script&gt;</span></span>
<span id="cb58-105"><a href="#cb58-105" aria-hidden="true" tabindex="-1"></a><span class="st">                function startClassification() {</span></span>
<span id="cb58-106"><a href="#cb58-106" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/start');</span></span>
<span id="cb58-107"><a href="#cb58-107" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', true);</span></span>
<span id="cb58-108"><a href="#cb58-108" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', false);</span></span>
<span id="cb58-109"><a href="#cb58-109" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-110"><a href="#cb58-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-111"><a href="#cb58-111" aria-hidden="true" tabindex="-1"></a><span class="st">                function stopClassification() {</span></span>
<span id="cb58-112"><a href="#cb58-112" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/stop');</span></span>
<span id="cb58-113"><a href="#cb58-113" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#startBtn').prop('disabled', false);</span></span>
<span id="cb58-114"><a href="#cb58-114" aria-hidden="true" tabindex="-1"></a><span class="st">                    $('#stopBtn').prop('disabled', true);</span></span>
<span id="cb58-115"><a href="#cb58-115" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-116"><a href="#cb58-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-117"><a href="#cb58-117" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateConfidence() {</span></span>
<span id="cb58-118"><a href="#cb58-118" aria-hidden="true" tabindex="-1"></a><span class="st">                    var confidence = $('#confidence').val();</span></span>
<span id="cb58-119"><a href="#cb58-119" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.post('/update_confidence', {confidence: confidence});</span></span>
<span id="cb58-120"><a href="#cb58-120" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-121"><a href="#cb58-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-122"><a href="#cb58-122" aria-hidden="true" tabindex="-1"></a><span class="st">                function updateClassification() {</span></span>
<span id="cb58-123"><a href="#cb58-123" aria-hidden="true" tabindex="-1"></a><span class="st">                    $.get('/get_classification', function(data) {</span></span>
<span id="cb58-124"><a href="#cb58-124" aria-hidden="true" tabindex="-1"></a><span class="st">                        $('#classification').text(data.label + ': ' </span></span>
<span id="cb58-125"><a href="#cb58-125" aria-hidden="true" tabindex="-1"></a><span class="st">                        + data.probability.toFixed(2));</span></span>
<span id="cb58-126"><a href="#cb58-126" aria-hidden="true" tabindex="-1"></a><span class="st">                    });</span></span>
<span id="cb58-127"><a href="#cb58-127" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb58-128"><a href="#cb58-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-129"><a href="#cb58-129" aria-hidden="true" tabindex="-1"></a><span class="st">                $(document).ready(function() {</span></span>
<span id="cb58-130"><a href="#cb58-130" aria-hidden="true" tabindex="-1"></a><span class="st">                    setInterval(updateClassification, 100);  </span></span>
<span id="cb58-131"><a href="#cb58-131" aria-hidden="true" tabindex="-1"></a><span class="st">                    // Update every 100ms</span></span>
<span id="cb58-132"><a href="#cb58-132" aria-hidden="true" tabindex="-1"></a><span class="st">                });</span></span>
<span id="cb58-133"><a href="#cb58-133" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;/script&gt;</span></span>
<span id="cb58-134"><a href="#cb58-134" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/head&gt;</span></span>
<span id="cb58-135"><a href="#cb58-135" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;body&gt;</span></span>
<span id="cb58-136"><a href="#cb58-136" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;h1&gt;Image Classification&lt;/h1&gt;</span></span>
<span id="cb58-137"><a href="#cb58-137" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;img src="</span><span class="sc">{{</span><span class="st"> url_for('video_feed') </span><span class="sc">}}</span><span class="st">" width="640" height="480" /&gt;</span></span>
<span id="cb58-138"><a href="#cb58-138" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-139"><a href="#cb58-139" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="startBtn" onclick="startClassification()"&gt;</span></span>
<span id="cb58-140"><a href="#cb58-140" aria-hidden="true" tabindex="-1"></a><span class="st">            Start Classification&lt;/button&gt;</span></span>
<span id="cb58-141"><a href="#cb58-141" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;button id="stopBtn" onclick="stopClassification()" disabled&gt;</span></span>
<span id="cb58-142"><a href="#cb58-142" aria-hidden="true" tabindex="-1"></a><span class="st">            Stop Classification&lt;/button&gt;</span></span>
<span id="cb58-143"><a href="#cb58-143" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-144"><a href="#cb58-144" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;label for="confidence"&gt;Confidence Threshold:&lt;/label&gt;</span></span>
<span id="cb58-145"><a href="#cb58-145" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;input type="number" id="confidence" name="confidence" min="0" </span></span>
<span id="cb58-146"><a href="#cb58-146" aria-hidden="true" tabindex="-1"></a><span class="st">            max="1" step="0.1" value="0.8" onchange="updateConfidence()"&gt;</span></span>
<span id="cb58-147"><a href="#cb58-147" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;br&gt;</span></span>
<span id="cb58-148"><a href="#cb58-148" aria-hidden="true" tabindex="-1"></a><span class="st">            &lt;div id="classification"&gt;Waiting for classification...&lt;/div&gt;</span></span>
<span id="cb58-149"><a href="#cb58-149" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/body&gt;</span></span>
<span id="cb58-150"><a href="#cb58-150" aria-hidden="true" tabindex="-1"></a><span class="st">        &lt;/html&gt;</span></span>
<span id="cb58-151"><a href="#cb58-151" aria-hidden="true" tabindex="-1"></a><span class="st">    '''</span>)</span>
<span id="cb58-152"><a href="#cb58-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-153"><a href="#cb58-153" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/video_feed'</span>)</span>
<span id="cb58-154"><a href="#cb58-154" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> video_feed():</span>
<span id="cb58-155"><a href="#cb58-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Response(generate_frames(),</span>
<span id="cb58-156"><a href="#cb58-156" aria-hidden="true" tabindex="-1"></a>                    mimetype<span class="op">=</span><span class="st">'multipart/x-mixed-replace; boundary=frame'</span>)</span>
<span id="cb58-157"><a href="#cb58-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-158"><a href="#cb58-158" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/start'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-159"><a href="#cb58-159" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> start_classification():</span>
<span id="cb58-160"><a href="#cb58-160" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb58-161"><a href="#cb58-161" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">True</span></span>
<span id="cb58-162"><a href="#cb58-162" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-163"><a href="#cb58-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-164"><a href="#cb58-164" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/stop'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-165"><a href="#cb58-165" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> stop_classification():</span>
<span id="cb58-166"><a href="#cb58-166" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> is_classifying</span>
<span id="cb58-167"><a href="#cb58-167" aria-hidden="true" tabindex="-1"></a>    is_classifying <span class="op">=</span> <span class="va">False</span></span>
<span id="cb58-168"><a href="#cb58-168" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-169"><a href="#cb58-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-170"><a href="#cb58-170" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/update_confidence'</span>, methods<span class="op">=</span>[<span class="st">'POST'</span>])</span>
<span id="cb58-171"><a href="#cb58-171" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> update_confidence():</span>
<span id="cb58-172"><a href="#cb58-172" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> confidence_threshold</span>
<span id="cb58-173"><a href="#cb58-173" aria-hidden="true" tabindex="-1"></a>    confidence_threshold <span class="op">=</span> <span class="bu">float</span>(request.form[<span class="st">'confidence'</span>])</span>
<span id="cb58-174"><a href="#cb58-174" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">''</span>, <span class="dv">204</span></span>
<span id="cb58-175"><a href="#cb58-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-176"><a href="#cb58-176" aria-hidden="true" tabindex="-1"></a><span class="at">@app.route</span>(<span class="st">'/get_classification'</span>)</span>
<span id="cb58-177"><a href="#cb58-177" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_classification():</span>
<span id="cb58-178"><a href="#cb58-178" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> is_classifying:</span>
<span id="cb58-179"><a href="#cb58-179" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> jsonify({<span class="st">'label'</span>: <span class="st">'Not classifying'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>})</span>
<span id="cb58-180"><a href="#cb58-180" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb58-181"><a href="#cb58-181" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> classification_queue.get_nowait()</span>
<span id="cb58-182"><a href="#cb58-182" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> Queue.Empty:</span>
<span id="cb58-183"><a href="#cb58-183" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> {<span class="st">'label'</span>: <span class="st">'Processing'</span>, <span class="st">'probability'</span>: <span class="dv">0</span>}</span>
<span id="cb58-184"><a href="#cb58-184" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> jsonify(result)</span>
<span id="cb58-185"><a href="#cb58-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-186"><a href="#cb58-186" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">'__main__'</span>:</span>
<span id="cb58-187"><a href="#cb58-187" aria-hidden="true" tabindex="-1"></a>    initialize_camera()</span>
<span id="cb58-188"><a href="#cb58-188" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>get_frame, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb58-189"><a href="#cb58-189" aria-hidden="true" tabindex="-1"></a>    threading.Thread(target<span class="op">=</span>classification_worker, daemon<span class="op">=</span><span class="va">True</span>).start()</span>
<span id="cb58-190"><a href="#cb58-190" aria-hidden="true" tabindex="-1"></a>    app.run(host<span class="op">=</span><span class="st">'0.0.0.0'</span>, port<span class="op">=</span><span class="dv">5000</span>, threaded<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sul terminale lanciare:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python3</span> img_class_live_infer.py</span></code><button title="Copia negli appunti" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>E accedere all‚Äôinterfaccia web:</p>
<ul>
<li>Sul Raspberry Pi stesso (se si ha una GUI): si apre un browser web e si va su<code>http://localhost:5000</code></li>
<li>Da un altro dispositivo sulla stessa rete: aprire un browser web e andare su <code>http://&lt;raspberry_pi_ip&gt;:5000</code> (Sostituire <code>&lt;raspberry_pi_ip&gt;</code> con l‚Äôindirizzo IP del Raspberry Pi). Per esempio: <code>http://192.168.4.210:5000/</code></li>
</ul>
<p>Ecco alcuni screenshot dell‚Äôapp in esecuzione su un desktop esterno</p>
<p><img src="images/png/app-inference.png" class="img-fluid"></p>
<p>Qui si pu√≤ vedere l‚Äôapp in esecuzione su YouTube:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/o1QsQrpCMw4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Il codice crea un‚Äôapplicazione web per la classificazione delle immagini in tempo reale utilizzando un Raspberry Pi, il suo modulo fotocamera e un modello TensorFlow Lite. L‚Äôapplicazione utilizza Flask per fornire un‚Äôinterfaccia web in cui √® possibile visualizzare il feed della fotocamera e vedere i risultati della classificazione in tempo reale.</p>
<section id="componenti-chiave" class="level4">
<h4 class="anchored" data-anchor-id="componenti-chiave">Componenti Chiave:</h4>
<ol type="1">
<li><strong>Applicazione Web Flask</strong>: Fornisce l‚Äôinterfaccia utente e gestisce le richieste.</li>
<li><strong>PiCamera2</strong>: Cattura le immagini dal modulo fotocamera Raspberry Pi.</li>
<li><strong>TensorFlow Lite</strong>: Esegue il modello di classificazione delle immagini.</li>
<li><strong>Threading</strong>: Gestisce le operazioni simultanee per prestazioni fluide.</li>
</ol>
</section>
<section id="caratteristiche-principali-1" class="level4">
<h4 class="anchored" data-anchor-id="caratteristiche-principali-1">Caratteristiche Principali:</h4>
<ul>
<li>Visualizzazione feed telecamera live</li>
<li>Classificazione immagini in tempo reale</li>
<li>Soglia di confidenza regolabile</li>
<li>Avvia/Arresta classificazione su richiesta</li>
</ul>
</section>
<section id="struttura-del-codice" class="level4">
<h4 class="anchored" data-anchor-id="struttura-del-codice">Struttura del Codice:</h4>
<ol type="1">
<li><strong>Importazioni e Setup</strong>:
<ul>
<li>Flask per applicazione web</li>
<li>PiCamera2 per controllo telecamera</li>
<li>TensorFlow Lite per l‚Äôinferenza</li>
<li>Threading e Queue per operazioni concorrenti</li>
</ul></li>
<li><strong>Variabili Globali</strong>:
<ul>
<li>Gestione telecamera e frame</li>
<li>Controllo classificazione</li>
<li>Informazioni modello ed etichetta</li>
</ul></li>
<li><strong>Funzioni della Telecamera</strong>:
<ul>
<li><code>initialize_camera()</code>: Imposta PiCamera2</li>
<li><code>get_frame()</code>: Cattura continuamente frame</li>
<li><code>generate_frames()</code>: Genera frame per il feed web</li>
</ul></li>
<li><strong>Funzioni del Modello</strong>:
<ul>
<li><code>load_model()</code>: Carica il modello TFLite</li>
<li><code>classify_image()</code>: Esegue l‚Äôinferenza su una singola immagine</li>
</ul></li>
<li><strong>Worker per la Classificazione</strong>:
<ul>
<li>Gira in un thread separato</li>
<li>Classifica continuamente i frame quando √® attivo</li>
<li>Aaggiorna una coda con i risultati pi√π recenti</li>
</ul></li>
<li><strong>Route di Flask</strong>:
<ul>
<li><code>/</code>: Serve la pagina HTML principale</li>
<li><code>/video_feed</code>: Trasmette il feed della telecamera</li>
<li><code>/start</code> and <code>/stop</code>: Controlla la classificazione</li>
<li><code>/update_confidence</code>: Regola la soglia di confidenza</li>
<li><code>/get_classification</code>: Restituisce l‚Äôultimo risultato di classificazione</li>
</ul></li>
<li><strong>Template HTML</strong>:
<ul>
<li>Visualizza il feed della telecamera e la classificazione dei risultati</li>
<li>Fornisce controlli per avviare/arrestare e regolare le impostazioni</li>
</ul></li>
<li><strong>Esecuzione Principale</strong>:
<ul>
<li>Inizializza la fotocamera e avvia i thread necessari</li>
<li>Esegue l‚Äôapplicazione Flask</li>
</ul></li>
</ol>
</section>
<section id="concetti-chiave" class="level4">
<h4 class="anchored" data-anchor-id="concetti-chiave">Concetti Chiave:</h4>
<ol type="1">
<li><strong>Operazioni Concorrenti</strong>: Utilizzo di thread per gestire l‚Äôacquisizione e la classificazione della telecamera separatamente dal server Web.</li>
<li><strong>Aggiornamenti in Tempo Reale</strong>: Aggiornamenti frequenti dei risultati della classificazione senza ricaricare la pagina.</li>
<li><strong>Riutilizzo del Modello</strong>: Caricamento del modello TFLite una volta e il riutilizzo per l‚Äôefficienza.</li>
<li><strong>Configurazione Flessibile</strong>: Consente agli utenti di regolare la soglia di confidenza al volo.</li>
</ol>
</section>
<section id="uso" class="level4">
<h4 class="anchored" data-anchor-id="uso">Uso:</h4>
<ol type="1">
<li>Assicurarsi che tutte le dipendenze siano installate.</li>
<li>Eseguire lo script su un Raspberry Pi con un modulo telecamera.</li>
<li>Accedere all‚Äôinterfaccia Web da un browser utilizzando l‚Äôindirizzo IP del Raspberry Pi.</li>
<li>Avviare la classificazione e regolare le impostazioni in base alle esigenze.</li>
</ol>
</section>
</section>
<section id="conclusione" class="level2">
<h2 class="anchored" data-anchor-id="conclusione">Conclusione:</h2>
<p>La classificazione delle immagini √® emersa come un‚Äôapplicazione potente e versatile dell‚Äôapprendimento automatico, con implicazioni significative per vari campi, dall‚Äôassistenza sanitaria al monitoraggio ambientale. Questo capitolo ha dimostrato come implementare un sistema di classificazione delle immagini robusto su dispositivi edge come Raspi-Zero e Raspi-5, mostrando il potenziale per l‚Äôintelligenza in tempo reale sul dispositivo.</p>
<p>Abbiamo esplorato l‚Äôintera pipeline di un progetto di classificazione delle immagini, dalla raccolta dati e dall‚Äôaddestramento del modello tramite Edge Impulse Studio all‚Äôimplementazione e all‚Äôesecuzione di inferenze su un Raspi. Il processo ha evidenziato diversi punti chiave:</p>
<ol type="1">
<li>L‚Äôimportanza di una corretta raccolta dati e pre-elaborazione per l‚Äôaddestramento efficace dei modelli.</li>
<li>La potenza dell‚Äôapprendimento tramite trasferimento, che ci consente di sfruttare modelli pre-addestrati come MobileNet V2 per un addestramento efficiente con dati limitati.</li>
<li>I compromessi tra accuratezza del modello e velocit√† di inferenza, particolarmente cruciali per i dispositivi edge.</li>
<li>L‚Äôimplementazione della classificazione in tempo reale tramite un‚Äôinterfaccia basata sul Web, che dimostra applicazioni pratiche.</li>
</ol>
<p>La capacit√† di eseguire questi modelli su dispositivi edge come Raspi apre numerose possibilit√† per applicazioni IoT, sistemi autonomi e soluzioni di monitoraggio in tempo reale. Consente una latenza ridotta, una migliore privacy e il funzionamento in ambienti con connettivit√† limitata.</p>
<p>Come abbiamo visto, anche con i vincoli computazionali dei dispositivi edge, √® possibile ottenere risultati impressionanti in termini di accuratezza e velocit√†. La flessibilit√† di regolare i parametri del modello, come le dimensioni di input e i valori alfa, consente una messa a punto precisa per soddisfare requisiti di progetto specifici.</p>
<p>Guardando al futuro, il campo dell‚Äôintelligenza artificiale edge e della classificazione delle immagini continua a evolversi rapidamente. I progressi nelle tecniche di compressione dei modelli, nell‚Äôaccelerazione hardware e nelle architetture di reti neurali pi√π efficienti promettono di espandere ulteriormente le capacit√† dei dispositivi edge nelle attivit√† di visione artificiale.</p>
<p>Questo progetto funge da base per applicazioni di visione artificiale pi√π complesse e incoraggia un‚Äôulteriore esplorazione nell‚Äôentusiasmante mondo dell‚Äôintelligenza artificiale edge e dell‚ÄôIoT. Che si tratti di automazione industriale, applicazioni per la casa intelligente o monitoraggio ambientale, le competenze e i concetti trattati qui forniscono un solido punto di partenza per un‚Äôampia gamma di progetti innovativi.</p>
</section>
<section id="risorse" class="level2">
<h2 class="anchored" data-anchor-id="risorse">Risorse</h2>
<ul>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/dataset">Esempio di Dataset</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/setup_test.ipynb">Impostazione del Notebook di Prova su un Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/10_Image_Classification.ipynb">Notebook di Classificazione delle Immagini su un Raspi</a></p></li>
<li><p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/2_Applications_Deploy/Class_16/cifar_10/CNN_Cifar_10_TFLite.ipynb#scrollTo=iiVBUpuHXEtw">CNN per classificare il dataset Cifar-10 su CoLab</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/blob/main/IMG_CLASS/notebooks/20_Cifar_10_Image_Classification.ipynb">Cifar 10 - Classificazione delle Immagini su un Raspi</a></p></li>
<li><p><a href="https://github.com/Mjrovai/EdgeML-with-Raspberry-Pi/tree/main/IMG_CLASS/python_scripts">Script Python</a></p></li>
<li><p><a href="https://studio.edgeimpulse.com/public/510251/live">Progetto Edge Impulse</a></p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../../contents/labs/raspi/setup/setup.it.html" class="pagination-link" aria-label="Setup">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Setup</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../../contents/labs/raspi/object_detection/object_detection.it.html" class="pagination-link" aria-label="Rilevamento degli Oggetti">
        <span class="nav-page-text">Rilevamento degli Oggetti</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/labs/raspi/image_classification/image_classification.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>