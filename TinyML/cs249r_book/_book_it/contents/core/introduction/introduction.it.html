<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Introduzione ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/ml_systems/ml_systems.it.html" rel="next">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script src="../../../scripts/ai_menu/dist/bundle.js" defer=""></script>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/introduction/introduction.it.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2b8d2ba3a08f8b4ab16660e3d0aa1206" class="alert alert-primary hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>‚≠ê [18 Ott] <b>Abbiamo raggiunto 1.000 stelle GitHub</b> üéâ Grazie a voi, Arduino e SEEED hanno donato kit hardware di IA per <a href="https://tinyml.seas.harvard.edu/4D/pastEvents">per i workshop TinyML</a> nei paesi in via di sviluppo <br> üéì [15 Nov] La <a href="https://www.edgeaifoundation.org/">EDGE AI Foundation</a> <strong>equipara i fondi per borse di studio accademiche</strong> per ogni nuovo GitHub ‚≠ê (fino a 10.000 stelle). <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per supportare!</a> üôè <br> üöÄ <b>La nostra missione. 1 ‚≠ê = 1 üë©‚Äçüéì Studente</b>. Ogni stella racconta una storia: studenti che acquisiscono conoscenze e sostenitori che guidano la missione. Insieme, stiamo facendo la differenza.</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/about/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/ai/socratiq.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LABORATORI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/part_LABS.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">LABORATORI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/overview.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/part_nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">part_nicla_vision.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/part_xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">part_xiao_esp32s3.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/part_raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">part_raspi.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/part_shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">part_shared.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#perch√©-i-sistemi-di-machine-learning-sono-importanti" id="toc-perch√©-i-sistemi-di-machine-learning-sono-importanti" class="nav-link active" data-scroll-target="#perch√©-i-sistemi-di-machine-learning-sono-importanti"><span class="header-section-number">1.1</span> Perch√© i Sistemi di Machine Learning Sono Importanti</a></li>
  <li><a href="#levoluzione-dellia" id="toc-levoluzione-dellia" class="nav-link" data-scroll-target="#levoluzione-dellia"><span class="header-section-number">1.2</span> L‚Äôevoluzione dell‚ÄôIA</a>
  <ul>
  <li><a href="#ia-simbolica-1956-1974" id="toc-ia-simbolica-1956-1974" class="nav-link" data-scroll-target="#ia-simbolica-1956-1974"><span class="header-section-number">1.2.1</span> IA Simbolica (1956-1974)</a></li>
  <li><a href="#sistemi-esperti-anni-70-80" id="toc-sistemi-esperti-anni-70-80" class="nav-link" data-scroll-target="#sistemi-esperti-anni-70-80"><span class="header-section-number">1.2.2</span> Sistemi Esperti (anni ‚Äô70-‚Äô80)</a></li>
  <li><a href="#apprendimento-statistico-un-cambio-di-paradigma-anni-90" id="toc-apprendimento-statistico-un-cambio-di-paradigma-anni-90" class="nav-link" data-scroll-target="#apprendimento-statistico-un-cambio-di-paradigma-anni-90"><span class="header-section-number">1.2.3</span> Apprendimento Statistico: Un Cambio di Paradigma (anni ‚Äô90)</a></li>
  <li><a href="#apprendimento-superficiale-anni-2000" id="toc-apprendimento-superficiale-anni-2000" class="nav-link" data-scroll-target="#apprendimento-superficiale-anni-2000"><span class="header-section-number">1.2.4</span> Apprendimento Superficiale (anni 2000)</a></li>
  <li><a href="#deep-learning-2012-oggi" id="toc-deep-learning-2012-oggi" class="nav-link" data-scroll-target="#deep-learning-2012-oggi"><span class="header-section-number">1.2.5</span> Deep Learning (2012-Oggi)</a></li>
  </ul></li>
  <li><a href="#lascesa-dellingegneria-dei-sistemi-di-ml" id="toc-lascesa-dellingegneria-dei-sistemi-di-ml" class="nav-link" data-scroll-target="#lascesa-dellingegneria-dei-sistemi-di-ml"><span class="header-section-number">1.3</span> L‚ÄôAscesa dell‚ÄôIngegneria dei Sistemi di ML</a></li>
  <li><a href="#definizione-di-un-sistema-ml" id="toc-definizione-di-un-sistema-ml" class="nav-link" data-scroll-target="#definizione-di-un-sistema-ml"><span class="header-section-number">1.4</span> Definizione di un sistema ML</a></li>
  <li><a href="#il-ciclo-di-vita-dei-sistemi-ml" id="toc-il-ciclo-di-vita-dei-sistemi-ml" class="nav-link" data-scroll-target="#il-ciclo-di-vita-dei-sistemi-ml"><span class="header-section-number">1.5</span> Il ciclo di vita dei sistemi ML</a></li>
  <li><a href="#lo-spettro-dei-sistemi-ml" id="toc-lo-spettro-dei-sistemi-ml" class="nav-link" data-scroll-target="#lo-spettro-dei-sistemi-ml"><span class="header-section-number">1.6</span> Lo Spettro dei Sistemi ML</a></li>
  <li><a href="#implicazioni-del-sistema-di-ml-sul-ciclo-di-vita-ml" id="toc-implicazioni-del-sistema-di-ml-sul-ciclo-di-vita-ml" class="nav-link" data-scroll-target="#implicazioni-del-sistema-di-ml-sul-ciclo-di-vita-ml"><span class="header-section-number">1.7</span> Implicazioni del Sistema di ML sul Ciclo di Vita ML</a>
  <ul>
  <li><a href="#tendenze-emergenti" id="toc-tendenze-emergenti" class="nav-link" data-scroll-target="#tendenze-emergenti"><span class="header-section-number">1.7.1</span> Tendenze Emergenti</a></li>
  </ul></li>
  <li><a href="#applicazioni-e-impatto-nel-mondo-reale" id="toc-applicazioni-e-impatto-nel-mondo-reale" class="nav-link" data-scroll-target="#applicazioni-e-impatto-nel-mondo-reale"><span class="header-section-number">1.8</span> Applicazioni e Impatto nel Mondo Reale</a>
  <ul>
  <li><a href="#caso-di-studio-farmbeats-ml-edge-ed-embedded-per-lagricoltura" id="toc-caso-di-studio-farmbeats-ml-edge-ed-embedded-per-lagricoltura" class="nav-link" data-scroll-target="#caso-di-studio-farmbeats-ml-edge-ed-embedded-per-lagricoltura"><span class="header-section-number">1.8.1</span> Caso di Studio: FarmBeats: ML Edge ed Embedded per l‚ÄôAgricoltura</a></li>
  <li><a href="#caso-di-studio-alphafold-ml-scientifico-su-larga-scala" id="toc-caso-di-studio-alphafold-ml-scientifico-su-larga-scala" class="nav-link" data-scroll-target="#caso-di-studio-alphafold-ml-scientifico-su-larga-scala"><span class="header-section-number">1.8.2</span> Caso di Studio: AlphaFold: ML Scientifico su Larga Scala</a></li>
  <li><a href="#caso-di-studio-veicoli-autonomi-abbracciare-lo-spettro-ml" id="toc-caso-di-studio-veicoli-autonomi-abbracciare-lo-spettro-ml" class="nav-link" data-scroll-target="#caso-di-studio-veicoli-autonomi-abbracciare-lo-spettro-ml"><span class="header-section-number">1.8.3</span> Caso di Studio: Veicoli Autonomi: Abbracciare lo Spettro ML</a></li>
  </ul></li>
  <li><a href="#sfide-e-considerazioni" id="toc-sfide-e-considerazioni" class="nav-link" data-scroll-target="#sfide-e-considerazioni"><span class="header-section-number">1.9</span> Sfide e Considerazioni</a>
  <ul>
  <li><a href="#sfide-dei-dati" id="toc-sfide-dei-dati" class="nav-link" data-scroll-target="#sfide-dei-dati"><span class="header-section-number">1.9.1</span> Sfide dei Dati</a></li>
  <li><a href="#sfide-del-modello" id="toc-sfide-del-modello" class="nav-link" data-scroll-target="#sfide-del-modello"><span class="header-section-number">1.9.2</span> Sfide del Modello</a></li>
  <li><a href="#sfide-di-sistema" id="toc-sfide-di-sistema" class="nav-link" data-scroll-target="#sfide-di-sistema"><span class="header-section-number">1.9.3</span> Sfide di Sistema</a></li>
  <li><a href="#considerazioni-etiche-e-sociali" id="toc-considerazioni-etiche-e-sociali" class="nav-link" data-scroll-target="#considerazioni-etiche-e-sociali"><span class="header-section-number">1.9.4</span> Considerazioni Etiche e Sociali</a></li>
  </ul></li>
  <li><a href="#direzioni-future" id="toc-direzioni-future" class="nav-link" data-scroll-target="#direzioni-future"><span class="header-section-number">1.10</span> Direzioni Future</a></li>
  <li><a href="#percorso-di-apprendimento-e-struttura-del-libro" id="toc-percorso-di-apprendimento-e-struttura-del-libro" class="nav-link" data-scroll-target="#percorso-di-apprendimento-e-struttura-del-libro"><span class="header-section-number">1.11</span> Percorso di Apprendimento e Struttura del Libro</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/introduction/introduction.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/introduction/introduction.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-introduction" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/cover_introduction.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E 3 Prompt: Un‚Äôillustrazione 2D dettagliata, rettangolare e piatta che raffigura una roadmap dei capitoli di un libro sui sistemi di apprendimento automatico, su uno sfondo bianco nitido e pulito. L‚Äôimmagine presenta una strada tortuosa che attraversa vari punti di riferimento simbolici. Ogni punto di riferimento rappresenta un argomento del capitolo: Introduzione, Sistemi di ML, Avvio al Deep Learning, Workflow dell‚ÄôIA, Data Engineering, Framework di IA, Addestramento dell‚ÄôIA, IA Efficiente, Ottimizzazioni dei Modelli, Accelerazione IA, Benchmarking dell‚ÄôIA, Apprendimento On-Device, Operazioni di ML, Sicurezza e Privacy, IA Responsabile, IA Sostenibile, AI for Good, IA Robusta, IA Generativa. Lo stile √® pulito, moderno e piatto, adatto a un libro tecnico, con ogni punto di riferimento chiaramente etichettato con il titolo del capitolo.</em></figcaption>
</figure>
</div>
<section id="perch√©-i-sistemi-di-machine-learning-sono-importanti" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="perch√©-i-sistemi-di-machine-learning-sono-importanti"><span class="header-section-number">1.1</span> Perch√© i Sistemi di Machine Learning Sono Importanti</h2>
<p>L‚Äôintelligenza artificiale √® ovunque. Si pensi alla routine mattutina: Ci si sveglia con una sveglia intelligente basata sull‚ÄôIA che ha appreso i propri schemi di sonno. Il telefono suggerisce il percorso per andare al lavoro, avendo appreso dai pattern del traffico. Durante il tragitto, l‚Äôapp musicale crea automaticamente una playlist che si pensa piacer√†. Al lavoro, il client di posta elettronica filtra lo spam e d√† priorit√† ai messaggi importanti. Durante il giorno, lo smartwatch monitora l‚Äôattivit√†, suggerendo quando muoversi o fare esercizio. La sera, il servizio di streaming consiglia programmi che potrebbero piacere, mentre i dispositivi smart home regolano l‚Äôilluminazione e la temperatura in base alle preferenze apprese.</p>
<p>Ma queste comodit√† quotidiane sono solo l‚Äôinizio. L‚ÄôIA sta trasformando il mondo in modi straordinari. Oggi, i sistemi di IA rilevano tumori in fase iniziale con una precisione senza precedenti, prevedono e tracciano eventi meteorologici estremi per salvare vite e accelerano la scoperta di farmaci simulando milioni di interazioni molecolari. I veicoli autonomi percorrono strade cittadine complesse elaborando dati di sensori in tempo reale da decine di fonti. I modelli linguistici si impegnano in conversazioni sofisticate, traducono tra centinaia di lingue e aiutano gli scienziati ad analizzare vasti database di ricerca. Nei laboratori scientifici, i sistemi di IA stanno facendo scoperte rivoluzionarie, dalla previsione di strutture proteiche che sbloccano nuovi trattamenti medici all‚Äôidentificazione di materiali promettenti per celle solari e batterie di nuova generazione. Anche nei campi creativi, l‚ÄôIA collabora con artisti e musicisti per esplorare nuove forme di espressione, spingendo i confini della creativit√† umana.</p>
<p>Questa non √® fantascienza, √® la realt√† di come l‚Äôintelligenza artificiale, in particolare i sistemi di apprendimento automatico, si sia intrecciata nel tessuto della nostra vita quotidiana. All‚Äôinizio degli anni ‚Äô90, <a href="https://en.wikipedia.org/wiki/Mark_Weiser">Mark Weiser</a>, un pioniere dell‚Äôinformatica, ha introdotto il mondo a un concetto rivoluzionario che avrebbe cambiato per sempre il modo in cui interagiamo con la tecnologia. Questa visione √® stata riassunta in modo sintetico nel suo articolo fondamentale, ‚ÄúThe Computer for the 21st Century‚Äù (<a href="#fig-ubiquitous" class="quarto-xref">Figura&nbsp;<span>1.1</span></a>). Weiser immaginava un futuro in cui l‚Äôinformatica sarebbe stata perfettamente integrata nei nostri ambienti, diventando una parte invisibile e integrante della vita quotidiana.</p>
<div id="fig-ubiquitous" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ubiquitous-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/21st_computer.png" class="img-fluid figure-img" style="width:50.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ubiquitous-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.1: Ubiquitous computing as envisioned di Mark Weiser.
</figcaption>
</figure>
</div>
<p>Ha definito questo concetto ‚Äúubiquitous computing‚Äù, promettendo un mondo in cui la tecnologia ci avrebbe servito senza richiedere la nostra costante attenzione o interazione. Oggi ci ritroviamo a vivere nel futuro immaginato da Weiser, in gran parte reso possibile dai sistemi di apprendimento automatico. La vera essenza della sua visione, ovvero creare un ambiente intelligente in grado di anticipare le nostre esigenze e agire per nostro conto, √® diventata realt√† attraverso lo sviluppo e l‚Äôimplementazione di sistemi di ML che abbracciano interi ecosistemi, dai potenti data center cloud ai dispositivi edge fino ai pi√π piccoli sensori IoT.</p>
<p>Eppure la maggior parte di noi raramente pensa ai sistemi complessi che rendono possibile tutto questo. Dietro ciascuna di queste interazioni apparentemente semplici si nasconde una sofisticata infrastruttura di dati, algoritmi e risorse informatiche che lavorano insieme. Comprendere come funzionano questi sistemi, le loro capacit√†, limitazioni e requisiti, √® diventato sempre pi√π critico man mano che si integrano sempre di pi√π nel nostro mondo.</p>
<p>Per apprezzare l‚Äôentit√† di questa trasformazione e la complessit√† dei moderni sistemi di machine learning, dobbiamo capire come siamo arrivati fin qui. Il viaggio dall‚Äôintelligenza artificiale primitiva agli odierni sistemi ML onnipresenti √® una storia non solo di evoluzione tecnologica, ma anche di prospettive mutevoli su ci√≤ che √® possibile e ci√≤ che √® necessario per rendere l‚ÄôIA pratica e affidabile.</p>
</section>
<section id="levoluzione-dellia" class="level2 page-columns page-full" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="levoluzione-dellia"><span class="header-section-number">1.2</span> L‚Äôevoluzione dell‚ÄôIA</h2>
<p>L‚Äôevoluzione dell‚ÄôIA, rappresentata nella cronologia mostrata in <a href="#fig-ai-timeline" class="quarto-xref">Figura&nbsp;<span>1.2</span></a>, evidenzia traguardi chiave come lo sviluppo del <strong>perceptron</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> nel 1957 da parte di Frank Rosenblatt, un elemento fondamentale per le moderne reti neurali. Si immagini di entrare in un laboratorio informatico nel 1965. Si troveranno mainframe delle dimensioni di una stanza che eseguono programmi in grado di dimostrare teoremi matematici di base o di giocare a semplici giochi come il tris. Questi primi sistemi di intelligenza artificiale, pur essendo rivoluzionari per l‚Äôepoca, erano ben lontani dagli odierni sistemi di apprendimento automatico in grado di rilevare il cancro nelle immagini mediche o di comprendere il linguaggio umano. La cronologia mostra la progressione dalle prime innovazioni come il chatbot ELIZA nel 1966, a importanti innovazioni come Deep Blue di IBM che ha sconfitto il campione di scacchi Garry Kasparov nel 1997. I progressi pi√π recenti includono l‚Äôintroduzione di GPT-3 di OpenAI nel 2020 e GPT-4 nel 2023, dimostrando la drammatica evoluzione e la crescente complessit√† dei sistemi di IA nel corso dei decenni.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;La prima rete neurale artificiale, un modello semplice che potrebbe imparare a classificare schemi visivi, simile a un singolo neurone che prende una decisione s√¨/no in base ai suoi input.</p></div></div><div id="fig-ai-timeline" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://spectrum.ieee.org/media-library/a-chart-of-milestones-in-ai-from-1950-to-2020.png?id=27547255" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-timeline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.2: Pietre miliari nell‚ÄôIA dal 1950 al 2020. Fonte: IEEE Spectrum
</figcaption>
</figure>
</div>
<p>Esploriamo come siamo arrivati fin qui.</p>
<section id="ia-simbolica-1956-1974" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="ia-simbolica-1956-1974"><span class="header-section-number">1.2.1</span> IA Simbolica (1956-1974)</h3>
<p>La storia del machine learning inizia alla storica conferenza di Dartmouth del 1956, dove pionieri come John McCarthy, Marvin Minsky e Claude Shannon coniarono per primi il termine ‚Äúintelligenza artificiale‚Äù. Il loro approccio si basava su un‚Äôidea convincente: l‚Äôintelligenza poteva essere ridotta alla manipolazione dei simboli. Si consideri il sistema STUDENT di Daniel Bobrow del 1964, uno dei primi programmi di IA in grado di risolvere problemi di algebra:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: STUDENT (1964)
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Problema: "Se il numero di clienti che Tom ottiene √® il doppio del 
quadrato del 20% del numero di pubblicit√† che gestisce e 
il numero di pubblicit√† √® 45, qual √® il numero di
clienti che Tom ottiene?"
 
STUDENT dovrebbe:

1. Analizzare il testo
2. Convertirlo in equazioni algebriche
3. Risolvere l'equazione: n = 2(0.2 √ó 45)¬≤
4. Fornire la risposta: 162 clienti</code></pre>
</div>
</div>
<p>Le prime IA come STUDENT soffrivano di una limitazione fondamentale: potevano gestire solo input che corrispondevano esattamente ai loro schemi e regole pre-programmati. Si immagini un traduttore linguistico che funziona solo quando le frasi seguono una struttura grammaticale perfetta: anche piccole variazioni come cambiare l‚Äôordine delle parole, usare sinonimi o schemi di linguaggio naturali causerebbero il fallimento di STUDENT. Questa ‚Äúfragilit√†‚Äù significava che, mentre queste soluzioni potevano apparire intelligenti quando gestivano casi molto specifici per cui erano state progettate, si sarebbero completamente guastate quando si trovavano di fronte anche a piccole variazioni o complessit√† del mondo reale. Questa limitazione non era solo un inconveniente tecnico, ma rivelava un problema pi√π profondo con gli approcci basati su regole all‚ÄôIA: non potevano realmente comprendere o generalizzare dalla loro programmazione, potevano solo abbinare e manipolare i modelli esattamente come specificato.</p>
</section>
<section id="sistemi-esperti-anni-70-80" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="sistemi-esperti-anni-70-80"><span class="header-section-number">1.2.2</span> Sistemi Esperti (anni ‚Äô70-‚Äô80)</h3>
<p>Verso la met√† degli anni ‚Äô70, i ricercatori si resero conto che l‚ÄôIA generale era troppo ambiziosa. Si concentraronoinvece, sull‚Äôacquisizione di conoscenze esperte umane in domini specifici. MYCIN, sviluppato a Stanford, √® stato uno dei primi sistemi esperti su larga scala progettati per diagnosticare le infezioni del sangue:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: MYCIN (1976)
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Esempio di regola da MYCIN:
IF
    L'infezione √® una batteriemia primaria
    Il sito della coltura √® uno dei siti sterili
    Il presunto portale di ingresso √® il tratto gastrointestinale
THEN
    Ci sono prove suggestive (0,7) che l'infezione √® batterioide</code></pre>
</div>
</div>
<p>Mentre MYCIN ha rappresentato un importante progresso nell‚ÄôIA medica con le sue 600 regole esperte per la diagnosi delle infezioni del sangue, ha rivelato sfide fondamentali che ancora oggi affliggono l‚Äôapprendimento automatico. Ottenere la conoscenza del dominio da esperti umani e convertirla in regole precise si √® rivelato incredibilmente dispendioso in termini di tempo e difficile: i medici spesso non riuscivano a spiegare esattamente come prendevano le decisioni. MYCIN ha lottato con informazioni incerte o incomplete, a differenza dei medici umani che potevano fare ipotesi istruite. Forse la cosa pi√π importante √® che la manutenzione e l‚Äôaggiornamento della base di regole sono diventati esponenzialmente pi√π complessi con la crescita di MYCIN: l‚Äôaggiunta di nuove regole spesso entrava in conflitto con quelle esistenti e la conoscenza medica stessa continuava a evolversi. Queste stesse sfide di acquisizione della conoscenza, gestione dell‚Äôincertezza e manutenzione rimangono preoccupazioni centrali nell‚Äôapprendimento automatico moderno, anche se ora utilizziamo approcci tecnici diversi per affrontarle.</p>
</section>
<section id="apprendimento-statistico-un-cambio-di-paradigma-anni-90" class="level3 page-columns page-full" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="apprendimento-statistico-un-cambio-di-paradigma-anni-90"><span class="header-section-number">1.2.3</span> Apprendimento Statistico: Un Cambio di Paradigma (anni ‚Äô90)</h3>
<p>Gli anni ‚Äô90 hanno segnato una trasformazione radicale nell‚Äôintelligenza artificiale, poich√© il campo si √® spostato dalle regole codificate a mano verso approcci di apprendimento statistico. Questa non √® stata una scelta semplice: √® stata guidata da tre fattori convergenti che hanno reso i metodi statistici possibili e potenti. La rivoluzione digitale ha significato che enormi quantit√† di dati erano improvvisamente disponibili per addestrare gli algoritmi. La <strong>legge di Moore</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> ha fornito la potenza di calcolo necessaria per elaborare questi dati in modo efficace. E i ricercatori hanno sviluppato nuovi algoritmi come le ‚ÄúSupport Vector Machines‚Äù [macchine a vettori di supporto] e reti neurali migliorate che potevano effettivamente apprendere modelli da questi dati anzich√© seguire regole pre-programmate. Questa combinazione ha cambiato radicalmente il modo in cui abbiamo costruito l‚ÄôIA: invece di cercare di codificare direttamente la conoscenza umana, ora potevamo lasciare che le macchine scoprissero automaticamente i pattern da esempi, portando a un‚ÄôIA pi√π solida e adattabile.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;L‚Äôosservazione fatta dal co-fondatore di Intel Gordon Moore nel 1965 secondo cui il numero di transistor su un microchip raddoppia circa ogni due anni, mentre il costo si dimezza. Questa crescita esponenziale della potenza di calcolo √® stata un fattore chiave dei progressi nell‚Äôapprendimento automatico, sebbene il ritmo abbia iniziato a rallentare negli ultimi anni.</p></div></div><p>Si consideri come si √® evoluto il filtraggio dello spam via e-mail:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Sistemi di Rilevamento Precoce dello Spam
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>Basati su regole (anni '80):
IF contains("viagra") OR contains("winner") THEN spam

Statistici (anni '90):
P(spam|word) = (frequency in spam emails) / (total frequency)

Combinati usando Naive Bayes:
P(spam|email) ‚àù P(spam) √ó ‚àè P(word|spam)</code></pre>
</div>
</div>
<p>Il passaggio agli approcci statistici ha cambiato radicalmente il nostro modo di pensare alla creazione di IA introducendo tre concetti fondamentali che rimangono importanti ancora oggi. In primo luogo, la qualit√† e la quantit√† dei dati di addestramento sono diventati importanti quanto gli algoritmi stessi: l‚ÄôIA poteva apprendere solo i modelli presenti nei suoi esempi di addestramento. In secondo luogo, avevamo bisogno di metodi rigorosi per valutare quanto bene l‚ÄôIA funzionasse effettivamente, portando a metriche che potessero misurare il successo e confrontare diversi approcci. In terzo luogo, abbiamo scoperto una tensione intrinseca tra precisione (avere ragione quando facciamo una previsione) e richiamo (catturare tutti i casi che dovremmo trovare), costringendo i progettisti a fare compromessi espliciti in base alle esigenze della loro applicazione. Ad esempio, un filtro antispam potrebbe tollerare un po‚Äô di spam per evitare di bloccare e-mail importanti, mentre la diagnosi medica potrebbe dover catturare ogni potenziale caso anche se ci√≤ significa pi√π falsi allarmi.</p>
<p><a href="#tbl-ai-evolution-strengths" class="quarto-xref">Tabella&nbsp;<span>1.1</span></a> racchiude il percorso evolutivo degli approcci di IA di cui abbiamo discusso finora, evidenziando i punti di forza e le capacit√† chiave emersi con ogni nuovo paradigma. Spostandoci da sinistra a destra nella tabella, possiamo osservare diverse tendenze importanti. Parleremo di apprendimento ‚Äúsuperficiale‚Äù e ‚Äúprofondo‚Äù in seguito, ma √® utile comprendere i compromessi tra gli approcci trattati finora.</p>
<div id="tbl-ai-evolution-strengths" class="hover striped quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;1.1: Evoluzione dell‚ÄôIA - Aspetti Chiave Positivi
</figcaption>
<div aria-describedby="tbl-ai-evolution-strengths-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-hover table-striped caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 22%">
<col style="width: 19%">
<col style="width: 18%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspetto</th>
<th style="text-align: left;">IA simbolica</th>
<th style="text-align: left;">Sistemi esperti</th>
<th style="text-align: left;">Apprendimento statistico</th>
<th style="text-align: left;">Apprendimento superficiale/profondo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Punto di forza</td>
<td style="text-align: left;">Ragionamento logico</td>
<td style="text-align: left;">Competenza di dominio</td>
<td style="text-align: left;">Versatilit√†</td>
<td style="text-align: left;">Riconoscimento di pattern</td>
</tr>
<tr class="even">
<td style="text-align: left;">Miglior caso d‚Äôuso</td>
<td style="text-align: left;">Problemi ben definiti e basati su regole</td>
<td style="text-align: left;">Problemi di dominio specifici</td>
<td style="text-align: left;">Vari problemi di dati strutturati</td>
<td style="text-align: left;">Problemi di dati complessi e non strutturati</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Gestione dei dati</td>
<td style="text-align: left;">Dati minimi necessari</td>
<td style="text-align: left;">Basato sulla conoscenza del dominio</td>
<td style="text-align: left;">Dati moderati richiesti</td>
<td style="text-align: left;">Elaborazione dati su larga scala</td>
</tr>
<tr class="even">
<td style="text-align: left;">Adattabilit√†</td>
<td style="text-align: left;">Regole fisse</td>
<td style="text-align: left;">Adattabilit√† specifica del dominio</td>
<td style="text-align: left;">Adattabile a vari domini</td>
<td style="text-align: left;">Altamente adattabile a diverse attivit√†</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Complessit√† del problema</td>
<td style="text-align: left;">Semplice, basato sulla logica</td>
<td style="text-align: left;">Complicato, specifico del dominio</td>
<td style="text-align: left;">Complesso, strutturato</td>
<td style="text-align: left;">Altamente complesso, non strutturato</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>La tabella funge da ponte tra i primi approcci di cui abbiamo parlato e gli sviluppi pi√π recenti nell‚Äôapprendimento superficiale e profondo che esploreremo in seguito. Pone le basi per comprendere perch√© determinati approcci hanno acquisito importanza in epoche diverse e come ogni nuovo paradigma si √® basato e ha affrontato i limiti dei suoi predecessori. Inoltre, illustra come i punti di forza degli approcci precedenti continuino a influenzare e migliorare le moderne tecniche di IA, in particolare nell‚Äôera dei modelli di fondazione.</p>
</section>
<section id="apprendimento-superficiale-anni-2000" class="level3" data-number="1.2.4">
<h3 data-number="1.2.4" class="anchored" data-anchor-id="apprendimento-superficiale-anni-2000"><span class="header-section-number">1.2.4</span> Apprendimento Superficiale (anni 2000)</h3>
<p>Gli anni 2000 hanno segnato un periodo affascinante nella storia del machine learning che ora chiamiamo l‚Äôera dello ‚Äú‚Äúshallow learning‚Äù [apprendimento superficiale]. Per capire perch√© √® ‚Äúsuperficiale‚Äù, si immagini di costruire una casa: il ‚Äúdeep learning‚Äù [apprendimento profondo] (che √® arrivato dopo) √® come avere pi√π squadre di costruzione che lavorano a diversi livelli contemporaneamente, ciascuna squadra impara dal lavoro delle squadre sottostanti. Al contrario, l‚Äôapprendimento superficiale in genere aveva solo uno o due livelli di elaborazione, come avere solo una squadra di fondazione e una squadra di intelaiatura.</p>
<p>Durante questo periodo, diversi potenti algoritmi hanno dominato il panorama dell‚Äôapprendimento automatico. Ognuno ha portato punti di forza unici a problemi diversi: I ‚Äúdecision trees‚Äù [alberi decisionali] hanno fornito risultati interpretabili prendendo decisioni molto simili a un diagramma di flusso. I ‚ÄúK-nearest neighbors‚Äù hanno fatto previsioni trovando esempi simili nei dati passati, come chiedere consiglio ai vicini pi√π esperti. La regressione lineare e logistica hanno offerto modelli semplici e interpretabili che hanno funzionato bene per molti problemi del mondo reale. Le ‚ÄúSupport Vector Machine (SVM)‚Äù eccellevano nel trovare confini complessi tra categorie usando il ‚Äútrucco del kernel‚Äù: Si immagini di poter districare una ciotola di spaghetti in linee rette sollevandola in una dimensione superiore. Questi algoritmi hanno costituito la base della macchina pratica.</p>
<p>Si consideri una tipica soluzione di visione artificiale del 2005:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esempio: Pipeline di Visione Artificiale Tradizionale
</div>
</div>
<div class="callout-body-container callout-body">
<pre><code>1. Estrazione Manuale delle Feature
   - SIFT (Scale-Invariant Feature Transform)
   - HOG (Histogram of Oriented Gradients)
   - Filtri di Gabor
2. Selezione/Ingegnerizzazione delle Feature
3. Modello di Apprendimento "Superficiale" (ad esempio, SVM)
4. Post-elaborazione</code></pre>
</div>
</div>
<p>Ci√≤ che ha reso questa era unica √® stato il suo approccio ibrido: caratteristiche ingegnerizzate dall‚Äôuomo combinate con l‚Äôapprendimento statistico. Avevano solide basi matematiche (i ricercatori potevano dimostrare perch√© funzionavano). Hanno funzionato bene anche con dati limitati. Erano efficienti dal punto di vista computazionale. Hanno prodotto risultati affidabili e riproducibili.</p>
<p>Prendiamo l‚Äôesempio del rilevamento dei volti, in cui l‚Äôalgoritmo Viola-Jones (2001) ha ottenuto prestazioni in tempo reale utilizzando semplici ‚Äúfeature‚Äù [caratteristiche] rettangolari e una cascata di classificatori. Questo algoritmo ha alimentato il rilevamento dei volti delle fotocamere digitali per quasi un decennio.</p>
</section>
<section id="deep-learning-2012-oggi" class="level3 page-columns page-full" data-number="1.2.5">
<h3 data-number="1.2.5" class="anchored" data-anchor-id="deep-learning-2012-oggi"><span class="header-section-number">1.2.5</span> Deep Learning (2012-Oggi)</h3>
<p>Mentre le ‚ÄúSupport Vector Machine‚Äù eccellevano nel trovare confini complessi tra categorie usando trasformazioni matematiche, il deep learning ha adottato un approccio radicalmente diverso ispirato all‚Äôarchitettura del cervello umano. Il deep learning √® costruito da ‚Äúlayer‚Äù [strati] di neuroni artificiali, dove ogni layer impara a trasformare i suoi dati di input in rappresentazioni sempre pi√π astratte. Si immagini di elaborare un‚Äôimmagine di un gatto: il primo layer potrebbe imparare a rilevare semplici bordi e contrasti, il layer successivo li combina in forme e texture di base, un altro layer potrebbe riconoscere baffi e orecchie a punta e quelli finali assemblano queste caratteristiche nel concetto di ‚Äúgatto‚Äù. A differenza dei metodi di apprendimento superficiali che richiedevano agli esseri umani di progettare attentamente le feature, le reti di deep learning possono scoprire automaticamente feature utili direttamente dai dati grezzi. Questa capacit√† di apprendere rappresentazioni gerarchiche, da semplici a complesse, da concrete ad astratte, √® ci√≤ che rende il deep learning ‚Äúdeep‚Äù [profondo] e si √® rivelato un approccio straordinariamente potente per la gestione di dati complessi del mondo reale come immagini, discorsi e testo.</p>
<p>Nel 2012, una rete neurale profonda chiamata AlexNet, mostrata in <a href="#fig-alexnet" class="quarto-xref">Figura&nbsp;<span>1.3</span></a>, ha raggiunto una svolta nella competizione ImageNet che avrebbe trasformato il campo del machine learning. La sfida era formidabile: classificare correttamente 1,2 milioni di immagini ad alta risoluzione in 1.000 categorie diverse. Mentre gli approcci precedenti hanno lottato con tassi di errore superiori al 25%, AlexNet ha raggiunto un tasso di errore del 15,3%, superando notevolmente tutti i metodi esistenti.</p>
<div id="fig-alexnet" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/png/alexnet_arch.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alexnet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.3: Architettura della rete neurale profonda per Alexnet. Fonte: <span class="citation" data-cites="krizhevsky2012imagenet">Krizhevsky, Sutskever, e Hinton (<a href="../../../references.it.html#ref-krizhevsky2012imagenet" role="doc-biblioref">2017</a>)</span>
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-krizhevsky2012imagenet" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, e Geoffrey E. Hinton. 2017. <span>¬´ImageNet classification with deep convolutional neural networks¬ª</span>. <em>Communications of the ACM</em> 60 (6): 84‚Äì90. <a href="https://doi.org/10.1145/3065386">https://doi.org/10.1145/3065386</a>.
</div></div></figure>
</div>
<p>Il successo di AlexNet non √® stato solo un risultato tecnico, √® stato un momento spartiacque che ha dimostrato la fattibilit√† pratica del deep learning. Ha dimostrato che con dati sufficienti, potenza di calcolo e innovazioni architettoniche, le reti neurali potevano superare le funzionalit√† progettate a mano e i metodi di apprendimento superficiale che avevano dominato il campo per decenni. Questo singolo risultato ha innescato un‚Äôesplosione di ricerca e applicazioni nel deep learning che continua ancora oggi.</p>
<p>Da questa base, il deep learning √® entrato in un‚Äôera di portata senza precedenti. Verso la fine del 2010, aziende come Google, Facebook e OpenAI stavano addestrando reti neurali migliaia di volte pi√π grandi di <strong>AlexNet</strong><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Questi modelli massicci, spesso chiamati ‚Äúfoundation models‚Äù [modelli di base], hanno portato il deep learning a nuovi livelli. GPT-3, rilasciato nel 2020, conteneva 175 miliardi di <strong>parametri</strong><a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>‚Äîsi immagini uno studente che potesse leggere l‚Äôintera Wikipedia pi√π volte e apprendere modelli da ogni articolo. Questi modelli hanno mostrato capacit√† straordinarie: scrivere testi simili a quelli umani, impegnarsi in conversazioni, generare immagini da descrizioni e persino scrivere codice per computer. L‚Äôintuizione chiave era semplice ma potente: man mano che ingrandivamo le reti neurali e fornivamo loro pi√π dati, queste diventavano in grado di risolvere attivit√† sempre pi√π complesse. Tuttavia, questa scala ha portato sfide di sistema senza precedenti: come si addestrano in modo efficiente modelli che richiedono migliaia di GPU che lavorano in parallelo? Come si archiviano e si forniscono modelli di centinaia di gigabyte di dimensioni? Come si gestiscono gli enormi set di dati necessari per l‚Äôaddestramento?</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Una rivoluzionaria rete neurale profonda del 2012 che ha vinto la <a href="https://www.image-net.org/challenges/LSVRC/">ImageNet competition</a> con un ampio margine e ha contribuito a innescare la rivoluzione del deep learning.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;Simile a come le connessioni neurali del cervello diventano pi√π forti man mano che si apprende una nuova abilit√†, avere pi√π parametri significa generalmente che il modello pu√≤ apprendere schemi pi√π complessi.</p></div><div id="fn5"><p><sup>5</sup>&nbsp;Un tipo di rete neurale appositamente progettata per l‚Äôelaborazione di immagini, ispirata al funzionamento del sistema visivo umano. La parte ‚Äúconvoluzionale‚Äù si riferisce al modo in cui analizza le immagini in piccoli blocchi, in modo simile a come i nostri occhi si concentrano su diverse parti di una scena.</p></div></div><p>La rivoluzione del deep learning del 2012 non √® emersa dal nulla, ma √® stata costruita sulla ricerca sulle reti neurali risalente agli anni ‚Äô50. La storia inizia con il Perceptron di Frank Rosenblatt nel 1957, che ha catturato l‚Äôimmaginazione dei ricercatori mostrando come un semplice neurone artificiale potesse imparare a classificare gli schemi. Sebbene potesse gestire solo problemi linearmente separabili, una limitazione drammaticamente evidenziata dal libro del 1969 di Minsky e Papert ‚ÄúPerceptrons‚Äù, ha introdotto il concetto fondamentale di reti neurali addestrabili. Gli anni ‚Äô80 portarono altre importanti scoperte: Rumelhart, Hinton e Williams introdussero la backpropagation nel 1986, fornendo un modo sistematico per addestrare reti multi-layer, mentre Yann LeCun ne dimostr√≤ l‚Äôapplicazione pratica nel riconoscimento di cifre scritte a mano utilizzando ‚Äú<strong>convolutional neural networks (CNN)‚Äù [reti neurali convoluzionali]</strong><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<div id="vid-tl" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;1.1: Demo di Rete Convoluzionale del 1989
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/FwFduRA_L6Q" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p>Tuttavia, queste reti sono rimaste in gran parte inattive negli anni ‚Äô90 e 2000, non perch√© le idee fossero sbagliate, ma perch√© erano avanti coi tempi: il campo mancava di tre ingredienti importanti: dati sufficienti per addestrare reti complesse, potenza di calcolo sufficiente per elaborare questi dati e le innovazioni tecniche necessarie per addestrare efficacemente reti molto profonde.</p>
<p>Il campo ha dovuto attendere la convergenza dei big data, hardware di elaborazione migliore e innovazioni algoritmiche prima che il potenziale del deep learning potesse essere sbloccato. Questo lungo periodo di gestazione aiuta a spiegare perch√© il momento ImageNet del 2012 √® stato meno una rivoluzione improvvisa e pi√π il culmine di decenni di ricerca accumulata che ha finalmente trovato il suo momento. Come esploreremo nelle sezioni seguenti, questa evoluzione ha portato a due sviluppi significativi nel campo. In primo luogo, ha dato origine alla definizione del campo dell‚Äôingegneria dei sistemi di apprendimento automatico, una disciplina che insegna come colmare il divario tra progressi teorici e implementazione pratica. In secondo luogo, ha reso necessaria una definizione pi√π completa dei sistemi di apprendimento automatico, che comprenda non solo gli algoritmi, ma anche i dati e l‚Äôinfrastruttura informatica. Le attuali sfide di scala riecheggiano molte delle stesse domande fondamentali su metodi di calcolo, dati e apprendimento con cui i ricercatori si sono confrontati sin dall‚Äôinizio del campo, ma ora all‚Äôinterno di un quadro pi√π complesso e interconnesso.</p>
</section>
</section>
<section id="lascesa-dellingegneria-dei-sistemi-di-ml" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="lascesa-dellingegneria-dei-sistemi-di-ml"><span class="header-section-number">1.3</span> L‚ÄôAscesa dell‚ÄôIngegneria dei Sistemi di ML</h2>
<p>La storia che abbiamo tracciato, dai primi giorni del Perceptron alla rivoluzione del deep learning, √® stata in gran parte una storia di innovazioni algoritmiche. Ogni epoca ha portato nuove intuizioni matematiche e approcci di modellazione che hanno ampliato i confini di ci√≤ che l‚ÄôIA poteva raggiungere. Ma qualcosa di importante √® cambiato nell‚Äôultimo decennio: il successo dei sistemi di IA √® diventato sempre pi√π dipendente non solo dalle innovazioni algoritmiche, ma anche da un‚Äôingegneria sofisticata.</p>
<p>Questo cambiamento rispecchia l‚Äôevoluzione dell‚Äôinformatica e dell‚Äôingegneria alla fine degli anni ‚Äô60 e all‚Äôinizio degli anni ‚Äô70. Durante quel periodo, man mano che i sistemi informatici diventavano pi√π complessi, emerse una nuova disciplina: la ‚ÄúComputer Engineering‚Äù [ingegneria informatica]. Questo campo colm√≤ il divario tra l‚Äôesperienza hardware dell‚ÄôIngegneria Elettrica e l‚Äôattenzione dell‚ÄôInformatica su algoritmi e software. L‚ÄôIngegneria Informatica nacque perch√© le sfide della progettazione e della costruzione di sistemi informatici complessi richiedevano un approccio integrato che nessuna delle due discipline poteva affrontare completamente da sola.</p>
<p>Oggi, stiamo assistendo a una transizione simile nel campo dell‚ÄôIA. Mentre l‚ÄôInformatica continua a spingere i confini degli algoritmi di ML e l‚ÄôIngegneria Elettrica fa progredire l‚Äôhardware di IA specializzato, nessuna delle due discipline affronta completamente i principi di ingegneria necessari per distribuire, ottimizzare e sostenere i sistemi di ML su larga scala. Questa lacuna evidenzia la necessit√† di una nuova disciplina: la ‚ÄúMachine Learning Systems Engineering‚Äù [ingegneria dei sistemi di apprendimento automatico].</p>
<p>Non esiste una definizione esplicita di cosa sia questo campo oggi, ma pu√≤ essere ampiamente definito come tale:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definizione di Machine Learning Systems Engineering
</div>
</div>
<div class="callout-body-container callout-body">
<p>La ‚ÄúMachine Learning Systems Engineering (MLSysEng)‚Äù √® la disciplina di progettazione, implementazione e gestione di sistemi di intelligenza artificiale su scale di elaborazione, dai dispositivi embedded con risorse limitate ai computer su scala industriale. Questo campo integra i principi delle discipline ingegneristiche che spaziano dall‚Äôhardware al software per creare sistemi affidabili, efficienti e ottimizzati per il loro contesto di distribuzione. Comprende il ciclo di vita completo delle applicazioni AI: dall‚Äôingegneria dei requisiti e dalla raccolta dati allo sviluppo di modelli, all‚Äôintegrazione di sistemi, alla distribuzione, al monitoraggio e alla manutenzione. Il campo enfatizza i principi ingegneristici di progettazione sistematica, vincoli di risorse, requisiti di prestazioni e affidabilit√† operativa.</p>
</div>
</div>
<p>Consideriamo l‚Äôesplorazione spaziale. Mentre gli astronauti si avventurano in nuove frontiere ed esplorano le vaste incognite dell‚Äôuniverso, le loro scoperte sono possibili solo grazie ai complessi sistemi di ingegneria che li supportano: i razzi che li sollevano nello spazio, i sistemi di supporto vitale che li mantengono in vita e le reti di comunicazione che li mantengono connessi alla Terra. Allo stesso modo, mentre i ricercatori di IA spingono i confini di ci√≤ che √® possibile con gli algoritmi di apprendimento, le loro scoperte diventano realt√† pratica solo attraverso un‚Äôattenta ingegneria dei sistemi. I moderni sistemi di IA necessitano di un‚Äôinfrastruttura solida per raccogliere e gestire i dati, di potenti sistemi di elaborazione per addestrare i modelli e di piattaforme di distribuzione affidabili per servire milioni di utenti.</p>
<p>Questa emergenza dell‚Äôingegneria dei sistemi di apprendimento automatico come disciplina importante riflette una realt√† pi√π ampia: trasformare gli algoritmi di IA in sistemi del mondo reale richiede di colmare il divario tra possibilit√† teoriche e implementazione pratica. Non basta avere un algoritmo brillante se non si riesce a raccogliere ed elaborare in modo efficiente i dati necessari, distribuirne il calcolo su centinaia di macchine, servirlo in modo affidabile a milioni di utenti o monitorarne le prestazioni in produzione.</p>
<p>Comprendere questa interazione tra algoritmi e ingegneria √® diventato fondamentale per i moderni professionisti dell‚ÄôIA. Mentre i ricercatori continuano a spingere i confini di ci√≤ che √® algoritmicamente possibile, gli ingegneri stanno affrontando la complessa sfida di far funzionare questi algoritmi in modo affidabile ed efficiente nel mondo reale. Questo ci porta a una domanda fondamentale: cos‚Äô√® esattamente un sistema di ‚Äúmachine learning‚Äù [apprendimento automatico] e cosa lo rende diverso dai tradizionali sistemi software?</p>
</section>
<section id="definizione-di-un-sistema-ml" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="definizione-di-un-sistema-ml"><span class="header-section-number">1.4</span> Definizione di un sistema ML</h2>
<p>Non esiste una definizione univoca e universalmente accettata di un sistema di apprendimento automatico. Questa ambiguit√† deriva dal fatto che diversi professionisti, ricercatori e settori spesso fanno riferimento ai sistemi di apprendimento automatico in contesti diversi e con ambiti diversi. Alcuni potrebbero concentrarsi esclusivamente sugli aspetti algoritmici, mentre altri potrebbero includere l‚Äôintera pipeline dalla raccolta dati all‚Äôimplementazione del modello. Questo uso approssimativo del termine riflette la natura multidisciplinare e in rapida evoluzione del campo.</p>
<p>Data questa diversit√† di prospettive, √® importante stabilire una definizione chiara e completa che comprenda tutti questi aspetti. In questo libro, adottiamo un approccio olistico ai sistemi di apprendimento automatico, considerando non solo gli algoritmi ma anche l‚Äôintero ecosistema in cui operano. Pertanto, definiamo un sistema di apprendimento automatico come segue:</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Definizione di un Sistema di Machine Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Un sistema di ‚Äúmachine learning‚Äù [apprendimento automatico] √® un sistema di elaborazione integrato che comprende tre componenti principali: (1) dati che guidano il comportamento algoritmico, (2) algoritmi di apprendimento che estraggono modelli da questi dati e (3) infrastruttura di elaborazione che consente sia il processo di apprendimento (ad esempio, addestramento) sia l‚Äôapplicazione della conoscenza appresa (ad esempio, inferenza/servizio). Insieme, questi componenti creano un sistema di elaborazione in grado di fare previsioni, generare contenuti o intraprendere azioni in base a modelli appresi.</p>
</div>
</div>
<p>Il nucleo di qualsiasi sistema di apprendimento automatico √® costituito da tre componenti interrelati, come illustrato in <a href="#fig-ai-triangle" class="quarto-xref">Figura&nbsp;<span>1.4</span></a>: modelli/algoritmi, dati e infrastruttura informatica. Questi componenti formano una dipendenza triangolare in cui ogni elemento plasma fondamentalmente le possibilit√† degli altri. L‚Äôarchitettura del modello detta sia le richieste computazionali per l‚Äôaddestramento e l‚Äôinferenza, sia il volume e la struttura dei dati richiesti per un apprendimento efficace. La scala e la complessit√† dei dati influenzano l‚Äôinfrastruttura necessaria per l‚Äôarchiviazione e l‚Äôelaborazione, determinando contemporaneamente quali architetture del modello sono fattibili. Le capacit√† dell‚Äôinfrastruttura stabiliscono limiti pratici sia sulla scala del modello che sulla capacit√† di elaborazione dei dati, creando un framework all‚Äôinterno del quale devono operare gli altri componenti.</p>
<div id="fig-ai-triangle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/triangle.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-triangle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.4: I sistemi di apprendimento automatico coinvolgono algoritmi, dati e calcoli, tutti interconnessi tra loro.
</figcaption>
</figure>
</div>
<p>Ciascuno di questi componenti ha uno scopo distinto ma interconnesso:</p>
<ul>
<li><p><strong>Algoritmi:</strong> Modelli matematici e metodi che apprendono pattern dai dati per fare previsioni o decisioni</p></li>
<li><p><strong>Dati:</strong> Processi e infrastrutture per la raccolta, l‚Äôarchiviazione, l‚Äôelaborazione, la gestione e la fornitura di dati sia per l‚Äôaddestramento che per l‚Äôinferenza.</p></li>
<li><p><strong>Calcolo:</strong> Infrastruttura hardware e software che consente l‚Äôaddestramento, la fornitura e il funzionamento efficienti di modelli su larga scala.</p></li>
</ul>
<p>L‚Äôinterdipendenza di questi componenti significa che nessun singolo elemento pu√≤ funzionare in modo isolato. L‚Äôalgoritmo pi√π sofisticato non pu√≤ apprendere senza dati o risorse di elaborazione su cui eseguire. I set di dati pi√π grandi sono inutili senza algoritmi per estrarre modelli o infrastrutture per elaborarli. E l‚Äôinfrastruttura di elaborazione pi√π potente non serve a nulla senza algoritmi da eseguire o dati da elaborare.</p>
<p>Per illustrare queste relazioni, possiamo fare un paragone con l‚Äôesplorazione spaziale. Gli sviluppatori di algoritmi sono come gli astronauti: esplorano nuove frontiere e fanno scoperte. I team di data science funzionano come specialisti del controllo missione, assicurando il flusso costante di informazioni e risorse critiche necessarie per far funzionare la missione. Gli ingegneri delle infrastrutture informatiche sono come gli ingegneri missilistici: progettano e costruiscono i sistemi che rendono possibile la missione. Proprio come una missione spaziale richiede l‚Äôintegrazione perfetta di astronauti, controllo missione e sistemi missilistici, un sistema di apprendimento automatico richiede l‚Äôattenta orchestrazione di algoritmi, dati e infrastrutture informatiche.</p>
</section>
<section id="il-ciclo-di-vita-dei-sistemi-ml" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="il-ciclo-di-vita-dei-sistemi-ml"><span class="header-section-number">1.5</span> Il ciclo di vita dei sistemi ML</h2>
<p>I sistemi software tradizionali seguono un ciclo di vita prevedibile in cui gli sviluppatori scrivono istruzioni esplicite che i computer devono eseguire. Questi sistemi sono basati su decenni di consolidate pratiche di ingegneria del software. I sistemi di controllo delle versioni mantengono cronologie precise delle modifiche del codice. Le pipeline di integrazione e distribuzione continue automatizzano i processi di test e rilascio. Gli strumenti di analisi statica misurano la qualit√† del codice e identificano potenziali problemi. Questa infrastruttura consente uno sviluppo, un test e una distribuzione affidabili di sistemi software, seguendo principi ben definiti di ingegneria del software.</p>
<p>I sistemi di apprendimento automatico rappresentano una deviazione fondamentale da questo paradigma tradizionale. Mentre i sistemi tradizionali eseguono una logica di programmazione esplicita, i sistemi di apprendimento automatico derivano il loro comportamento da pattern nei dati. Questo passaggio dal codice ai dati come driver principale del comportamento del sistema introduce nuove complessit√†.</p>
<p>Come illustrato in <a href="#fig-ml_lifecycle_overview" class="quarto-xref">Figura&nbsp;<span>1.5</span></a>, il ciclo di vita ML √® costituito da fasi interconnesse dalla raccolta dati al monitoraggio del modello, con cicli di feedback per il miglioramento continuo quando le prestazioni si degradano o i modelli necessitano di miglioramenti.</p>
<div id="fig-ml_lifecycle_overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/png/ml_lifecycle_overview.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml_lifecycle_overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.5: Il tipico ciclo di vita di un sistema di apprendimento automatico.
</figcaption>
</figure>
</div>
<p>A differenza del codice sorgente, che cambia solo quando gli sviluppatori lo modificano, i dati riflettono la natura dinamica del mondo reale. Le modifiche nelle distribuzioni dei dati possono alterare silenziosamente il comportamento del sistema. Gli strumenti tradizionali di ingegneria del software, progettati per sistemi basati su codice deterministico, si dimostrano insufficienti per la gestione di questi sistemi dipendenti dai dati. Ad esempio, i sistemi di controllo delle versioni che eccellono nel tracciare modifiche discrete del codice hanno difficolt√† a gestire grandi set di dati in evoluzione. I framework di test progettati per output deterministici devono essere adattati per previsioni probabilistiche. Questa natura dipendente dai dati crea un ciclo di vita pi√π dinamico, che richiede un monitoraggio e un adattamento continui per mantenere la pertinenza del sistema man mano che i modelli di dati del mondo reale si evolvono.</p>
<p>Per comprendere il ciclo di vita del sistema di apprendimento automatico √® necessario esaminarne le fasi distinte. Ogni fase presenta requisiti unici sia dal punto di vista dell‚Äôapprendimento che da quello dell‚Äôinfrastruttura. Questa duplice considerazione, delle esigenze di apprendimento e del supporto dei sistemi, √® estremamente importante per la creazione di sistemi di machine learning efficaci.</p>
<p>Tuttavia, le varie fasi del ciclo di vita ML in produzione non sono isolate; sono, infatti, profondamente interconnesse. Questa interconnessione pu√≤ creare circoli virtuosi o viziosi. In un circolo virtuoso, dati di alta qualit√† consentono un apprendimento efficace, infrastrutture robuste supportano un‚Äôelaborazione efficiente e sistemi ben progettati facilitano la raccolta di dati ancora migliori. Tuttavia, in un circolo vizioso, una scarsa qualit√† dei dati mina l‚Äôapprendimento, infrastrutture inadeguate ostacolano l‚Äôelaborazione e le limitazioni del sistema impediscono il miglioramento della raccolta dati: ogni problema aggrava gli altri.</p>
</section>
<section id="lo-spettro-dei-sistemi-ml" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="lo-spettro-dei-sistemi-ml"><span class="header-section-number">1.6</span> Lo Spettro dei Sistemi ML</h2>
<p>La complessit√† della gestione dei sistemi di machine learning diventa ancora pi√π evidente se consideriamo l‚Äôampio spettro in cui il ML viene distribuito oggi. I sistemi di ML esistono su scale molto diverse e in ambienti diversi, ognuno dei quali presenta sfide e vincoli unici.</p>
<p>Da un lato, abbiamo sistemi di ML basati su cloud in esecuzione in enormi data center. Questi sistemi, come i grandi modelli linguistici o i motori di raccomandazione, elaborano petabyte di dati e servono milioni di utenti contemporaneamente. Possono sfruttare risorse di elaborazione virtualmente illimitate, ma devono gestire un‚Äôenorme complessit√† operativa e costi.</p>
<p>Dall‚Äôaltro lato, troviamo sistemi TinyML in esecuzione su microcontrollori e dispositivi embedded. Questi sistemi devono eseguire attivit√† di ML con gravi vincoli di memoria, potenza di elaborazione e consumo energetico. Si immagini un dispositivo per la casa intelligente, come Alexa o Google Assistant, che deve riconoscere i comandi vocali utilizzando meno energia di una lampadina a LED, o un sensore che deve rilevare anomalie mentre funziona a batteria per mesi o addirittura anni.</p>
<p>Tra questi estremi, troviamo una ricca variet√† di sistemi di ML adattati a diversi contesti. I sistemi Edge ML avvicinano il calcolo alle fonti dei dati, riducendo i requisiti di latenza e larghezza di banda e gestendo al contempo le risorse di elaborazione locali. I sistemi ML mobili devono bilanciare capacit√† sofisticate con limitazioni di durata della batteria e del processore su smartphone e tablet. I sistemi ML aziendali spesso operano entro vincoli aziendali specifici, concentrandosi su attivit√† particolari e integrandosi con l‚Äôinfrastruttura esistente. Alcune organizzazioni impiegano approcci ibridi, distribuendo le capacit√† ML su pi√π livelli per bilanciare vari requisiti.</p>
</section>
<section id="implicazioni-del-sistema-di-ml-sul-ciclo-di-vita-ml" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="implicazioni-del-sistema-di-ml-sul-ciclo-di-vita-ml"><span class="header-section-number">1.7</span> Implicazioni del Sistema di ML sul Ciclo di Vita ML</h2>
<p>La diversit√† dei sistemi ML nell‚Äôintero spettro rappresenta una complessa interazione di requisiti, vincoli e compromessi. Queste decisioni hanno un impatto fondamentale su ogni fase del ciclo di vita ML di cui abbiamo parlato in precedenza, dalla raccolta dati al funzionamento continuo.</p>
<p>I requisiti di prestazioni spesso guidano le decisioni architettoniche iniziali. Le applicazioni sensibili alla latenza, come i veicoli autonomi o il rilevamento delle frodi in tempo reale, potrebbero richiedere architetture edge o embedded nonostante i loro vincoli di risorse. Al contrario, le applicazioni che richiedono un‚Äôenorme potenza di calcolo per l‚Äôaddestramento, come i grandi modelli linguistici, gravitano naturalmente verso architetture cloud centralizzate. Tuttavia, le mere prestazioni sono solo una considerazione in uno spazio decisionale complesso.</p>
<p>La gestione delle risorse varia notevolmente tra le architetture. I sistemi cloud devono ottimizzare l‚Äôefficienza dei costi su larga scala, bilanciando costosi cluster GPU, sistemi di archiviazione e larghezza di banda di rete. I sistemi edge affrontano limiti di risorse fissate e devono gestire attentamente l‚Äôelaborazione e l‚Äôarchiviazione locali. I sistemi mobili ed embedded operano con i vincoli pi√π rigorosi, in cui ogni byte di memoria e milliwatt di potenza sono importanti. Queste considerazioni sulle risorse influenzano direttamente sia la progettazione del modello che l‚Äôarchitettura del sistema.</p>
<p>La complessit√† operativa aumenta con la distribuzione del sistema. Mentre le architetture cloud centralizzate traggono vantaggio da strumenti di distribuzione maturi e servizi gestiti, i sistemi edge e ibridi devono gestire la complessit√† della gestione del sistema distribuito. Questa complessit√† si manifesta durante l‚Äôintero ciclo di vita del ML, dalla raccolta dati e dal controllo delle versioni alla distribuzione e al monitoraggio del modello. Come discusso nell‚Äôesame del debito tecnico, questa complessit√† operativa pu√≤ aumentare nel tempo se non gestita attentamente.</p>
<p>Le considerazioni sui dati spesso introducono pressioni concorrenti. I requisiti sulla privacy o le normative sulla sovranit√† dei dati potrebbero spingere verso architetture edge o integrate, mentre la necessit√† di dati di formazione su larga scala potrebbe favorire approcci cloud. Anche la velocit√† e il volume dei dati influenzano le scelte architettoniche: i dati dei sensori in tempo reale potrebbero richiedere l‚Äôelaborazione edge per gestire la larghezza di banda, mentre l‚Äôanalisi batch potrebbe essere pi√π adatta all‚Äôelaborazione cloud.</p>
<p>I requisiti di evoluzione e manutenzione devono essere considerati fin dall‚Äôinizio. Le architetture cloud offrono flessibilit√† per l‚Äôevoluzione del sistema, ma possono comportare costi continui significativi. I sistemi edge ed embedded potrebbero essere pi√π difficili da aggiornare, ma potrebbero offrire un sovraccarico operativo inferiore. Il ciclo continuo dei sistemi ML di cui abbiamo parlato in precedenza diventa particolarmente impegnativo nelle architetture distribuite, dove l‚Äôaggiornamento dei modelli e il mantenimento dello stato di salute del sistema richiedono un‚Äôattenta orchestrazione su pi√π piani.</p>
<p>Questi compromessi sono raramente semplici scelte binarie. I moderni sistemi ML adottano spesso approcci ibridi, bilanciando attentamente queste considerazioni in base a casi d‚Äôuso e vincoli specifici. La chiave √® comprendere come queste decisioni influenzeranno il sistema durante tutto il suo ciclo di vita, dallo sviluppo iniziale al funzionamento continuo e all‚Äôevoluzione.</p>
<section id="tendenze-emergenti" class="level3" data-number="1.7.1">
<h3 data-number="1.7.1" class="anchored" data-anchor-id="tendenze-emergenti"><span class="header-section-number">1.7.1</span> Tendenze Emergenti</h3>
<p>Siamo solo all‚Äôinizio. Man mano che i sistemi di apprendimento automatico continuano a evolversi, diverse tendenze chiave stanno rimodellando il panorama della progettazione e dell‚Äôimplementazione dei sistemi ML.</p>
<p>L‚Äôascesa dei ‚Äúagentic system‚Äù [sistemi agenti] segna una profonda evoluzione nei sistemi ML. I sistemi ML tradizionali erano principalmente reattivi: facevano previsioni o classificazioni basate sui dati di input. Al contrario, i ‚Äúagentic system‚Äù possono intraprendere azioni, imparare dai loro risultati e adattare il loro comportamento di conseguenza. Questi sistemi, esemplificati da agenti autonomi in grado di pianificare, ragionare ed eseguire attivit√† complesse, introducono nuove sfide architettoniche. Richiedono framework sofisticati per il processo decisionale, vincoli di sicurezza e interazione in tempo reale con l‚Äôambiente.</p>
<p>L‚Äôevoluzione architettonica √® guidata da nuovi pattern di hardware e di distribuzione. Acceleratori AI specializzati stanno emergendo in tutto lo spettro, dai potenti chip dei data center agli efficienti processori edge alle minuscole unit√† di elaborazione neurale nei dispositivi mobili. Questo panorama informatico eterogeneo sta abilitando nuove possibilit√† architettoniche, come la distribuzione dinamica dei modelli tra livelli in base alle capacit√† di elaborazione e alle condizioni attuali. I confini tradizionali tra cloud, edge e sistemi embedded stanno diventando sempre pi√π fluidi.</p>
<p>L‚Äôefficienza delle risorse sta acquisendo importanza man mano che i costi ambientali ed economici del ML su larga scala diventano pi√π evidenti. Ci√≤ ha innescato l‚Äôinnovazione nella compressione dei modelli, nelle tecniche di addestramento efficienti e nell‚Äôelaborazione consapevole dei consumi energetici. I sistemi futuri dovranno probabilmente bilanciare la spinta verso modelli pi√π potenti con le crescenti preoccupazioni per la sostenibilit√†. Questa enfasi sull‚Äôefficienza √® particolarmente rilevante data la nostra precedente discussione sul debito tecnico e sui costi operativi.</p>
<p>L‚Äôintelligenza di sistema si sta muovendo verso un funzionamento pi√π autonomo. I futuri sistemi ML probabilmente incorporeranno un auto-monitoraggio pi√π sofisticato, una gestione automatizzata delle risorse e strategie di distribuzione adattive. Questa evoluzione si basa sul ciclo continuo discusso in precedenza, ma con una maggiore automazione nella gestione dei turni di distribuzione dei dati, degli aggiornamenti dei modelli e dell‚Äôottimizzazione del sistema.</p>
<p>Le sfide dell‚Äôintegrazione stanno diventando pi√π complesse man mano che i sistemi ML interagiscono con ecosistemi tecnologici pi√π ampi. La necessit√† di integrarsi con i sistemi software esistenti, gestire diverse fonti di dati e operare oltre i confini organizzativi sta guidando nuovi approcci alla progettazione del sistema. Questa complessit√† di integrazione aggiunge nuove dimensioni alle considerazioni sul debito tecnico esplorato in precedenza.</p>
<p>Queste tendenze suggeriscono che i futuri sistemi ML dovranno essere sempre pi√π adattabili ed efficienti, gestendo al contempo una crescente complessit√†. Comprendere queste direzioni √® importante per costruire sistemi che possano evolversi con il settore, evitando al contempo l‚Äôaccumulo di debito tecnico di cui abbiamo parlato in precedenza.</p>
</section>
</section>
<section id="applicazioni-e-impatto-nel-mondo-reale" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="applicazioni-e-impatto-nel-mondo-reale"><span class="header-section-number">1.8</span> Applicazioni e Impatto nel Mondo Reale</h2>
<p>La capacit√† di creare e rendere operativi sistemi ML su diverse scale e ambienti ha portato a cambiamenti trasformativi in numerosi settori. Questa sezione presenta alcuni esempi in cui i concetti teorici e le considerazioni pratiche di cui abbiamo discusso si manifestano in applicazioni tangibili e di impatto nel mondo reale.</p>
<p>This section showcases a few examples where theoretical concepts and practical considerations we have discussed manifest in tangible, impactful applications and real-world impact.</p>
<section id="caso-di-studio-farmbeats-ml-edge-ed-embedded-per-lagricoltura" class="level3" data-number="1.8.1">
<h3 data-number="1.8.1" class="anchored" data-anchor-id="caso-di-studio-farmbeats-ml-edge-ed-embedded-per-lagricoltura"><span class="header-section-number">1.8.1</span> Caso di Studio: FarmBeats: ML Edge ed Embedded per l‚ÄôAgricoltura</h3>
<p>FarmBeats, un progetto sviluppato da Microsoft Research, mostrato in <a href="#fig-farmbeats-overview" class="quarto-xref">Figura&nbsp;<span>1.6</span></a>, √® un progresso significativo nell‚Äôapplicazione dell‚Äôapprendimento automatico all‚Äôagricoltura. Questo sistema mira ad aumentare la produttivit√† agricola e ridurre i costi sfruttando le tecnologie AI e IoT. FarmBeats esemplifica come i sistemi ML edge ed embedded possono essere distribuiti in ambienti reali e difficili per risolvere problemi pratici. Portando le capacit√† ML direttamente in azienda agricola, FarmBeats dimostra il potenziale dei sistemi AI distribuiti nella trasformazione delle industrie tradizionali.</p>
<div id="fig-farmbeats-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/png/farmbeats.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-farmbeats-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.6: Microsoft Farmbeats: AI, Edge e IoT per l‚ÄôAgricoltura.
</figcaption>
</figure>
</div>
<p><strong>Aspetti dei Dati</strong></p>
<p>L‚Äôecosistema di dati in FarmBeats √® diversificato e distribuito. I sensori distribuiti nei campi raccolgono dati in tempo reale su umidit√† del suolo, temperatura e livelli di nutrienti. I droni dotati di telecamere multispettrali catturano immagini ad alta risoluzione delle colture, fornendo informazioni sulla salute delle piante e sui pattern di crescita. Le stazioni meteorologiche forniscono dati climatici locali, mentre le registrazioni agricole storiche offrono un contesto per le tendenze a lungo termine. La sfida non risiede solo nella raccolta di questi dati eterogenei, ma anche nella gestione del loro flusso da luoghi dispersi, spesso remoti, con connettivit√† limitata. FarmBeats impiega tecniche innovative di trasmissione dati, come l‚Äôutilizzo di spazi TV vuoti (frequenze di trasmissione inutilizzate) per estendere la connettivit√† Internet a sensori distanti. Questo approccio alla raccolta e alla trasmissione dei dati incarna i principi dell‚Äôedge computing discussi in precedenza, in cui l‚Äôelaborazione dei dati inizia alla fonte per ridurre i requisiti di larghezza di banda e consentire il processo decisionale in tempo reale.</p>
<p><strong>Aspetti Algoritmo/Modello</strong></p>
<p>FarmBeats utilizza una variet√† di algoritmi ML su misura per applicazioni agricole. Per la previsione dell‚Äôumidit√† del suolo, utilizza reti neurali temporali in grado di catturare le complesse dinamiche del movimento dell‚Äôacqua nel suolo. Gli algoritmi di visione artificiale elaborano le immagini dei droni per rilevare lo stress delle colture, le infestazioni di parassiti e le stime della resa. Questi modelli devono essere robusti ai dati rumorosi e in grado di funzionare con risorse computazionali limitate. I metodi di apprendimento automatico come il ‚Äútransfer learning‚Äù consentono ai modelli di addestrarsi su aziende agricole ricche di dati per essere adattati all‚Äôuso in aree con dati storici limitati. Il sistema incorpora anche una combinazione di metodi che combinano gli output di pi√π algoritmi per migliorare l‚Äôaccuratezza e l‚Äôaffidabilit√† delle previsioni. Una sfida chiave che FarmBeats affronta √® la personalizzazione del modello, ovvero l‚Äôadattamento di modelli generali alle condizioni specifiche delle singole aziende agricole, che possono avere composizioni del suolo, microclimi e pratiche agricole uniche.</p>
<p><strong>Aspetti dell‚ÄôInfrastruttura Informatica</strong></p>
<p>FarmBeats esemplifica il paradigma di edge computing esplorato nella discussione sullo spettro del sistema ML. Al livello pi√π basso, i modelli ML embedded vengono eseguiti direttamente su dispositivi e sensori IoT, eseguendo il filtraggio dei dati di base e il rilevamento delle anomalie. I dispositivi edge, come i ‚Äúruggedized field gateway‚Äù [gateway di campo rinforzati], aggregano i dati da pi√π sensori ed eseguono modelli pi√π complessi per il processo decisionale locale. Questi dispositivi edge operano in condizioni difficili, richiedendo progetti hardware robusti e una gestione efficiente dell‚Äôalimentazione per funzionare in modo affidabile in contesti agricoli remoti. Il sistema impiega un‚Äôarchitettura gerarchica, con attivit√† pi√π intensive dal punto di vista computazionale scaricate su server locali o sul cloud. Questo approccio a livelli consente a FarmBeats di bilanciare la necessit√† di elaborazione in tempo reale con i vantaggi dell‚Äôanalisi centralizzata dei dati e del training del modello. L‚Äôinfrastruttura include anche meccanismi per gli aggiornamenti dei modelli over-the-air, assicurando che i dispositivi edge possano ricevere modelli migliorati man mano che diventano disponibili pi√π dati e gli algoritmi vengono perfezionati.</p>
<p><strong>Impatto e Implicazioni Future</strong></p>
<p>FarmBeats mostra come i sistemi ML possono essere distribuiti in ambienti reali con risorse limitate per guidare miglioramenti significativi nei settori tradizionali. Fornendo agli agricoltori informazioni basate sull‚ÄôIA, il sistema ha dimostrato il potenziale per aumentare le rese delle colture, ridurre l‚Äôuso dell‚Äôacqua e ottimizzare l‚Äôallocazione delle risorse. Guardando al futuro, l‚Äôapproccio FarmBeats potrebbe essere esteso per affrontare le sfide globali in materia di sicurezza alimentare e agricoltura sostenibile. Il successo di questo sistema evidenzia anche la crescente importanza dell‚Äôedge e dell‚Äôembedded ML nelle applicazioni IoT, dove avvicinare l‚Äôintelligenza alla sorgente dei dati pu√≤ portare a soluzioni pi√π reattive, efficienti e scalabili. Man mano che le capacit√† di edge computing continuano a progredire, possiamo aspettarci di vedere simili architetture ML distribuite applicate ad altri domini, dalle smart city al monitoraggio ambientale.</p>
</section>
<section id="caso-di-studio-alphafold-ml-scientifico-su-larga-scala" class="level3" data-number="1.8.2">
<h3 data-number="1.8.2" class="anchored" data-anchor-id="caso-di-studio-alphafold-ml-scientifico-su-larga-scala"><span class="header-section-number">1.8.2</span> Caso di Studio: AlphaFold: ML Scientifico su Larga Scala</h3>
<p>AlphaFold, sviluppato da DeepMind, √® un traguardo storico nell‚Äôapplicazione dell‚Äôapprendimento automatico a problemi scientifici complessi. Questo sistema di IA √® progettato per prevedere la struttura tridimensionale delle proteine, come mostrato in <a href="#fig-alphafold-overview" class="quarto-xref">Figura&nbsp;<span>1.7</span></a>, dalle loro sequenze di amminoacidi, una sfida nota come ‚Äúproblema del ripiegamento delle proteine‚Äù che ha lasciato perplessi gli scienziati per decenni. Il successo di AlphaFold dimostra come i sistemi di ML su larga scala possano accelerare la scoperta scientifica e potenzialmente rivoluzionare campi come la biologia strutturale e la progettazione di farmaci. Questo studio di caso esemplifica l‚Äôuso di tecniche di ML avanzate e di enormi risorse computazionali per affrontare problemi alle frontiere della scienza.</p>
<div id="fig-alphafold-overview" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/alphafold.gif" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-alphafold-overview-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.7: Esempi di target proteici nella categoria di modellazione libera. Fonte: Google DeepMind
</figcaption>
</figure>
</div>
<p><strong>Aspetti dei Dati</strong></p>
<p>I dati alla base del successo di AlphaFold sono vasti e sfaccettati. Il set di dati principale √® il Protein Data Bank (PDB), che contiene le strutture determinate sperimentalmente di oltre 180.000 proteine. Questo √® completato da database di sequenze proteiche, che assommano a centinaia di milioni. AlphaFold utilizza anche dati evolutivi sotto forma di allineamenti di sequenze multiple (MSA), che forniscono informazioni sui modelli di conservazione degli amminoacidi nelle proteine correlate. La sfida non risiede solo nel volume dei dati, ma anche nella loro qualit√† e rappresentazione. Le strutture proteiche sperimentali possono contenere errori o essere incomplete, il che richiede sofisticati processi di pulizia e convalida dei dati. Inoltre, la rappresentazione delle strutture e delle sequenze proteiche in una forma adatta all‚Äôapprendimento automatico √® una sfida significativa di per s√©. La pipeline di dati di AlphaFold prevede complessi passaggi di pre-elaborazione per convertire i dati grezzi di sequenza e strutturali in feature significative che catturano le propriet√† fisiche e chimiche rilevanti per il ripiegamento delle proteine.</p>
<p><strong>Aspetti Algoritmo/Modello</strong></p>
<p>L‚Äôapproccio algoritmico di AlphaFold rappresenta un ‚Äútour de force‚Äù nell‚Äôapplicazione del deep learning ai problemi scientifici. Al centro, AlphaFold utilizza una nuova architettura di rete neurale che si combina con tecniche di biologia computazionale. Il modello impara a prevedere distanze inter-residuo e angoli di torsione, che vengono poi utilizzati per costruire una struttura proteica 3D completa. Un‚Äôinnovazione fondamentale √® l‚Äôuso di layer di ‚Äúattenzione equivariante‚Äù che rispettano le simmetrie intrinseche nelle strutture proteiche. Il processo di apprendimento coinvolge pi√π fasi, tra cui il ‚Äúpre-addestramento‚Äù iniziale su un ampio corpus di sequenze proteiche, seguito da una messa a punto su strutture note. AlphaFold incorpora anche la conoscenza del dominio sotto forma di vincoli basati sulla fisica e funzioni di punteggio, creando un sistema ibrido che sfrutta sia l‚Äôapprendimento basato sui dati sia la conoscenza scientifica pregressa. La capacit√† del modello di generare stime di confidenza accurate per le sue previsioni √® fondamentale, consentendo ai ricercatori di valutare l‚Äôaffidabilit√† delle strutture previste.</p>
<p><strong>Aspetti dell‚ÄôInfrastruttura Informatica</strong></p>
<p>Le esigenze computazionali di AlphaFold esemplificano le sfide dei sistemi ML scientifici su larga scala. L‚Äôaddestramento del modello richiede enormi risorse di elaborazione parallela, sfruttando cluster di GPU o TPU (Tensor Processing Unit) in un ambiente di elaborazione distribuito. DeepMind ha utilizzato l‚Äôinfrastruttura cloud di Google, con la versione finale di AlphaFold addestrata su 128 core TPUv3 per diverse settimane. Il processo di inferenza, sebbene meno intensivo dal punto di vista computazionale rispetto all‚Äôaddestramento, richiede comunque risorse significative, soprattutto quando si prevedono strutture per proteine di grandi dimensioni o si elaborano molte proteine in parallelo. Per rendere AlphaFold pi√π accessibile alla comunit√† scientifica, DeepMind ha collaborato con l‚ÄôEuropean Bioinformatics Institute per creare un <a href="https://alphafold.ebi.ac.uk/">database pubblico</a> di strutture proteiche previste, che di per s√© rappresenta una sfida sostanziale per l‚Äôelaborazione e la gestione dei dati. Questa infrastruttura consente ai ricercatori di tutto il mondo di accedere alle previsioni di AlphaFold senza dover eseguire il modello in proprio, dimostrando come le risorse di elaborazione centralizzate e ad alte prestazioni possano essere sfruttate per democratizzare l‚Äôaccesso alle funzionalit√† ML avanzate.</p>
<p><strong>Impatto e Implicazioni Future</strong></p>
<p>L‚Äôimpatto di AlphaFold sulla biologia strutturale √® stato profondo, con il potenziale di accelerare la ricerca in aree che vanno dalla biologia fondamentale alla scoperta di farmaci. Fornendo previsioni strutturali accurate per proteine che hanno resistito ai metodi sperimentali, AlphaFold apre nuove strade per comprendere i meccanismi delle malattie e progettare terapie mirate. Il successo di AlphaFold serve anche come una potente dimostrazione di come il ML pu√≤ essere applicato ad altri complessi problemi scientifici, portando potenzialmente a scoperte in campi come la scienza dei materiali o la modellazione climatica. Tuttavia, solleva anche importanti questioni sul ruolo dell‚ÄôIA nella scoperta scientifica e sulla natura mutevole dell‚Äôindagine scientifica nell‚Äôera dei sistemi ML su larga scala. Mentre guardiamo al futuro, l‚Äôapproccio AlphaFold suggerisce un nuovo paradigma per il ML scientifico, in cui enormi risorse computazionali vengono combinate con conoscenze specifiche del dominio per spingere i confini della comprensione umana.</p>
</section>
<section id="caso-di-studio-veicoli-autonomi-abbracciare-lo-spettro-ml" class="level3" data-number="1.8.3">
<h3 data-number="1.8.3" class="anchored" data-anchor-id="caso-di-studio-veicoli-autonomi-abbracciare-lo-spettro-ml"><span class="header-section-number">1.8.3</span> Caso di Studio: Veicoli Autonomi: Abbracciare lo Spettro ML</h3>
<p>Waymo, una sussidiaria di Alphabet Inc., √® all‚Äôavanguardia nella tecnologia dei veicoli autonomi, rappresentando una delle applicazioni pi√π ambiziose dei sistemi di apprendimento automatico fino ad oggi. Evoluzione del Google Self-Driving Car Project avviato nel 2009, l‚Äôapproccio di Waymo alla guida autonoma esemplifica come i sistemi ML possano abbracciare l‚Äôintero spettro, dai sistemi embedded all‚Äôinfrastruttura cloud. Questo caso di studio mostra l‚Äôimplementazione pratica di sistemi ML complessi in un ambiente reale critico per la sicurezza, integrando il processo decisionale in tempo reale con l‚Äôaddestramento e l‚Äôadattamento a lungo termine.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/hA_-MkU0Nfw?si=6DIH7qwMbeMicnJ5" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Aspetti dei Dati</strong></p>
<p>L‚Äôecosistema di dati alla base della tecnologia Waymo √® vasto e dinamico. Ogni veicolo funge da data center itinerante, la sua suite di sensori, composta da LiDAR, radar e telecamere ad alta risoluzione, genera circa un terabyte di dati per ora di guida. Questi dati del mondo reale sono integrati da un set di dati simulato ancora pi√π esteso, con i veicoli Waymo che hanno percorso oltre 20 miliardi di miglia in simulazione e pi√π di 20 milioni di miglia su strade pubbliche. La sfida non risiede solo nel volume di dati, ma nella loro eterogeneit√† e nella necessit√† di elaborazione in tempo reale. Waymo deve gestire contemporaneamente sia dati strutturati (ad esempio, coordinate GPS) che non strutturati (ad esempio, immagini della telecamera). La pipeline di dati si estende dall‚Äôelaborazione edge sul veicolo stesso a enormi sistemi di archiviazione ed elaborazione basati su cloud. Sono necessari sofisticati processi di validazione e pulizia dei dati, data la natura critica per la sicurezza dell‚Äôapplicazione. Inoltre, la rappresentazione dell‚Äôambiente del veicolo in una forma adatta all‚Äôapprendimento automatico presenta sfide significative, che richiedono una pre-elaborazione complessa per convertire i dati grezzi dei sensori in caratteristiche significative che catturino le dinamiche degli scenari di traffico.</p>
<p><strong>Aspetti Algoritmo/Modello</strong></p>
<p>Lo stack ML di Waymo rappresenta un sofisticato insieme di algoritmi su misura per la sfida multiforme della guida autonoma. Il sistema di percezione impiega tecniche di deep learning, tra cui reti neurali convoluzionali, per elaborare dati visivi per il rilevamento e il tracciamento di oggetti. I modelli di previsione, necessari per anticipare il comportamento di altri utenti della strada, sfruttano reti neurali ricorrenti per comprendere sequenze temporali. Waymo ha sviluppato modelli ML personalizzati come VectorNet per prevedere le traiettorie dei veicoli. I sistemi di pianificazione e decisionali possono incorporare tecniche di apprendimento per rinforzo o apprendimento per imitazione per navigare in scenari di traffico complessi. Un‚Äôinnovazione fondamentale nell‚Äôapproccio di Waymo √® l‚Äôintegrazione di questi diversi modelli in un sistema coerente in grado di funzionare in tempo reale. I modelli ML devono anche essere interpretabili in una certa misura, poich√© comprendere il ragionamento alla base delle decisioni di un veicolo √® fondamentale per la sicurezza e la conformit√† alle normative. Il processo di apprendimento di Waymo implica un continuo perfezionamento basato su esperienze di guida nel mondo reale e simulazioni approfondite, creando un ciclo di feedback che migliora costantemente le prestazioni del sistema.</p>
<p><strong>Aspetti dell‚ÄôInfrastruttura Informatica</strong></p>
<p>L‚Äôinfrastruttura informatica che supporta i veicoli autonomi di Waymo incarna le sfide dell‚Äôimplementazione di sistemi ML nell‚Äôintero spettro, dall‚Äôedge al cloud. Ogni veicolo √® dotato di una piattaforma informatica personalizzata in grado di elaborare dati dei sensori e prendere decisioni in tempo reale, spesso sfruttando hardware specializzato come GPU o acceleratori AI personalizzati. Questo edge computing √® completato da un ampio utilizzo dell‚Äôinfrastruttura cloud, sfruttando la potenza dei data center di Google per la formazione di modelli, l‚Äôesecuzione di simulazioni su larga scala e l‚Äôesecuzione di apprendimento a livello di flotta. La connettivit√† tra questi livelli √® fondamentale, con veicoli che richiedono comunicazioni affidabili e ad alta larghezza di banda per aggiornamenti in tempo reale e caricamento dati. L‚Äôinfrastruttura di Waymo deve essere progettata per robustezza e tolleranza agli errori, garantendo un funzionamento sicuro anche in caso di guasti hardware o interruzioni di rete. La portata delle operazioni di Waymo presenta sfide significative nella gestione dei dati, nell‚Äôimplementazione dei modelli e nel monitoraggio del sistema in una flotta di veicoli distribuita geograficamente.</p>
<p><strong>Impatto e Implicazioni Future</strong></p>
<p>L‚Äôimpatto di Waymo si estende oltre il progresso tecnologico, rivoluzionando potenzialmente i trasporti, la pianificazione urbana e numerosi aspetti della vita quotidiana. Il lancio di Waymo One, un servizio di ‚Äúride-hailing‚Äù [a chiamata] commerciale che utilizza veicoli autonomi a Phoenix, in Arizona, rappresenta una pietra miliare significativa nell‚Äôimplementazione pratica dei sistemi di IA in applicazioni critiche per la sicurezza. I progressi di Waymo hanno implicazioni pi√π ampie per lo sviluppo di sistemi di IA solidi e reali, guidando innovazioni nella tecnologia dei sensori, nell‚Äôedge computing e nella sicurezza dell‚ÄôIA che hanno applicazioni ben oltre l‚Äôindustria automobilistica. Tuttavia, solleva anche importanti questioni su responsabilit√†, etica e interazione tra sistemi di IA e societ√† umana. Mentre Waymo continua ad espandere le sue operazioni ed esplorare applicazioni nei trasporti su camion e nelle consegne dell‚Äôultimo miglio, funge da importante banco di prova per sistemi di ML avanzati, guidando i progressi in aree come l‚Äôapprendimento continuo, la percezione robusta e l‚Äôinterazione uomo-IA. Il caso di studio di Waymo sottolinea sia l‚Äôenorme potenziale dei sistemi di ML per trasformare i settori sia le complesse sfide implicate nell‚Äôimplementazione dell‚ÄôIA nel mondo reale.</p>
</section>
</section>
<section id="sfide-e-considerazioni" class="level2" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="sfide-e-considerazioni"><span class="header-section-number">1.9</span> Sfide e Considerazioni</h2>
<p>La creazione e l‚Äôimplementazione di sistemi di apprendimento automatico presentano sfide uniche che vanno oltre lo sviluppo software tradizionale. Queste sfide aiutano a spiegare perch√© la creazione di sistemi ML efficaci non riguarda solo la scelta dell‚Äôalgoritmo giusto o la raccolta di dati sufficienti. Esploriamo le aree chiave in cui i professionisti del ML affrontano ostacoli significativi.</p>
<section id="sfide-dei-dati" class="level3" data-number="1.9.1">
<h3 data-number="1.9.1" class="anchored" data-anchor-id="sfide-dei-dati"><span class="header-section-number">1.9.1</span> Sfide dei Dati</h3>
<p>Il fondamento di qualsiasi sistema ML sono i suoi dati e la gestione di questi dati presenta diverse sfide fondamentali. Innanzitutto, c‚Äô√® la questione di base della qualit√† dei dati: i dati del mondo reale sono spesso disordinati e incoerenti. Si immagini un‚Äôapplicazione sanitaria che deve elaborare le cartelle cliniche dei pazienti di diversi ospedali. Ogni ospedale potrebbe registrare le informazioni in modo diverso, utilizzare unit√† di misura diverse o avere standard diversi per i dati da raccogliere. Alcune cartelle potrebbero avere informazioni mancanti, mentre altre potrebbero contenere errori o incongruenze che devono essere eliminate prima che i dati possano essere utili.</p>
<p>Man mano che i sistemi ML crescono, spesso devono gestire quantit√† di dati sempre maggiori. Un servizio di streaming video come Netflix, ad esempio, deve elaborare miliardi di interazioni con gli spettatori per alimentare il suo sistema di raccomandazione. Questa scala introduce nuove sfide su come archiviare, elaborare e gestire in modo efficiente set di dati cos√¨ grandi.</p>
<p>Un‚Äôaltra sfida critica √® il modo in cui i dati cambiano nel tempo. Questo fenomeno, noto come ‚Äúdata drift‚Äù, si verifica quando i modelli nei nuovi dati iniziano a differire dai modelli da cui il sistema ha appreso originariamente. Ad esempio, molti modelli predittivi hanno avuto difficolt√† durante la pandemia di COVID-19 perch√© il comportamento dei consumatori √® cambiato cos√¨ drasticamente che i modelli storici sono diventati meno rilevanti. I sistemi ML hanno bisogno di modi per rilevare quando ci√≤ accade e adattarsi di conseguenza.</p>
</section>
<section id="sfide-del-modello" class="level3" data-number="1.9.2">
<h3 data-number="1.9.2" class="anchored" data-anchor-id="sfide-del-modello"><span class="header-section-number">1.9.2</span> Sfide del Modello</h3>
<p>La creazione e la manutenzione dei modelli ML stessi presentano un‚Äôaltra serie di sfide. I moderni modelli ML, in particolare nel deep learning, possono essere estremamente complessi. Si consideri un modello linguistico come GPT-3, che ha centinaia di miliardi di parametri (le singole impostazioni che il modello apprende durante l‚Äôaddestramento). Questa complessit√† crea sfide pratiche: questi modelli richiedono un‚Äôenorme potenza di calcolo per l‚Äôaddestramento e l‚Äôesecuzione, rendendo difficile la loro distribuzione in situazioni con risorse limitate, come su telefoni cellulari o dispositivi IoT.</p>
<p>Addestrare questi modelli in modo efficace √® di per s√© una sfida significativa. A differenza della programmazione tradizionale in cui scriviamo istruzioni esplicite, i modelli ML imparano dagli esempi. Questo processo di apprendimento comporta molte scelte: come dovremmo strutturare il modello? Per quanto tempo dovremmo addestrarlo? Come possiamo sapere se sta imparando le cose giuste? Prendere queste decisioni spesso richiede sia competenza tecnica che notevoli tentativi ed errori.</p>
<p>Una sfida particolarmente importante √® garantire che i modelli funzionino bene in condizioni reali. Un modello potrebbe funzionare in modo eccellente sui suoi dati di addestramento ma fallire quando si trova di fronte a situazioni leggermente diverse nel mondo reale. Questo divario tra le prestazioni di formazione e le prestazioni nel mondo reale √® una sfida centrale nell‚Äôapprendimento automatico, specialmente per applicazioni critiche come veicoli autonomi o sistemi di diagnosi medica.</p>
</section>
<section id="sfide-di-sistema" class="level3" data-number="1.9.3">
<h3 data-number="1.9.3" class="anchored" data-anchor-id="sfide-di-sistema"><span class="header-section-number">1.9.3</span> Sfide di Sistema</h3>
<p>Far funzionare i sistemi ML in modo affidabile nel mondo reale presenta una serie di sfide. A differenza dei software tradizionali che seguono regole fisse, i sistemi ML devono gestire l‚Äôincertezza e la variabilit√† nei loro input e output. In genere necessitano sia di sistemi di formazione (per apprendere dai dati) sia di sistemi di servizio (per fare previsioni), ognuno con requisiti e vincoli diversi.</p>
<p>Si consideri un‚Äôazienda che costruisce un sistema di riconoscimento vocale. Hanno bisogno di infrastrutture per raccogliere e archiviare dati audio, sistemi per addestrare modelli su questi dati e quindi sistemi separati per elaborare effettivamente il parlato degli utenti in tempo reale. Ogni parte di questa pipeline deve funzionare in modo affidabile ed efficiente e tutte le parti devono funzionare insieme senza problemi.</p>
<p>Questi sistemi necessitano anche di monitoraggio e aggiornamento costanti. Come facciamo a sapere se il sistema funziona correttamente? Come aggiorniamo i modelli senza interrompere il servizio? Come gestiamo errori o input imprevisti? Queste sfide operative diventano particolarmente complesse quando i sistemi ML servono milioni di utenti.</p>
</section>
<section id="considerazioni-etiche-e-sociali" class="level3" data-number="1.9.4">
<h3 data-number="1.9.4" class="anchored" data-anchor-id="considerazioni-etiche-e-sociali"><span class="header-section-number">1.9.4</span> Considerazioni Etiche e Sociali</h3>
<p>Man mano che i sistemi ML diventano pi√π diffusi nella nostra vita quotidiana, il loro impatto pi√π ampio sulla societ√† diventa sempre pi√π importante da considerare. Una delle principali preoccupazioni √® l‚Äôequit√†: i sistemi ML a volte possono imparare a prendere decisioni che discriminano determinati gruppi di persone. Ci√≤ accade spesso in modo involontario, poich√© i sistemi rilevano pregiudizi presenti nei loro dati di formazione. Ad esempio, un sistema di screening delle domande di lavoro potrebbe imparare inavvertitamente a favorire determinati dati demografici se tali gruppi avevano storicamente maggiori probabilit√† di essere assunti.</p>
<p>Un‚Äôaltra considerazione importante √® la trasparenza. Molti modelli ML moderni, in particolare i modelli di deep learning, funzionano come ‚Äúscatole nere‚Äù: sebbene possano fare previsioni, √® spesso difficile capire come sono arrivati alle loro decisioni. Ci√≤ diventa particolarmente problematico quando i sistemi ML prendono decisioni importanti sulla vita delle persone, come nell‚Äôassistenza sanitaria o nei servizi finanziari.</p>
<p>Anche la privacy √® una delle principali preoccupazioni. I sistemi ML spesso necessitano di grandi quantit√† di dati per funzionare in modo efficace, ma questi dati potrebbero contenere informazioni personali sensibili. Come bilanciamo la necessit√† di dati con la necessit√† di proteggere la privacy individuale? Come possiamo garantire che i modelli non memorizzino e rivelino inavvertitamente informazioni private?</p>
<p>Queste sfide non sono semplicemente problemi tecnici da risolvere, ma considerazioni in corso che modellano il nostro approccio alla progettazione e all‚Äôimplementazione del sistema ML. In questo libro, esploreremo queste sfide in dettaglio ed esamineremo le strategie per affrontarle in modo efficace.</p>
</section>
</section>
<section id="direzioni-future" class="level2" data-number="1.10">
<h2 data-number="1.10" class="anchored" data-anchor-id="direzioni-future"><span class="header-section-number">1.10</span> Direzioni Future</h2>
<p>Guardando al futuro dei sistemi di apprendimento automatico, diverse tendenze entusiasmanti stanno plasmando il campo. Questi sviluppi promettono sia di risolvere le sfide esistenti sia di aprire nuove possibilit√† per ci√≤ che i sistemi ML possono realizzare.</p>
<p>Una delle tendenze pi√π significative √® la democratizzazione della tecnologia AI. Proprio come i personal computer hanno trasformato l‚Äôinformatica da mainframe specializzati a strumenti di uso quotidiano, i sistemi ML stanno diventando pi√π accessibili a sviluppatori e organizzazioni di tutte le dimensioni. I provider cloud ora offrono modelli pre-addestrati e piattaforme ML automatizzate che riducono le competenze necessarie per implementare soluzioni AI. Questa democratizzazione sta abilitando nuove applicazioni in tutti i settori, dalle piccole imprese che utilizzano l‚ÄôAI per il servizio clienti ai ricercatori che applicano l‚ÄôML a problemi precedentemente intrattabili.</p>
<p>Con l‚Äôaumento delle preoccupazioni sui costi computazionali e sull‚Äôimpatto ambientale, c‚Äô√® una crescente attenzione nel rendere i sistemi ML pi√π efficienti. I ricercatori stanno sviluppando nuove tecniche per addestrare modelli con meno dati e potenza di calcolo. L‚Äôinnovazione nell‚Äôhardware specializzato, dalle GPU migliorate ai chip AI personalizzati, sta rendendo i sistemi ML pi√π veloci e pi√π efficienti dal punto di vista energetico. Questi progressi potrebbero rendere disponibili sofisticate capacit√† AI su pi√π dispositivi, dagli smartphone ai sensori IoT.</p>
<p>Forse la tendenza pi√π trasformativa √® lo sviluppo di sistemi ML pi√π autonomi in grado di adattarsi e migliorarsi. Questi sistemi stanno iniziando a gestire le proprie attivit√† di manutenzione, rilevando quando hanno bisogno di essere riqualificati, trovando e correggendo automaticamente gli errori e ottimizzando le proprie prestazioni. Questa automazione potrebbe ridurre drasticamente le spese generali operative dei sistemi ML in esecuzione, migliorandone al contempo l‚Äôaffidabilit√†.</p>
<p>Sebbene queste tendenze siano promettenti, √® importante riconoscere i limiti del campo. La creazione di un‚Äôintelligenza generale veramente artificiale rimane un obiettivo lontano. Gli attuali sistemi ML eccellono in attivit√† specifiche, ma mancano della flessibilit√† e della comprensione che gli esseri umani danno per scontate. Le sfide relative a pregiudizi, trasparenza e privacy continuano a richiedere un‚Äôattenta considerazione. Man mano che i sistemi ML diventano pi√π diffusi, sar√† fondamentale affrontare queste limitazioni sfruttando al contempo nuove capacit√†.</p>
</section>
<section id="percorso-di-apprendimento-e-struttura-del-libro" class="level2" data-number="1.11">
<h2 data-number="1.11" class="anchored" data-anchor-id="percorso-di-apprendimento-e-struttura-del-libro"><span class="header-section-number">1.11</span> Percorso di Apprendimento e Struttura del Libro</h2>
<p>Questo libro √® progettato per guidare dalla comprensione dei fondamenti dei sistemi ML alla progettazione e all‚Äôimplementazione efficaci. Per affrontare le complessit√† e le sfide dell‚Äôingegneria dei Sistemi di Machine Learning, abbiamo organizzato il contenuto attorno a cinque pilastri fondamentali che comprendono il ciclo di vita dei sistemi ML. Questi pilastri forniscono un framework per comprendere, sviluppare e mantenere sistemi ML robusti.</p>
<div id="fig-pillars" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/book_pillars.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pillars-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;1.8: Panoramica dei cinque pilastri fondamentali del sistema dell‚Äôingegneria dei Sistemi di Machine Learning.
</figcaption>
</figure>
</div>
<p>Come illustrato nella Figura <a href="#fig-pillars" class="quarto-xref">Figura&nbsp;<span>1.8</span></a>, i cinque pilastri centrali del framework sono:</p>
<ul>
<li><strong>Dati</strong>: Enfatizzazione dell‚Äôingegneria dei dati e dei principi fondamentali fondamentali per il funzionamento dell‚ÄôIA in relazione ai dati.</li>
<li><strong>Addestramento</strong>: Esplorazione delle metodologie per l‚Äôaddestramento dell‚ÄôIA, concentrandosi su efficienza, ottimizzazione e tecniche di accelerazione per migliorare le prestazioni del modello.</li>
<li><strong>Distribuzione</strong>: Inclusione di benchmark, strategie di addestramento su dispositivo e operazioni di apprendimento automatico per garantire un‚Äôapplicazione efficace del modello.</li>
<li><strong>Operazioni</strong>: Evidenziazione delle sfide di manutenzione uniche per i sistemi di apprendimento automatico, che richiedono approcci specializzati distinti dai sistemi di ingegneria tradizionali.</li>
<li><strong>Etica e Governance</strong>: Affrontare preoccupazioni quali sicurezza, privacy, pratiche di IA responsabili e le pi√π ampie implicazioni sociali delle tecnologie di IA.</li>
</ul>
<p>Ogni pilastro rappresenta una fase critica nel ciclo di vita dei sistemi ML ed √® composto da elementi fondamentali che si basano l‚Äôuno sull‚Äôaltro. Questa struttura garantisce una comprensione completa di ‚ÄúMachine Learning in Science and Engineering‚Äù (MLSE), dai principi di base alle applicazioni avanzate e alle considerazioni etiche.</p>
<p>Per informazioni pi√π dettagliate sulla panoramica del libro, sui contenuti, sui risultati di apprendimento, sul pubblico target, sui prerequisiti e sulla guida alla navigazione, fare riferimento alla sezione <a href="../../../contents/core/about/about.it.html">Informazioni sul libro</a>. L√¨ si troveranno anche preziosi dettagli sulla nostra comunit√† di apprendimento e su come massimizzare l‚Äôesperienza con questa risorsa.</p>



</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/ml_systems/ml_systems.it.html" class="pagination-link" aria-label="Sistemi di ML">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University). Traduzione di <a href="https://github.com/BravoBaldo">Baldassarre Cesarano</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/introduction/introduction.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/introduction/introduction.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>