<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Avvio al Deep Learning ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/workflow/workflow.it.html" rel="next">
<link href="../../../contents/core/ml_systems/ml_systems.it.html" rel="prev">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script src="../../../scripts/ai_menu/dist/bundle.js" defer=""></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/dl_primer/dl_primer.it.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2b8d2ba3a08f8b4ab16660e3d0aa1206" class="alert alert-primary hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>‚≠ê [18 Ott] <b>Abbiamo raggiunto 1.000 stelle GitHub</b> üéâ Grazie a voi, Arduino e SEEED hanno donato kit hardware di IA per <a href="https://tinyml.seas.harvard.edu/4D/pastEvents">per i workshop TinyML</a> nei paesi in via di sviluppo <br> üéì [15 Nov] La <a href="https://www.edgeaifoundation.org/">EDGE AI Foundation</a> <strong>equipara i fondi per borse di studio accademiche</strong> per ogni nuovo GitHub ‚≠ê (fino a 10.000 stelle). <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per supportare!</a> üôè <br> üöÄ <b>La nostra missione. 1 ‚≠ê = 1 üë©‚Äçüéì Studente</b>. Ogni stella racconta una storia: studenti che acquisiscono conoscenze e sostenitori che guidano la missione. Insieme, stiamo facendo la differenza.</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/about/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/ai/socratiq.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LABORATORI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/part_LABS.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">LABORATORI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/overview.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/part_nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">part_nicla_vision.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/part_xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">part_xiao_esp32s3.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/part_raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">part_raspi.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/part_shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">part_shared.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#panoramica" id="toc-panoramica" class="nav-link active" data-scroll-target="#panoramica"><span class="header-section-number">3.1</span> Panoramica</a>
  <ul>
  <li><a href="#definizione-e-importanza" id="toc-definizione-e-importanza" class="nav-link" data-scroll-target="#definizione-e-importanza"><span class="header-section-number">3.1.1</span> Definizione e Importanza</a></li>
  <li><a href="#breve-storia-del-deep-learning" id="toc-breve-storia-del-deep-learning" class="nav-link" data-scroll-target="#breve-storia-del-deep-learning"><span class="header-section-number">3.1.2</span> Breve Storia del Deep Learning</a></li>
  <li><a href="#applicazioni-del-deep-learning" id="toc-applicazioni-del-deep-learning" class="nav-link" data-scroll-target="#applicazioni-del-deep-learning"><span class="header-section-number">3.1.3</span> Applicazioni del Deep Learning</a></li>
  <li><a href="#rilevanza-per-lia-embedded" id="toc-rilevanza-per-lia-embedded" class="nav-link" data-scroll-target="#rilevanza-per-lia-embedded"><span class="header-section-number">3.1.4</span> Rilevanza per l‚ÄôIA Embedded</a></li>
  </ul></li>
  <li><a href="#reti-neurali" id="toc-reti-neurali" class="nav-link" data-scroll-target="#reti-neurali"><span class="header-section-number">3.2</span> Reti Neurali</a>
  <ul>
  <li><a href="#perceptron" id="toc-perceptron" class="nav-link" data-scroll-target="#perceptron"><span class="header-section-number">3.2.1</span> Perceptron</a></li>
  <li><a href="#perceptron-multilayer" id="toc-perceptron-multilayer" class="nav-link" data-scroll-target="#perceptron-multilayer"><span class="header-section-number">3.2.2</span> Perceptron Multilayer</a></li>
  <li><a href="#processo-di-training" id="toc-processo-di-training" class="nav-link" data-scroll-target="#processo-di-training"><span class="header-section-number">3.2.3</span> Processo di Training</a>
  <ul class="collapse">
  <li><a href="#forward-pass" id="toc-forward-pass" class="nav-link" data-scroll-target="#forward-pass">Forward Pass</a></li>
  <li><a href="#sec-backward_pass" id="toc-sec-backward_pass" class="nav-link" data-scroll-target="#sec-backward_pass">Backward Pass (Backpropagation)</a></li>
  </ul></li>
  <li><a href="#architetture-dei-modelli" id="toc-architetture-dei-modelli" class="nav-link" data-scroll-target="#architetture-dei-modelli"><span class="header-section-number">3.2.4</span> Architetture dei Modelli</a>
  <ul class="collapse">
  <li><a href="#multilayer-perceptron-mlp" id="toc-multilayer-perceptron-mlp" class="nav-link" data-scroll-target="#multilayer-perceptron-mlp">Multilayer Perceptron (MLP)</a></li>
  <li><a href="#convolutional-neural-networks-cnns" id="toc-convolutional-neural-networks-cnns" class="nav-link" data-scroll-target="#convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)</a></li>
  <li><a href="#recurrent-neural-networks-rnn" id="toc-recurrent-neural-networks-rnn" class="nav-link" data-scroll-target="#recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</a></li>
  <li><a href="#generative-adversarial-network-gan" id="toc-generative-adversarial-network-gan" class="nav-link" data-scroll-target="#generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a></li>
  <li><a href="#autoencoder" id="toc-autoencoder" class="nav-link" data-scroll-target="#autoencoder">Autoencoder</a></li>
  <li><a href="#transformer-network" id="toc-transformer-network" class="nav-link" data-scroll-target="#transformer-network">Transformer Network</a></li>
  </ul></li>
  <li><a href="#ml-tradizionale-vs-deep-learning" id="toc-ml-tradizionale-vs-deep-learning" class="nav-link" data-scroll-target="#ml-tradizionale-vs-deep-learning"><span class="header-section-number">3.2.5</span> ML Tradizionale vs Deep Learning</a></li>
  <li><a href="#scelta-tra-ml-tradizionale-e-dl" id="toc-scelta-tra-ml-tradizionale-e-dl" class="nav-link" data-scroll-target="#scelta-tra-ml-tradizionale-e-dl"><span class="header-section-number">3.2.6</span> Scelta tra ML tradizionale e DL</a>
  <ul class="collapse">
  <li><a href="#disponibilit√†-e-volume-dei-dati" id="toc-disponibilit√†-e-volume-dei-dati" class="nav-link" data-scroll-target="#disponibilit√†-e-volume-dei-dati">Disponibilit√† e Volume dei Dati</a></li>
  <li><a href="#complessit√†-del-problema" id="toc-complessit√†-del-problema" class="nav-link" data-scroll-target="#complessit√†-del-problema">Complessit√† del Problema</a></li>
  <li><a href="#risorse-hardware-e-computazionali" id="toc-risorse-hardware-e-computazionali" class="nav-link" data-scroll-target="#risorse-hardware-e-computazionali">Risorse Hardware e Computazionali</a></li>
  <li><a href="#normativa-di-conformit√†" id="toc-normativa-di-conformit√†" class="nav-link" data-scroll-target="#normativa-di-conformit√†">Normativa di Conformit√†</a></li>
  <li><a href="#interpretabilit√†" id="toc-interpretabilit√†" class="nav-link" data-scroll-target="#interpretabilit√†">Interpretabilit√†</a></li>
  </ul></li>
  <li><a href="#fare-una-scelta-informata" id="toc-fare-una-scelta-informata" class="nav-link" data-scroll-target="#fare-una-scelta-informata"><span class="header-section-number">3.2.7</span> Fare una Scelta Informata</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione"><span class="header-section-number">3.3</span> Conclusione</a></li>
  <li><a href="#sec-deep-learning-primer-resource" id="toc-sec-deep-learning-primer-resource" class="nav-link" data-scroll-target="#sec-deep-learning-primer-resource"><span class="header-section-number">3.4</span> Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/dl_primer/dl_primer.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/dl_primer/dl_primer.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-dl_primer" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Risorse: <a href="#sec-deep-learning-primer-resource">Slide</a>, <a href="#sec-deep-learning-primer-resource">Video</a>, <a href="#sec-deep-learning-primer-resource">Esercizi</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/cover_dl_primer.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E 3 Prompt: Foto di un‚Äôaula classica con una grande lavagna che domina una parete. I disegni a gesso mostrano una rete neurale profonda dettagliata con diversi livelli nascosti e ogni nodo e connessione √® etichettato con precisione con il gesso bianco. Il pavimento in legno rustico e le pareti in mattoni creano un contrasto con i concetti moderni. Intorno alla stanza, poster incorniciati sottolineano i temi del deep learning: reti convoluzionali, trasformatori, neuroni, funzioni di attivazione e altro ancora.</em></figcaption>
</figure>
</div>
<p>Questa sezione funge da introduzione al deep learning, fornendo ai professionisti dei sistemi il contesto essenziale e le conoscenze fondamentali necessarie per implementare efficacemente soluzioni di deep learning. Invece di addentrarci in profondit√† teoriche, ci concentriamo su concetti chiave, architetture e considerazioni pratiche rilevanti per l‚Äôimplementazione dei sistemi. Iniziamo con una panoramica dell‚Äôevoluzione del deep learning e del suo particolare significato nei sistemi di intelligenza artificiale embedded. Concetti fondamentali come le reti neurali vengono introdotti con un‚Äôenfasi sulle considerazioni di implementazione piuttosto che sulle basi matematiche.</p>
<p>L‚Äôintroduzione esplora le principali architetture di deep learning da una prospettiva di sistema, esaminandone le implicazioni pratiche e i requisiti di risorse. Confrontiamo inoltre il deep learning con gli approcci tradizionali di machine learning, aiutando i lettori a fare scelte architettoniche informate basate su vincoli di sistema del mondo reale. Questa panoramica di alto livello definisce il contesto per le tecniche e le ottimizzazioni pi√π dettagliate incentrate sui sistemi trattate nei capitoli successivi.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Obiettivi dell‚ÄôApprendimento
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Comprendere i concetti di base e le definizioni delle reti neurali profonde.</p></li>
<li><p>Riconoscere che esistono diverse architetture di modelli di deep learning.</p></li>
<li><p>Confronto tra deep learning e approcci di machine learning [apprendimento automatico] tradizionali in varie dimensioni.</p></li>
<li><p>Acquisire gli elementi concettuali di base per approfondire le tecniche e le applicazioni avanzate del deep learning.</p></li>
</ul>
</div>
</div>
<section id="panoramica" class="level2 page-columns page-full" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="panoramica"><span class="header-section-number">3.1</span> Panoramica</h2>
<section id="definizione-e-importanza" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="definizione-e-importanza"><span class="header-section-number">3.1.1</span> Definizione e Importanza</h3>
<p>Il deep learning, un‚Äôarea specializzata nell‚Äôapprendimento automatico e nell‚Äôintelligenza artificiale (IA), utilizza algoritmi modellati sulla struttura e la funzione del cervello umano, noti come reti neurali artificiali. Questo campo √® un elemento fondamentale nell‚ÄôIA, che guida il progresso in diversi settori come la visione artificiale, l‚Äôelaborazione del linguaggio naturale e i veicoli a guida autonoma. La sua importanza nei sistemi di IA embedded √® evidenziata dalla sua capacit√† di gestire calcoli e previsioni intricati, ottimizzando le risorse limitate nelle impostazioni embedded.</p>
<p>La <a href="#fig-ai-ml-dl" class="quarto-xref">Figura&nbsp;<span>3.1</span></a> fornisce una rappresentazione visiva di come il deep learning si inserisce nel contesto pi√π ampio dell‚ÄôIA e del ‚Äúmachine learning‚Äù [apprendimento automatico]. Il diagramma illustra lo sviluppo cronologico e la relativa segmentazione di questi tre campi interconnessi, mostrando il deep learning come un sottoinsieme specializzato dell‚Äôapprendimento automatico, che a sua volta √® un sottoinsieme dell‚ÄôIA.</p>
<div id="fig-ai-ml-dl" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ai-ml-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ai_dl_progress_nvidia.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ai-ml-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.1: Il diagramma illustra l‚Äôintelligenza artificiale come campo onnicomprensivo che comprende tutti i metodi computazionali che imitano le funzioni cognitive umane. Il Machine learning [apprendimento automatico] √® un sottoinsieme dell‚ÄôIA che include algoritmi in grado di apprendere dai dati. Il deep learning, un ulteriore sottoinsieme del ML, coinvolge specificamente reti neurali in grado di apprendere pattern [schemi] pi√π complessi in grandi volumi di dati. Fonte: NVIDIA.
</figcaption>
</figure>
</div>
<p>Come mostrato nella figura, l‚ÄôIA rappresenta il campo sovraordinato, che comprende tutti i metodi computazionali che imitano le funzioni cognitive umane. Il machine learning √® mostrato come un sottoinsieme dell‚ÄôIA che include algoritmi in grado di apprendere dai dati. Il deep learning, il sottoinsieme pi√π piccolo nel diagramma, coinvolge specificamente reti neurali in grado di apprendere modelli pi√π complessi da grandi volumi di dati.</p>
</section>
<section id="breve-storia-del-deep-learning" class="level3 page-columns page-full" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="breve-storia-del-deep-learning"><span class="header-section-number">3.1.2</span> Breve Storia del Deep Learning</h3>
<p>L‚Äôidea del deep learning ha origine nelle prime reti neurali artificiali. Ha vissuto diversi cicli di interesse, a partire dall‚Äôintroduzione del Perceptron negli anni ‚Äô50 <span class="citation" data-cites="rosenblatt1957perceptron">(<a href="../../../references.it.html#ref-rosenblatt1957perceptron" role="doc-biblioref">Rosenblatt 1957</a>)</span>, seguita dall‚Äôinvenzione degli algoritmi di backpropagation negli anni ‚Äô80 <span class="citation" data-cites="rumelhart1986learning">(<a href="../../../references.it.html#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, e Williams 1986</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-rosenblatt1957perceptron" class="csl-entry" role="listitem">
Rosenblatt, Frank. 1957. <em>The perceptron, a perceiving and recognizing automaton Project Para</em>. Cornell Aeronautical Laboratory.
</div><div id="ref-rumelhart1986learning" class="csl-entry" role="listitem">
Rumelhart, David E., Geoffrey E. Hinton, e Ronald J. Williams. 1986. <span>¬´Learning representations by back-propagating errors¬ª</span>. <em>Nature</em> 323 (6088): 533‚Äì36. <a href="https://doi.org/10.1038/323533a0">https://doi.org/10.1038/323533a0</a>.
</div><div id="ref-krizhevsky2012imagenet" class="csl-entry" role="listitem">
Krizhevsky, Alex, Ilya Sutskever, e Geoffrey E. Hinton. 2012. <span>¬´<span>ImageNet</span> Classification with Deep Convolutional Neural Networks¬ª</span>. In <em>Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States</em>, a cura di Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, L√©on Bottou, e Kilian Q. Weinberger, 1106‚Äì14. <a href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html</a>.
</div></div><p>Il termine ‚Äúdeep learning‚Äù √® diventato importante negli anni 2000, caratterizzato da progressi nella potenza di calcolo e nell‚Äôaccessibilit√† dei dati. Traguardi importanti includono l‚Äôaddestramento di successo di reti profonde come AlexNet <span class="citation" data-cites="krizhevsky2012imagenet">(<a href="../../../references.it.html#ref-krizhevsky2012imagenet" role="doc-biblioref">Krizhevsky, Sutskever, e Hinton 2012</a>)</span> da parte di <a href="https://amturing.acm.org/award_winners/hinton_4791679.cfm">Geoffrey Hinton</a>, una figura di spicco nell‚Äôintelligenza artificiale, e il rinnovato focus sulle reti neurali come strumenti efficaci per l‚Äôanalisi e la modellazione dei dati.</p>
<p>Il deep learning ha recentemente registrato una crescita esponenziale, trasformando vari settori. La <a href="#fig-trends" class="quarto-xref">Figura&nbsp;<span>3.2</span></a> illustra questa notevole progressione, evidenziando due tendenze chiave nel settore. Innanzitutto, il grafico mostra che la crescita computazionale ha seguito un modello di raddoppio di 18 mesi dal 1952 al 2010. Questa tendenza ha poi accelerato drasticamente fino a un ciclo di raddoppio di 6 mesi dal 2010 al 2022, indicando un balzo significativo nelle capacit√† computazionali.</p>
<p>In secondo luogo, la figura raffigura l‚Äôemergere di modelli su larga scala tra il 2015 e il 2022. Questi modelli sono apparsi da 2 a 3 ordini di grandezza pi√π veloci rispetto alla tendenza generale, seguendo un ciclo di raddoppio di 10 mesi ancora pi√π aggressivo. Questo rapido ridimensionamento delle dimensioni del modello rappresenta un cambiamento di paradigma nelle capacit√† di deep learning.</p>
<div id="fig-trends" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-trends-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://epochai.org/assets/images/posts/2022/compute-trends.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-trends-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.2: Crescita dei modelli di deep learning.
</figcaption>
</figure>
</div>
<p>Molteplici fattori hanno contribuito a questa impennata, tra cui i progressi nella potenza computazionale, l‚Äôabbondanza di big data e i miglioramenti nei progetti algoritmici. In primo luogo, la crescita delle capacit√† computazionali, in particolare l‚Äôarrivo delle Graphics Processing Units (GPU) [unit√† di elaborazione grafica] e delle Tensor Processing Units (TPU) [unit√† di elaborazione tensoriale] <span class="citation" data-cites="jouppi2017datacenter">(<a href="../../../references.it.html#ref-jouppi2017datacenter" role="doc-biblioref">Jouppi et al. 2017</a>)</span>, ha accelerato notevolmente i tempi di training e inferenza dei modelli di apprendimento profondo. Questi miglioramenti hardware hanno consentito la costruzione e il training di reti pi√π complesse e profonde di quanto fosse possibile negli anni precedenti.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jouppi2017datacenter" class="csl-entry" role="listitem">
Jouppi, Norman P., Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, et al. 2017. <span>¬´In-Datacenter Performance Analysis of a Tensor Processing Unit¬ª</span>. In <em>Proceedings of the 44th Annual International Symposium on Computer Architecture</em>, 1‚Äì12. ISCA ‚Äô17. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/3079856.3080246">https://doi.org/10.1145/3079856.3080246</a>.
</div></div><p>In secondo luogo, la rivoluzione digitale ha prodotto una grande quantit√† di big data, offrendo materiale ricco da cui i modelli di deep learning possono imparare e distinguersi in attivit√† quali il riconoscimento di immagini e parlato, la traduzione linguistica e il gioco. I grandi set di dati etichettati sono stati fondamentali per perfezionare e distribuire con successo applicazioni di deep learning in contesti reali.</p>
<p>Inoltre, le collaborazioni e gli sforzi open source hanno alimentato una comunit√† dinamica di ricercatori e professionisti, accelerando i progressi nelle tecniche di deep learning. Innovazioni come il ‚Äúdeep reinforcement learning‚Äù, il ‚Äútransfer learning‚Äù e l‚Äôintelligenza artificiale generativa hanno ampliato la portata di ci√≤ che √® realizzabile col deep learning, aprendo nuove possibilit√† in vari settori, tra cui sanit√†, finanza, trasporti e intrattenimento.</p>
<p>Le organizzazioni di tutto il mondo riconoscono il potenziale trasformativo del deep learning e investono molto in ricerca e sviluppo per sfruttare le sue capacit√† nel fornire soluzioni innovative, ottimizzare le operazioni e creare nuove opportunit√† di business. Mentre il deep learning continua la sua traiettoria ascendente, √® destinato a ridefinire il modo in cui interagiamo con la tecnologia, migliorando la praticit√†, la sicurezza e la connettivit√† nelle nostre vite.</p>
</section>
<section id="applicazioni-del-deep-learning" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="applicazioni-del-deep-learning"><span class="header-section-number">3.1.3</span> Applicazioni del Deep Learning</h3>
<p>Il deep learning √® ampiamente utilizzato in numerosi settori oggi, con il suo impatto trasformativo evidente in vari settori, come illustrato in <a href="#fig-deeplearning" class="quarto-xref">Figura&nbsp;<span>3.3</span></a>. Nella finanza, alimenta la previsione del mercato azionario, la valutazione del rischio e il rilevamento delle frodi, guidando le strategie di investimento e migliorando le decisioni finanziarie. Il marketing sfrutta il deep learning per la segmentazione e la personalizzazione dei clienti, consentendo pubblicit√† altamente mirate e l‚Äôottimizzazione dei contenuti in base all‚Äôanalisi del comportamento dei consumatori. Nella produzione, semplifica i processi e migliora il controllo di qualit√†, consentendo alle aziende di aumentare la produttivit√† e ridurre al minimo gli sprechi. L‚Äôassistenza sanitaria trae vantaggio dal deep learning nella diagnosi, nella pianificazione del trattamento e nel monitoraggio dei pazienti, salvando potenzialmente vite umane attraverso migliori previsioni mediche.</p>
<div id="fig-deeplearning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-deeplearning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/deeplearning.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-deeplearning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.3: Applicazioni, vantaggi e implementazioni del deep learning in vari settori, tra cui finanza, marketing, produzione e assistenza sanitaria. Fonte: <a href="https://www.leewayhertz.com/what-is-deep-learning/">Leeway Hertz</a>
</figcaption>
</figure>
</div>
<p>Oltre a questi settori principali, il deep learning migliora i prodotti e i servizi di tutti i giorni. Netflix lo utilizza per rafforzare i suoi sistemi di raccomandazione, fornendo agli utenti pi√π <a href="https://dl.acm.org/doi/abs/10.1145/3543873.3587675">raccomandazioni personalizzate</a>. Google ha migliorato notevolmente il suo servizio di traduzione, gestendo ora oltre <a href="https://cloud.google.com/translate/docs/languages">100 lingue</a> con maggiore accuratezza, come evidenziato nei suoi <a href="https://research.google/blog/recent-advances-in-google-translate/">recenti progressi</a>. I veicoli autonomi di aziende come Waymo, Cruise e Motional sono diventati realt√† grazie al deep learning nel loro <a href="https://motional.com/news/technically-speaking-improving-av-perception-through-transformative-machine-learning">perception system</a>. Inoltre, Amazon impiega il deep learning edge nei dispositivi Alexa per attivit√† come <a href="https://towardsdatascience.com/how-amazon-alexa-works-your-guide-to-natural-language-processing-ai-7506004709d3">individuazione di parole chiave</a>. Queste applicazioni dimostrano come il machine learning spesso predice ed elabora le informazioni con maggiore accuratezza e velocit√† rispetto agli esseri umani, rivoluzionando vari aspetti della nostra vita quotidiana.</p>
</section>
<section id="rilevanza-per-lia-embedded" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="rilevanza-per-lia-embedded"><span class="header-section-number">3.1.4</span> Rilevanza per l‚ÄôIA Embedded</h3>
<p>L‚ÄôIA embedded, l‚Äôintegrazione di algoritmi di intelligenza artificiale direttamente nei dispositivi hardware, trae naturalmente vantaggio dalle capacit√† del deep learning. La combinazione di algoritmi di deep learning e sistemi embedded ha gettato le basi per dispositivi intelligenti e autonomi in grado di analisi avanzate on-device [sul dispositivo]. Il deep learning aiuta a estrarre pattern e informazioni complesse dai dati di input, il che √® essenziale nello sviluppo di sistemi embedded intelligenti, dagli elettrodomestici ai macchinari industriali. Questa collaborazione inaugura una nuova era di dispositivi intelligenti e interconnessi, in grado di apprendere e adattarsi al comportamento dell‚Äôutente e alle condizioni ambientali, ottimizzando le prestazioni e offrendo praticit√† ed efficienza senza precedenti.</p>
</section>
</section>
<section id="reti-neurali" class="level2 page-columns page-full" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="reti-neurali"><span class="header-section-number">3.2</span> Reti Neurali</h2>
<p>Il deep learning trae ispirazione dalle reti neurali del cervello umano per creare pattern decisionali. Questa sezione approfondisce i concetti fondamentali del deep learning, offrendo approfondimenti sugli argomenti pi√π complessi trattati pi√π avanti in questa introduzione.</p>
<p>Le reti neurali fungono da fondamento del deep learning, ispirate alle reti neurali biologiche nel cervello umano per elaborare e analizzare i dati in modo gerarchico. Le reti neurali sono composte da unit√† di base chiamate perceptron, che sono solitamente organizzate in layer [strati]. Ogni layer √® costituito da diversi perceptron e pi√π layer sono impilati per formare l‚Äôintera rete. Le connessioni tra questi layer sono definite da insiemi di pesi o parametri che determinano come i dati vengono elaborati mentre fluiscono dall‚Äôinput all‚Äôoutput della rete.</p>
<p>Di seguito, esaminiamo i componenti e le strutture primarie nelle reti neurali.</p>
<section id="perceptron" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="perceptron"><span class="header-section-number">3.2.1</span> Perceptron</h3>
<p>Il Perceptron √® l‚Äôunit√† di base o il nodo che costituisce la base per strutture pi√π complesse. Funziona prendendo pi√π input, ognuno dei quali rappresenta una feature dell‚Äôoggetto in analisi, come le caratteristiche di una casa per prevederne il prezzo o gli attributi di una canzone per prevederne la popolarit√† nei servizi di streaming musicale. Questi input sono indicati come <span class="math inline">\(x_1, x_2, ..., x_n\)</span>. Un perceptron pu√≤ essere configurato per eseguire attivit√† di regressione o classificazione. Per la regressione, viene utilizzato l‚Äôoutput numerico effettivo <span class="math inline">\(\hat{y}\)</span>. Per la classificazione, l‚Äôoutput dipende dal fatto che <span class="math inline">\(\hat{y}\)</span> superi una determinata soglia. Se <span class="math inline">\(\hat{y}\)</span> supera questa soglia, il perceptron potrebbe restituire una classe (ad esempio, ‚Äòyes‚Äô) e, in caso contrario, un‚Äôaltra classe (ad esempio, ‚Äòno‚Äô).</p>
<p><a href="#fig-perceptron" class="quarto-xref">Figura&nbsp;<span>3.4</span></a> illustra gli elementi fondamentali di un perceptron, che funge da fondamento per reti neurali pi√π complesse. Un perceptron pu√≤ essere pensato come un decisore in miniatura, che utilizza i suoi pesi, il sui bias [polarizzazione] e la sua funzione di attivazione per elaborare input e generare output in base ai parametri appresi. Questo concetto costituisce la base per comprendere architetture di reti neurali pi√π complesse, come i perceptron multilayer [multistrato]. In queste strutture avanzate, i layer di perceptron lavorano di concerto, con l‚Äôoutput di ogni layer che funge da input per il layer successivo. Questa disposizione gerarchica crea un modello di deep learning in grado di comprendere e modellare pattern complessi e astratti all‚Äôinterno dei dati. Impilando queste semplici unit√†, le reti neurali acquisiscono la capacit√† di affrontare attivit√† sempre pi√π sofisticate, dal riconoscimento delle immagini all‚Äôelaborazione del linguaggio naturale.</p>
<div id="fig-perceptron" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-perceptron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/Rosenblattperceptron.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-perceptron-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.4: Perceptron. Concepiti negli anni ‚Äô50, i perceptron hanno aperto la strada allo sviluppo di reti neurali pi√π complesse e sono stati un elemento fondamentale nel deep learning. Fonte: Wikimedia - Chrislb.
</figcaption>
</figure>
</div>
<p>Ciascun input <span class="math inline">\(x_i\)</span> ha un peso corrispondente <span class="math inline">\(w_{ij}\)</span> e il perceptron moltiplica semplicemente ogni input per il suo peso corrispondente. Questa operazione √® simile alla regressione lineare, dove l‚Äôoutput intermedio, <span class="math inline">\(z\)</span>, √® calcolato come la somma dei prodotti degli input e dei loro pesi:</p>
<p><span class="math display">\[
z = \sum (x_i \cdot w_{ij})
\]</span></p>
<p>A questo calcolo intermedio, viene aggiunto un termine di bias <span class="math inline">\(b\)</span>, che consente al modello di adattarsi meglio ai dati spostando la funzione di output lineare verso l‚Äôalto o verso il basso. Pertanto, la combinazione lineare intermedia calcolata dal perceptron, incluso il bias, diventa:</p>
<p><span class="math display">\[
z = \sum (x_i \cdot w_{ij}) + b
\]</span></p>
<p>Questa forma base di un perceptron pu√≤ modellare solo relazioni lineari tra input e output. I pattern trovati in natura sono spesso complessi e si estendono oltre le relazioni lineari. Per consentire al perceptron di gestire relazioni non lineari, una funzione di attivazione viene applicata all‚Äôoutput lineare <span class="math inline">\(z\)</span>.</p>
<p><span class="math display">\[
\hat{y} = \sigma(z)
\]</span></p>
<p><a href="#fig-nonlinear" class="quarto-xref">Figura&nbsp;<span>3.5</span></a> illustra un esempio in cui i dati presentano un pattern non lineare che non potrebbe essere modellato adeguatamente con un approccio lineare. La funzione di attivazione, come la sigmoide, la tanh o la ReLU, trasforma la somma di input lineare in un output non lineare. L‚Äôobiettivo principale di questa funzione √® introdurre la non linearit√† nel modello, consentendogli di apprendere ed eseguire attivit√† pi√π sofisticate. Pertanto, l‚Äôoutput finale del perceptron, inclusa la funzione di attivazione, pu√≤ essere espresso come:</p>
<div id="fig-nonlinear" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nonlinear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/nonlinear_patterns.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nonlinear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.5: Le funzioni di attivazione consentono la modellazione di relazioni non lineari complesse. Fonte: Medium - Sachin Kaushik.
</figcaption>
</figure>
</div>
</section>
<section id="perceptron-multilayer" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="perceptron-multilayer"><span class="header-section-number">3.2.2</span> Perceptron Multilayer</h3>
<p>I ‚ÄúMultilayer perceptron‚Äù (MLP) sono un‚Äôevoluzione del modello del perceptron a singolo layer, caratterizzato da pi√π layer di nodi collegati in modo ‚Äúfeedforward‚Äù. <a href="#fig-mlp" class="quarto-xref">Figura&nbsp;<span>3.6</span></a> fornisce una rappresentazione visiva di questa struttura. Come illustrato nella figura, le informazioni in una rete ‚Äúfeedforward‚Äù si muovono in una sola direzione: dal livello di input a sinistra, attraverso i livelli nascosti al centro, fino al livello di output a destra, senza cicli o loop.</p>
<div id="fig-mlp" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mlp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.nomidl.com/wp-content/uploads/2022/04/image-7.png" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mlp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.6: Perceptron Multilayer. Fonte: Wikimedia - Charlie.
</figcaption>
</figure>
</div>
<p>Mentre un singolo perceptron √® limitato nella sua capacit√† di modellare pattern complessi, la vera forza delle reti neurali emerge dall‚Äôassemblaggio di pi√π layer. Ciascun layer √® costituito da numerosi perceptron che lavorano insieme, consentendo alla rete di catturare relazioni intricate e non lineari all‚Äôinterno dei dati. Con sufficiente profondit√† e ampiezza, queste reti possono approssimare praticamente qualsiasi funzione, indipendentemente da quanto sia complessa.</p>
</section>
<section id="processo-di-training" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="processo-di-training"><span class="header-section-number">3.2.3</span> Processo di Training</h3>
<p>Una rete neurale riceve un input, esegue un calcolo e produce una previsione. La previsione √® determinata dai calcoli eseguiti all‚Äôinterno dei set di perceptron trovati tra i layer di input e output. Questi calcoli dipendono principalmente dall‚Äôinput e dai pesi. Poich√© non si ha il controllo sull‚Äôinput, l‚Äôobiettivo durante il training [addestramento] √® quello di regolare i pesi in modo tale che l‚Äôoutput della rete fornisca la previsione pi√π accurata.</p>
<p>Il processo di addestramento prevede diversi passaggi chiave, a partire dal passaggio in avanti (forward), in cui i pesi esistenti della rete vengono utilizzati per calcolare l‚Äôoutput per un dato input. Questo output viene poi confrontato con i veri valori target per calcolare un errore, che misura quanto bene la previsione della rete corrisponde al risultato previsto. In seguito, viene eseguito un passaggio all‚Äôindietro (backward). Ci√≤ comporta l‚Äôutilizzo dell‚Äôerrore per apportare modifiche ai pesi della rete tramite un processo chiamato ‚Äúbackpropagation‚Äù. Questa regolazione riduce l‚Äôerrore nelle previsioni successive. Il ciclo di passaggio forward [in avanti], calcolo dell‚Äôerrore e passaggio backward [all‚Äôindietro] viene ripetuto iterativamente. Questo processo continua finch√© le previsioni della rete non sono sufficientemente accurate o non viene raggiunto un numero predefinito di iterazioni, riducendo al minimo la ‚Äúfunzione di perdita‚Äù utilizzata per misurare l‚Äôerrore.</p>
<section id="forward-pass" class="level4">
<h4 class="anchored" data-anchor-id="forward-pass">Forward Pass</h4>
<p>Il forward pass √® la fase iniziale in cui i dati si spostano attraverso la rete dal livello di input a quello di output, come illustrato in <a href="#fig-forward-propagation" class="quarto-xref">Figura&nbsp;<span>3.7</span></a>. All‚Äôinizio dell‚Äôaddestramento, i pesi della rete vengono inizializzati in modo casuale, impostando le condizioni iniziali. Durante il ‚Äúforward pass‚Äù, ogni layer esegue calcoli specifici sui dati di input utilizzando questi pesi e il bias, e i risultati vengono poi passati al layer successivo. L‚Äôoutput finale di questa fase √® la previsione della rete. Questa ‚Äúprediction‚Äù viene confrontata con i valori target effettivi presenti nel set di dati per calcolare la ‚Äúloss‚Äù [perdita], che pu√≤ essere considerata come la differenza tra gli output previsti e i valori target. La perdita quantifica le prestazioni della rete in questa fase, fornendo una metrica cruciale per la successiva regolazione dei pesi durante il backward pass.</p>
<div id="fig-forward-propagation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-forward-propagation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/forwardpropagation.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-forward-propagation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.7: Reti neurali: propagazione forward e backward. Fonte: <a href="https://www.linkedin.com/pulse/lecture2-unveiling-theoretical-foundations-ai-machine-underdown-phd-oqsuc/">Linkedin</a>
</figcaption>
</figure>
</div>
</section>
<section id="sec-backward_pass" class="level4">
<h4 class="anchored" data-anchor-id="sec-backward_pass">Backward Pass (Backpropagation)</h4>
<p>Dopo aver completato il forward pass e calcolato la perdita, che misura quanto le previsioni del modello si discostano dai valori target effettivi, il passo successivo √® migliorare le prestazioni del modello regolando i pesi della rete. Poich√© non possiamo controllare gli input del modello, la regolazione dei pesi diventa il nostro metodo principale per perfezionare il modello.</p>
<p>Determiniamo come regolare i pesi del nostro modello tramite un algoritmo chiave chiamato ‚Äúbackpropagation‚Äù. La backpropagation utilizza la perdita calcolata per determinare il gradiente di ciascun peso. Questi gradienti descrivono la direzione e l‚Äôentit√† in cui i pesi devono essere regolati. Regolando i pesi in base a questi gradienti, il modello √® meglio posizionato per fare previsioni pi√π vicine ai valori target effettivi nel successivo ‚Äúforward pass‚Äù.</p>
<p>Comprendere questi concetti fondamentali apre la strada alla comprensione di architetture e tecniche di deep learning pi√π complesse, favorendo lo sviluppo di applicazioni pi√π sofisticate e produttive, in particolare all‚Äôinterno di sistemi di intelligenza artificiale embedded.</p>
<p><a href="#vid-gd" class="quarto-xref">Video&nbsp;<span>3.1</span></a> and <a href="#vid-bp" class="quarto-xref">Video&nbsp;<span>3.2</span></a> build upon <a href="#vid-nn" class="quarto-xref">Video&nbsp;<span>3.3</span></a>. Riguardano la ‚Äúgradient descent‚Äù [discesa del gradiente] e la backpropagation nelle reti neurali.</p>
<div id="vid-gd" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;3.1: Gradient descent
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/IHZwWFHWa-w" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<div id="vid-bp" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;3.2: Backpropagation
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Ilg3gGewQ5U" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="architetture-dei-modelli" class="level3 page-columns page-full" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="architetture-dei-modelli"><span class="header-section-number">3.2.4</span> Architetture dei Modelli</h3>
<p>Le architetture di deep learning si riferiscono ai vari approcci strutturati che stabiliscono come i neuroni e i layer sono organizzati e interagiscono nelle reti neurali. Queste architetture si sono evolute per affrontare efficacemente diversi problemi e diversi tipi di dati. Questa sezione fornisce una panoramica di alcune note architetture di deep learning e delle loro caratteristiche.</p>
<section id="multilayer-perceptron-mlp" class="level4">
<h4 class="anchored" data-anchor-id="multilayer-perceptron-mlp">Multilayer Perceptron (MLP)</h4>
<p>Gli MLP sono architetture di deep learning di base che comprendono tre layer: uno di input, uno o pi√π layer nascosti e un layer di output. Questi layer sono completamente connessi, il che significa che ogni neurone in uno layer √® collegato a ogni neurone nei layer precedenti e successivi. Gli MLP possono modellare funzioni complesse e sono utilizzati in varie attivit√†, come regressione, classificazione e riconoscimento di pattern. La loro capacit√† di apprendere relazioni non lineari tramite backpropagation li rende uno strumento versatile nel toolkit di deep learning.</p>
<p>Nei sistemi di intelligenza artificiale embedded, gli MLP possono funzionare come modelli compatti per attivit√† pi√π semplici come l‚Äôanalisi dei dati dei sensori o il riconoscimento di pattern di base, in cui le risorse computazionali sono limitate. La loro capacit√† di apprendere relazioni non lineari con una complessit√† relativamente minore li rende una scelta adatta per i sistemi embedded.</p>
<div id="exr-mlp" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;3.1: Multilayer Perceptron (MLP)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Abbiamo appena scalfito la superficie delle reti neurali. Ora, proveremo ad applicare questi concetti in esempi pratici. Nei notebook Colab forniti, si esploreranno:</p>
<p><strong>Previsione dei prezzi delle case:</strong> Scoprire come le reti neurali possono analizzare i dati sugli alloggi per stimare i valori delle propriet√†. <a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/1_Fundamentals/Class_07/TF_Boston_Housing_Regression.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
<p><strong>Classificazione delle immagini:</strong> Scoprire come creare una rete per comprendere il famoso set di dati di cifre scritte a mano MNIST. <a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/1_Fundamentals/Class_09/TF_MNIST_Classification_v2.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
<p><strong>Diagnosi medica nel mondo reale:</strong> Usare il deep learning per affrontare l‚Äôimportante compito della classificazione del cancro al seno. <a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/1_Fundamentals/Class_13/docs/WDBC_Project/Breast_Cancer_Classification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
<section id="convolutional-neural-networks-cnns" class="level4">
<h4 class="anchored" data-anchor-id="convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)</h4>
<p>Le CNN [reti neurali convoluzionali] sono utilizzate principalmente in attivit√† di riconoscimento di immagini e video. Questa architettura √® composta da due parti principali: la base convoluzionale e i layer completamente connessi. Nella base convoluzionale, i layer convoluzionali filtrano i dati di input per identificare feature come bordi, angoli e texture [trame]. Dopo ogni layer convoluzionale, √® possibile applicare un layer di pooling [raggruppamento] per ridurre le dimensioni spaziali dei dati, diminuendo cos√¨ il carico computazionale e concentrando le feature estratte. A differenza degli MLP, che trattano le feature di input come entit√† piatte e indipendenti, le CNN mantengono le relazioni spaziali tra i pixel, rendendole particolarmente efficaci per i dati di immagini e video. Le feature estratte dalla base convoluzionale vengono poi passate ai layer completamente connessi, simili a quelli utilizzati negli MLP, che eseguono la classificazione in base alle feature estratte dai layer di convoluzione. Le CNN si sono dimostrate altamente efficaci nel riconoscimento delle immagini, nel rilevamento di oggetti e in altre applicazioni di visione artificiale.</p>
<p><a href="#vid-nn" class="quarto-xref">Video&nbsp;<span>3.3</span></a> spiega come funzionano le reti neurali usando il riconoscimento di cifre scritte a mano come applicazione di esempio. Affronta anche la matematica alla base delle reti neurali.</p>
<div id="vid-nn" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;3.3: Reti MLP &amp; CNN
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/aircAruvnKk?si=ZRj8jf4yx7ZMe8EK" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p>Le CNN sono fondamentali per le attivit√† di riconoscimento di immagini e video, in cui spesso √® necessaria l‚Äôelaborazione in tempo reale. Possono essere ottimizzate per i sistemi embedded utilizzando tecniche come la quantizzazione e il ‚Äúpruning‚Äù [potatura] per ridurre al minimo l‚Äôutilizzo della memoria e le richieste computazionali, consentendo funzionalit√† efficienti di rilevamento di oggetti e riconoscimento facciale in dispositivi con risorse computazionali limitate.</p>
<div id="exr-cnn" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;3.2: Convolutional Neural Networks (CNNs)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Abbiamo discusso del fatto che le CNN [Reti neurali convoluzionali] sono eccellenti nell‚Äôidentificare le caratteristiche delle immagini, il che le rende ideali per attivit√† come la classificazione degli oggetti. Ora, si potr√† mettere in pratica questa conoscenza! Questo notebook Colab si concentra sulla creazione di una CNN per classificare le immagini dal set di dati CIFAR-10, che include oggetti come aeroplani, automobili e animali. Si impareranno le principali differenze tra CIFAR-10 e il set di dati MNIST che abbiamo esplorato in precedenza e come queste differenze influenzano la scelta del modello. Alla fine di questo notebook si avr√† una conoscenza delle CNN per il riconoscimento delle immagini.</p>
<p><a href="https://colab.research.google.com/github/Mjrovai/UNIFEI-IESTI01-TinyML-2022.1/blob/main/00_Curse_Folder/1_Fundamentals/Class_11/CNN_Cifar_10.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
<section id="recurrent-neural-networks-rnn" class="level4">
<h4 class="anchored" data-anchor-id="recurrent-neural-networks-rnn">Recurrent Neural Networks (RNN)</h4>
<p>Le RNN [Reti Neurali Ricorrenti] sono adatte per l‚Äôanalisi di dati sequenziali, come la previsione di serie temporali e l‚Äôelaborazione del linguaggio naturale. In questa architettura, le connessioni tra i nodi formano un grafo diretto lungo una sequenza temporale, consentendo il trasporto delle informazioni attraverso le sequenze tramite vettori di stato nascosti. Le varianti delle RNN includono le Long Short-Term Memory (LSTM) e le Gated Recurrent Units (GRU), progettate per catturare dipendenze pi√π lunghe nei dati sequenziali.</p>
<p>Queste reti possono essere utilizzate nei sistemi di riconoscimento vocale, nella manutenzione predittiva o nei dispositivi IoT in cui sono comuni i pattern di dati sequenziali. Le ottimizzazioni specifiche per le piattaforme embedded possono aiutare a gestirne i requisiti di elaborazione e memoria tipicamente elevati.</p>
</section>
<section id="generative-adversarial-network-gan" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)</h4>
<p>Le GAN [Reti Generative Avversarie] sono costituite da due reti, un generatore e un discriminatore, addestrate simultaneamente tramite l‚Äôaddestramento adversarial [avversario] <span class="citation" data-cites="goodfellow2020generative">(<a href="../../../references.it.html#ref-goodfellow2020generative" role="doc-biblioref">Goodfellow et al. 2020</a>)</span>. Il generatore produce dati che tentano di imitare la distribuzione di quelli reali, mentre il discriminatore distingue tra dati reali e dati generati. Le GAN sono ampiamente utilizzate nella generazione di immagini, nel trasferimento di stile e nell‚Äôaumento dei dati.</p>
<div class="no-row-height column-margin column-container"><div id="ref-goodfellow2020generative" class="csl-entry" role="listitem">
Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, e Yoshua Bengio. 2020. <span>¬´Generative adversarial networks¬ª</span>. <em>Commun. ACM</em> 63 (11): 139‚Äì44. <a href="https://doi.org/10.1145/3422622">https://doi.org/10.1145/3422622</a>.
</div></div><p>In contesti embedded, le reti GAN potrebbero essere utilizzate per l‚Äôaumento dei dati sul dispositivo per migliorare il training dei modelli direttamente sul dispositivo embedded, consentendo un apprendimento continuo e un adattamento ai nuovi dati senza la necessit√† di risorse di cloud computing.</p>
</section>
<section id="autoencoder" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="autoencoder">Autoencoder</h4>
<p>Gli autoencoder sono reti neurali per la compressione dei dati e la riduzione del rumore <span class="citation" data-cites="bank2023autoencoders">(<a href="../../../references.it.html#ref-bank2023autoencoders" role="doc-biblioref">Bank, Koenigstein, e Giryes 2023</a>)</span>. Sono strutturati per codificare i dati di input in una rappresentazione a dimensione inferiore e quindi decodificarli nella loro forma originale. Varianti come gli Variational Autoencoders (VAE) [Autoencoder Variazionali] introducono livelli probabilistici che consentono propriet√† generative, trovando applicazioni nella generazione di immagini e nel rilevamento di anomalie.</p>
<div class="no-row-height column-margin column-container"><div id="ref-bank2023autoencoders" class="csl-entry" role="listitem">
Bank, Dor, Noam Koenigstein, e Raja Giryes. 2023. <span>¬´Autoencoders¬ª</span>. <em>Machine Learning for Data Science Handbook: Data Mining and Knowledge Discovery Handbook</em>, 353‚Äì74.
</div></div><p>L‚Äôuso degli autoencoder pu√≤ aiutare nella trasmissione e nell‚Äôarchiviazione efficiente dei dati, migliorando le prestazioni complessive dei sistemi embedded con risorse di calcolo e di memoria limitate.</p>
</section>
<section id="transformer-network" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="transformer-network">Transformer Network</h4>
<p>Le ‚ÄúTransformer network‚Äù [reti di trasformatori] sono emerse come un‚Äôarchitettura potente, specialmente nell‚Äôelaborazione del linguaggio naturale <span class="citation" data-cites="vaswani2017attention">(<a href="../../../references.it.html#ref-vaswani2017attention" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. Queste reti utilizzano meccanismi di auto-attenzione per soppesare l‚Äôinfluenza di diverse parole di input su ogni parola di output, consentendo il calcolo parallelo e catturando pattern intricati nei dati. Le reti di trasformatori hanno portato a risultati all‚Äôavanguardia in attivit√† come la traduzione linguistica, la sintesi e la generazione di testo.</p>
<div class="no-row-height column-margin column-container"><div id="ref-vaswani2017attention" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, e Illia Polosukhin. 2017. <span>¬´Attention is all you need¬ª</span>. <em>Adv Neural Inf Process Syst</em> 30.
</div></div><p>Queste reti possono essere ottimizzate per eseguire attivit√† correlate alla lingua direttamente sul dispositivo. Ad esempio, i trasformatori possono essere utilizzati nei sistemi embedded per servizi di traduzione in tempo reale o interfacce assistite dalla voce, dove latenza ed efficienza computazionale sono cruciali. Tecniche come la distillazione del modello possono essere impiegate per distribuire queste reti su dispositivi embedded con risorse limitate.</p>
<p>Queste architetture servono a scopi specifici ed eccellono in diversi domini, offrendo un ricco toolkit per affrontare diversi problemi nei sistemi di intelligenza artificiale embedded. Comprendere le sfumature di queste architetture √® fondamentale nella progettazione di modelli di deep learning efficaci ed efficienti per varie applicazioni.</p>
</section>
</section>
<section id="ml-tradizionale-vs-deep-learning" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="ml-tradizionale-vs-deep-learning"><span class="header-section-number">3.2.5</span> ML Tradizionale vs Deep Learning</h3>
<p>Il deep learning estende il machine learning tradizionale utilizzando reti neurali per discernere i pattern nei dati. Al contrario, il machine learning tradizionale si basa su un set di algoritmi consolidati come alberi decisionali, k-nearest neighbor e macchine a vettori di supporto, ma non coinvolge le reti neurali. <a href="#fig-ml-dl" class="quarto-xref">Figura&nbsp;<span>3.8</span></a> fornisce un confronto visivo tra Machine Learning e Deep Learning, evidenziandone le principali differenze di approccio e capacit√†.</p>
<div id="fig-ml-dl" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/mlvsdl.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml-dl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;3.8: Confronto tra Machine Learning e Deep Learning. Fonte: <a href="https://aoyilmaz.medium.com/understanding-the-differences-between-deep-learning-and-machine-learning-eb41d64f1732">Medium</a>
</figcaption>
</figure>
</div>
<p>Come mostrato nella figura, i modelli di deep learning possono elaborare dati grezzi direttamente ed estrarre automaticamente le feature rilevanti, mentre il machine learning tradizionale richiede spesso l‚Äôingegneria manuale delle feature. La figura illustra anche come i modelli di deep learning possono gestire attivit√† pi√π complesse e set di dati pi√π grandi rispetto ai tradizionali approcci di machine learning.</p>
<p>Per evidenziare ulteriormente le differenze, <a href="#tbl-mlvsdl" class="quarto-xref">Tabella&nbsp;<span>3.1</span></a> fornisce un confronto pi√π dettagliato delle caratteristiche contrastanti tra ML tradizionale e deep learning. Questa tabella integra la rappresentazione visiva in <a href="#fig-ml-dl" class="quarto-xref">Figura&nbsp;<span>3.8</span></a> offrendo punti di confronto specifici tra vari aspetti di questi due approcci.</p>
<div id="tbl-mlvsdl" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-mlvsdl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;3.1: Confronto tra machine learning tradizionale e deep learning.
</figcaption>
<div aria-describedby="tbl-mlvsdl-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 38%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspetto</th>
<th style="text-align: left;">ML tradizionale</th>
<th style="text-align: left;">Deep Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Requisiti dei dati</td>
<td style="text-align: left;">Da basso a moderato (efficiente con set di dati pi√π piccoli)</td>
<td style="text-align: left;">Alto (richiede set di dati di grandi dimensioni per un apprendimento adeguato)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Complessit√† del modello</td>
<td style="text-align: left;">Moderata (adatta a problemi ben definiti)</td>
<td style="text-align: left;">Alta (rileva pattern intricati, adatta a compiti complessi)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Risorse di calcolo</td>
<td style="text-align: left;">Da basse a moderate (economiche, meno dispendiose in termini di risorse)</td>
<td style="text-align: left;">Alta (richiede una potenza di calcolo e risorse sostanziali)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Velocit√† di distribuzione</td>
<td style="text-align: left;">Veloce (cicli di training e distribuzione pi√π rapidi)</td>
<td style="text-align: left;">Lento (tempi di training pi√π lunghi, in particolare con set di dati pi√π grandi)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Interpretabilit√†</td>
<td style="text-align: left;">Alta (chiare intuizioni sui percorsi decisionali)</td>
<td style="text-align: left;">Bassa (strutture complesse a layer, natura ‚Äúscatola nera‚Äù)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Manutenzione</td>
<td style="text-align: left;">Pi√π facile (semplice da aggiornare e mantenere)</td>
<td style="text-align: left;">Complesso (richiede pi√π sforzi nella manutenzione e negli aggiornamenti)</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="scelta-tra-ml-tradizionale-e-dl" class="level3" data-number="3.2.6">
<h3 data-number="3.2.6" class="anchored" data-anchor-id="scelta-tra-ml-tradizionale-e-dl"><span class="header-section-number">3.2.6</span> Scelta tra ML tradizionale e DL</h3>
<section id="disponibilit√†-e-volume-dei-dati" class="level4">
<h4 class="anchored" data-anchor-id="disponibilit√†-e-volume-dei-dati">Disponibilit√† e Volume dei Dati</h4>
<p><strong>Quantit√† di Dati:</strong> Gli algoritmi di machine learning tradizionali, come gli alberi decisionali o Naive Bayes, sono spesso pi√π adatti quando la disponibilit√† dei dati √® limitata. Offrono previsioni affidabili anche con set di dati pi√π piccoli. Ci√≤ √® particolarmente vero nella diagnostica medica per la previsione delle malattie e nella segmentazione dei clienti nel marketing.</p>
<p><strong>Diversit√† e Qualit√† dei Dati:</strong> Gli algoritmi di machine learning tradizionali spesso funzionano bene con dati strutturati (l‚Äôinput del modello √® un set di funzionalit√†, idealmente indipendenti l‚Äôuna dall‚Äôaltra) ma possono richiedere un notevole sforzo di pre-elaborazione (ad esempio, la ‚Äúfeature engineering‚Äù [progettazione delle funzionalit√†]). D‚Äôaltro canto, il deep learning adotta l‚Äôapproccio di eseguire automaticamente la progettazione delle funzionalit√† come parte dell‚Äôarchitettura del modello. Questo approccio consente la costruzione di modelli end-to-end in grado di mappare direttamente da dati di input non strutturati (come testo, audio e immagini) all‚Äôoutput desiderato senza fare affidamento su euristiche semplicistiche con efficacia limitata. Tuttavia, ci√≤ si traduce in modelli pi√π grandi che richiedono pi√π dati e risorse computazionali. Nei dati rumorosi, la necessit√† di set di dati pi√π grandi √® ulteriormente enfatizzata quando si utilizza il Deep Learning.</p>
</section>
<section id="complessit√†-del-problema" class="level4">
<h4 class="anchored" data-anchor-id="complessit√†-del-problema">Complessit√† del Problema</h4>
<p><strong>Granularit√† del Problema:</strong> I problemi che sono semplici o moderatamente complessi, che possono coinvolgere relazioni lineari o polinomiali tra variabili, spesso trovano una migliore aderenza ai metodi tradizionali di apprendimento automatico.</p>
<p><strong>Rappresentazione Gerarchica delle Feature:</strong> I modelli di deep learning sono eccellenti in attivit√† che richiedono una rappresentazione gerarchica delle feature [caratteristiche], come il riconoscimento di immagini e voce. Tuttavia, non tutti i problemi richiedono questa complessit√† e gli algoritmi tradizionali di apprendimento automatico possono talvolta offrire soluzioni pi√π semplici e ugualmente efficaci.</p>
</section>
<section id="risorse-hardware-e-computazionali" class="level4">
<h4 class="anchored" data-anchor-id="risorse-hardware-e-computazionali">Risorse Hardware e Computazionali</h4>
<p><strong>Vincoli di Risorse:</strong> La disponibilit√† di risorse computazionali spesso influenza la scelta tra ML tradizionale e deep learning. Il primo √® generalmente meno dispendioso in termini di risorse e quindi preferibile in ambienti con limitazioni hardware o vincoli di budget.</p>
<p><strong>Scalabilit√† e Velocit√†:</strong> Gli algoritmi tradizionali di apprendimento automatico, come le Support Vector Machines (SVM) [macchine a vettori di supporto ], spesso consentono tempi di training pi√π rapidi e una scalabilit√† pi√π semplice, il che √® particolarmente vantaggioso nei progetti con tempistiche ristrette e volumi di dati in crescita.</p>
</section>
<section id="normativa-di-conformit√†" class="level4">
<h4 class="anchored" data-anchor-id="normativa-di-conformit√†">Normativa di Conformit√†</h4>
<p>La conformit√† normativa √® fondamentale in vari settori, e richiede l‚Äôaderenza a linee guida e ‚Äúbest practice‚Äù come il General Data Protection Regulation (GDPR) [Regolamento generale sulla protezione dei dati] nell‚ÄôUE. I modelli ML tradizionali, grazie alla loro intrinseca interpretabilit√†, spesso si allineano meglio a queste normative, soprattutto in settori come la finanza e l‚Äôassistenza sanitaria.</p>
</section>
<section id="interpretabilit√†" class="level4">
<h4 class="anchored" data-anchor-id="interpretabilit√†">Interpretabilit√†</h4>
<p>Comprendere il processo decisionale √® pi√π facile con le tecniche tradizionali di apprendimento automatico rispetto ai modelli di deep learning, che funzionano come ‚Äúscatole nere‚Äù, rendendo difficile tracciare i percorsi decisionali.</p>
</section>
</section>
<section id="fare-una-scelta-informata" class="level3" data-number="3.2.7">
<h3 data-number="3.2.7" class="anchored" data-anchor-id="fare-una-scelta-informata"><span class="header-section-number">3.2.7</span> Fare una Scelta Informata</h3>
<p>Considerati i vincoli dei sistemi di intelligenza artificiale embedded, comprendere le differenze tra le tecniche di ML tradizionali e il deep learning diventa essenziale. Entrambe le strade offrono vantaggi unici e le loro caratteristiche distintive spesso determinano la scelta dell‚Äôuna rispetto all‚Äôaltra in diversi scenari.</p>
<p>Nonostante ci√≤, il deep learning ha costantemente superato i metodi tradizionali di apprendimento automatico in diverse aree chiave grazie all‚Äôabbondanza di dati, ai progressi computazionali e alla comprovata efficacia in attivit√† complesse. Ecco alcuni motivi specifici per cui ci concentriamo sul deep learning:</p>
<ol type="1">
<li><p><strong>Prestazioni Superiori in Attivit√† Complesse:</strong> I modelli di deep learning, in particolare le reti neurali profonde, eccellono in attivit√† in cui le relazioni tra i punti dati sono incredibilmente intricate. Attivit√† come il riconoscimento di immagini e parlato, la traduzione linguistica e la riproduzione di giochi complessi come Go e Scacchi hanno visto progressi significativi principalmente attraverso algoritmi di deep learning.</p></li>
<li><p><strong>Gestione Efficiente dei Dati non Strutturati:</strong> A differenza dei metodi tradizionali di apprendimento automatico, il deep learning pu√≤ elaborare in modo pi√π efficace i dati non strutturati. Ci√≤ √® fondamentale nel panorama dei dati odierno, in cui la stragrande maggioranza dei dati, come testo, immagini e video, non √® strutturata.</p></li>
<li><p><strong>Sfruttamento dei Big Data:</strong> Con la disponibilit√† dei Big Data, i modelli di deep learning possono apprendere e migliorare continuamente. Questi modelli eccellono nell‚Äôutilizzare grandi set di dati per migliorare la loro accuratezza predittiva, un limite degli approcci tradizionali di machine-learning.</p></li>
<li><p><strong>Progressi Hardware e Calcolo Parallelo:</strong> L‚Äôavvento di potenti GPU e la disponibilit√† di piattaforme di cloud computing hanno consentito il rapido training di modelli di deep learning. Questi progressi hanno affrontato una delle sfide significative del deep learning: la necessit√† di risorse computazionali sostanziali.</p></li>
<li><p><strong>Adattabilit√† Dinamica e Apprendimento Continuo:</strong> I modelli di deep learning possono adattarsi dinamicamente a nuove informazioni o dati. Possono essere addestrati per generalizzare il loro apprendimento a nuovi dati mai visti, cruciali in campi in rapida evoluzione come la guida autonoma o la traduzione linguistica in tempo reale.</p></li>
</ol>
<p>Sebbene il deep learning abbia guadagnato una notevole popolarit√†, √® essenziale comprendere che il machine learning tradizionale √® ancora rilevante. Man mano che ci addentriamo nei meandri del deep learning, evidenzieremo anche le situazioni in cui i metodi tradizionali di machine learning potrebbero essere pi√π appropriati, grazie alla loro semplicit√†, efficienza e interpretabilit√†. Concentrandoci in questo testo sul deep learning, intendiamo fornire ai lettori le conoscenze e gli strumenti per affrontare problemi moderni e complessi in vari ambiti, fornendo al contempo approfondimenti sui vantaggi comparativi e sugli scenari applicativi appropriati per il deep learning e le tecniche tradizionali di machine learning.</p>
</section>
</section>
<section id="conclusione" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="conclusione"><span class="header-section-number">3.3</span> Conclusione</h2>
<p>Il deep learning √® diventato un potente set di tecniche per affrontare le complesse sfide del riconoscimento di pattern e della previsione. Iniziando con una panoramica, abbiamo delineato i concetti e i principi fondamentali che governano il deep learning, gettando le basi per studi pi√π avanzati.</p>
<p>Al centro del deep learning, abbiamo esplorato le idee di base delle reti neurali, potenti modelli computazionali ispirati alla struttura neuronale interconnessa del cervello umano. Questa esplorazione ci ha permesso di apprezzare le capacit√† e il potenziale delle reti neurali nella creazione di algoritmi sofisticati in grado di apprendere e adattarsi dai dati.</p>
<p>Comprendere il ruolo delle librerie e dei framework √® stata una parte fondamentale della nostra discussione. Abbiamo offerto approfondimenti sugli strumenti che possono facilitare lo sviluppo e l‚Äôimplementazione di modelli di deep learning. Queste risorse semplificano l‚Äôimplementazione delle reti neurali e aprono strade all‚Äôinnovazione e all‚Äôottimizzazione.</p>
<p>Successivamente, abbiamo affrontato le sfide che si potrebbero incontrare quando si racchiudono algoritmi di deep learning nei sistemi embedded, fornendo una prospettiva critica sulle complessit√† e sulle considerazioni relative all‚Äôintroduzione dell‚Äôintelligenza artificiale nei dispositivi edge.</p>
<p>Inoltre, abbiamo esaminato i limiti del deep learning. Attraverso le discussioni, abbiamo svelato le sfide affrontate nelle applicazioni del deep learning e delineato scenari in cui l‚Äôapprendimento automatico tradizionale potrebbe superare il deep learning. Queste sezioni sono fondamentali per promuovere una visione equilibrata delle capacit√† e dei limiti del deep learning.</p>
<p>In questo ‚ÄúAvviamento‚Äù, abbiamo fornito le conoscenze per fare scelte informate tra l‚Äôimplementazione dell‚Äôapprendimento automatico tradizionale o delle tecniche di deep learning, a seconda delle esigenze e dei vincoli unici di un problema specifico.</p>
<p>Concludendo questo capitolo, ci auguriamo che sia stato acquisito il ‚Äúlinguaggio‚Äù di base del deep learning e si sia pronti ad approfondire i capitoli successivi con una solida comprensione e una prospettiva critica. Il viaggio che √® pieno di entusiasmanti opportunit√† e sfide nel racchiudere l‚Äôintelligenza artificiale nei sistemi.</p>
</section>
<section id="sec-deep-learning-primer-resource" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="sec-deep-learning-primer-resource"><span class="header-section-number">3.4</span> Risorse</h2>
<p>Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Stiamo lavorando costantemente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale secondo il proprio ritmo. Incoraggiamo studenti e docenti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/16ensKAKBG8DOUHF4f5thTJklVGTadxjm3kPkdoPyabI/edit#slide=id.g94db9f9f78_0_2">Past, Present, and Future of ML.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1X92JqVkUY7k6yJXQcT2u83dpdrx5UzGFAJkkDMDfKe0/edit#slide=id.g94db9f9f78_0_2">Thinking About Loss.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1x3xbZHo4VtaZgoXfueCbOGGXuWRYj0nOsKwAAoGsrD0/edit#slide=id.g94db9f9f78_0_2">Minimizing Loss.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1zQwhTwF_plXBPQLxluahpzoQg-VdMyJbctaJxSUncag/edit?usp=drive_link">First Neural Network.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1jXCAC6IT5f9XFKZbfhJ4p2D5URVTYqgAnkcQR4ALhSk/edit?usp=drive_link&amp;resourcekey=0-K228bxVdwO2w3kr0daV2cw">Understanding Neurons.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1VtWV9LAVLJ0uAkhFMbDJFjsUH6IvBDnPde4lR1cD2mo/edit?usp=drive_link">Intro to CLassification.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1G56D0-qG9YWnzQQeje9LMpcLSotMgBCiMyfj53yz7lY/edit?usp=drive_link">Training, Validation, and Test Data.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1hQDabWqaKUWRb60Cze-MhAyeUUVyNgyTUMBpLnqhtvc/edit?resourcekey=0-uHZoNwsbjeY3EIMD3fYAfg#slide=id.g94db9f9f78_0_2">Intro to Convolutions.</a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="#vid-nn" class="quarto-xref">Video&nbsp;<span>3.3</span></a></p></li>
<li><p><a href="#vid-gd" class="quarto-xref">Video&nbsp;<span>3.1</span></a></p></li>
<li><p><a href="#vid-bp" class="quarto-xref">Video&nbsp;<span>3.2</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.</p>
<ul>
<li><p><a href="#exr-mlp" class="quarto-xref">Esercizio&nbsp;<span>3.1</span></a></p></li>
<li><p><a href="#exr-cnn" class="quarto-xref">Esercizio&nbsp;<span>3.2</span></a></p></li>
</ul>
</div>
</div>
</div>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/ml_systems/ml_systems.it.html" class="pagination-link" aria-label="Sistemi di ML">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/workflow/workflow.it.html" class="pagination-link" aria-label="Workflow dell'IA">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University). Traduzione di <a href="https://github.com/BravoBaldo">Baldassarre Cesarano</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/dl_primer/dl_primer.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/dl_primer/dl_primer.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>