<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Addestramento dell‚ÄôIA ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../contents/core/efficient_ai/efficient_ai.it.html" rel="next">
<link href="../../../contents/core/frameworks/frameworks.it.html" rel="prev">
<link href="../../../favicon.png" rel="icon" type="image/png">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>
<script src="../../../scripts/ai_menu/dist/bundle.js" defer=""></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../contents/core/training/training.it.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2b8d2ba3a08f8b4ab16660e3d0aa1206" class="alert alert-primary hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>‚≠ê [18 Ott] <b>Abbiamo raggiunto 1.000 stelle GitHub</b> üéâ Grazie a voi, Arduino e SEEED hanno donato kit hardware di IA per <a href="https://tinyml.seas.harvard.edu/4D/pastEvents">per i workshop TinyML</a> nei paesi in via di sviluppo <br> üéì [15 Nov] La <a href="https://www.edgeaifoundation.org/">EDGE AI Foundation</a> <strong>equipara i fondi per borse di studio accademiche</strong> per ogni nuovo GitHub ‚≠ê (fino a 10.000 stelle). <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per supportare!</a> üôè <br> üöÄ <b>La nostra missione. 1 ‚≠ê = 1 üë©‚Äçüéì Studente</b>. Ogni stella racconta una storia: studenti che acquisiscono conoscenze e sostenitori che guidano la missione. Insieme, stiamo facendo la differenza.</p>
</div><i class="bi bi-x-lg quarto-announcement-action"></i></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/about/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/ai/socratiq.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SocratiQ AI</span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/training/training.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell‚ÄôIA</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/core/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">LABORATORI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/part_LABS.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">LABORATORI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/overview.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/part_nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">part_nicla_vision.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/part_xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">part_xiao_esp32s3.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/part_raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">part_raspi.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/part_shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">part_shared.it.html</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#panoramica" id="toc-panoramica" class="nav-link active" data-scroll-target="#panoramica"><span class="header-section-number">7.1</span> Panoramica</a></li>
  <li><a href="#matematica-delle-reti-neurali" id="toc-matematica-delle-reti-neurali" class="nav-link" data-scroll-target="#matematica-delle-reti-neurali"><span class="header-section-number">7.2</span> Matematica delle Reti Neurali</a>
  <ul>
  <li><a href="#notazione-delle-reti-neurali" id="toc-notazione-delle-reti-neurali" class="nav-link" data-scroll-target="#notazione-delle-reti-neurali"><span class="header-section-number">7.2.1</span> Notazione delle Reti Neurali</a></li>
  <li><a href="#funzione-loss-come-misura-della-bont√†-di-adattamento-rispetto-ai-dati-di-addestramento" id="toc-funzione-loss-come-misura-della-bont√†-di-adattamento-rispetto-ai-dati-di-addestramento" class="nav-link" data-scroll-target="#funzione-loss-come-misura-della-bont√†-di-adattamento-rispetto-ai-dati-di-addestramento"><span class="header-section-number">7.2.2</span> Funzione Loss come Misura della Bont√† di Adattamento Rispetto ai Dati di Addestramento</a></li>
  <li><a href="#addestramento-di-reti-neurali-con-discesa-del-gradiente" id="toc-addestramento-di-reti-neurali-con-discesa-del-gradiente" class="nav-link" data-scroll-target="#addestramento-di-reti-neurali-con-discesa-del-gradiente"><span class="header-section-number">7.2.3</span> Addestramento di Reti Neurali con Discesa del Gradiente</a></li>
  <li><a href="#backpropagation" id="toc-backpropagation" class="nav-link" data-scroll-target="#backpropagation"><span class="header-section-number">7.2.4</span> Backpropagation</a></li>
  </ul></li>
  <li><a href="#grafi-del-calcolo-differenziabili" id="toc-grafi-del-calcolo-differenziabili" class="nav-link" data-scroll-target="#grafi-del-calcolo-differenziabili"><span class="header-section-number">7.3</span> Grafi del Calcolo Differenziabili</a></li>
  <li><a href="#dati-di-training" id="toc-dati-di-training" class="nav-link" data-scroll-target="#dati-di-training"><span class="header-section-number">7.4</span> Dati di Training</a>
  <ul>
  <li><a href="#suddivisioni-di-dataset" id="toc-suddivisioni-di-dataset" class="nav-link" data-scroll-target="#suddivisioni-di-dataset"><span class="header-section-number">7.4.1</span> Suddivisioni di Dataset</a>
  <ul class="collapse">
  <li><a href="#set-di-training" id="toc-set-di-training" class="nav-link" data-scroll-target="#set-di-training">Set di Training</a></li>
  <li><a href="#set-di-validazione" id="toc-set-di-validazione" class="nav-link" data-scroll-target="#set-di-validazione">Set di Validazione</a></li>
  <li><a href="#set-di-test" id="toc-set-di-test" class="nav-link" data-scroll-target="#set-di-test">Set di Test</a></li>
  </ul></li>
  <li><a href="#errori-e-insidie-comuni" id="toc-errori-e-insidie-comuni" class="nav-link" data-scroll-target="#errori-e-insidie-comuni"><span class="header-section-number">7.4.2</span> Errori e Insidie Comuni</a>
  <ul class="collapse">
  <li><a href="#dati-di-training-insufficienti" id="toc-dati-di-training-insufficienti" class="nav-link" data-scroll-target="#dati-di-training-insufficienti">Dati di Training Insufficienti</a></li>
  <li><a href="#perdita-di-dati-tra-set" id="toc-perdita-di-dati-tra-set" class="nav-link" data-scroll-target="#perdita-di-dati-tra-set">Perdita di Dati Tra Set</a></li>
  <li><a href="#set-di-validazione-piccolo-o-non-rappresentativo" id="toc-set-di-validazione-piccolo-o-non-rappresentativo" class="nav-link" data-scroll-target="#set-di-validazione-piccolo-o-non-rappresentativo">Set di Validazione Piccolo o Non Rappresentativo</a></li>
  <li><a href="#riutilizzo-del-set-di-test-pi√π-volte" id="toc-riutilizzo-del-set-di-test-pi√π-volte" class="nav-link" data-scroll-target="#riutilizzo-del-set-di-test-pi√π-volte">Riutilizzo del Set di Test Pi√π Volte</a></li>
  <li><a href="#stesse-suddivisioni-dei-dati-negli-esperimenti" id="toc-stesse-suddivisioni-dei-dati-negli-esperimenti" class="nav-link" data-scroll-target="#stesse-suddivisioni-dei-dati-negli-esperimenti">Stesse Suddivisioni dei Dati negli Esperimenti</a></li>
  <li><a href="#mancata-stratificazione-delle-suddivisioni" id="toc-mancata-stratificazione-delle-suddivisioni" class="nav-link" data-scroll-target="#mancata-stratificazione-delle-suddivisioni">Mancata Stratificazione delle Suddivisioni</a></li>
  <li><a href="#ignorare-le-dipendenze-delle-serie-temporali" id="toc-ignorare-le-dipendenze-delle-serie-temporali" class="nav-link" data-scroll-target="#ignorare-le-dipendenze-delle-serie-temporali">Ignorare le Dipendenze delle Serie Temporali</a></li>
  <li><a href="#nessun-dato-non-visto-per-la-valutazione-finale" id="toc-nessun-dato-non-visto-per-la-valutazione-finale" class="nav-link" data-scroll-target="#nessun-dato-non-visto-per-la-valutazione-finale">Nessun Dato Non Visto per la Valutazione Finale</a></li>
  <li><a href="#sovra-ottimizzazione-del-set-di-validazione" id="toc-sovra-ottimizzazione-del-set-di-validazione" class="nav-link" data-scroll-target="#sovra-ottimizzazione-del-set-di-validazione">Sovra-ottimizzazione del Set di Validazione</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#algoritmi-di-ottimizzazione" id="toc-algoritmi-di-ottimizzazione" class="nav-link" data-scroll-target="#algoritmi-di-ottimizzazione"><span class="header-section-number">7.5</span> Algoritmi di Ottimizzazione</a>
  <ul>
  <li><a href="#ottimizzazioni" id="toc-ottimizzazioni" class="nav-link" data-scroll-target="#ottimizzazioni"><span class="header-section-number">7.5.1</span> Ottimizzazioni</a></li>
  <li><a href="#compromessi" id="toc-compromessi" class="nav-link" data-scroll-target="#compromessi"><span class="header-section-number">7.5.2</span> Compromessi</a></li>
  <li><a href="#algoritmi-di-benchmarking" id="toc-algoritmi-di-benchmarking" class="nav-link" data-scroll-target="#algoritmi-di-benchmarking"><span class="header-section-number">7.5.3</span> Algoritmi di Benchmarking</a></li>
  </ul></li>
  <li><a href="#ottimizzazione-degli-iperparametri" id="toc-ottimizzazione-degli-iperparametri" class="nav-link" data-scroll-target="#ottimizzazione-degli-iperparametri"><span class="header-section-number">7.6</span> Ottimizzazione degli Iperparametri</a>
  <ul>
  <li><a href="#algoritmi-di-ricerca" id="toc-algoritmi-di-ricerca" class="nav-link" data-scroll-target="#algoritmi-di-ricerca"><span class="header-section-number">7.6.1</span> Algoritmi di Ricerca</a></li>
  <li><a href="#implicazioni-di-sistema" id="toc-implicazioni-di-sistema" class="nav-link" data-scroll-target="#implicazioni-di-sistema"><span class="header-section-number">7.6.2</span> Implicazioni di Sistema</a></li>
  <li><a href="#gli-auto-tuner" id="toc-gli-auto-tuner" class="nav-link" data-scroll-target="#gli-auto-tuner"><span class="header-section-number">7.6.3</span> Gli Auto Tuner</a>
  <ul class="collapse">
  <li><a href="#bigml" id="toc-bigml" class="nav-link" data-scroll-target="#bigml">BigML</a></li>
  <li><a href="#tinyml" id="toc-tinyml" class="nav-link" data-scroll-target="#tinyml">TinyML</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regolarizzazione" id="toc-regolarizzazione" class="nav-link" data-scroll-target="#regolarizzazione"><span class="header-section-number">7.7</span> Regolarizzazione</a>
  <ul>
  <li><a href="#l1-e-l2" id="toc-l1-e-l2" class="nav-link" data-scroll-target="#l1-e-l2"><span class="header-section-number">7.7.1</span> L1 e L2</a></li>
  <li><a href="#dropout" id="toc-dropout" class="nav-link" data-scroll-target="#dropout"><span class="header-section-number">7.7.2</span> Dropout</a></li>
  <li><a href="#arresto-anticipato" id="toc-arresto-anticipato" class="nav-link" data-scroll-target="#arresto-anticipato"><span class="header-section-number">7.7.3</span> Arresto Anticipato</a></li>
  </ul></li>
  <li><a href="#funzioni-di-attivazione" id="toc-funzioni-di-attivazione" class="nav-link" data-scroll-target="#funzioni-di-attivazione"><span class="header-section-number">7.8</span> Funzioni di Attivazione</a>
  <ul>
  <li><a href="#sigmoide" id="toc-sigmoide" class="nav-link" data-scroll-target="#sigmoide"><span class="header-section-number">7.8.1</span> Sigmoide</a></li>
  <li><a href="#tanh" id="toc-tanh" class="nav-link" data-scroll-target="#tanh"><span class="header-section-number">7.8.2</span> Tanh</a></li>
  <li><a href="#relu" id="toc-relu" class="nav-link" data-scroll-target="#relu"><span class="header-section-number">7.8.3</span> ReLU</a></li>
  <li><a href="#softmax" id="toc-softmax" class="nav-link" data-scroll-target="#softmax"><span class="header-section-number">7.8.4</span> Softmax</a></li>
  <li><a href="#pro-e-contro" id="toc-pro-e-contro" class="nav-link" data-scroll-target="#pro-e-contro"><span class="header-section-number">7.8.5</span> Pro e Contro</a></li>
  </ul></li>
  <li><a href="#inizializzazione-dei-pesi" id="toc-inizializzazione-dei-pesi" class="nav-link" data-scroll-target="#inizializzazione-dei-pesi"><span class="header-section-number">7.9</span> Inizializzazione dei Pesi</a>
  <ul>
  <li><a href="#inizializzazione-uniforme-e-normale" id="toc-inizializzazione-uniforme-e-normale" class="nav-link" data-scroll-target="#inizializzazione-uniforme-e-normale"><span class="header-section-number">7.9.1</span> Inizializzazione Uniforme e Normale</a></li>
  <li><a href="#inizializzazione-xavier" id="toc-inizializzazione-xavier" class="nav-link" data-scroll-target="#inizializzazione-xavier"><span class="header-section-number">7.9.2</span> Inizializzazione Xavier</a></li>
  <li><a href="#inizializzazione-he" id="toc-inizializzazione-he" class="nav-link" data-scroll-target="#inizializzazione-he"><span class="header-section-number">7.9.3</span> Inizializzazione He</a></li>
  </ul></li>
  <li><a href="#colli-di-bottiglia-del-sistema" id="toc-colli-di-bottiglia-del-sistema" class="nav-link" data-scroll-target="#colli-di-bottiglia-del-sistema"><span class="header-section-number">7.10</span> ‚ÄúColli di Bottiglia‚Äù del Sistema</a>
  <ul>
  <li><a href="#complessit√†-a-runtime-della-moltiplicazione-di-matrici" id="toc-complessit√†-a-runtime-della-moltiplicazione-di-matrici" class="nav-link" data-scroll-target="#complessit√†-a-runtime-della-moltiplicazione-di-matrici"><span class="header-section-number">7.10.1</span> Complessit√† a Runtime della Moltiplicazione di Matrici</a>
  <ul class="collapse">
  <li><a href="#moltiplicazioni-di-layer-vs.-attivazioni" id="toc-moltiplicazioni-di-layer-vs.-attivazioni" class="nav-link" data-scroll-target="#moltiplicazioni-di-layer-vs.-attivazioni">Moltiplicazioni di Layer vs.&nbsp;Attivazioni</a></li>
  <li><a href="#mini-batch" id="toc-mini-batch" class="nav-link" data-scroll-target="#mini-batch">Mini-batch</a></li>
  <li><a href="#ottimizzazione-della-moltiplicazione-di-matrici" id="toc-ottimizzazione-della-moltiplicazione-di-matrici" class="nav-link" data-scroll-target="#ottimizzazione-della-moltiplicazione-di-matrici">Ottimizzazione della Moltiplicazione di Matrici</a></li>
  </ul></li>
  <li><a href="#calcolo-vs.-collo-di-bottiglia-della-memoria" id="toc-calcolo-vs.-collo-di-bottiglia-della-memoria" class="nav-link" data-scroll-target="#calcolo-vs.-collo-di-bottiglia-della-memoria"><span class="header-section-number">7.10.2</span> Calcolo vs.&nbsp;Collo di Bottiglia della Memoria</a>
  <ul class="collapse">
  <li><a href="#addestramento-vs.-inferenza" id="toc-addestramento-vs.-inferenza" class="nav-link" data-scroll-target="#addestramento-vs.-inferenza">Addestramento vs.&nbsp;Inferenza</a></li>
  <li><a href="#dimensione-del-batch" id="toc-dimensione-del-batch" class="nav-link" data-scroll-target="#dimensione-del-batch">Dimensione del Batch</a></li>
  <li><a href="#caratteristiche-hardware" id="toc-caratteristiche-hardware" class="nav-link" data-scroll-target="#caratteristiche-hardware">Caratteristiche Hardware</a></li>
  <li><a href="#architetture-dei-modelli" id="toc-architetture-dei-modelli" class="nav-link" data-scroll-target="#architetture-dei-modelli">Architetture dei Modelli</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#parallelizzazione-del-training" id="toc-parallelizzazione-del-training" class="nav-link" data-scroll-target="#parallelizzazione-del-training"><span class="header-section-number">7.11</span> Parallelizzazione del Training</a>
  <ul>
  <li><a href="#parallelismo-dei-dati" id="toc-parallelismo-dei-dati" class="nav-link" data-scroll-target="#parallelismo-dei-dati"><span class="header-section-number">7.11.1</span> Parallelismo dei Dati</a></li>
  <li><a href="#parallelismo-del-modello" id="toc-parallelismo-del-modello" class="nav-link" data-scroll-target="#parallelismo-del-modello"><span class="header-section-number">7.11.2</span> Parallelismo del Modello</a></li>
  <li><a href="#confronto" id="toc-confronto" class="nav-link" data-scroll-target="#confronto"><span class="header-section-number">7.11.3</span> Confronto</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione"><span class="header-section-number">7.12</span> Conclusione</a></li>
  <li><a href="#sec-ai-training-resource" id="toc-sec-ai-training-resource" class="nav-link" data-scroll-target="#sec-ai-training-resource"><span class="header-section-number">7.13</span> Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/training/training.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/training/training.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-ai_training" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Risorse: <a href="#sec-ai-training-resource">Slide</a>, <a href="../frameworks/frameworks.it.html#sec-ai-frameworks-resource">Video</a>, <a href="#sec-ai-training-resource">Esercizi</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/ai_training.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E 3 Prompt: Un‚Äôillustrazione per l‚Äôaddestramento dell‚ÄôIA, raffigurante una rete neurale con neuroni che vengono riparati e attivati. La scena include una vasta rete di neuroni, ognuno dei quali si illumina e si attiva per rappresentare attivit√† e apprendimento. Tra questi neuroni, piccole figure che ricordano ingegneri e scienziati lavorano attivamente, riparando e modificando i neuroni. Questi lavoratori in miniatura simboleggiano il processo di addestramento della rete, regolando pesi e bias per ottenere la convergenza. L‚Äôintera scena √® una metafora visiva dello sforzo intricato e collaborativo coinvolto nell‚Äôaddestramento dell‚ÄôIA, con i lavoratori che rappresentano l‚Äôottimizzazione e l‚Äôapprendimento continui all‚Äôinterno di una rete neurale. Lo sfondo √® una serie complessa di neuroni interconnessi, che creano un senso di profondit√† e complessit√†.</em></figcaption>
</figure>
</div>
<p>Il training √® fondamentale per sviluppare sistemi di IA accurati e utili utilizzando tecniche di apprendimento automatico. A un livello elevato, il training implica l‚Äôinserimento di dati negli algoritmi di machine learning in modo che possano imparare pattern e fare previsioni. Tuttavia, il training efficace dei modelli richiede di affrontare vari problemi relativi a dati, algoritmi, ottimizzazione dei parametri del modello e abilitazione della generalizzazione. Questo capitolo esplorer√† le sfumature e le considerazioni relative al training dei modelli di apprendimento automatico.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Obiettivi dell‚ÄôApprendimento
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Comprendere la matematica fondamentale delle reti neurali, tra cui le trasformazioni lineari, funzioni di attivazione, funzioni di perdita, backpropagation e ottimizzazione tramite ‚Äúgradient descent‚Äù [discesa del gradiente].</p></li>
<li><p>Scoprire come sfruttare efficacemente i dati per il training del modello tramite la suddivisione appropriata in set di addestramento, convalida e test per abilitare la generalizzazione.</p></li>
<li><p>Scoprire vari algoritmi di ottimizzazione come lo ‚Äústochastic gradient descent‚Äù e adattamenti come momentum e Adam che accelerano l‚Äôaddestramento.</p></li>
<li><p>Scoprire tecniche di ottimizzazione e regolarizzazione degli iperparametri per migliorare la generalizzazione del modello riducendo l‚Äôoverfitting.</p></li>
<li><p>Scoprire strategie di inizializzazione del peso appropriate abbinate alle architetture del modello e alle scelte di attivazione che accelerano la convergenza.</p></li>
<li><p>Identificare i colli di bottiglia posti da operazioni chiave come la moltiplicazione di matrici durante l‚Äôaddestramento e il deployment.</p></li>
<li><p>Scoprire come i miglioramenti hardware come GPU, TPU e acceleratori specializzati velocizzano le operazioni matematiche critiche per accelerare l‚Äôaddestramento.</p></li>
<li><p>Scoprire tecniche di parallelizzazione, sia parallelismo dei dati che del modello, per distribuire l‚Äôaddestramento su pi√π dispositivi e accelerare la produttivit√† del sistema.</p></li>
</ul>
</div>
</div>
<section id="panoramica" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="panoramica"><span class="header-section-number">7.1</span> Panoramica</h2>
<p>Il training √® fondamentale per sviluppare sistemi di intelligenza artificiale accurati e utili tramite il machine learning. Il training crea un modello di apprendimento automatico che pu√≤ essere generalizzato a dati nuovi e inediti anzich√© memorizzare gli esempi dell‚Äôaddestramento. Ci√≤ avviene inserendo dati di training in algoritmi che apprendono pattern da questi esempi regolando i parametri interni.</p>
<p>Gli algoritmi riducono al minimo una ‚Äúfunzione loss‚Äù [perdita], che confronta le loro previsioni sui dati di training con le etichette o le soluzioni note, guidando l‚Äôapprendimento. Un training efficace richiede spesso set di dati rappresentativi di alta qualit√† sufficientemente grandi da catturare la variabilit√† nei casi d‚Äôuso del mondo reale.</p>
<p>Richiede inoltre la scelta di un algoritmo adatto all‚Äôattivit√†, che si tratti di una rete neurale per la visione artificiale, un algoritmo di apprendimento di rinforzo per il controllo robotico o un metodo basato su alberi per la previsione categoriale. √à necessaria un‚Äôattenta messa a punto per la struttura del modello, come la profondit√† e la larghezza della rete neurale e i parametri di apprendimento come la dimensione del passo e la forza della regolarizzazione.</p>
<p>Sono importanti anche le tecniche per prevenire l‚Äôoverfitting, come le penalit√† di regolarizzazione nonch√© la convalida con dati trattenuti. L‚Äôoverfitting pu√≤ verificarsi quando un modello si adatta troppo ai dati di training, non riuscendo a generalizzare con i nuovi dati. Ci√≤ pu√≤ accadere se il modello √® troppo complesso o √® stato addestrato troppo a lungo.</p>
<p>Per evitare l‚Äôoverfitting, le tecniche di regolarizzazione possono aiutare a vincolare il modello. Un metodo di regolarizzazione consiste nell‚Äôaggiungere un termine di penalit√† alla funzione di perdita che scoraggia la complessit√†, come la norma L2 dei pesi. Questo penalizza i valori dei parametri elevati. Un‚Äôaltra tecnica √® il dropout, in cui una percentuale di neuroni viene impostata casualmente a zero durante l‚Äôaddestramento. Ci√≤ riduce il co-adattamento dei neuroni.</p>
<p>I metodi di validazione aiutano anche a rilevare ed evitare l‚Äôoverfitting. Una parte dei dati di training viene tenuta fuori dal ciclo di training come un set di validazione. Il modello viene valutato su questi dati. Se l‚Äôerrore di convalida aumenta mentre l‚Äôerrore di training diminuisce, si verifica un overfitting. Il training pu√≤ quindi essere interrotto in anticipo o regolarizzato in modo pi√π forte. La regolarizzazione e la convalida consentono ai modelli di addestrarsi alla massima capacit√† senza overfitting [sovra-adattare] i dati di training.</p>
<p>Il training richiede notevoli risorse di elaborazione, in particolare per le reti neurali profonde (deep) utilizzate nella visione artificiale, nell‚Äôelaborazione del linguaggio naturale e in altre aree. Queste reti hanno milioni di pesi regolabili che devono essere regolati tramite un training esteso. I miglioramenti hardware e le tecniche di training distribuite hanno consentito di addestrare reti neurali sempre pi√π grandi che possono raggiungere prestazioni di livello umano in alcune attivit√†.</p>
<p>In sintesi, alcuni punti chiave sul training:</p>
<ul>
<li><strong>I Dati sono cruciali:</strong> I modelli di machine learning apprendono dagli esempi nei dati di training. Dati pi√π rappresentativi e di qualit√† elevata portano a migliori prestazioni del modello. I dati devono essere elaborati e formattati per il training.</li>
<li><strong>Gli algoritmi imparano dai dati:</strong> Diversi algoritmi (reti neurali, alberi decisionali, ecc.) hanno approcci diversi per trovare dei pattern nei dati. √à importante scegliere l‚Äôalgoritmo giusto per l‚Äôattivit√†.</li>
<li><strong>L‚Äôaddestramento affina i parametri del modello:</strong> L‚Äôaddestramento del modello regola i parametri interni per trovare pattern nei dati. I modelli avanzati come le reti neurali hanno molti pesi regolabili. L‚Äôaddestramento regola iterativamente i pesi per ridurre al minimo una funzione di perdita.</li>
<li><strong>La generalizzazione √® l‚Äôobiettivo:</strong> Un modello che sovra-adatta i dati di addestramento non generalizzer√† bene. Le tecniche di regolarizzazione (dropout, early stopping <a href="#arresto-anticipato">arresto anticipato</a>, ecc.) riducono il sovra-adattamento. I dati di validazione vengono utilizzati per valutare la generalizzazione.</li>
<li><strong>L‚Äôaddestramento richiede risorse di elaborazione:</strong> L‚Äôaddestramento di modelli complessi richiede una notevole potenza di elaborazione e tempo. I miglioramenti hardware e il training distribuito su GPU/TPU hanno consentito dei progressi.</li>
</ul>
<p>Guideremo attraverso questi dettagli nelle restanti sezioni. Comprendere come sfruttare in modo efficace dati, algoritmi, ottimizzazione dei parametri e generalizzazione attraverso il training √® essenziale per sviluppare sistemi di intelligenza artificiale capaci e distribuibili che funzionino in modo robusto nel mondo reale.</p>
</section>
<section id="matematica-delle-reti-neurali" class="level2 page-columns page-full" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="matematica-delle-reti-neurali"><span class="header-section-number">7.2</span> Matematica delle Reti Neurali</h2>
<p>Il deep learning ha rivoluzionato l‚Äôapprendimento automatico e l‚Äôintelligenza artificiale, consentendo ai computer di apprendere pattern complessi e prendere decisioni intelligenti. La rete neurale √® al centro della rivoluzione del deep learning e, come discusso nella sezione 3, ‚ÄúAvvio al Deep Learning‚Äù, √® un pilastro in alcuni di questi progressi.</p>
<p>Le reti neurali sono costituite da semplici funzioni stratificate l‚Äôuna sull‚Äôaltra. Ogni layer acquisisce alcuni dati, esegue alcuni calcoli e li passa al layer successivo. Questi layer apprendono progressivamente funzionalit√† di alto livello utili per le attivit√† che la rete √® addestrata a svolgere. Ad esempio, in una rete addestrata per il riconoscimento delle immagini, il layer di input pu√≤ acquisire valori di pixel, mentre i layer successivi possono rilevare forme semplici come i bordi. I layer successivi possono rilevare forme pi√π complesse come nasi, occhi, ecc. Il layer di output finale classifica l‚Äôimmagine nel suo complesso.</p>
<p>La rete, in una rete neurale, si riferisce al modo in cui questi layer sono connessi. L‚Äôoutput di ogni layer √® considerato un set di neuroni, che sono collegati ai neuroni nei layer successivi, formando una ‚Äúrete‚Äù. Il modo in cui questi neuroni interagiscono √® determinato dai pesi tra di loro, che modellano le forze sinaptiche simili a quelle di un neurone del cervello. La rete neurale viene addestrata regolando questi pesi. Concretamente, i pesi vengono inizialmente impostati in modo casuale, quindi viene immesso l‚Äôinput, l‚Äôoutput viene confrontato con il risultato desiderato e, infine, i pesi vengono modificati per migliorare la rete. Questo processo viene ripetuto finch√© la rete non riduce al minimo in modo affidabile la perdita (loss), indicando di aver appreso i pattern nei dati.</p>
<p>Come viene definito matematicamente questo processo? Formalmente, le reti neurali sono modelli matematici costituiti da operazioni lineari e non lineari alternate, parametrizzate da un set di pesi apprendibili che vengono addestrati per minimizzare una qualche funzione di perdita (loss). Questa funzione di perdita misura quanto √® buono il nostro modello per quanto riguarda l‚Äôadattamento dei nostri dati di addestramento e produce un valore numerico quando viene valutato sul nostro modello rispetto ai dati di addestramento. L‚Äôaddestramento delle reti neurali comporta la valutazione ripetuta della funzione di perdita su molti dati diversi per misurare quanto √® buono il nostro modello, quindi la modifica continua dei pesi del nostro modello utilizzando la backpropagation in modo che la perdita diminuisca, ottimizzando infine il modello per adattarlo ai nostri dati.</p>
<section id="notazione-delle-reti-neurali" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="notazione-delle-reti-neurali"><span class="header-section-number">7.2.1</span> Notazione delle Reti Neurali</h3>
<p>Il nucleo di una rete neurale pu√≤ essere visto come una sequenza di operazioni lineari e non lineari alternate, come mostrato in <a href="#fig-neural-net-diagram" class="quarto-xref">Figura&nbsp;<span>7.1</span></a>.</p>
<div id="fig-neural-net-diagram" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-neural-net-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/aitrainingnn.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-neural-net-diagram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.1: Diagramma della rete neurale. Fonte: astroML.
</figcaption>
</figure>
</div>
<p>Le reti neurali sono strutturate con layer [strati] di neuroni collegati da pesi (che rappresentano operazioni lineari) e funzioni di attivazione (che rappresentano operazioni non lineari). Esaminando la figura, vediamo come le informazioni fluiscono attraverso la rete, partendo dal layer di input, passando attraverso uno o pi√π layer nascosti, e infine raggiungendo il layer di output. Ogni connessione tra neuroni rappresenta un peso, mentre ciascun neurone applica tipicamente una funzione di attivazione non lineare ai suoi input.</p>
<p>La rete neurale funziona prendendo un vettore di input <span class="math inline">\(x_i\)</span> e passandolo attraverso una serie di layer, ognuno dei quali esegue operazioni lineari e non lineari. L‚Äôoutput della rete a ogni layer <span class="math inline">\(A_j\)</span> pu√≤ essere rappresentato come:</p>
<p><span class="math display">\[
A_j = f\left(\sum_{i=1}^{N} w_{ij} x_i\right)
\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(N\)</span> - Il numero totale di feature di input.</li>
<li><span class="math inline">\(x_{i}\)</span> - La singola feature di input, dove <span class="math inline">\(i\)</span> varia da <span class="math inline">\(1\)</span> a <span class="math inline">\(N\)</span>.</li>
<li><span class="math inline">\(w_{ij}\)</span> - I pesi che collegano il neurone <span class="math inline">\(i\)</span> in uno layer al neurone <span class="math inline">\(j\)</span> nel layer successivo, che vengono aggiustati durante l‚Äôaddestramento.</li>
<li><span class="math inline">\(f(\theta)\)</span> - La funzione di attivazione non lineare applicata a ogni layer (ad esempio, ReLU, softmax, ecc.).</li>
<li><span class="math inline">\(A_{j}\)</span> - L‚Äôoutput della rete neurale a ogni layer <span class="math inline">\(j\)</span>, dove <span class="math inline">\(j\)</span> indica il numero del layer.</li>
</ul>
<p>Nel contesto di <a href="#fig-neural-net-diagram" class="quarto-xref">Figura&nbsp;<span>7.1</span></a>, <span class="math inline">\(x_1, x_2, x_3, x_4,\)</span> e <span class="math inline">\(x_5\)</span> rappresentano le caratteristiche di input. Ogni neurone di input <span class="math inline">\(x_i\)</span> corrisponde a una feature dei dati di input. Le frecce dal layer di input al layer nascosto indicano le connessioni tra i neuroni di input e i neuroni nascosti, con ogni connessione associata a un peso <span class="math inline">\(w_{ij}\)</span>.</p>
<p>Il layer nascosto √® costituito dai neuroni <span class="math inline">\(a_1, a_2, a_3,\)</span> e <span class="math inline">\(a_4\)</span>, ognuno dei quali riceve input da tutti i neuroni nello layer di input. I pesi <span class="math inline">\(w_{ij}\)</span> collegano i neuroni di input ai neuroni nascosti. Ad esempio, <span class="math inline">\(w_{11}\)</span> √® il peso che collega l‚Äôinput <span class="math inline">\(x_1\)</span> al neurone nascosto <span class="math inline">\(a_1\)</span>.</p>
<p>Il numero di nodi in ogni layer e il numero totale di layer insieme definiscono l‚Äôarchitettura della rete neurale. Nel primo layer (layer di input), il numero di nodi corrisponde alla dimensionalit√† dei dati di input, mentre nell‚Äôultimo layer (layer di output), il numero di nodi corrisponde alla dimensionalit√† dell‚Äôoutput. Il numero di nodi nei layer intermedi pu√≤ essere impostato arbitrariamente, consentendo flessibilit√† nella progettazione dell‚Äôarchitettura di rete.</p>
<p>I pesi, che determinano il modo in cui ogni layer della rete neurale interagisce con gli altri, sono matrici di numeri reali. Inoltre, ogni layer in genere include un vettore di bias [polarizzazione], ma qui lo ignoriamo per semplicit√†. La matrice dei pesi <span class="math inline">\(W_j\)</span> che collega il layer <span class="math inline">\(j-1\)</span> al layer <span class="math inline">\(j\)</span> ha le dimensioni:</p>
<p><span class="math display">\[
W_j \in \mathbb{R}^{d_j \times d_{j-1}}
\]</span></p>
<p>dove <span class="math inline">\(d_j\)</span> √® il numero di nodi nel layer <span class="math inline">\(j\)</span> e <span class="math inline">\(d_{j-1}\)</span> √® il numero di nodi nel layer precedente <span class="math inline">\(j-1\)</span>.</p>
<p>L‚Äôoutput finale <span class="math inline">\(y_k\)</span> della rete si ottiene applicando un‚Äôaltra funzione di attivazione <span class="math inline">\(g(\theta)\)</span> alla somma ponderata degli output del layer nascosto:</p>
<p><span class="math display">\[
y = g\left(\sum_{j=1}^{M} w_{jk} A_j\right)
\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(M\)</span> - Il numero di neuroni nascosti nel layer finale prima dell‚Äôoutput.</li>
<li><span class="math inline">\(w_{jk}\)</span> - Il peso tra il neurone nascosto <span class="math inline">\(a_j\)</span> e il neurone di output <span class="math inline">\(y_k\)</span>.</li>
<li><span class="math inline">\(g(\theta)\)</span> - La funzione di attivazione applicata alla somma ponderata degli output del layer nascosto.</li>
</ul>
<p>La nostra rete neurale, come definita, esegue una sequenza di operazioni lineari e non lineari sui dati di input (<span class="math inline">\(x_{i}\)</span>) per ottenere previsioni (<span class="math inline">\(y_{i}\)</span>), che si spera siano una buona risposta a ci√≤ che vogliamo che la rete neurale faccia sull‚Äôinput (ad esempio, classificare se l‚Äôimmagine di input √® un gatto o meno). La nostra rete neurale pu√≤ quindi essere rappresentata succintamente come una funzione <span class="math inline">\(N\)</span> che accetta un input <span class="math inline">\(x \in \mathbb{R}^{d_0}\)</span> parametrizzato da <span class="math inline">\(W_1, ..., W_n\)</span> e produce l‚Äôoutput finale <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
y = N(x; W_1, ..., W_n) \quad \text{where } A_0 = x
\]</span></p>
<p>Questa equazione indica che la rete inizia con l‚Äôinput <span class="math inline">\(A_0 = x\)</span> e calcola iterativamente <span class="math inline">\(A_j\)</span> a ogni layer utilizzando i parametri <span class="math inline">\(W_j\)</span> fino a produrre l‚Äôoutput finale <span class="math inline">\(y\)</span> al layer di output.</p>
<p>Successivamente vedremo come valutare questa rete neurale rispetto ai dati di addestramento introducendo una funzione di perdita.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Perch√© sono necessarie le operazioni non lineari? Se avessimo solo layer lineari, l‚Äôintera rete sarebbe equivalente a un singolo layer lineare costituito dal prodotto degli operatori lineari. Quindi, le funzioni non lineari svolgono un ruolo chiave nella potenza delle reti neurali poich√© migliorano la capacit√† della rete neurale di adattare le funzioni.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Anche le convoluzioni sono operatori lineari e possono essere convertite in una moltiplicazione di matrici.</p>
</div>
</div>
</section>
<section id="funzione-loss-come-misura-della-bont√†-di-adattamento-rispetto-ai-dati-di-addestramento" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="funzione-loss-come-misura-della-bont√†-di-adattamento-rispetto-ai-dati-di-addestramento"><span class="header-section-number">7.2.2</span> Funzione Loss come Misura della Bont√† di Adattamento Rispetto ai Dati di Addestramento</h3>
<p>Dopo aver definito la nostra rete neurale, ci vengono forniti alcuni dati di addestramento, ovvero un set di punti <span class="math inline">\({(x_j, y_j)}\)</span> per <span class="math inline">\(j=1 \rightarrow M\)</span>, dove <span class="math inline">\(M\)</span> √® il numero totale di campioni nel set di dati e <span class="math inline">\(j\)</span> indicizza ogni campione. Vogliamo valutare quanto √® buona la nostra rete neurale nell‚Äôadattare questi dati. Per fare ci√≤, introduciamo una funzione di perdita, ovvero una funzione che prende l‚Äôoutput della rete neurale su un particolare punto dati <span class="math inline">\(\hat{y_j} = N(x_j; W_1, ..., W_n)\)</span> e lo confronta con la ‚Äúetichetta‚Äù di quel particolare dato (il corrispondente <span class="math inline">\(y_j\)</span>) e restituisce un singolo scalare numerico (ovvero un numero reale) che rappresenta quanto √® ‚Äúbene‚Äù la rete neurale adatta quel particolare dato; la misura finale di quanto √® buona la rete neurale sull‚Äôintero set di dati √® quindi solo la media delle perdite su tutti i dati.</p>
<p>Esistono molti tipi diversi di funzioni di perdita; ad esempio, nel caso della classificazione delle immagini, potremmo usare la funzione di ‚Äúcross-entropy loss‚Äù [perdita di entropia incrociata], che ci dice quanto bene si confrontano due vettori che rappresentano le previsioni di classificazione (ad esempio, se la nostra previsione prevede che un‚Äôimmagine sia pi√π probabilmente un cane, ma l‚Äôetichetta dice che √® un gatto, restituir√† una ‚Äúperdita‚Äù elevata, che indica un cattivo adattamento).</p>
<p>Matematicamente, una funzione di perdita √® una funzione che prende due vettori con valori reali, uno che rappresenta gli output previsti della rete neurale e l‚Äôaltro che rappresenta le etichette vere, e restituisce un singolo scalare numerico che rappresenta l‚Äôerrore o la ‚Äúperdita‚Äù.</p>
<p><span class="math display">\[
L: \mathbb{R}^{d_{n}} \times \mathbb{R}^{d_{n}} \longrightarrow \mathbb{R}
\]</span></p>
<p>Per un singolo esempio di training, la perdita √® data da:</p>
<p><span class="math display">\[
L(N(x_j; W_1, ..., W_n), y_j)
\]</span></p>
<p>dove <span class="math inline">\(\hat{y}_j = N(x_j; W_1, ..., W_n)\)</span> √® l‚Äôoutput previsto della rete neurale per l‚Äôinput <span class="math inline">\(x_j\)</span>, and <span class="math inline">\(y_j\)</span> √® la vera etichetta.</p>
<p>La perdita totale nell‚Äôintero set di dati, <span class="math inline">\(L_{full}\)</span>, viene quindi calcolata come la perdita media in tutti i dati di training:</p>
<blockquote class="blockquote">
<p>Funzione di Perdita per l‚ÄôOttimizzazione del Modello di Rete Neurale su Dataset <span class="math display">\[
L_{full} = \frac{1}{M} \sum_{j=1}^{M} L(N(x_j; W_1,...W_n), y_j)
\]</span></p>
</blockquote>
</section>
<section id="addestramento-di-reti-neurali-con-discesa-del-gradiente" class="level3 page-columns page-full" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="addestramento-di-reti-neurali-con-discesa-del-gradiente"><span class="header-section-number">7.2.3</span> Addestramento di Reti Neurali con Discesa del Gradiente</h3>
<p>Ora che possiamo misurare quanto bene la nostra rete si adatta ai dati di training, possiamo ottimizzare i pesi della rete neurale per ridurre al minimo questa perdita. In questo contesto, stiamo denotando <span class="math inline">\(W_i\)</span> come pesi per ogni layer <span class="math inline">\(i\)</span> nella rete. Ad alto livello, modifichiamo i parametri delle matrici a valori reali <span class="math inline">\(W_i\)</span> per ridurre al minimo la funzione di perdita <span class="math inline">\(L_{full}\)</span>. Nel complesso, il nostro obiettivo matematico √®</p>
<blockquote class="blockquote">
<p>Obiettivo dell‚ÄôAddestramento della Rete Neurale <span class="math display">\[
min_{W_1, ..., W_n} L_{full}
\]</span> <span class="math display">\[
= min_{W_1, ..., W_n} \frac{1}{M} \sum_{j=1}^{M} L(N(x_j; W_1,...W_n), y_j)
\]</span></p>
</blockquote>
<p>Quindi, come ottimizziamo questo obiettivo? Ricordiamo dal calcolo che la minimizzazione di una funzione pu√≤ essere eseguita prendendo la derivata della funzione relativa ai parametri di input e modificando i parametri nella direzione del gradiente. Questa tecnica √® chiamata a ‚Äúdiscesa del gradiente‚Äù e concretamente comporta il calcolo della derivata della funzione di perdita <span class="math inline">\(L_{full}\)</span> relativa a <span class="math inline">\(W_1, ..., W_n\)</span> per ottenere un gradiente per questi parametri per fare un passo avanti, poi aggiornare questi parametri nella direzione del gradiente. Quindi, possiamo addestrare la nostra rete neurale utilizzando la discesa del gradiente, che applica ripetutamente la regola di aggiornamento.</p>
<blockquote class="blockquote">
<p>Regola di Aggiornamento della Discesa del Gradiente <span class="math display">\[
W_i := W_i - \lambda \frac{\partial L_{full}}{\partial W_i} \mbox{ for } i=1..n
\]</span></p>
</blockquote>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>In pratica, il gradiente viene calcolato su un mini-batch di punti dati per migliorare l‚Äôefficienza computazionale. Questo processo √® chiamato ‚Äúdiscesa del gradiente stocastico‚Äù o ‚Äúdiscesa del gradiente batch‚Äù.</p>
</div>
</div>
<p>Dove <span class="math inline">\(\lambda\)</span> √® la dimensione del passo o il tasso di apprendimento delle nostre modifiche, nell‚Äôaddestramento della nostra rete neurale, eseguiamo ripetutamente il passaggio precedente fino alla convergenza, o quando la perdita non diminuisce pi√π. <a href="#fig-gradient-descent" class="quarto-xref">Figura&nbsp;<span>7.2</span></a> illustra questo processo: vogliamo raggiungere il punto minimo, il che si ottiene seguendo il gradiente (come illustrato con le frecce blu nella figura). Questo precedente approccio √® noto come discesa del gradiente completa poich√© stiamo calcolando la derivata relativa a tutti i dati di addestramento e solo dopo eseguiamo un singolo passaggio del gradiente; un approccio pi√π efficiente √® quello di calcolare il gradiente relativo solo a un batch casuale di dati e poi eseguire un passaggio, un processo noto come discesa del gradiente batch o discesa del gradiente stocastica <span class="citation" data-cites="robbins1951stochastic">(<a href="../../../references.it.html#ref-robbins1951stochastic" role="doc-biblioref">Robbins e Monro 1951</a>)</span>, che √® pi√π efficiente poich√© ora eseguiamo molti pi√π passi per passaggio di tutti i dati di addestramento. Successivamente, tratteremo la matematica alla base del calcolo del gradiente della funzione di perdita relativa a <span class="math inline">\(W_i\)</span>, un processo noto come backpropagation.</p>
<div class="no-row-height column-margin column-container"><div id="ref-robbins1951stochastic" class="csl-entry" role="listitem">
Robbins, Herbert, e Sutton Monro. 1951. <span>¬´A Stochastic Approximation Method¬ª</span>. <em>The Annals of Mathematical Statistics</em> 22 (3): 400‚Äì407. <a href="https://doi.org/10.1214/aoms/1177729586">https://doi.org/10.1214/aoms/1177729586</a>.
</div></div><div id="fig-gradient-descent" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gradient-descent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/aitrainingsgd.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gradient-descent-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.2: Discesa del gradiente. Fonte: Towards Data Science.
</figcaption>
</figure>
</div>
</section>
<section id="backpropagation" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="backpropagation"><span class="header-section-number">7.2.4</span> Backpropagation</h3>
<p>L‚Äôaddestramento delle reti neurali comporta ripetute applicazioni dell‚Äôalgoritmo di discesa del gradiente, che prevede il calcolo della derivata della funzione di perdita rispetto alle <span class="math inline">\(W_i\)</span>. Come calcoliamo la derivata della perdita relativa alle <span class="math inline">\(W_i\)</span>, dato che le <span class="math inline">\(W_i\)</span> sono funzioni annidate l‚Äôuna dell‚Äôaltra in una rete neurale profonda? Il trucco √® sfruttare la <strong>regola della catena:</strong> possiamo calcolare la derivata della perdita relativa alle <span class="math inline">\(W_i\)</span> applicando ripetutamente la regola della catena in un processo completo noto come backpropagation. In particolare, possiamo calcolare i gradienti calcolando la derivata della perdita relativa agli output dell‚Äôultimo layer, poi usarla progressivamente per calcolare la derivata della perdita relativa a ciascun layer precedente a quello di input. Questo processo inizia dalla fine della rete (il layer pi√π vicino all‚Äôoutput) e procede all‚Äôindietro, e quindi prende il nome di backpropagation.</p>
<p>Analizziamolo. Possiamo calcolare la derivata della perdita relativa agli <em>output di ciascun layer della rete neurale</em> utilizzando applicazioni ripetute della regola della catena.</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{\partial L_{n}} = \frac{\partial A_{n}}{\partial L_{n}} \frac{\partial L_{full}}{\partial A_{n}}
\]</span></p>
<p><span class="math display">\[
\frac{\partial L_{full}}{\partial L_{n-1}} = \frac{\partial A_{n-1}}{\partial L_{n-1}} \frac{\partial L_{n}}{\partial A_{n-1}} \frac{\partial A_{n}}{\partial L_{n}} \frac{\partial L_{full}}{\partial A_{n}}  
\]</span></p>
<p>o pi√π in generale</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{\partial L_{i}} = \frac{\partial A_{i}}{\partial L_{i}} \frac{\partial L_{i+1}}{\partial A_{i}} ... \frac{\partial A_{n}}{\partial L_{n}} \frac{\partial L_{full}}{\partial A_{n}}  
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>In quale ordine dovremmo eseguire questo calcolo? Da una prospettiva computazionale, √® preferibile eseguire i calcoli dalla fine alla parte frontale. (ad esempio: prima si calcola <span class="math inline">\(\frac{\partial L_{full}}{\partial A_{n}}\)</span>, poi i termini precedenti, anzich√© iniziare dal centro) poich√© ci√≤ evita di materializzare e calcolare grandi jacobiani. Questo perch√© <span class="math inline">\(\ \frac {\partial L_{full}}{\partial A_{n}}\)</span> √® un vettore; quindi, qualsiasi operazione di matrice che include questo termine ha un output che √® compresso per essere un vettore. Quindi, eseguire il calcolo dalla fine evita grandi moltiplicazioni matrice-matrice assicurando che i prodotti intermedi siano vettori.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Nella nostra notazione, assumiamo che le attivazioni intermedie <span class="math inline">\(A_{i}\)</span> siano vettori <em>colonna</em>, anzich√© vettori <em>riga</em>, quindi la regola della catena √® <span class="math inline">\(\frac{\partial L}{\partial L_{i}} = \frac{\partial L_{i+1}}{\partial L_{i}} ... \frac{\partial L}{\partial L_{n}}\)</span> piuttosto che <span class="math inline">\(\frac{\partial L}{\partial L_{i}} = \frac{\partial L}{\partial L_{n}} ... \frac{\partial L_{i+1}}{\partial L_{i}}\)</span></p>
</div>
</div>
<p>Dopo aver calcolato la derivata della perdita relativa all‚Äô<em>output di ogni layer</em>, possiamo facilmente ottenere la derivata della perdita relativa ai <em>parametri</em>, utilizzando di nuovo la regola della catena:</p>
<p><span class="math display">\[
\frac{\partial L_{full}}{W_{i}} = \frac{\partial L_{i}}{\partial W_{i}} \frac{\partial L_{full}}{\partial L_{i}}
\]</span></p>
<p>Ed √® in definitiva cos√¨ che le derivate dei pesi dei layer vengono calcolate usando la backpropagation! Come appare concretamente in un esempio specifico? Di seguito, esaminiamo un esempio specifico di una semplice rete neurale a 2 layer su un‚Äôattivit√† di regressione usando una funzione di perdita MSE con input a 100 dimensioni e uno layer nascosto a 30 dimensioni:</p>
<blockquote class="blockquote">
<p>Esempio di backpropagation<br>
Supponiamo di avere una rete neurale a due layer <span class="math display">\[
L_1 = W_1 A_{0}
\]</span> <span class="math display">\[
A_1 = ReLU(L_1)
\]</span> <span class="math display">\[
L_2 = W_2 A_{1}
\]</span> <span class="math display">\[
A_2 = ReLU(L_2)
\]</span> <span class="math display">\[
NN(x) = \mbox{Let } A_{0} = x \mbox{ then output } A_2
\]</span> dove <span class="math inline">\(W_1 \in \mathbb{R}^{30 \times 100}\)</span> e <span class="math inline">\(W_2 \in \mathbb{R}^{1 \times 30}\)</span>. Inoltre, supponiamo di utilizzare la funzione di perdita MSE: <span class="math display">\[
L(x, y) = (x-y)^2
\]</span> Vogliamo calcolare <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_i} \mbox{ for } i=1,2
\]</span> Notare quanto segue: <span class="math display">\[
\frac{\partial L(x, y)}{\partial x} = 2 \times (x-y)
\]</span> <span class="math display">\[
\frac{\partial ReLU(x)}{\partial x} \delta  = \left\{\begin{array}{lr}
0 &amp; \text{for } x \leq 0 \\
1 &amp; \text{for } x \geq 0 \\
\end{array}\right\} \odot \delta
\]</span> <span class="math display">\[
\frac{\partial WA}{\partial A} \delta = W^T \delta
\]</span> <span class="math display">\[
\frac{\partial WA}{\partial W} \delta = \delta A^T
\]</span> Quindi abbiamo <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_2} = \frac{\partial L_2}{\partial W_2} \frac{\partial A_2}{\partial L_2} \frac{\partial L(NN(x), y)}{\partial A_2}
\]</span> <span class="math display">\[
= (2L(NN(x) - y) \odot ReLU'(L_2)) A_1^T
\]</span> e <span class="math display">\[
\frac{\partial L(NN(x), y)}{\partial W_1} = \frac{\partial L_1}{\partial W_1} \frac{\partial A_1}{\partial L_1} \frac{\partial L_2}{\partial A_1} \frac{\partial A_2}{\partial L_2} \frac{\partial L(NN(x), y)}{\partial A_2}
\]</span> <span class="math display">\[
= [ReLU'(L_1) \odot (W_2^T [2L(NN(x) - y) \odot ReLU'(L_2)])] A_0^T
\]</span></p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Consiglio
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ricontrollare il lavoro assicurandosi che le forme siano corrette!</p>
<ul>
<li>Tutti i prodotti di Hadamard (<span class="math inline">\(\odot\)</span>) dovrebbero operare su tensori della stessa forma</li>
<li>Tutte le moltiplicazioni di matrici dovrebbero operare su matrici che condividono una dimensione comune (ad esempio, m per n, n per k)</li>
<li>Tutti i gradienti relativi ai pesi dovrebbero avere la stessa forma delle stesse matrici dei pesi</li>
</ul>
</div>
</div>
<p>L‚Äôintero processo di backpropagation pu√≤ essere complesso, specialmente per reti molto profonde. Fortunatamente, framework di machine learning come PyTorch supportano la differenziazione automatica, che esegue la backpropagation. In questi framework, dobbiamo semplicemente specificare il passaggio in avanti e le derivate ci verranno calcolate automaticamente. Tuttavia, √® utile comprendere il processo teorico che avviene internamente in questi framework di apprendimento automatico.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Nota
</div>
</div>
<div class="callout-body-container callout-body">
<p>Come visto sopra, le attivazioni intermedie <span class="math inline">\(A_i\)</span> vengono riutilizzate nella backpropagation. Per migliorare le prestazioni, queste attivazioni vengono memorizzate nella cache dal passaggio in avanti per evitare di essere ricalcolate. Tuttavia, le attivazioni devono essere mantenute in memoria tra i passaggi in avanti e indietro, il che comporta un maggiore utilizzo della memoria. Se la rete e le dimensioni del batch sono grandi, ci√≤ potrebbe causare problemi di memoria. Analogamente, le derivate rispetto agli output di ogni layer vengono memorizzate nella cache per evitare il ricalcolo.</p>
</div>
</div>
<div id="exr-nn" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;7.1: Reti Neurali con Backpropagation e Discesa del Gradiente
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Scoprire la matematica dietro le potenti reti neurali! Il deep learning potrebbe sembrare magico, ma √® radicato nei principi matematici. In questo capitolo, abbiamo scomposto la notazione delle reti neurali, le funzioni di perdita e la potente tecnica della backpropagation. Ora, prepariamoci a implementare questa teoria con questi notebook Colab. Immergersi nel cuore di come le reti neurali apprendono. Si vedr√† la matematica dietro la backpropagation e la discesa del gradiente, aggiornando quei pesi passo dopo passo.</p>
<p><a href="https://colab.research.google.com/github/jigsawlabs-student/pytorch-intro-curriculum/blob/main/5-training-mathematically/20-backpropagation-and-gradient-descent.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
</section>
<section id="grafi-del-calcolo-differenziabili" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="grafi-del-calcolo-differenziabili"><span class="header-section-number">7.3</span> Grafi del Calcolo Differenziabili</h2>
<p>In generale, la discesa del gradiente stocastico mediante backpropagation pu√≤ essere eseguita su qualsiasi grafo computazionale che un utente pu√≤ definire, a condizione che le operazioni del calcolo siano differenziabili. Pertanto, le librerie generiche di deep learning come PyTorch e Tensorflow consentono agli utenti di specificare il loro processo computazionale (ad esempio, reti neurali) come grafo computazionale. La backpropagation viene eseguita automaticamente tramite differenziazione automatica quando la discesa del gradiente stocastico viene eseguita su questi grafi computazionali. Inquadrare l‚Äôaddestramento dell‚ÄôIA come un problema di ottimizzazione su grafi di calcolo differenziabili √® un modo generale per comprendere cosa sta accadendo internamente con i sistemi di deep learning.</p>
<p>La struttura raffigurata in <a href="#fig-computational-graph" class="quarto-xref">Figura&nbsp;<span>7.3</span></a> mostra un segmento di un grafo computazionale differenziabile. In questo grafo, l‚Äôinput ‚Äòx‚Äô viene elaborato tramite una serie di operazioni: viene prima moltiplicato per una matrice di pesi ‚ÄòW‚Äô (MatMul), poi aggiunto a un bias ‚Äòb‚Äô (Add) e infine passato a una funzione di attivazione, Rectified Linear Unit (ReLU). Questa sequenza di operazioni ci fornisce l‚Äôoutput C. La natura differenziabile del grafo significa che ogni operazione ha un gradiente ben definito. La differenziazione automatica, come implementata nei framework ML, sfrutta questa propriet√† per calcolare in modo efficiente i gradienti della perdita rispetto a ciascun parametro nella rete (ad esempio, ‚ÄòW‚Äô e ‚Äòb‚Äô).</p>
<div id="fig-computational-graph" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-computational-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="./images/png/graph.png" style="height:40.0%" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-computational-graph-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.3: Grafo Computazionale. Fonte: TensorFlow.
</figcaption>
</figure>
</div>
</section>
<section id="dati-di-training" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="dati-di-training"><span class="header-section-number">7.4</span> Dati di Training</h2>
<p>Per consentire un training efficace della rete neurale, i dati disponibili devono essere suddivisi in set di training, di validazione e di test. Il set di training viene utilizzato per addestrare i parametri del modello. Il set di validazione valuta il modello durante il training per ottimizzare gli iperparametri e prevenire l‚Äôoverfitting. Il set di test fornisce una valutazione finale imparziale delle prestazioni del modello addestrato.</p>
<p>Mantenere chiare suddivisioni tra training, validation e test con dati rappresentativi √® fondamentale per addestrare, ottimizzare e valutare correttamente i modelli per ottenere le migliori prestazioni nel mondo reale. A tal fine, scopriremo le insidie o gli errori comuni che le persone commettono quando creano queste suddivisioni dei dati.</p>
<p><a href="#tbl-training_splits" class="quarto-xref">Tabella&nbsp;<span>7.1</span></a> confronta le differenze tra le suddivisioni dei dati di training, validazione e test:</p>
<div id="tbl-training_splits" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-training_splits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;7.1: Confronto tra suddivisioni di dati di training, validazione e test.
</figcaption>
<div aria-describedby="tbl-training_splits-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 19%">
<col style="width: 57%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Suddivisione</th>
<th style="text-align: left;">Scopo</th>
<th style="text-align: left;">Dimensioni tipiche</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Set di addestramento</td>
<td style="text-align: left;">Addestrare i parametri del modello</td>
<td style="text-align: left;">60-80% dei dati totali</td>
</tr>
<tr class="even">
<td style="text-align: left;">Set di validazione</td>
<td style="text-align: left;">Valutare il modello durante l‚Äôaddestramento per ottimizzare gli iperparametri e prevenire l‚Äôoverfitting</td>
<td style="text-align: left;">‚àº20% dei dati totali</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Set di test</td>
<td style="text-align: left;">Fornire una valutazione imparziale del modello finale addestrato</td>
<td style="text-align: left;">‚àº20% dei dati totali</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="suddivisioni-di-dataset" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="suddivisioni-di-dataset"><span class="header-section-number">7.4.1</span> Suddivisioni di Dataset</h3>
<section id="set-di-training" class="level4">
<h4 class="anchored" data-anchor-id="set-di-training">Set di Training</h4>
<p>Il set di training viene utilizzato per addestrare il modello. √à il sottoinsieme pi√π grande, in genere il 60-80% dei dati totali. Il modello vede e impara dai dati di addestramento per fare previsioni. √à necessario un set di training sufficientemente grande e rappresentativo affinch√© il modello apprenda efficacemente i pattern sottostanti.</p>
</section>
<section id="set-di-validazione" class="level4">
<h4 class="anchored" data-anchor-id="set-di-validazione">Set di Validazione</h4>
<p>Il set di validazione valuta il modello durante l‚Äôaddestramento, in genere dopo ogni epoca. Solitamente, il 20% dei dati viene assegnato a questo set. Il modello non impara n√© aggiorna i suoi parametri in base ai dati di validazione. Vengono usati per ottimizzare gli iperparametri e apportare altre modifiche per migliorare l‚Äôaddestramento. Il monitoraggio di metriche come perdita e accuratezza sul set di validazione impedisce l‚Äôoverfitting solo sui dati di addestramento.</p>
</section>
<section id="set-di-test" class="level4">
<h4 class="anchored" data-anchor-id="set-di-test">Set di Test</h4>
<p>Il set di test agisce come un dataset che il modello non ha visto durante l‚Äôaddestramento. Viene utilizzato per fornire una valutazione imparziale del modello addestrato finale. In genere, il 20% dei dati √® riservato ai test. Mantenere un set di test ‚Äúhold-out‚Äù [esterno] √® fondamentale per ottenere una stima accurata di come il modello addestrato si comporterebbe su dati non ancora visti del mondo reale. La mancanza di dati dal set di test deve essere evitata a tutti i costi.</p>
<p>Le proporzioni relative dei set di training, validazione e test possono variare in base alle dimensioni dei dati e all‚Äôapplicazione. Tuttavia, seguire le linee guida generali per una suddivisione 60/20/20 √® un buon punto di partenza. Un‚Äôattenta suddivisione dei dati garantisce che i modelli siano adeguatamente addestrati, ottimizzati e valutati per ottenere le prestazioni migliori.</p>
<p><a href="#vid-train-dev-test" class="quarto-xref">Video&nbsp;<span>7.1</span></a> spiega come suddividere correttamente il dataset in set di training, validazione e test, assicurando un processo di training ottimale.</p>
<div id="vid-train-dev-test" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.1: Train/Dev/Test Sets
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1waHlpKiNyY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="errori-e-insidie-comuni" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="errori-e-insidie-comuni"><span class="header-section-number">7.4.2</span> Errori e Insidie Comuni</h3>
<section id="dati-di-training-insufficienti" class="level4">
<h4 class="anchored" data-anchor-id="dati-di-training-insufficienti">Dati di Training Insufficienti</h4>
<p>Assegnare troppo pochi dati al set di training √® un errore comune quando si suddividono i dati, il che pu√≤ avere un impatto significativo sulle prestazioni del modello. Se il set di training √® troppo piccolo, il modello non avr√† campioni sufficienti per apprendere in modo efficace i veri pattern nei dati. Ci√≤ comporta un‚Äôelevata varianza e impedisce al modello di generalizzare bene ai nuovi dati.</p>
<p>Ad esempio, se si addestra un modello di classificazione delle immagini per riconoscere cifre scritte a mano, fornire solo 10 o 20 immagini per classe di cifre sarebbe del tutto inadeguato. Il modello avrebbe bisogno di pi√π esempi per catturare le ampie varianze negli stili di scrittura, rotazioni, larghezze dei tratti e altre varianti.</p>
<p>Come regola generale, la dimensione del training set dovrebbe essere di almeno centinaia o migliaia di esempi affinch√© la maggior parte degli algoritmi di apprendimento automatico funzioni in modo efficace. A causa dell‚Äôelevato numero di parametri, il set di training spesso deve essere di decine o centinaia di migliaia per le reti neurali profonde, in particolare quelle che utilizzano layer convoluzionali.</p>
<p>Dati di training insufficienti si manifestano in genere in sintomi quali alti tassi di errore su set di validazione/test, bassa accuratezza del modello, alta varianza e overfitting su campioni di set di training di piccole dimensioni. La soluzione √® raccogliere pi√π dati di training di qualit√†. Le tecniche di data augmentation possono anche aiutare ad aumentare virtualmente le dimensioni dei dati di training per immagini, audio, ecc.</p>
<p>√à importante considerare attentamente la complessit√† del modello e la difficolt√† del problema quando si assegnano i campioni di training per garantire che siano disponibili dati sufficienti affinch√© il modello possa apprendere correttamente. Si consiglia inoltre di seguire le linee guida sulle dimensioni minime dei set di training per diversi algoritmi. Sono necessari pi√π dati di training per mantenere il successo complessivo di qualsiasi applicazione di machine learning.</p>
<p>Si consideri <a href="#fig-over-under-fitting" class="quarto-xref">Figura&nbsp;<span>7.4</span></a> dove proviamo a classificare/suddividere i dati in due categorie (qui, per colore): a sinistra, l‚Äôoverfitting √® rappresentato da un modello che ha appreso troppo bene le sfumature nei dati di training (o il set di dati era troppo piccolo o abbiamo eseguito il modello per troppo tempo), facendo s√¨ che segua il rumore insieme al segnale, come indicato dalle eccessive curve della linea. Il lato destro mostra l‚Äôunderfitting, dove la semplicit√† del modello gli impedisce di catturare la struttura sottostante del dataset, con conseguente linea che non si adatta bene ai dati. Il grafico centrale rappresenta un adattamento ideale, dove il modello bilancia bene tra generalizzazione e adattamento, catturando la tendenza principale dei dati senza essere influenzato da valori anomali. Sebbene il modello non sia un adattamento perfetto (manca di alcuni punti), ci interessa di pi√π la sua capacit√† di riconoscere pattern generali piuttosto che valori anomali idiosincratici.</p>
<div id="fig-over-under-fitting" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-over-under-fitting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/fits.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-over-under-fitting-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.4: Adattamento dei dati: overfitting, right fit e underfitting. Fonte: MathWorks.
</figcaption>
</figure>
</div>
<p><a href="#fig-fitting-time" class="quarto-xref">Figura&nbsp;<span>7.5</span></a> il processo di adattamento dei dati nel tempo. Durante l‚Äôaddestramento, cerchiamo il ‚Äúpunto ottimale‚Äù tra underfitting e overfitting. Inizialmente, quando il modello non ha avuto abbastanza tempo per apprendere i pattern nei dati, ci troviamo nella zona di underfitting, indicata da alti tassi di errore sul set di convalida (da ricordare che il modello √® addestrato sul set di addestramento e testiamo la sua generalizzabilit√† sul set di convalida o sui dati che non ha mai visto prima). A un certo punto, raggiungiamo un minimo globale per i tassi di errore e idealmente vogliamo interrompere l‚Äôaddestramento l√¨. Se continuiamo l‚Äôaddestramento, il modello inizier√† a ‚Äúmemorizzare‚Äù o a conoscere i dati troppo bene, tanto che il tasso di errore inizier√† a risalire, poich√© il modello non riuscir√† a generalizzare a dati che non ha mai visto prima.</p>
<div id="fig-fitting-time" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-fitting-time-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/aitrainingfit.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-fitting-time-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.5: Adattamento dei dati nel tempo. Fonte: IBM.
</figcaption>
</figure>
</div>
<p>Il <a href="#vid-bias" class="quarto-xref">Video&nbsp;<span>7.2</span></a> fornisce una panoramica di bias e varianza e la relazione tra i due concetti e l‚Äôaccuratezza del modello.</p>
<div id="vid-bias" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.2: Bias/Varianza
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/SjQyLhQIXSM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
<section id="perdita-di-dati-tra-set" class="level4">
<h4 class="anchored" data-anchor-id="perdita-di-dati-tra-set">Perdita di Dati Tra Set</h4>
<p>Il ‚Äúdata leakage‚Äù [perdita di dati] si riferisce al trasferimento involontario di informazioni tra i set di training, convalida e test. Ci√≤ viola il presupposto fondamentale che le divisioni siano reciprocamente esclusive. La perdita di dati porta a risultati di valutazione seriamente compromessi e metriche di prestazioni gonfiate.</p>
<p>Un modo comune in cui si verifica la perdita di dati √® se alcuni campioni del set di test vengono inavvertitamente inclusi nei dati di training. Quando si valuta il set di test, il modello ha gi√† visto alcuni dati, il che fornisce punteggi eccessivamente ottimistici. Ad esempio, se il 2% dei dati di test trapelano nel set di training di un classificatore binario, pu√≤ comportare un aumento della precisione fino al 20%!</p>
<p>Se le divisioni dei dati non vengono eseguite con attenzione, possono verificarsi forme di perdita pi√π sottili. Se le divisioni non vengono randomizzate e mescolate correttamente, i campioni che sono vicini tra loro nel set di dati potrebbero finire nella stessa divisione, portando a distorsioni della distribuzione. Ci√≤ crea una fuga di informazioni basata sulla prossimit√† nel set di dati.</p>
<p>Un altro caso √® quando i set di dati hanno campioni collegati, intrinsecamente connessi, come grafici, reti o dati di serie temporali. La suddivisione ‚Äúingenua‚Äù pu√≤ isolare nodi o intervalli di tempo connessi in set diversi. I modelli possono fare ipotesi non valide basate su informazioni parziali.</p>
<p>Per prevenire la perdita di dati √® necessario creare una solida separazione tra le suddivisioni: nessun campione dovrebbe esistere in pi√π di una suddivisione. Il mescolamento e la suddivisione randomizzata aiutano a creare divisioni robuste. Le tecniche di ‚Äúcross-validation‚Äù [validazione incrociata] possono essere utilizzate per una valutazione pi√π rigorosa. Rilevare la perdita √® difficile, ma i segnali rivelatori includono modelli che funzionano molto meglio sui dati di test rispetto a quelli di validazione.</p>
<p>La perdita di dati compromette gravemente la validit√† della valutazione perch√© il modello ha gi√† visto parzialmente i dati di test. Nessuna quantit√† di messa a punto o architetture complesse pu√≤ sostituire le suddivisioni nette dei dati. √à meglio essere prudenti e creare una separazione completa tra le suddivisioni per evitare questo errore fondamentale nelle pipeline di machine learning.</p>
</section>
<section id="set-di-validazione-piccolo-o-non-rappresentativo" class="level4">
<h4 class="anchored" data-anchor-id="set-di-validazione-piccolo-o-non-rappresentativo">Set di Validazione Piccolo o Non Rappresentativo</h4>
<p>Il set di validazione viene utilizzato per valutare le prestazioni del modello durante l‚Äôaddestramento e per ottimizzare gli iperparametri. Per valutazioni affidabili e stabili, il set di validazione deve essere sufficientemente ampio e rappresentativo della distribuzione dei dati reali. Tuttavia, ci√≤ pu√≤ rendere pi√π impegnativa la selezione e l‚Äôottimizzazione del modello.</p>
<p>Ad esempio, se il set di validazione contiene solo 100 campioni, le metriche calcolate avranno un‚Äôelevata varianza. A causa del rumore, l‚Äôaccuratezza pu√≤ variare fino al 5-10% tra le epoche. Questo rende difficile sapere se un calo nell‚Äôaccuratezza della validazione √® dovuto a un overfitting o a una varianza naturale. Con un set di validazione pi√π ampio, diciamo 1000 campioni, le metriche saranno molto pi√π stabili.</p>
<p>Inoltre, se il set di validazione non √® rappresentativo, forse mancano alcune sottoclassi, la capacit√† stimata del modello potrebbe essere gonfiata. Ci√≤ potrebbe portare a scelte di iperparametri scadenti o a interruzioni premature dell‚Äôaddestramento. I modelli selezionati in base a tali set di validazione distorti non si generalizzano bene ai dati reali.</p>
<p>Una buona regola pratica √® che la dimensione del set di convalida dovrebbe essere di almeno diverse centinaia di campioni e fino al 10-20% del set di addestramento, lasciando comunque campioni sufficienti per l‚Äôaddestramento. Le divisioni dovrebbero anche essere stratificate, il che significa che le proporzioni di classe nel set di validazione dovrebbero corrispondere a quelle nel set di dati completo, soprattutto se si lavora con set di dati sbilanciati. Un set di validazione pi√π ampio che rappresenti le caratteristiche dei dati originali √® essenziale per una corretta selezione e messa a punto del modello.</p>
</section>
<section id="riutilizzo-del-set-di-test-pi√π-volte" class="level4">
<h4 class="anchored" data-anchor-id="riutilizzo-del-set-di-test-pi√π-volte">Riutilizzo del Set di Test Pi√π Volte</h4>
<p>Il set di test √® progettato per fornire una valutazione imparziale del modello completamente addestrato solo una volta alla fine del processo di sviluppo del modello. Riutilizzare il set di test pi√π volte durante lo sviluppo per la valutazione del modello, la messa a punto degli iperparametri, la selezione del modello, ecc., pu√≤ causare un overfitting sui dati di test. Invece, si deve riservare il set di test per una valutazione finale del modello completamente addestrato, trattandolo come una scatola nera per simularne le prestazioni su dati reali. Questo approccio fornisce metriche affidabili per determinare se il modello √® pronto per la distribuzione in produzione.</p>
<p>Se il set di test viene riutilizzato come parte del processo di validazione, il modello potrebbe iniziare a vedere e imparare dai campioni di test. Questo, insieme all‚Äôottimizzazione intenzionale o meno delle prestazioni del modello sul set di test, pu√≤ gonfiare artificialmente metriche come l‚Äôaccuratezza.</p>
<p>Ad esempio, supponiamo che il set di test venga utilizzato ripetutamente per la selezione del modello su 5 architetture. In tal caso, il modello potrebbe raggiungere il 99% di accuratezza del test memorizzando i campioni anzich√© apprendere pattern generalizzabili. Tuttavia, quando implementati nel mondo reale, l‚Äôaccuratezza dei nuovi dati potrebbe scendere del 60%.</p>
<p>La prassi migliore √® interagire con il set di test solo una volta alla fine per segnalare metriche imparziali su come il modello finale ottimizzato si comporterebbe nel mondo reale. Durante lo sviluppo del modello, il set di convalida dovrebbe essere utilizzato per tutte le attivit√† di ottimizzazione dei parametri, selezione del modello, arresto anticipato e simili. √à importante riservare una parte, come il 20-30% dell‚Äôintero set di dati, esclusivamente per la valutazione finale del modello. Questi dati non dovrebbero essere utilizzati per la convalida, l‚Äôottimizzazione o la selezione del modello durante lo sviluppo.</p>
<p>Non mantenere un set ‚Äúhold-out‚Äù non visto per la convalida finale rischia di ottimizzare i risultati e trascurare potenziali errori prima del rilascio del modello. Avere alcuni dati nuovi fornisce un controllo di integrit√† finale sull‚Äôefficacia nel mondo reale. Mantenere la completa separazione di addestramento/validazione dal set di test √® essenziale per ottenere stime accurate delle prestazioni del modello. Anche piccole deviazioni da un singolo utilizzo del set di test potrebbero falsare positivamente i risultati e le metriche, fornendo una visione eccessivamente ottimistica dell‚Äôefficacia nel mondo reale.</p>
</section>
<section id="stesse-suddivisioni-dei-dati-negli-esperimenti" class="level4">
<h4 class="anchored" data-anchor-id="stesse-suddivisioni-dei-dati-negli-esperimenti">Stesse Suddivisioni dei Dati negli Esperimenti</h4>
<p>Quando si confrontano diversi modelli di machine learning o si sperimentano varie architetture e iperparametri, utilizzare le stesse suddivisioni dei dati per l‚Äôaddestramento, la validazione e il test nei diversi esperimenti pu√≤ introdurre distorsioni e invalidare le comparazioni.</p>
<p>Se le stesse suddivisioni vengono riutilizzate, i risultati della valutazione potrebbero essere pi√π bilanciati e misurare accuratamente quale modello funziona meglio. Ad esempio, una certa suddivisione casuale dei dati potrebbe favorire il modello A rispetto al modello B indipendentemente dagli algoritmi. Riutilizzare questa suddivisione causer√† quindi distorsioni a favore del modello A.</p>
<p>Invece, le suddivisioni dei dati dovrebbero essere randomizzate o mescolate per ogni iterazione sperimentale. Ci√≤ garantisce che la casualit√† nel campionamento delle suddivisioni non conferisca un vantaggio ingiusto a nessun modello.</p>
<p>Con diverse suddivisioni per esperimento, la valutazione diventa pi√π solida. Ogni modello viene testato su un‚Äôampia gamma di set di test estratti casualmente dalla popolazione complessiva, attenuando la variazione e rimuovendo la correlazione tra i risultati.</p>
<p>La prassi corretta √® quella di impostare un ‚Äúseed‚Äù casuale prima di suddividere i dati per ogni esperimento. La suddivisione dovrebbe avvenire dopo il rimescolamento/ricampionamento come parte della pipeline sperimentale. Eseguire confronti sulle stesse suddivisioni viola l‚Äôipotesi i.i.d (indipendenti e identicamente distribuite) richiesta per la validit√† statistica.</p>
<p>Le suddivisioni univoche sono essenziali per confronti di modelli equi. Sebbene richieda un‚Äôelaborazione pi√π intensiva, l‚Äôallocazione randomizzata per esperimento rimuove la distorsione del campionamento e consente un benchmarking valido. Ci√≤ evidenzia le vere differenze nelle prestazioni del modello indipendentemente dalle caratteristiche di una particolare suddivisione.</p>
</section>
<section id="mancata-stratificazione-delle-suddivisioni" class="level4">
<h4 class="anchored" data-anchor-id="mancata-stratificazione-delle-suddivisioni">Mancata Stratificazione delle Suddivisioni</h4>
<p>Quando si suddividono i dati in set di training, validazione e test, la mancata stratificazione delle suddivisioni pu√≤ comportare una rappresentazione non uniforme delle classi target tra le suddivisioni e introdurre un bias di campionamento. Ci√≤ √® particolarmente problematico per i set di dati sbilanciati.</p>
<p>La suddivisione stratificata implica il campionamento dei dati in modo che la proporzione di classi di output sia approssimativamente preservata in ogni suddivisione. Ad esempio, se si esegue una suddivisione training-test 70/30 su un set di dati con campioni negativi al 60% e positivi al 40%, la stratificazione garantisce esempi negativi al ~60% e positivi al ~40% sia nei set di training che nei set di test.</p>
<p>Senza stratificazione, la casualit√† potrebbe comportare che la suddivisione di training abbia campioni positivi al 70% mentre il test ha campioni positivi al 30%. Il modello addestrato su questa distribuzione di training distorta non si generalizzer√† bene. Lo squilibrio delle classi compromette anche le metriche del modello come l‚Äôaccuratezza.</p>
<p>La stratificazione funziona meglio quando viene eseguita utilizzando etichette, sebbene proxy come il clustering possano essere utilizzati per l‚Äôapprendimento non supervisionato. Diventa essenziale per set di dati altamente distorti con classi rare che potrebbero essere facilmente omesse dalle suddivisioni.</p>
<p>Librerie come Scikit-Learn hanno metodi di suddivisione stratificati nativi. Non utilizzarli potrebbe inavvertitamente introdurre bias di campionamento e danneggiare le prestazioni del modello sui gruppi minoritari. Dopo aver eseguito le suddivisioni, il bilanciamento complessivo delle classi dovrebbe essere esaminato per garantire una rappresentazione uniforme tra le suddivisioni.</p>
<p>La stratificazione fornisce un set di dati bilanciato sia per l‚Äôaddestramento del modello che per la valutazione. Sebbene la semplice suddivisione casuale sia facile, tenendo conto delle esigenze di stratificazione, specialmente per dati sbilanciati nel mondo reale, si traduce in uno sviluppo e una valutazione del modello pi√π solidi.</p>
</section>
<section id="ignorare-le-dipendenze-delle-serie-temporali" class="level4">
<h4 class="anchored" data-anchor-id="ignorare-le-dipendenze-delle-serie-temporali">Ignorare le Dipendenze delle Serie Temporali</h4>
<p>I dati delle serie temporali hanno una struttura temporale intrinseca con osservazioni dipendenti dal contesto passato. Suddividere ingenuamente i dati delle serie temporali in set di training e test senza tenere conto di questa dipendenza porta a perdite di dati e bias di lookahead.</p>
<p>Ad esempio, suddividere semplicemente una serie temporale nel primo 70% di training e nell‚Äôultimo 30% come dati di test contaminer√† i dati di training con dati futuri. Il modello pu√≤ usare queste informazioni per ‚Äúsbirciare‚Äù in avanti durante il training.</p>
<p>Ci√≤ si traduce in una valutazione eccessivamente ottimistica delle prestazioni del modello. Il modello pu√≤ sembrare che preveda il futuro in modo accurato, ma in realt√† ha appreso implicitamente in base ai dati futuri, il che non si traduce in prestazioni nel mondo reale.</p>
<p>Dovrebbero essere utilizzate tecniche di validazione incrociata delle serie temporali appropriate, come il concatenamento in avanti, per preservare l‚Äôordine e la dipendenza. Il set di test dovrebbe contenere solo dati da una finestra temporale futura a cui il modello non √® stato esposto per il training.</p>
<p>Non tenere conto delle relazioni temporali porta a ipotesi di causalit√† non valide. Se i dati di training contengono dati futuri, il modello potrebbe anche dover imparare come estrapolare ulteriormente le previsioni.</p>
<p>Mantenere il flusso temporale degli eventi ed evitare il bias di lookahead √® fondamentale per addestrare e testare correttamente i modelli di serie temporali. Ci√≤ garantisce che possano davvero prevedere pattern futuri e non solo memorizzare i dati di training passati.</p>
</section>
<section id="nessun-dato-non-visto-per-la-valutazione-finale" class="level4">
<h4 class="anchored" data-anchor-id="nessun-dato-non-visto-per-la-valutazione-finale">Nessun Dato Non Visto per la Valutazione Finale</h4>
<p>Un errore comune quando si suddividono i dati √® non metterne da parte una porzione solo per la valutazione finale del modello completato. Tutti i dati vengono utilizzati per training, validazione e set di test durante lo sviluppo.</p>
<p>Questo non lascia dati non visti per ottenere una stima imparziale di come il modello finale ottimizzato si comporterebbe nel mondo reale. Le metriche sul set di test utilizzate durante lo sviluppo potrebbero riflettere solo parzialmente le reali capacit√† del modello.</p>
<p>Ad esempio, scelte come l‚Äôarresto anticipato e l‚Äôottimizzazione degli iperparametri sono spesso ottimizzate in base alle prestazioni del set di test. Questo accoppia il modello ai dati di test. √à necessario un set di dati non visto per interrompere questo accoppiamento e ottenere metriche reali del mondo reale.</p>
<p>La ‚Äúbest practice‚Äù √® quella di riservare una parte, come il 20-30% del set di dati completo, esclusivamente per la valutazione finale del modello. Questi dati non dovrebbero essere utilizzati per la convalida, l‚Äôottimizzazione o la selezione del modello durante lo sviluppo.</p>
<p>Il salvataggio di alcuni dati non visti consente di valutare il modello completamente addestrato come una scatola nera su dati del mondo reale. Questo fornisce metriche affidabili per decidere se il modello √® pronto per la distribuzione in produzione.</p>
<p>Non mantenere un set ‚Äúhold-out‚Äù non visto per la convalida finale rischia di ottimizzare i risultati e trascurare potenziali errori prima del rilascio del modello. Avere alcuni dati nuovi fornisce un controllo di integrit√† finale sull‚Äôefficacia nel mondo reale.</p>
</section>
<section id="sovra-ottimizzazione-del-set-di-validazione" class="level4">
<h4 class="anchored" data-anchor-id="sovra-ottimizzazione-del-set-di-validazione">Sovra-ottimizzazione del Set di Validazione</h4>
<p>Il set di validazione √® pensato per guidare il processo di training del modello, non per fungere da dati di training aggiuntivi. L‚Äôeccessiva ottimizzazione del set di validazione per massimizzare le metriche delle prestazioni lo tratta pi√π come un set di training secondario, portando a metriche gonfiate e scarsa generalizzazione.</p>
<p>Ad esempio, tecniche come l‚Äôottimizzazione estensiva degli iperparametri o l‚Äôaggiunta di incrementi di dati mirati a migliorare l‚Äôaccuratezza della convalida possono far s√¨ che il modello si adatti troppo ai dati di validazione. Il modello pu√≤ raggiungere un‚Äôaccuratezza di validazione del 99% ma solo un‚Äôaccuratezza di test del 55%.</p>
<p>Analogamente, riutilizzare il set di validazione per un arresto anticipato pu√≤ anche ottimizzare il modello specificamente per quei dati. L‚Äôarresto alle migliori prestazioni di validazione sovra-adatta il rumore e le fluttuazioni causate dalle piccole dimensioni di validazione.</p>
<p>Il set di validazione funge da proxy per ottimizzare e selezionare i modelli. Tuttavia, l‚Äôobiettivo rimane massimizzare le prestazioni dei dati del mondo reale, non il set di validazione. Ridurre al minimo la perdita o l‚Äôerrore sui dati di validazione non si traduce automaticamente in una buona generalizzazione.</p>
<p>Un buon approccio √® quello di mantenere l‚Äôuso del set di validazione al minimo: gli iperparametri possono essere regolati grossolanamente prima sui dati di training, ad esempio. Il set di validazione guida il training ma non dovrebbe influenzare o alterare il modello stesso. √à uno strumento diagnostico, non di ottimizzazione.</p>
<p>Quando si valutano le prestazioni sul set di validazione, bisogna fare attenzione a non sovra-adattare. Sono necessari dei compromessi per costruire modelli che funzionino bene sulla popolazione complessiva e non siano eccessivamente regolati sui campioni di validazione.</p>
</section>
</section>
</section>
<section id="algoritmi-di-ottimizzazione" class="level2 page-columns page-full" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="algoritmi-di-ottimizzazione"><span class="header-section-number">7.5</span> Algoritmi di Ottimizzazione</h2>
<p>Stochastic gradient descent (SGD) √® un algoritmo di ottimizzazione semplice ma potente per l‚Äôaddestramento di modelli di machine learning. Funziona stimando il gradiente della funzione di perdita relativa ai parametri del modello utilizzando un singolo esempio di addestramento e poi aggiornando i parametri nella direzione che riduce la perdita.</p>
<p>Sebbene concettualmente semplice, SGD necessita di alcune aree di miglioramento. Innanzitutto, scegliere un tasso di apprendimento appropriato pu√≤ essere difficile: troppo piccolo e i progressi sono molto lenti; troppo grande e i parametri possono oscillare e non convergere. In secondo luogo, SGD tratta tutti i parametri in modo uguale e indipendente, il che potrebbe non essere l‚Äôideale in tutti i casi. Infine, SGD vanilla [standard] utilizza solo informazioni sul gradiente di primo ordine, il che si traduce in progressi lenti su problemi mal condizionati.</p>
<section id="ottimizzazioni" class="level3 page-columns page-full" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="ottimizzazioni"><span class="header-section-number">7.5.1</span> Ottimizzazioni</h3>
<p>Nel corso degli anni, sono state proposte varie ottimizzazioni per accelerare e migliorare l‚ÄôSGD vanilla. <span class="citation" data-cites="ruder2016overview">Ruder (<a href="../../../references.it.html#ref-ruder2016overview" role="doc-biblioref">2016</a>)</span> fornisce un‚Äôeccellente panoramica dei diversi ottimizzatori. In breve, diverse tecniche di ottimizzazione SGD comunemente utilizzate includono:</p>
<div class="no-row-height column-margin column-container"><div id="ref-ruder2016overview" class="csl-entry" role="listitem">
Ruder, Sebastian. 2016. <span>¬´An overview of gradient descent optimization algorithms¬ª</span>. <em>ArXiv preprint</em> abs/1609.04747 (settembre). <a href="http://arxiv.org/abs/1609.04747v2">http://arxiv.org/abs/1609.04747v2</a>.
</div></div><p><strong>Momentum:</strong> Accumula un vettore di velocit√† in direzioni di gradiente persistente attraverso le iterazioni. Ci√≤ aiuta ad accelerare i progressi smorzando le oscillazioni e mantiene i progressi in direzioni coerenti.</p>
<p><strong>Nesterov Accelerated Gradient (NAG):</strong> Una variante di momentum che calcola i gradienti in ‚Äúlook ahead‚Äù anzich√© nella posizione del parametro corrente. Questo aggiornamento anticipatorio impedisce l‚Äôovershooting mentre il momentum mantiene il progresso accelerato.</p>
<p><strong>Adagrad:</strong> Un algoritmo di velocit√† di apprendimento adattivo che mantiene una velocit√† di apprendimento per parametro ridotta proporzionalmente alla somma storica dei gradienti di ciascun parametro. Aiuta a eliminare la necessit√† di regolare manualmente i tassi di apprendimento <span class="citation" data-cites="john2010adaptive">(<a href="../../../references.it.html#ref-john2010adaptive" role="doc-biblioref">Duchi, Hazan, e Singer 2010</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-john2010adaptive" class="csl-entry" role="listitem">
Duchi, John C., Elad Hazan, e Yoram Singer. 2010. <span>¬´Adaptive Subgradient Methods for Online Learning and Stochastic Optimization¬ª</span>. In <em>COLT 2010 - The 23rd Conference on Learning Theory, Haifa, Israel, June 27-29, 2010</em>, a cura di Adam Tauman Kalai e Mehryar Mohri, 257‚Äì69. Omnipress. <a href="http://colt2010.haifa.il.ibm.com/papers/COLT2010proceedings.pdf#page=265">http://colt2010.haifa.il.ibm.com/papers/COLT2010proceedings.pdf#page=265</a>.
</div><div id="ref-zeiler2012reinforcement" class="csl-entry" role="listitem">
Zeiler, Matthew D. 2012. <span>¬´ADADELTA: An Adaptive Learning Rate Method¬ª</span>, dicembre, 119‚Äì49. <a href="https://doi.org/10.1002/9781118266502.ch6">https://doi.org/10.1002/9781118266502.ch6</a>.
</div></div><p><strong>Adadelta:</strong> Una modifica ad Adagrad limita la finestra dei gradienti passati accumulati, riducendo cos√¨ il decadimento aggressivo dei tassi di apprendimento <span class="citation" data-cites="zeiler2012reinforcement">(<a href="../../../references.it.html#ref-zeiler2012reinforcement" role="doc-biblioref">Zeiler 2012</a>)</span>.</p>
<p><strong>RMSProp:</strong> Divide il tasso di apprendimento per una media esponenzialmente decrescente dei gradienti quadrati. Ci√≤ ha un effetto di normalizzazione simile ad Adagrad ma non accumula i gradienti nel tempo, evitando un rapido decadimento dei tassi di apprendimento <span class="citation" data-cites="hinton2017overview">(<a href="../../../references.it.html#ref-hinton2017overview" role="doc-biblioref">Hinton 2017</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-hinton2017overview" class="csl-entry" role="listitem">
Hinton, Geoffrey. 2017. <span>¬´Overview of Minibatch Gradient Descent¬ª</span>. University of Toronto; University Lecture.
</div><div id="ref-diederik2015adam" class="csl-entry" role="listitem">
Kingma, Diederik P., e Jimmy Ba. 2014. <span>¬´Adam: A Method for Stochastic Optimization¬ª</span>. A cura di Yoshua Bengio e Yann LeCun, dicembre. <a href="http://arxiv.org/abs/1412.6980v9">http://arxiv.org/abs/1412.6980v9</a>.
</div></div><p><strong>Adam:</strong> Combinazione di momentum e rmsprop dove rmsprop modifica il tasso di apprendimento in base alla media delle recenti ampiezze dei gradienti. Mostra un progresso iniziale molto rapido e regola automaticamente le dimensioni dei passi <span class="citation" data-cites="diederik2015adam">(<a href="../../../references.it.html#ref-diederik2015adam" role="doc-biblioref">Kingma e Ba 2014</a>)</span>.</p>
<p><strong>AMSGrad:</strong> Una variante di Adam che assicura una convergenza stabile mantenendo il massimo dei gradienti quadratici passati, impedendo al tasso di apprendimento di aumentare durante l‚Äôaddestramento <span class="citation" data-cites="reddi2019convergence">(<a href="../../../references.it.html#ref-reddi2019convergence" role="doc-biblioref">Reddi, Kale, e Kumar 2019</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-reddi2019convergence" class="csl-entry" role="listitem">
Reddi, Sashank J., Satyen Kale, e Sanjiv Kumar. 2019. <span>¬´On the Convergence of Adam and Beyond¬ª</span>. <em>arXiv preprint arXiv:1904.09237</em>, aprile. <a href="http://arxiv.org/abs/1904.09237v1">http://arxiv.org/abs/1904.09237v1</a>.
</div></div><p>Tra questi metodi, Adam √® ampiamente considerato l‚Äôalgoritmo di ottimizzazione di riferimento per molte attivit√† di deep-learning. Supera costantemente SGD vanilla in termini di velocit√† di addestramento e prestazioni. Altri ottimizzatori potrebbero essere pi√π adatti in alcuni casi, in particolare per modelli pi√π semplici.</p>
</section>
<section id="compromessi" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="compromessi"><span class="header-section-number">7.5.2</span> Compromessi</h3>
<p><a href="#tbl-optim-algos" class="quarto-xref">Tabella&nbsp;<span>7.2</span></a> √® una tabella di pro e contro per alcuni dei principali algoritmi di ottimizzazione per l‚Äôaddestramento di reti neurali:</p>
<div id="tbl-optim-algos" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-optim-algos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;7.2: Confronto dei pro e dei contro di diversi algoritmi di ottimizzazione.
</figcaption>
<div aria-describedby="tbl-optim-algos-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 39%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Algoritmo</th>
<th style="text-align: left;">Pro</th>
<th style="text-align: left;">Contro</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Momentum</td>
<td style="text-align: left;"><ul>
<li>Convergenza pi√π rapida dovuta all‚Äôaccelerazione lungo i gradienti</li>
<li>Minore oscillazione rispetto a SGD vanilla</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Richiede la messa a punto del parametro momentum</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Nesterov Accelerated Gradient (NAG)</td>
<td style="text-align: left;"><ul>
<li>Pi√π veloce dello slancio standard in alcuni casi</li>
<li>Gli aggiornamenti anticipati impediscono il superamento</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Pi√π complesso da comprendere intuitivamente</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Adagrad</td>
<td style="text-align: left;"><ul>
<li>Elimina la necessit√† di regolare manualmente i tassi di apprendimento</li>
<li>Funziona bene su gradienti radi</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Il tasso di apprendimento potrebbe decadere troppo rapidamente su gradienti densi</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Adadelta</td>
<td style="text-align: left;"><ul>
<li>Decadimento del tasso di apprendimento meno aggressivo rispetto ad Adagrad</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Ancora sensibile al valore iniziale del tasso di apprendimento</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">RMSProp</td>
<td style="text-align: left;"><ul>
<li>Regola automaticamente i tassi di apprendimento</li>
<li>Funziona bene nella pratica</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Nessun aspetto negativo importante</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Adam</td>
<td style="text-align: left;"><ul>
<li>Combinazione di momentum e tassi di apprendimento adattivo</li>
<li>Convergenza efficiente e veloce</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Prestazioni di generalizzazione leggermente peggiori in alcuni casi</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">AMSGrad</td>
<td style="text-align: left;"><ul>
<li>Miglioramento di Adam che affronta il problema della generalizzazione</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Non √® stato utilizzato/testato cos√¨ ampiamente come Adam</li>
</ul></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="algoritmi-di-benchmarking" class="level3 page-columns page-full" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="algoritmi-di-benchmarking"><span class="header-section-number">7.5.3</span> Algoritmi di Benchmarking</h3>
<p>Non esiste un singolo metodo migliore per tutti i tipi di problemi. Ci√≤ significa che abbiamo bisogno di un benchmarking completo per identificare l‚Äôottimizzatore pi√π efficace per set di dati e modelli specifici. Le prestazioni di algoritmi come Adam, RMSProp e Momentum variano a seconda delle dimensioni del batch, dei programmi di apprendimento, dell‚Äôarchitettura del modello, della distribuzione dei dati e della regolarizzazione. Queste variazioni sottolineano l‚Äôimportanza di valutare ogni ottimizzatore in diverse condizioni.</p>
<p>Prendiamo ad esempio Adam, che spesso eccelle nelle attivit√† di visione artificiale, a differenza di RMSProp, che potrebbe mostrare una migliore generalizzazione in determinate attivit√† di elaborazione del linguaggio naturale. La forza di Momentum risiede nella sua accelerazione in scenari con direzioni di gradiente coerenti, mentre i tassi di apprendimento adattivo di Adagrad sono pi√π adatti per problemi di gradiente sparso.</p>
<p>Questa vasta gamma di interazioni tra ottimizzatori dimostra la difficolt√† di dichiarare un singolo algoritmo universalmente superiore. Ogni ottimizzatore ha punti di forza unici, rendendo fondamentale valutare vari metodi per scoprire empiricamente le loro condizioni di applicazione ottimali.</p>
<p>Un approccio di benchmarking completo dovrebbe valutare la velocit√† di convergenza e fattori come errore di generalizzazione, stabilit√†, sensibilit√† degli iperparametri ed efficienza computazionale, tra gli altri. Ci√≤ comporta il monitoraggio delle curve di apprendimento di training e convalida su pi√π esecuzioni e il confronto degli ottimizzatori su vari set di dati e modelli per comprenderne i punti di forza e di debolezza.</p>
<p>AlgoPerf, introdotto da <span class="citation" data-cites="dahl2023benchmarking">D√ºrr et al. (<a href="../../../references.it.html#ref-dahl2023benchmarking" role="doc-biblioref">2021</a>)</span>, risponde alla necessit√† di un sistema di benchmarking robusto. Questa piattaforma valuta le prestazioni dell‚Äôottimizzatore utilizzando criteri quali curve di loss [perdita] di training, errore di generalizzazione, sensibilit√† agli iperparametri ed efficienza computazionale. AlgoPerf testa vari metodi di ottimizzazione, tra cui Adam, LAMB e Adafactor, su diversi tipi di modelli come CNN e RNN/LSTM su set di dati stabiliti. Utilizza la ‚Äúcontainerizzazione‚Äù e la raccolta automatica di metriche per ridurre al minimo le incongruenze e consente esperimenti controllati su migliaia di configurazioni, fornendo una base affidabile per confrontare gli ottimizzatori.</p>
<div class="no-row-height column-margin column-container"><div id="ref-dahl2023benchmarking" class="csl-entry" role="listitem">
D√ºrr, Marc, Gunnar Nissen, Kurt-Wolfram S√ºhs, Philipp Schwenkenbecher, Christian Geis, Marius Ringelstein, Hans-Peter Hartung, et al. 2021. <span>¬´CSF Findings in Acute NMDAR and LGI1 Antibody‚ÄìAssociated Autoimmune Encephalitis¬ª</span>. <em>Neurology Neuroimmunology &amp;amp; Neuroinflammation</em> 8 (6). <a href="https://doi.org/10.1212/nxi.0000000000001086">https://doi.org/10.1212/nxi.0000000000001086</a>.
</div></div><p>Le informazioni ottenute da AlgoPerf e benchmark simili sono inestimabili per guidare la scelta ottimale o la messa a punto degli ottimizzatori. Abilitando valutazioni riproducibili, questi benchmark contribuiscono a una comprensione pi√π approfondita delle prestazioni di ciascun ottimizzatore, aprendo la strada a innovazioni future e progressi accelerati nel settore.</p>
</section>
</section>
<section id="ottimizzazione-degli-iperparametri" class="level2 page-columns page-full" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="ottimizzazione-degli-iperparametri"><span class="header-section-number">7.6</span> Ottimizzazione degli Iperparametri</h2>
<p>Gli iperparametri sono impostazioni importanti nei modelli di machine learning che incidono notevolmente sulle prestazioni finali dei modelli. A differenza di altri parametri del modello che vengono appresi durante l‚Äôaddestramento, gli iperparametri vengono specificati dai ‚Äúdata scientist‚Äù o dagli ingegneri del machine learning prima dell‚Äôaddestramento del modello.</p>
<p>La scelta dei valori degli iperparametri corretti consente ai modelli di apprendere pattern dai dati in modo efficace. Alcuni esempi di iperparametri chiave negli algoritmi di apprendimento automatico includono:</p>
<ul>
<li><strong>Reti neurali:</strong> Velocit√† di apprendimento, dimensione del batch, numero di unit√† nascoste, funzioni di attivazione</li>
<li><strong>Macchine a vettori di supporto:</strong> Forza di regolarizzazione, tipo di kernel e parametri</li>
<li><strong>Random forest:</strong> Numero di alberi, profondit√† dell‚Äôalbero</li>
<li><strong>K-means:</strong> Numero di cluster</li>
</ul>
<p>Il problema √® che non ci sono regole pratiche affidabili per scegliere configurazioni ottimali degli iperparametri: in genere si devono provare valori diversi e valutare le prestazioni. Questo processo √® chiamato ‚Äúhyperparameter tuning‚Äù <a href="#ottimizzazione-degli-iperparametri">ottimizzazione degli iperparametri</a>.</p>
<p>Nei primi anni del moderno deep learning, i ricercatori erano ancora alle prese con problemi di convergenza instabile e lenta. I punti dolenti comuni includevano perdite di training che fluttuavano selvaggiamente, gradienti che esplodevano o svanivano e un‚Äôampia serie di tentativi ed errori necessari per addestrare le reti in modo affidabile. Di conseguenza, un punto focale iniziale era l‚Äôutilizzo di iperparametri per controllare l‚Äôottimizzazione del modello. Ad esempio, tecniche seminali come la normalizzazione batch consentivano una convergenza pi√π rapida del modello regolando gli aspetti dello spostamento interno delle covariate. I metodi di velocit√† di apprendimento adattivo hanno anche mitigato la necessit√† di estese pianificazioni manuali. Questi affrontavano problemi di ottimizzazione durante l‚Äôaddestramento, come la divergenza incontrollata del gradiente. Le velocit√† di apprendimento adattate con attenzione sono anche il fattore di controllo primario per ottenere una convergenza rapida e stabile anche oggi.</p>
<p>Con l‚Äôespansione esponenziale della capacit√† computazionale negli anni successivi, modelli molto pi√π grandi potevano essere addestrati senza cadere preda di problemi di pura ottimizzazione numerica. L‚Äôattenzione si √® spostata verso la generalizzazione, sebbene una convergenza efficiente fosse un prerequisito fondamentale. Tecniche all‚Äôavanguardia come ‚ÄúTransformers‚Äù hanno introdotto miliardi di parametri. A tali dimensioni, gli iperparametri relativi a capacit√†, regolarizzazione, ensembling [raggruppamento], ecc., hanno assunto un ruolo centrale per la messa a punto, anzich√© solo le metriche di convergenza grezze.</p>
<p>La lezione √® che comprendere l‚Äôaccelerazione e la stabilit√† del processo di ottimizzazione stesso costituisce il lavoro di base. Schemi di inizializzazione, dimensioni dei batch, decadimenti di peso e altri iperparametri di training rimangono indispensabili oggi. Dominare una convergenza rapida e impeccabile consente ai professionisti di espandere la propria attenzione sulle esigenze emergenti relative alla messa a punto di parametri quali accuratezza, robustezza ed efficienza su larga scala.</p>
<section id="algoritmi-di-ricerca" class="level3 page-columns page-full" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="algoritmi-di-ricerca"><span class="header-section-number">7.6.1</span> Algoritmi di Ricerca</h3>
<p>Quando si tratta del processo critico di ottimizzazione degli iperparametri, ci sono diversi algoritmi sofisticati su cui gli specialisti del machine learning si affidano per cercare sistematicamente nel vasto spazio di possibili configurazioni dei modelli. Alcuni degli algoritmi di ricerca degli iperparametri pi√π importanti includono:</p>
<ul>
<li><p><strong>Grid Search:</strong> Il metodo di ricerca pi√π elementare, in cui si definisce manualmente una griglia di valori da controllare per ogni iperparametro. Ad esempio, controllando <code>velocit√† di apprendimento = [0.01, 0.1, 1]</code> e <code>dimensioni batch = [32, 64, 128]</code>. Il vantaggio principale √® la semplicit√†, ma pu√≤ portare a un‚Äôesplosione esponenziale nello spazio di ricerca, rendendolo dispendioso in termini di tempo. √à pi√π adatto per l‚Äôottimizzazione di un piccolo numero di parametri.</p></li>
<li><p><strong>Random Search:</strong> Invece di definire una griglia, si selezionano casualmente valori per ogni iperparametro da un intervallo o set predefinito. Questo metodo √® pi√π efficiente nell‚Äôesplorazione di un vasto spazio di iperparametri perch√© non richiede una ricerca esaustiva. Tuttavia, potrebbe comunque non trovare parametri ottimali poich√© non esplora sistematicamente tutte le possibili combinazioni.</p></li>
<li><p><strong>Bayesian Optimization:</strong> Questo √® un approccio probabilistico avanzato per l‚Äôesplorazione adattiva basato su una funzione surrogata per modellare le prestazioni su iterazioni. √à semplice ed efficiente: trova iperparametri altamente ottimizzati in meno passaggi di valutazione. Tuttavia, richiede un maggiore investimento nella configurazione <span class="citation" data-cites="jasper2012practical">(<a href="../../../references.it.html#ref-jasper2012practical" role="doc-biblioref">Snoek, Larochelle, e Adams 2012</a>)</span>.</p></li>
<li><p><strong>Evolutionary Algorithms:</strong> Questi algoritmi imitano i principi della selezione naturale. Generano popolazioni di combinazioni di iperparametri e le evolvono nel tempo in base alle prestazioni. Questi algoritmi offrono solide capacit√† di ricerca pi√π adatte per superfici di risposta complesse. Tuttavia, sono necessarie molte iterazioni per una convergenza ragionevole.</p></li>
<li><p><strong>Population Based Training (PBT):</strong> Un metodo che ottimizza gli iperparametri addestrando pi√π modelli in parallelo, consentendo loro di condividere e adattare configurazioni di successo durante l‚Äôaddestramento, combinando elementi di ricerca casuale e algoritmi evolutivi <span class="citation" data-cites="jaderberg2017population">(<a href="../../../references.it.html#ref-jaderberg2017population" role="doc-biblioref">Jaderberg et al. 2017</a>)</span>.</p></li>
<li><p><strong>Neural Architecture Search:</strong> Un approccio alla progettazione di architetture ad alte prestazioni per reti neurali. Tradizionalmente, gli approcci NAS utilizzano una qualche forma di apprendimento di rinforzo per proporre architetture di reti neurali, che vengono poi ripetutamente valutate <span class="citation" data-cites="zoph2023cybernetical">(<a href="../../../references.it.html#ref-zoph2023cybernetical" role="doc-biblioref">Zoph e Le 2016</a>)</span>.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="ref-jasper2012practical" class="csl-entry" role="listitem">
Snoek, Jasper, Hugo Larochelle, e Ryan P. Adams. 2012. <span>¬´Practical Bayesian Optimization of Machine Learning Algorithms¬ª</span>. In <em>Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States</em>, a cura di Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, L√©on Bottou, e Kilian Q. Weinberger, 2960‚Äì68. <a href="https://proceedings.neurips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html">https://proceedings.neurips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html</a>.
</div><div id="ref-jaderberg2017population" class="csl-entry" role="listitem">
Jaderberg, Max, Valentin Dalibard, Simon Osindero, Wojciech M. Czarnecki, Jeff Donahue, Ali Razavi, Oriol Vinyals, et al. 2017. <span>¬´Population Based Training of Neural Networks¬ª</span>. <em>arXiv preprint arXiv:1711.09846</em>, novembre. <a href="http://arxiv.org/abs/1711.09846v2">http://arxiv.org/abs/1711.09846v2</a>.
</div><div id="ref-zoph2023cybernetical" class="csl-entry" role="listitem">
Zoph, Barret, e Quoc V. Le. 2016. <span>¬´Neural Architecture Search with Reinforcement Learning¬ª</span>, novembre, 367‚Äì92. <a href="https://doi.org/10.1002/9781394217519.ch17">https://doi.org/10.1002/9781394217519.ch17</a>.
</div></div></section>
<section id="implicazioni-di-sistema" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="implicazioni-di-sistema"><span class="header-section-number">7.6.2</span> Implicazioni di Sistema</h3>
<p>La messa a punto degli iperparametri pu√≤ avere un impatto significativo sul tempo di convergenza durante l‚Äôaddestramento del modello, influenzando direttamente il runtime complessivo. I valori corretti per gli iperparametri chiave di training sono cruciali per un‚Äôefficiente convergenza del modello. Ad esempio, la velocit√† di apprendimento dell‚Äôiperparametro controlla la dimensione del passo durante l‚Äôottimizzazione della discesa del gradiente. Impostando correttamente uno scheduling della velocit√† di apprendimento assicura che l‚Äôalgoritmo di ottimizzazione converga rapidamente verso un buon minimo. Una velocit√† di apprendimento troppo bassa porta a una convergenza dolorosamente lenta, mentre un valore troppo grande causa una fluttuazione selvaggia delle perdite. Una messa a punto corretta assicura un rapido movimento verso pesi e bias ottimali.</p>
<p>Analogamente, la dimensione del batch per la discesa del gradiente stocastica influisce sulla stabilit√† della convergenza. La giusta dimensione del batch attenua le fluttuazioni negli aggiornamenti dei parametri per avvicinarsi pi√π rapidamente al minimo. Sono necessarie pi√π dimensioni del batch per evitare una convergenza rumorosa, mentre le dimensioni maggiori del batch non riescono a generalizzare e rallentano la convergenza a causa di aggiornamenti dei parametri meno frequenti. La messa a punto degli iperparametri per una convergenza pi√π rapida e una durata di addestramento ridotta ha implicazioni dirette sui costi e sui requisiti di risorse per il ridimensionamento dei sistemi di machine learning:</p>
<ul>
<li><p><strong>Costi computazionali inferiori:</strong> Tempi di convergenza pi√π brevi significano costi computazionali inferiori per i modelli di training. Il training ML sfrutta spesso grandi istanze di cloud computing come cluster GPU e TPU che comportano pesanti costi orari. Ridurre al minimo i tempi di training riduce direttamente questo costo di noleggio delle risorse, che tende a dominare i budget ML per le organizzazioni. Un‚Äôiterazione pi√π rapida consente inoltre agli esperti di dati di sperimentare pi√π liberamente all‚Äôinterno dello stesso budget.</p></li>
<li><p><strong>Tempo di training ridotto:</strong> Un tempo di training ridotto sblocca opportunit√† per addestrare pi√π modelli utilizzando lo stesso budget computazionale. Gli iperparametri ottimizzati estendono ulteriormente le risorse disponibili, consentendo alle aziende di sviluppare e sperimentare pi√π modelli con vincoli di risorse per massimizzare le prestazioni.</p></li>
<li><p><strong>Efficienza delle risorse:</strong> Un training pi√π rapido consente di allocare istanze di calcolo pi√π piccole nel cloud poich√© i modelli richiedono l‚Äôaccesso alle risorse per una durata pi√π breve. Ad esempio, un job di training di un‚Äôora consente di utilizzare istanze GPU meno potenti rispetto a un training di pi√π ore, che richiede un accesso di elaborazione sostenuto su intervalli pi√π lunghi. Ci√≤ consente di risparmiare sui costi, soprattutto per carichi di lavoro di grandi dimensioni.</p></li>
</ul>
<p>Ci sono anche altri vantaggi. Ad esempio, una convergenza pi√π rapida riduce la pressione sui team di ingegneria ML in merito al provisioning delle risorse di training. Le semplici routine di riaddestramento del modello possono utilizzare risorse meno potenti anzich√© richiedere l‚Äôaccesso a code ad alta priorit√† per cluster GPU di livello di produzione vincolati, liberando risorse di distribuzione per altre applicazioni.</p>
</section>
<section id="gli-auto-tuner" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="gli-auto-tuner"><span class="header-section-number">7.6.3</span> Gli Auto Tuner</h3>
<p>Data la sua importanza, esiste un‚Äôampia gamma di offerte commerciali per aiutare con l‚Äôottimizzazione degli iperparametri. Toccheremo brevemente due esempi: uno incentrato sull‚Äôottimizzazione per ML su scala cloud e l‚Äôaltro per modelli di apprendimento automatico mirati ai microcontrollori. <a href="#tbl-platform-comparison" class="quarto-xref">Tabella&nbsp;<span>7.3</span></a> delinea le principali differenze:</p>
<div id="tbl-platform-comparison" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-platform-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;7.3: Confronto di piattaforme di ottimizzazione per diversi casi d‚Äôuso di machine learning.
</figcaption>
<div aria-describedby="tbl-platform-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 13%">
<col style="width: 15%">
<col style="width: 21%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Piattaforma</th>
<th style="text-align: left;">Caso d‚ÄôUso Target</th>
<th style="text-align: left;">Tecniche di ottimizzazione</th>
<th style="text-align: left;">Vantaggi</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Vertex AI di Google</td>
<td style="text-align: left;">Apprendimento automatico su scala cloud</td>
<td style="text-align: left;">Ottimizzazione bayesiana, addestramento Population-Based</td>
<td style="text-align: left;">Nasconde la complessit√†, consentendo modelli rapidi e pronti per l‚Äôimplementazione con ottimizzazione iperparametrica all‚Äôavanguardia</td>
</tr>
<tr class="even">
<td style="text-align: left;">EON Tuner di Edge Impulse</td>
<td style="text-align: left;">Modelli di microcontrollori (TinyML)</td>
<td style="text-align: left;">Ottimizzazione bayesiana</td>
<td style="text-align: left;">Adatta i modelli per dispositivi con risorse limitate, semplifica l‚Äôottimizzazione per l‚Äôimplementazione embedded</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<section id="bigml" class="level4">
<h4 class="anchored" data-anchor-id="bigml">BigML</h4>
<p>Sono disponibili diverse piattaforme commerciali di auto-tuning per risolvere questo problema. Una soluzione √® Vertex AI Cloud di Google, che offre un ampio supporto integrato per tecniche di ottimizzazione all‚Äôavanguardia.</p>
<p>Una delle funzionalit√† pi√π importanti della piattaforma di apprendimento automatico gestita da Vertex AI di Google √® l‚Äôottimizzazione efficiente e integrata degli iperparametri per lo sviluppo del modello. Per addestrare con successo modelli ML performanti √® necessario identificare configurazioni ottimali per un set di iperparametri esterni che determinano il comportamento del modello, ponendo un problema di ricerca ad alta dimensione impegnativo. Vertex AI semplifica questo processo tramite strumenti di Automated Machine Learning (AutoML).</p>
<p>In particolare, gli scienziati dei dati possono sfruttare i motori di ottimizzazione degli iperparametri di Vertex AI fornendo un set di dati etichettato e scegliendo un tipo di modello come un classificatore di reti neurali o Random Forest. Vertex avvia un job di ‚ÄúHyperparameter Search‚Äù in modo trasparente sul backend, gestendo completamente il provisioning delle risorse, l‚Äôaddestramento del modello, il monitoraggio delle metriche e l‚Äôanalisi dei risultati automaticamente utilizzando algoritmi di ottimizzazione avanzati.</p>
<p>Internamente, Vertex AutoML impiega varie strategie di ricerca per esplorare in modo intelligente le configurazioni di iperparametri pi√π promettenti in base ai risultati delle valutazioni precedenti. Tra queste, l‚Äôottimizzazione bayesiana √® offerta in quanto fornisce un‚Äôefficienza di campionamento superiore, richiedendo meno iterazioni di training per ottenere una qualit√† del modello ottimizzata rispetto ai metodi standard di Grid Search o di Random Search. Per spazi di ricerca di architettura neurale pi√π complessi, Vertex AutoML utilizza il Population-Based Training, che addestra simultaneamente pi√π modelli e regola dinamicamente i loro iperparametri sfruttando le prestazioni di altri modelli nella popolazione, analogamente ai principi di selezione naturale.</p>
<p>Vertex AI democratizza le tecniche di ricerca di iperparametri all‚Äôavanguardia su scala cloud per tutti gli sviluppatori ML, astraendo la complessit√† di esecuzione e di orchestrazione sottostante. Gli utenti si concentrano esclusivamente sul loro set di dati, sui requisiti del modello e sugli obiettivi di accuratezza, mentre Vertex gestisce il ciclo di ottimizzazione, l‚Äôallocazione delle risorse, il training del modello, il monitoraggio dell‚Äôaccuratezza e l‚Äôarchiviazione degli artefatti internamente. Il risultato √® ottenere modelli ML ottimizzati e pronti per la distribuzione pi√π velocemente per il problema target.</p>
</section>
<section id="tinyml" class="level4">
<h4 class="anchored" data-anchor-id="tinyml">TinyML</h4>
<p>Edge Impulse‚Äôs Efficient On-device Neural Network Tuner (EON Tuner) √® uno strumento di ottimizzazione automatizzata degli iperparametri progettato per sviluppare modelli di apprendimento automatico per microcontrollori. Semplifica il processo di sviluppo del modello trovando automaticamente la migliore configurazione di rete neurale per un‚Äôimplementazione efficiente e accurata su dispositivi con risorse limitate.</p>
<p>La funzionalit√† chiave di EON Tuner √® la seguente. Innanzitutto, gli sviluppatori definiscono gli iperparametri del modello, come numero di layer, nodi per layer, funzioni di attivazione e pianificazione della velocit√† di ‚Äúannealing‚Äù [https://it.wikipedia.org/wiki/Ricottura_simulata] dell‚Äôapprendimento. Questi parametri costituiscono lo spazio di ricerca che verr√† ottimizzato. Successivamente, viene selezionata la piattaforma del microcontrollore target, fornendo vincoli hardware embedded. L‚Äôutente pu√≤ anche specificare obiettivi di ottimizzazione, come la riduzione dell‚Äôingombro di memoria, la riduzione della latenza, la riduzione del consumo energetico o la massimizzazione della precisione.</p>
<p>Con lo spazio di ricerca definito e gli obiettivi di ottimizzazione, EON Tuner sfrutta l‚Äôottimizzazione degli iperparametri bayesiani per esplorare in modo intelligente possibili configurazioni. Ogni configurazione potenziale viene automaticamente implementata come specifica di modello completa, addestrata e valutata per metriche di qualit√†. Il processo continuo bilancia esplorazione e sfruttamento per arrivare a impostazioni ottimizzate su misura per l‚Äôarchitettura del chip scelta dallo sviluppatore e i requisiti di prestazioni.</p>
<p>EON Tuner libera gli esperti di machine learning dal processo iterativo esigente di messa a punto manuale dei modelli, regolando automaticamente i modelli per il deployment embedded. Lo strumento si integra perfettamente nel flusso di lavoro Edge Impulse, portando i modelli dal concetto a implementazioni ottimizzate in modo efficiente sui microcontrollori. L‚Äôesperienza racchiusa in EON Tuner per quanto riguarda l‚Äôottimizzazione del modello ML per i microcontrollori garantisce che sia gli sviluppatori principianti che quelli esperti possano rapidamente iterare per ottenere modelli adatti alle esigenze del loro progetto.</p>
<div id="exr-hpt" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;7.2: Ottimizzazione degli Iperparametri
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Prepariamoci a scoprire i segreti della messa a punto degli iperparametri e portiamo i modelli PyTorch al livello successivo! Gli iperparametri sono come i quadranti e le manopole nascosti che controllano i superpoteri di apprendimento del modello. In questo notebook Colab, si collaborer√† con Ray Tune per trovare le combinazioni perfette di iperparametri. Scopriamo come definire quali valori cercare, impostare il codice di training per l‚Äôottimizzazione e lasciare che Ray Tune faccia il grosso del lavoro. Alla fine, si diventer√† professionisti della messa a punto degli iperparametri!</p>
<p><a href="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/30bcc2970bf630097b13789b5cdcea48/hyperparameter_tuning_tutorial.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
<p><a href="#vid-hyperparameter" class="quarto-xref">Video&nbsp;<span>7.3</span></a> spiega l‚Äôorganizzazione sistematica del processo di ottimizzazione degli iperparametri.</p>
<div id="vid-hyperparameter" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.3: Iperparametro
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AXDByU3D1hA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
</section>
<section id="regolarizzazione" class="level2 page-columns page-full" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="regolarizzazione"><span class="header-section-number">7.7</span> Regolarizzazione</h2>
<p>La regolarizzazione √® una tecnica critica per migliorare le prestazioni e la generalizzabilit√† dei modelli di machine learning in impostazioni applicate. Si riferisce alla limitazione matematica o alla penalizzazione della complessit√† del modello per evitare il sovra-adattamento dei dati di training. Senza regolarizzazione, i modelli ML complessi sono inclini al sovra-adattamento del set di dati e alla memorizzazione di peculiarit√† e rumore nel set di training anzich√© all‚Äôapprendimento di pattern significativi. Possono raggiungere un‚Äôelevata accuratezza di training ma hanno prestazioni scadenti quando valutano nuovi input non ancora visti.</p>
<p>La regolarizzazione aiuta ad affrontare questo problema ponendo vincoli che favoriscono modelli pi√π semplici e pi√π generalizzabili che non si agganciano a errori di campionamento. Tecniche come la regolarizzazione L1/L2 penalizzano direttamente valori di parametri elevati durante il training, costringendo il modello a utilizzare i parametri pi√π piccoli che possono spiegare adeguatamente il segnale. Le regole di arresto anticipato interrompono il training quando le prestazioni del set di validazione smettono di migliorare, prima che il modello inizi a sovra-adattarsi.</p>
<p>Una regolarizzazione appropriata √® fondamentale quando si distribuiscono modelli a nuove popolazioni di utenti e ambienti in cui sono probabili cambiamenti di distribuzione. Ad esempio, un modello irregolare di rilevamento delle frodi addestrato presso una banca potrebbe funzionare inizialmente, ma accumulare debiti tecnici nel tempo man mano che emergono nuovi pattern di frode.</p>
<p>La regolarizzazione di reti neurali complesse offre anche vantaggi computazionali: modelli pi√π piccoli richiedono meno ‚Äúdata augmentation‚Äù, potenza di calcolo e archiviazione dei dati. La regolarizzazione consente anche sistemi di intelligenza artificiale pi√π efficienti, in cui accuratezza, robustezza e gestione delle risorse sono attentamente bilanciate rispetto alle limitazioni del set di addestramento.</p>
<p>Diverse potenti tecniche di regolarizzazione sono comunemente utilizzate per migliorare la generalizzazione del modello. L‚Äôarchitettura della strategia ottimale richiede la comprensione di come ogni metodo influisce sull‚Äôapprendimento e sulla complessit√† del modello.</p>
<section id="l1-e-l2" class="level3 page-columns page-full" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="l1-e-l2"><span class="header-section-number">7.7.1</span> L1 e L2</h3>
<p>Due delle forme di regolarizzazione pi√π ampiamente utilizzate sono la regolarizzazione L1 e la L2. Entrambe penalizzano la complessit√† del modello aggiungendo un termine extra alla funzione di costo ottimizzata durante l‚Äôaddestramento. Questo termine cresce all‚Äôaumentare dei parametri del modello.</p>
<p>La regolarizzazione L2, nota anche come ‚Äúridge regression‚Äù [https://it.wikipedia.org/wiki/Regolarizzazione_di_Tichonov], aggiunge la somma delle grandezze al quadrato di tutti i parametri moltiplicata per un coefficiente Œ±. Questa penalit√† quadratica riduce i valori dei parametri estremi in modo pi√π aggressivo rispetto alle tecniche L1. L‚Äôimplementazione richiede solo la modifica della funzione di costo e la messa a punto di Œ±.</p>
<p><span class="math display">\[R_{L2}(\Theta) = \alpha \sum_{i=1}^{n}\theta_{i}^2\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(R_{L2}(\Theta)\)</span> - Il termine di regolarizzazione L2 che viene aggiunto alla funzione di costo</li>
<li><span class="math inline">\(\alpha\)</span> - L‚Äôiperparametro di regolarizzazione L2 che controlla la forza della regolarizzazione</li>
<li><span class="math inline">\(\theta_{i}\)</span> - L‚Äôi-esimo parametro del modello</li>
<li><span class="math inline">\(n\)</span> - Il numero di parametri nel modello</li>
<li><span class="math inline">\(\theta_{i}^2\)</span> - Il quadrato di ciascun parametro</li>
</ul>
<p>E la funzione di costo regolarizzata L2 completa √®:</p>
<p><span class="math display">\[J(\theta) = L(\theta) + R_{L2}(\Theta)\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(L(\theta)\)</span> - La funzione di costo non regolarizzata originale</li>
<li><span class="math inline">\(J(\theta)\)</span> - La nuova funzione di costo regolarizzata</li>
</ul>
<p>Sia la regolarizzazione L1 che L2 penalizzano i pesi elevati nella rete neurale. Tuttavia, la differenza fondamentale tra la regolarizzazione L1 e L2 √® che la regolarizzazione L2 penalizza i quadrati dei parametri anzich√© i valori assoluti. Questa differenza fondamentale ha un impatto considerevole sui pesi regolarizzati risultanti. La regolarizzazione L1, o regressione LASSO [https://it.wikipedia.org/wiki/Regolarizzazione_(matematica)], utilizza la somma assoluta delle grandezze anzich√© il quadrato moltiplicato per Œ±. La penalizzazione del valore assoluto dei pesi induce scarsit√† poich√© il gradiente degli errori estrapola linearmente mentre i termini dei pesi tendono a zero; questo √® diverso dalla penalizzazione del valore al quadrato dei pesi, dove la penalit√† si riduce man mano che i pesi tendono a 0. Inducendo scarsit√† nel vettore dei parametri, la regolarizzazione L1 esegue automaticamente la selezione delle feature, impostando i pesi delle feature irrilevanti a zero. A differenza della regolarizzazione L2, la L1 porta alla scarsit√† poich√© i pesi sono impostati su 0; nella regolarizzazione L2, i pesi sono impostati su un valore molto vicino a 0 ma generalmente non raggiungono mai esattamente 0. La regolarizzazione L1 incoraggia la scarsit√† ed √® stata utilizzata in alcuni lavori per addestrare reti sparse che potrebbero essere pi√π efficienti in termini di hardware <span class="citation" data-cites="torsten2021sparsity">(<a href="../../../references.it.html#ref-torsten2021sparsity" role="doc-biblioref">Hoefler et al. 2021</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-torsten2021sparsity" class="csl-entry" role="listitem">
Hoefler, Torsten, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, e Alexandra Peste. 2021. <span>¬´Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks¬ª</span>, gennaio. <a href="http://arxiv.org/abs/2102.00554v1">http://arxiv.org/abs/2102.00554v1</a>.
</div></div><p><span class="math display">\[R_{L1}(\Theta) = \alpha \sum_{i=1}^{n}||\theta_{i}||\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(R_{L1}(\Theta)\)</span> - Il termine di regolarizzazione L1 che viene aggiunto alla funzione di costo</li>
<li><span class="math inline">\(\alpha\)</span> - L‚Äôiperparametro di regolarizzazione L1 che controlla la forza della regolarizzazione</li>
<li><span class="math inline">\(\theta_{i}\)</span> - L‚Äôi-esimo parametro del modello</li>
<li><span class="math inline">\(n\)</span> - Il numero di parametri nel modello</li>
<li><span class="math inline">\(||\theta_{i}||\)</span> - La norma L1, che assume il valore assoluto di ciascun parametro</li>
</ul>
<p>E la funzione di costo regolarizzata L1 completa √®:</p>
<p><span class="math display">\[J(\theta) = L(\theta) + R_{L1}(\Theta)\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(L(\theta)\)</span> - La funzione di costo non regolarizzata originale</li>
<li><span class="math inline">\(J(\theta)\)</span> - La nuova funzione di costo regolarizzata</li>
</ul>
<p>La scelta tra L1 e L2 dipende dalla complessit√† del modello prevista e dalla necessit√† o meno di una selezione di feature intrinseche. Entrambi richiedono una messa a punto iterativa su un set di validazione per selezionare l‚Äôiperparametro Œ± ottimale.</p>
<p><a href="#vid-regularization" class="quarto-xref">Video&nbsp;<span>7.4</span></a> e <a href="#vid-whyreg" class="quarto-xref">Video&nbsp;<span>7.5</span></a> spiegano come funziona la regolarizzazione.</p>
<div id="vid-regularization" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.4: Regolarizzazione
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/6g0t3Phly2M" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p><a href="#vid-whyreg" class="quarto-xref">Video&nbsp;<span>7.5</span></a> spiega come la regolarizzazione pu√≤ aiutare a ridurre l‚Äôoverfitting del modello per migliorare le prestazioni.</p>
<div id="vid-whyreg" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.5: Perch√© la Regolarizzazione Riduce l‚ÄôOverfitting
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/NyG-7nRpsW8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
<section id="dropout" class="level3 page-columns page-full" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="dropout"><span class="header-section-number">7.7.2</span> Dropout</h3>
<p>Un altro metodo di regolarizzazione ampiamente adottato √® ‚Äúdropout‚Äù <span class="citation" data-cites="srivastava2014dropout">(<a href="../../../references.it.html#ref-srivastava2014dropout" role="doc-biblioref">Srivastava et al. 2014</a>)</span>. Durante l‚Äôaddestramento, dropout imposta casualmente una frazione <span class="math inline">\(p\)</span> di output del nodo o attivazioni nascoste a zero. Questo incoraggia una maggiore distribuzione delle informazioni su pi√π nodi anzich√© affidarsi a un piccolo numero di nodi. Al momento della previsione, viene utilizzata l‚Äôintera rete neurale, con attivazioni intermedie scalate di <span class="math inline">\(1 - p\)</span> per mantenere le ampiezze di output. Le ottimizzazioni GPU semplificano l‚Äôimplementazione efficiente di dropout tramite framework come PyTorch e TensorFlow.</p>
<div class="no-row-height column-margin column-container"><div id="ref-srivastava2014dropout" class="csl-entry" role="listitem">
Srivastava, Nitish, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, e Ruslan Salakhutdinov. 2014. <span>¬´Dropout: a simple way to prevent neural networks from overfitting.¬ª</span> <em>J. Mach. Learn. Res.</em> 15 (1): 1929‚Äì58. <a href="https://doi.org/10.5555/2627435.2670313">https://doi.org/10.5555/2627435.2670313</a>.
</div></div><p>Siamo pi√π precisi. Durante l‚Äôaddestramento con dropout, l‚Äôoutput di ogni nodo <span class="math inline">\(a_i\)</span> viene passato attraverso una maschera di dropout <span class="math inline">\(r_i\)</span> prima di essere utilizzato dal layer successivo:</p>
<p><span class="math display">\[ √£_i = r_i \odot a_i \]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(a_i\)</span> - output del nodo <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(√£_i\)</span> - output del nodo <span class="math inline">\(i\)</span> dopo il dropout</li>
<li><span class="math inline">\(r_i\)</span> - variabile casuale di Bernoulli indipendente con probabilit√† <span class="math inline">\(1 - p\)</span> di essere 1</li>
<li><span class="math inline">\(\odot\)</span> - moltiplicazione elemento per elemento</li>
</ul>
<p>Per capire come funziona il dropout, √® importante sapere che la maschera di dropout <span class="math inline">\(r_i\)</span> √® basata sulle variabili casuali di Bernoulli. Una variabile casuale di Bernoulli assume un valore di 1 con probabilit√† <span class="math inline">\(1-p\)</span> (mantenendo l‚Äôattivazione) e un valore di 0 con probabilit√† <span class="math inline">\(p\)</span> (dropping [perdendo] l‚Äôattivazione). Ci√≤ significa che l‚Äôattivazione di ciascun nodo viene mantenuta o eliminata indipendentemente durante l‚Äôaddestramento. Questa maschera di dropout <span class="math inline">\(r_i\)</span> imposta casualmente una frazione <span class="math inline">\(p\)</span> di attivazioni a 0 durante l‚Äôaddestramento, costringendo la rete a creare rappresentazioni ridondanti.</p>
<p>Al momento del test, la maschera di dropout viene rimossa e le attivazioni vengono ridimensionate di <span class="math inline">\(1 - p\)</span> per mantenere le ampiezze di output previste:</p>
<p><span class="math display">\[ a_i^{test} = (1 - p)  a_i\]</span></p>
<p>Dove:</p>
<ul>
<li><span class="math inline">\(a_i^{test}\)</span> - output del nodo al momento del test</li>
<li><span class="math inline">\(p\)</span> - la probabilit√† di effettuare il dropping [eliminare] di un nodo.</li>
</ul>
<p>L‚Äôiperparametro chiave √® <span class="math inline">\(p\)</span>, la probabilit√† di eliminare ogni nodo, spesso impostata tra 0.2 e 0.5. Le reti pi√π grandi tendono a trarre vantaggio da un dropout maggiore, mentre le reti pi√π piccole rischiano di non adattarsi se vengono eliminati troppi nodi. Tentativi ed errori combinati con il monitoraggio delle prestazioni di validazione aiutano a regolare il livello di dropout.</p>
<p><a href="#vid-dropout" class="quarto-xref">Video&nbsp;<span>7.6</span></a> discute l‚Äôintuizione alla base della tecnica di regolarizzazione del dropout e il suo funzionamento.</p>
<div id="vid-dropout" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.6: Dropout
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ARq74QuavAo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
<section id="arresto-anticipato" class="level3" data-number="7.7.3">
<h3 data-number="7.7.3" class="anchored" data-anchor-id="arresto-anticipato"><span class="header-section-number">7.7.3</span> Arresto Anticipato</h3>
<p>L‚Äôintuizione alla base di ‚Äúearly stopping‚Äù <a href="#arresto-anticipato">arresto anticipato</a> implica il monitoraggio delle prestazioni del modello su un set di validazione ‚Äúheld-out‚Äù [esterno] in epoche di addestramento. Inizialmente, gli aumenti nell‚Äôidoneit√† del set di addestramento accompagnano i guadagni nell‚Äôaccuratezza della validazione man mano che il modello rileva pattern generalizzabili. Dopo un certo punto, tuttavia, il modello inizia a sovradimensionarsi, agganciandosi a peculiarit√† e rumore nei dati di addestramento che non si applicano pi√π in generale. Le prestazioni di validazione raggiungono il picco e poi si degradano se l‚Äôaddestramento continua. Le regole di ‚Äúarresto anticipato‚Äù interrompono l‚Äôaddestramento a questo picco per evitare il sovradimensionamento. Questa tecnica dimostra come le pipeline ML debbano monitorare il feedback del sistema, non solo massimizzare incondizionatamente le prestazioni su un set di addestramento statico. Lo stato del sistema evolve e gli endpoint ottimali cambiano.</p>
<p>Pertanto, i metodi formali di arresto anticipato richiedono il monitoraggio di una metrica come l‚Äôaccuratezza o la perdita di validazione dopo ogni epoca. Le curve comuni mostrano rapidi guadagni iniziali che si riducono gradualmente, alla fine raggiungendo un plateau e diminuiscono leggermente man mano che si verifica il sovradimensionamento. Il punto di arresto ottimale √® spesso compreso tra 5 e 15 epoche oltre il picco, a seconda dei ‚Äúpatient threshold‚Äù [limiti della pazienza!]. Il monitoraggio di pi√π metriche pu√≤ migliorare il segnale poich√© esiste una varianza tra le misure.</p>
<p>Le semplici regole di arresto anticipato si interrompono immediatamente alla prima degradazione post-picco. Metodi pi√π robusti introducono un parametro di ‚Äúpazienza‚Äù, ovvero il numero di epoche di degradazione consentite prima dell‚Äôarresto. Ci√≤ evita di interrompere prematuramente l‚Äôaddestramento a causa di fluttuazioni transitorie. Le finestre di ‚Äúpazienza‚Äù tipiche vanno da 50 a 200 batch di validazione. Finestre pi√π ampie comportano il rischio di overfitting. Le strategie di ottimizzazione formali possono determinare la ‚Äúpazienza‚Äù ottimale.</p>
<div id="exr-r" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;7.3: Regolarizzazione
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Combattere l‚ÄôOverfitting: Scoprire i Segreti della Regolarizzazione! L‚Äôoverfitting √® come se il modello memorizzasse le risposte a un test, per poi fallire l‚Äôesame reale. Le tecniche di regolarizzazione sono le guide di studio che aiutano il modello a generalizzare e ad affrontare nuovi problemi. In questo notebook Colab, impareremo come ottimizzare i parametri di regolarizzazione per risultati ottimali utilizzando la regolarizzazione L1 e L2, il dropout e l‚Äôarresto anticipato.</p>
<p><a href="https://colab.research.google.com/github/dphi-official/Deep_Learning_Bootcamp/blob/master/Optimization_Techniques/Regularization_and_Dropout.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
<p><a href="#vid-otherregs" class="quarto-xref">Video&nbsp;<span>7.7</span></a> tratta alcuni altri metodi di regolarizzazione che possono ridurre l‚Äôoverfitting del modello.</p>
<div id="vid-otherregs" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.7: Altri Metodi di Regolarizzazione
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/BOCLq2gpcGU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="funzioni-di-attivazione" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="funzioni-di-attivazione"><span class="header-section-number">7.8</span> Funzioni di Attivazione</h2>
<p>Le funzioni di attivazione svolgono un ruolo cruciale nelle reti neurali. Introducono comportamenti non lineari che consentono alle reti neurali di modellare pattern complessi. Le funzioni di attivazione elemento per elemento vengono applicate alle somme ponderate che arrivano a ciascun neurone nella rete. Senza funzioni di attivazione, le reti neurali sarebbero ridotte a modelli di regressione lineare.</p>
<p>Idealmente, le funzioni di attivazione possiedono alcune qualit√† desiderabili:</p>
<ul>
<li><strong>Non lineari:</strong> Consentono di modellare relazioni complesse tramite trasformazioni non lineari della somma degli input.</li>
<li><strong>Differenziabili:</strong> Devono avere derivate prime ben definite per abilitare la retropropagazione e l‚Äôottimizzazione basata sul gradiente durante l‚Äôaddestramento.</li>
<li><strong>Limitazione dell‚ÄôIntervallo:</strong> Limitano il segnale di output, impedendo un‚Äôesplosione. Ad esempio, la sigmoide schiaccia gli input a (0,1).</li>
</ul>
<p>Inoltre, propriet√† come efficienza computazionale, monotonicit√† e fluidit√† rendono alcune attivazioni pi√π adatte di altre in base all‚Äôarchitettura di rete e alla complessit√† del problema.</p>
<p>Esamineremo brevemente alcune delle funzioni di attivazione pi√π ampiamente adottate e i loro punti di forza e limiti. Forniremo anche linee guida per la selezione di funzioni appropriate abbinate ai vincoli del sistema ML e alle esigenze dei casi d‚Äôuso.</p>
<section id="sigmoide" class="level3" data-number="7.8.1">
<h3 data-number="7.8.1" class="anchored" data-anchor-id="sigmoide"><span class="header-section-number">7.8.1</span> Sigmoide</h3>
<p>L‚Äôattivazione sigmoide applica una curva a forma di S schiacciante che lega strettamente l‚Äôoutput tra 0 e 1. Ha la forma matematica:</p>
<p><span class="math display">\[ sigmoid(x) = \frac{1}{1+e^{-x}} \]</span></p>
<p>La trasformazione esponenziale consente alla funzione di passare gradualmente da quasi 0 a quasi 1 quando l‚Äôinput passa da molto negativo a molto positivo. L‚Äôaumento monotono copre l‚Äôintero intervallo (0,1).</p>
<p>La funzione sigmoide presenta diversi vantaggi. Fornisce sempre un gradiente uniforme per la retropropagazione e il suo output √® limitato tra 0 e 1, il che aiuta a prevenire valori ‚Äúesplosivi‚Äù durante l‚Äôaddestramento. Inoltre, ha una semplice formula matematica che √® facile da calcolare.</p>
<p>Tuttavia, la funzione sigmoide presenta anche alcuni svantaggi. Tende a saturarsi a valori di input estremi, il che pu√≤ causare la ‚Äúscomparsa‚Äù dei gradienti, rallentando o addirittura interrompendo il processo di apprendimento. Inoltre, la funzione non √® centrata sullo zero, il che significa che i suoi output non sono distribuiti simmetricamente attorno allo zero, il che pu√≤ portare ad aggiornamenti inefficienti durante l‚Äôaddestramento.</p>
</section>
<section id="tanh" class="level3" data-number="7.8.2">
<h3 data-number="7.8.2" class="anchored" data-anchor-id="tanh"><span class="header-section-number">7.8.2</span> Tanh</h3>
<p>Anche Tanh o ‚Äútangente iperbolica‚Äù assume una forma a S ma √® centrata sullo zero, il che significa che il valore medio dell‚Äôoutput √® 0.</p>
<p><span class="math display">\[ tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} \]</span></p>
<p>La trasformazione numeratore/denominatore sposta l‚Äôintervallo da (0,1) in Sigmoide a (-1, 1) in tanh.</p>
<p>La maggior parte dei pro/contro sono condivisi con la Sigmoide, ma Tanh evita alcuni problemi di saturazione dell‚Äôoutput essendo centrata. Tuttavia, soffre ancora di gradienti che svaniscono con molti layer.</p>
</section>
<section id="relu" class="level3" data-number="7.8.3">
<h3 data-number="7.8.3" class="anchored" data-anchor-id="relu"><span class="header-section-number">7.8.3</span> ReLU</h3>
<p>La Rectified Linear Unit (ReLU) introduce un semplice comportamento di soglia con la sua forma matematica:</p>
<p><span class="math display">\[ ReLU(x) = max(0, x) \]</span></p>
<p>Lascia tutti gli input positivi invariati mentre taglia tutti i valori negativi a 0. Questa attivazione sparsa e il calcolo economico rendono ReLU ampiamente favorito rispetto a sigmoide/tanh.</p>
<p><a href="#fig-activation-functions" class="quarto-xref">Figura&nbsp;<span>7.6</span></a> dimostra le 3 funzioni di attivazione di cui abbiamo discusso sopra in confronto a una funzione lineare:</p>
<div id="fig-activation-functions" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-activation-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpeg/activation-functions3.jpg" class="img-fluid figure-img" style="width:70.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-activation-functions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.6: Funzioni di Attivazione Comuni. Fonte: <a href="https://machine-learning.paperspace.com/wiki/activation-function">AI Wiki.</a>
</figcaption>
</figure>
</div>
</section>
<section id="softmax" class="level3" data-number="7.8.4">
<h3 data-number="7.8.4" class="anchored" data-anchor-id="softmax"><span class="header-section-number">7.8.4</span> Softmax</h3>
<p>La funzione di attivazione softmax √® generalmente utilizzata come ultimo layer per le attivit√† di classificazione per normalizzare il vettore del valore di attivazione in modo che i suoi elementi sommino a 1. Questo √® utile per le attivit√† di classificazione in cui vogliamo imparare a prevedere probabilit√† specifiche per classe di un input particolare, nel qual caso la probabilit√† cumulativa tra le classi √® uguale a 1. La funzione di attivazione softmax √® definita come</p>
<p><span class="math display">\[\sigma(z_i) = \frac{e^{z_{i}}}{\sum_{j=1}^K e^{z_{j}}} \ \ \ for\ i=1,2,\dots,K\]</span></p>
</section>
<section id="pro-e-contro" class="level3" data-number="7.8.5">
<h3 data-number="7.8.5" class="anchored" data-anchor-id="pro-e-contro"><span class="header-section-number">7.8.5</span> Pro e Contro</h3>
<p><a href="#tbl-af" class="quarto-xref">Tabella&nbsp;<span>7.4</span></a> sono i pro e i contro riassuntivi di queste varie funzioni di attivazione standard:</p>
<div id="tbl-af" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-af-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;7.4: Confronto dei pro e dei contro di diversi algoritmi di ottimizzazione.
</figcaption>
<div aria-describedby="tbl-af-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 54%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Attivazione</th>
<th style="text-align: left;">Pro</th>
<th style="text-align: left;">Contro</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Sigmoide</td>
<td style="text-align: left;"><ul>
<li>Gradiente uniforme per il backdrop [sfondo]</li>
<li>Output limitato tra 0 e 1</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>La saturazione elimina i gradienti</li>
<li>Non centrato sullo zero</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Tanh</td>
<td style="text-align: left;"><ul>
<li>Gradiente pi√π uniforme della sigmoide</li>
<li>Output centrato sullo zero [-1, 1]</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Soffre ancora di problemi di gradiente evanescente</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">ReLU</td>
<td style="text-align: left;"><ul>
<li>Efficiente dal punto di vista computazionale</li>
<li>Introduce la ‚Äúsparsity‚Äù [scarsit√†]</li>
<li>Evita gradienti evanescenti</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Unit√† ‚ÄúReLU morenti‚Äù</li>
<li>Non limitato</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Softmax</td>
<td style="text-align: left;"><ul>
<li>Utilizzato per l‚Äôultimo livello per normalizzare gli output in modo che siano una distribuzione</li>
<li>In genere utilizzato per attivit√† di classificazione</li>
</ul></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div id="exr-af" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;7.4: Funzioni di Attivazione
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Sblocchiamo la potenza delle funzioni di attivazione! Questi piccoli ‚Äúmuletti‚Äù matematici sono ci√≤ che rende le reti neurali cos√¨ incredibilmente flessibili. In questo notebook Colab, ci si cimenter√† con funzioni come Sigmoid, tanh e la superstar ReLU. Guardiamo come trasformano gli input e scopriamo quale funziona meglio in diverse situazioni. √à la chiave per costruire reti neurali in grado di affrontare problemi complessi!</p>
<p><a href="https://colab.research.google.com/github/jfogarty/machine-learning-intro-workshop/blob/master/notebooks/nn_activation_functions.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
</section>
<section id="inizializzazione-dei-pesi" class="level2 page-columns page-full" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="inizializzazione-dei-pesi"><span class="header-section-number">7.9</span> Inizializzazione dei Pesi</h2>
<p>La corretta inizializzazione dei pesi in una rete neurale prima dell‚Äôaddestramento √® un passaggio fondamentale che ha un impatto diretto sulle prestazioni del modello. L‚Äôinizializzazione casuale dei pesi a valori molto grandi o molto piccoli pu√≤ portare a problemi come gradienti che svaniscono/esplodono, convergenza lenta dell‚Äôaddestramento o intrappolati in minimi locali scadenti. La corretta inizializzazione del peso accelera la convergenza del modello durante l‚Äôaddestramento e comporta implicazioni per le prestazioni del sistema al momento dell‚Äôinferenza negli ambienti di produzione. Alcuni aspetti chiave sono:</p>
<ul>
<li><p><strong>Tempo di Accuratezza pi√π Rapido:</strong> Un‚Äôinizializzazione attentamente calibrata porta a una convergenza pi√π rapida, che si traduce nel raggiungimento da parte dei modelli di traguardi di accuratezza target in anticipo nel ciclo di training. Ad esempio, l‚Äôinizializzazione Xavier potrebbe ridurre il tempo di accuratezza del 20% rispetto a un‚Äôinizializzazione casuale errata. Poich√© l‚Äôaddestramento √® in genere la fase pi√π dispendiosa in termini di tempo e calcolo, ci√≤ migliora direttamente la velocit√† e la produttivit√† del sistema ML.</p></li>
<li><p><strong>Efficienza del Ciclo di Iterazione del Modello:</strong> Se i modelli vengono addestrati pi√π rapidamente, il tempo di risposta complessivo per le iterazioni di sperimentazione, valutazione e progettazione del modello diminuisce in modo significativo. I sistemi hanno maggiore flessibilit√† per esplorare architetture, pipeline di dati, ecc., entro determinati intervalli di tempo.</p></li>
<li><p><strong>Impatto sulle Epoche di Addestramento Necessarie:</strong> Il processo di addestramento viene eseguito per pi√π epoche, con ogni passaggio completo attraverso i dati che rappresenta un‚Äôepoca. Una buona inizializzazione pu√≤ ridurre le epoche necessarie per far convergere le curve di perdita e accuratezza sul set di addestramento del 10-30%. Ci√≤ significa risparmi tangibili sui costi di risorse e infrastruttura.</p></li>
<li><p><strong>Effetto sugli Iperparametri di Addestramento:</strong> I parametri di inizializzazione del peso interagiscono fortemente con determinati iperparametri di regolarizzazione che governano le dinamiche di addestramento, come i programmi di velocit√† di apprendimento e le probabilit√† di abbandono. Trovare la giusta combinazione di impostazioni non √® banale. Un‚Äôinizializzazione appropriata semplifica questa ricerca.</p></li>
</ul>
<p>L‚Äôinizializzazione dei pesi ha vantaggi a cascata per l‚Äôefficienza ingegneristica dell‚Äôapprendimento automatico e un overhead di risorse di sistema ridotto al minimo. √à una tattica facilmente trascurata che ogni professionista dovrebbe padroneggiare. La scelta di quale tecnica di inizializzazione del peso utilizzare dipende da fattori come l‚Äôarchitettura del modello (numero di layer, pattern di connettivit√†, ecc.), le funzioni di attivazione e il problema specifico da risolvere. Nel corso degli anni, i ricercatori hanno sviluppato e verificato empiricamente diverse strategie di inizializzazione mirate alle comuni architetture di reti neurali, di cui parleremo qui.</p>
<section id="inizializzazione-uniforme-e-normale" class="level3" data-number="7.9.1">
<h3 data-number="7.9.1" class="anchored" data-anchor-id="inizializzazione-uniforme-e-normale"><span class="header-section-number">7.9.1</span> Inizializzazione Uniforme e Normale</h3>
<p>Quando si inizializzano pesi in modo casuale, vengono comunemente utilizzate due distribuzioni di probabilit√† standard: uniforme e Gaussiana (normale). La distribuzione uniforme imposta una probabilit√† uguale che i parametri di peso iniziali rientrino in qualsiasi punto entro i limiti minimi e massimi impostati. Ad esempio, i limiti potrebbero essere -1 e 1, portando a una distribuzione uniforme dei pesi tra questi limiti. La distribuzione gaussiana, d‚Äôaltra parte, concentra la probabilit√† attorno a un valore medio, seguendo la forma di una curva a campana. La maggior parte dei valori di peso si raggrupper√† nella regione della media specificata, con meno campioni verso le estremit√†. Il parametro di deviazione standard controlla la distribuzione attorno alla media.</p>
<p>La scelta tra inizializzazione uniforme o normale dipende dall‚Äôarchitettura di rete e dalle funzioni di attivazione. Per reti poco profonde, si consiglia una distribuzione normale con una deviazione standard relativamente piccola (ad esempio, 0.01). La curva a campana impedisce valori di peso elevati che potrebbero innescare l‚Äôinstabilit√† di addestramento in reti piccole. Per reti pi√π profonde, una distribuzione normale con deviazione standard pi√π elevata (diciamo 0.5 o superiore) o una distribuzione uniforme pu√≤ essere preferita per tenere conto dei problemi di gradiente evanescente su molti layer. La maggiore diffusione determina una maggiore differenziazione tra i comportamenti dei neuroni. La messa a punto dei parametri di distribuzione di inizializzazione √® fondamentale per una convergenza stabile e rapida del modello. Il monitoraggio dei trend di ‚Äúloss‚Äù [perdita] di addestramento pu√≤ diagnosticare i problemi per modificare i parametri in modo iterativo.</p>
</section>
<section id="inizializzazione-xavier" class="level3 page-columns page-full" data-number="7.9.2">
<h3 data-number="7.9.2" class="anchored" data-anchor-id="inizializzazione-xavier"><span class="header-section-number">7.9.2</span> Inizializzazione Xavier</h3>
<p>Proposta da <span class="citation" data-cites="glorot2010understanding">Glorot e Bengio (<a href="../../../references.it.html#ref-glorot2010understanding" role="doc-biblioref">2010</a>)</span>, questa tecnica di inizializzazione √® progettata appositamente per le funzioni di attivazione sigmoide e tanh. Queste attivazioni saturate possono causare gradienti evanescenti o esplosivi durante la retro-propagazione su molti layer.</p>
<div class="no-row-height column-margin column-container"><div id="ref-glorot2010understanding" class="csl-entry" role="listitem">
Glorot, Xavier, e Yoshua Bengio. 2010. <span>¬´Understanding the difficulty of training deep feedforward neural networks.¬ª</span> In <em>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em>, 249‚Äì56. <a href="http://proceedings.mlr.press/v9/glorot10a.html">http://proceedings.mlr.press/v9/glorot10a.html</a>.
</div></div><p>Il metodo Xavier imposta in modo intelligente la varianza della distribuzione dei pesi in base al numero di input e output per ciascun layer. L‚Äôintuizione √® che questo bilancia il flusso di informazioni e gradienti in tutta la rete. Ad esempio, si consideri un layer con 300 unit√† di input e 100 unit√† di output. Inserendo questo nella formula varianza = 2/(#inputs + #outputs) si ottiene una varianza di 2/(300+100) = 0.01.</p>
<p>Il campionamento dei pesi iniziali da una distribuzione uniforme o normale centrata su 0 con questa varianza fornisce una convergenza di addestramento molto pi√π fluida per reti sigmoide/tanh profonde. I gradienti sono ben condizionati, impedendo la scomparsa o la crescita esponenziale.</p>
</section>
<section id="inizializzazione-he" class="level3 page-columns page-full" data-number="7.9.3">
<h3 data-number="7.9.3" class="anchored" data-anchor-id="inizializzazione-he"><span class="header-section-number">7.9.3</span> Inizializzazione He</h3>
<p>Come proposto da <span class="citation" data-cites="kaiming2015delving">He et al. (<a href="../../../references.it.html#ref-kaiming2015delving" role="doc-biblioref">2015</a>)</span>, questa tecnica di inizializzazione √® adattata alle funzioni di attivazione ReLU (Rectified Linear Unit). Le ReLU introducono il problema del neurone morente in cui le unit√† rimangono bloccate e producono solo 0 se inizialmente ricevono forti input negativi. Ci√≤ rallenta e ostacola l‚Äôaddestramento.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kaiming2015delving" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, e Jian Sun. 2015. <span>¬´Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification¬ª</span>. In <em>2015 IEEE International Conference on Computer Vision (ICCV)</em>, 1026‚Äì34. IEEE. <a href="https://doi.org/10.1109/iccv.2015.123">https://doi.org/10.1109/iccv.2015.123</a>.
</div></div><p>‚ÄúHe‚Äù supera questo problema campionando i pesi da una distribuzione con un set di varianza basato solo sul numero di input per layer, ignorando gli output. Ci√≤ mantiene i segnali in arrivo sufficientemente piccoli da attivare le ReLU nel loro regime lineare dall‚Äôinizio, evitando unit√† morte. Per un layer con 1024 input, la formula varianza = 2/1024 = 0.002 mantiene la maggior parte dei pesi concentrati strettamente attorno a 0.</p>
<p>Questa inizializzazione specializzata consente alle reti ReLU di convergere in modo efficiente fin dall‚Äôinizio. La scelta tra Xavier e He deve corrispondere alla funzione di attivazione della rete prevista.</p>
<div id="exr-wi" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;7.5: Inizializzazione dei Pesi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Facciamo partire la rete neurale col piede giusto con l‚Äôinizializzazione dei pesi! Il modo in cui si impostano quei pesi iniziali pu√≤ fare la differenza nell‚Äôaddestramento del modello. Si immagini di accordare gli strumenti di un‚Äôorchestra prima del concerto. In questo notebook Colab, si imparer√† che la giusta strategia di inizializzazione pu√≤ far risparmiare tempo, migliorare le prestazioni del modello e rendere il percorso di deep-learning molto pi√π fluido.</p>
<p><a href="https://colab.research.google.com/github/csaybar/DLcoursera/blob/master/Improving%20Deep%20Neural%20Networks%20Hyperparameter%20tuning%2C%20Regularization%20and%20Optimization/week5/Initialization/Initialization.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
<p><a href="#vid-weightinit" class="quarto-xref">Video&nbsp;<span>7.8</span></a> sottolinea l‚Äôimportanza di selezionare deliberatamente i valori di peso iniziale rispetto a scelte casuali.</p>
<div id="vid-weightinit" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;7.8: Inizializzazione dei Pesi
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/s2coXdufOzE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
<section id="colli-di-bottiglia-del-sistema" class="level2 page-columns page-full" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="colli-di-bottiglia-del-sistema"><span class="header-section-number">7.10</span> ‚ÄúColli di Bottiglia‚Äù del Sistema</h2>
<p>Come introdotto in precedenza, le reti neurali comprendono operazioni lineari (moltiplicazioni di matrici) intervallate da funzioni di attivazione non lineari elemento per elemento. La parte computazionalmente pi√π costosa delle reti neurali sono le trasformazioni lineari, in particolare le moltiplicazioni di matrici tra ogni layer. Questi layer lineari mappano le attivazioni dal layer precedente a uno spazio dimensionale superiore che funge da input per la funzione di attivazione del layer successivo.</p>
<section id="complessit√†-a-runtime-della-moltiplicazione-di-matrici" class="level3" data-number="7.10.1">
<h3 data-number="7.10.1" class="anchored" data-anchor-id="complessit√†-a-runtime-della-moltiplicazione-di-matrici"><span class="header-section-number">7.10.1</span> Complessit√† a Runtime della Moltiplicazione di Matrici</h3>
<section id="moltiplicazioni-di-layer-vs.-attivazioni" class="level4">
<h4 class="anchored" data-anchor-id="moltiplicazioni-di-layer-vs.-attivazioni">Moltiplicazioni di Layer vs.&nbsp;Attivazioni</h4>
<p>La maggior parte del calcolo nelle reti neurali deriva dalle moltiplicazioni di matrici tra layer. Si consideri un layer di rete neurale con una dimensione di input di <span class="math inline">\(M\)</span> = 500 e una dimensione di output di <span class="math inline">\(N\)</span> = 1000; la moltiplicazione di matrici richiede <span class="math inline">\(O(N \cdot M) = O(1000 \cdot 500) = 500,000\)</span> operazioni di moltiplicazione-accumulazione (MAC) tra quei layer.</p>
<p>Confronta questo col layer precedente, che aveva <span class="math inline">\(M\)</span> = 300 input, che richiedevano <span class="math inline">\(O(500 \cdot 300) = 150,000\)</span> operazioni. Man mano che le dimensioni dei layer aumentano, i requisiti computazionali aumentano quadraticamente con la dimensione del layer. I calcoli totali su <span class="math inline">\(L\)</span> layer possono essere espressi come <span class="math inline">\(\sum_{l=1}^{L-1} O\big(N^{(l)} \cdot M^{(l-1)}\big)\)</span>, dove il calcolo richiesto per ogni layer dipende dal prodotto delle dimensioni di input e output delle matrici che vengono moltiplicate.</p>
<p>Ora, confrontando la moltiplicazione della matrice con la funzione di attivazione, che richiede solo <span class="math inline">\(O(N) = 1000\)</span> non linearit√† elemento per elemento per <span class="math inline">\(N = 1000\)</span> output, possiamo vedere le trasformazioni lineari che dominano le attivazioni computazionalmente.</p>
<p>Queste grandi moltiplicazioni di matrici influiscono sulle scelte hardware, sulla latenza dell‚Äôinferenza e sui vincoli di potenza per le applicazioni di reti neurali nel mondo reale. Ad esempio, un tipico layer DNN potrebbe richiedere 500,000 moltiplicazioni-accumulazioni rispetto a solo 1000 attivazioni non lineari, dimostrando un aumento di 500x nelle operazioni matematiche.</p>
<p>Quando si addestrano reti neurali, in genere utilizziamo la discesa del gradiente in mini-batch, operando su piccoli batch di dati contemporaneamente. Considerando una dimensione batch di <span class="math inline">\(B\)</span> esempi di addestramento, l‚Äôinput per la moltiplicazione di matrice diventa una matrice <span class="math inline">\(M \times B\)</span>, mentre l‚Äôoutput √® una matrice <span class="math inline">\(N \times B\)</span>.</p>
</section>
<section id="mini-batch" class="level4">
<h4 class="anchored" data-anchor-id="mini-batch">Mini-batch</h4>
<p>Nell‚Äôaddestramento delle reti neurali, dobbiamo stimare ripetutamente il gradiente della funzione di perdita rispetto ai parametri di rete (ad esempio, pesi e bias). Questo gradiente indica in quale direzione i parametri devono essere aggiornati per ridurre al minimo la perdita. Come introdotto in precedenza, eseguiamo aggiornamenti su un batch di dati a ogni aggiornamento, noto anche come discesa del gradiente stocastico o ‚Äúdiscesa del gradiente mini-batch‚Äù.</p>
<p>L‚Äôapproccio pi√π semplice √® stimare il gradiente in base a un singolo esempio di addestramento, calcolare l‚Äôaggiornamento dei parametri, riassettare tutto e ripetere per l‚Äôesempio successivo. Tuttavia, ci√≤ comporta aggiornamenti dei parametri molto piccoli e frequenti che possono essere computazionalmente inefficienti e potrebbero dover essere pi√π accurati in termini di convergenza a causa della stocasticit√† dell‚Äôutilizzo di un solo dato per un aggiornamento del modello.</p>
<p>Invece, la discesa del gradiente in mini-batch bilancia la stabilit√† della convergenza e l‚Äôefficienza computazionale. Invece di calcolare il gradiente su singoli esempi, stimiamo il gradiente in base a piccoli ‚Äúmini-batch‚Äù di dati, solitamente tra 8 e 256 esempi in pratica.</p>
<p>Ci√≤ fornisce una stima del gradiente rumorosa ma coerente che porta a una convergenza pi√π stabile. Inoltre, l‚Äôaggiornamento dei parametri deve essere eseguito solo una volta per mini-batch anzich√© una volta per ogni esempio, riducendo il sovraccarico computazionale.</p>
<p>Regolando la dimensione del mini-batch, possiamo controllare il compromesso tra la fluidit√† della stima (i batch pi√π grandi sono generalmente migliori) e la frequenza degli aggiornamenti (i batch pi√π piccoli consentono aggiornamenti pi√π frequenti). Le dimensioni del mini-batch sono solitamente potenze di 2, quindi possono sfruttare in modo efficiente il parallelismo tra i core GPU.</p>
<p>Quindi, il calcolo totale esegue una moltiplicazione di matrici <span class="math inline">\(N \times M\)</span> per <span class="math inline">\(M \times B\)</span>, producendo <span class="math inline">\(O(N \cdot M \cdot B)\)</span> operazioni in virgola mobile. Come esempio numerico, <span class="math inline">\(N=1000\)</span> unit√† nascoste, <span class="math inline">\(M=500\)</span> unit√† di input e una dimensione del batch <span class="math inline">\(B=64\)</span> equivale a 1000 x 500 x 64 = 32 milioni di moltiplicazioni-accumulazioni per iterazione di training!</p>
<p>Al contrario, le funzioni di attivazione vengono applicate elemento per elemento alla matrice di output <span class="math inline">\(N \times B\)</span>, richiedendo solo <span class="math inline">\(O(N \cdot B)\)</span> calcoli. Per <span class="math inline">\(N=1000\)</span> e <span class="math inline">\(B=64\)</span>, si tratta di sole 64,000 non linearit√†, ovvero 500 volte meno lavoro della moltiplicazione di matrici.</p>
<p>Man mano che aumentiamo le dimensioni del batch per sfruttare appieno hardware parallelo come le GPU, la discrepanza tra la moltiplicazione di matrici e il costo della funzione di attivazione aumenta ulteriormente. Ci√≤ rivela come l‚Äôottimizzazione delle operazioni di algebra lineare offra enormi guadagni di efficienza.</p>
<p>Pertanto, la moltiplicazione di matrici √® fondamentale nell‚Äôanalisi di dove e come le reti neurali impiegano i calcoli. Ad esempio, le moltiplicazioni di matrici spesso rappresentano oltre il 90% della latenza di inferenza e del tempo di addestramento nelle comuni reti neurali convoluzionali e ricorrenti.</p>
</section>
<section id="ottimizzazione-della-moltiplicazione-di-matrici" class="level4">
<h4 class="anchored" data-anchor-id="ottimizzazione-della-moltiplicazione-di-matrici">Ottimizzazione della Moltiplicazione di Matrici</h4>
<p>Diverse tecniche migliorano l‚Äôefficienza delle operazioni generali matrice-matrice densa/sparsa e matrice-vettore per migliorare l‚Äôefficienza complessiva. Alcuni metodi chiave sono:</p>
<ul>
<li>Sfruttamento di librerie matematiche ottimizzate come <a href="https://developer.nvidia.com/cublas">cuBLAS</a> per l‚Äôaccelerazione GPU</li>
<li>Abilitazione di formati di precisione inferiore come FP16 o INT8 dove l‚Äôaccuratezza lo consente</li>
<li>Utilizzo di <a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">Tensor Processing Unit</a> con moltiplicazione di matrici in hardware</li>
<li>Calcoli consapevoli della sparsit√† e formati di archiviazione dati per sfruttare i parametri zero</li>
<li>Approssimazione delle moltiplicazioni di matrici con algoritmi come le Fast Fourier Transform</li>
<li>Progettazione dell‚Äôarchitettura del modello per ridurre le larghezze e le attivazioni degli layer</li>
<li>Quantizzazione, pruning [potatura], distillazione e altre tecniche di compressione</li>
<li>Parallelizzazione del calcolo sull‚Äôhardware disponibile</li>
<li>Risultati di caching/pre-calcolo ove possibile per ridurre le operazioni ridondanti</li>
</ul>
<p>Le potenziali tecniche di ottimizzazione sono vaste, data la porzione sproporzionata di tempo che i modelli trascorrono nella matematica di matrici e vettori. Anche i miglioramenti incrementali velocizzano i tempi di esecuzione e riducono il consumo di energia. Trovare nuovi modi per migliorare queste primitive di algebra lineare rimane un‚Äôarea di ricerca attiva allineata con le future esigenze di machine learning. Ne parleremo in dettaglio nei capitoli <a href="../../../contents/core/optimizations/optimizations.it.html">Ottimizzazioni</a> e <a href="../../../contents/core/hw_acceleration/hw_acceleration.it.html">Accelerazione IA</a>.</p>
</section>
</section>
<section id="calcolo-vs.-collo-di-bottiglia-della-memoria" class="level3 page-columns page-full" data-number="7.10.2">
<h3 data-number="7.10.2" class="anchored" data-anchor-id="calcolo-vs.-collo-di-bottiglia-della-memoria"><span class="header-section-number">7.10.2</span> Calcolo vs.&nbsp;Collo di Bottiglia della Memoria</h3>
<p>A questo punto, la moltiplicazione matrice-matrice √® l‚Äôoperazione matematica fondamentale alla base delle reti neurali. Sia l‚Äôaddestramento che l‚Äôinferenza per le reti neurali utilizzano ampiamente queste operazioni di moltiplicazione di matrici. L‚Äôanalisi mostra che oltre il 90% dei requisiti computazionali nelle reti neurali attuali derivano da moltiplicazioni di matrici. Di conseguenza, le prestazioni della moltiplicazione di matrici hanno un‚Äôenorme influenza sul tempo complessivo di addestramento o inferenza del modello.</p>
<section id="addestramento-vs.-inferenza" class="level4">
<h4 class="anchored" data-anchor-id="addestramento-vs.-inferenza">Addestramento vs.&nbsp;Inferenza</h4>
<p>Mentre l‚Äôaddestramento e l‚Äôinferenza si basano ampiamente sulle prestazioni della moltiplicazione di matrici, i loro profili computazionali precisi differiscono. In particolare, l‚Äôinferenza della rete neurale tende a essere pi√π legata al calcolo rispetto all‚Äôaddestramento per una dimensione di batch equivalente. La differenza fondamentale risiede nel passaggio di backpropagation, che √® richiesto solo durante l‚Äôaddestramento. La backpropagation implica una sequenza di operazioni di moltiplicazione di matrici per calcolare i gradienti rispetto alle attivazioni su ogni layer della rete. Tuttavia, √® fondamentale che qui non sia necessaria alcuna larghezza di banda di memoria aggiuntiva: gli input, gli output e i gradienti vengono letti/scritti dalla cache o dai registri.</p>
<p>Di conseguenza, l‚Äôaddestramento mostra intensit√† aritmetiche inferiori, con calcoli del gradiente limitati dall‚Äôaccesso alla memoria anzich√© dai <strong>FLOP</strong> (Floating Point Operations Per Second), una misura delle prestazioni computazionali che indica quanti calcoli in virgola mobile un sistema pu√≤ eseguire al secondo. Al contrario, la propagazione in avanti domina l‚Äôinferenza della rete neurale, che corrisponde a una serie di moltiplicazioni matrice-matrice. Senza una retrospettiva del gradiente che richiede molta memoria, le dimensioni dei batch pi√π grandi spingono facilmente l‚Äôinferenza a essere estremamente limitata dal calcolo. Le elevate intensit√† aritmetiche misurate mostrano questo. I tempi di risposta possono essere critici per alcune applicazioni di inferenza, costringendo il fornitore dell‚Äôapplicazione a utilizzare una dimensione di batch inferiore per soddisfare questi requisiti di tempo di risposta, riducendo cos√¨ l‚Äôefficienza dell‚Äôhardware; quindi, le inferenze potrebbero vedere un utilizzo inferiore dell‚Äôhardware.</p>
<p>Le implicazioni sono che il provisioning hardware e i compromessi tra larghezza di banda e FLOP differiscono a seconda che un sistema miri al training o all‚Äôinferenza. I server ad alta produttivit√† e bassa latenza per l‚Äôinferenza dovrebbero enfatizzare la potenza di calcolo anzich√© la memoria, mentre i cluster di training richiedono un‚Äôarchitettura pi√π bilanciata.</p>
<p>Tuttavia, la moltiplicazione di matrici mostra un‚Äôinteressante tensione: la larghezza di banda della memoria dell‚Äôhardware sottostante o le capacit√† di throughput aritmetico possono vincolarla. La capacit√† del sistema di recuperare e fornire dati matriciali rispetto alla sua capacit√† di eseguire operazioni di calcolo determina questa direzione.</p>
<p>Questo fenomeno ha impatti profondi; l‚Äôhardware deve essere progettato giudiziosamente e devono essere prese in considerazione le ottimizzazioni del software. Ottimizzare e bilanciare il calcolo rispetto alla memoria per alleviare questo collo di bottiglia della moltiplicazione di matrici √® fondamentale per un training un deployment efficienti del modello.</p>
<p>Infine, la dimensione del batch pu√≤ avere un impatto sui tassi di convergenza durante l‚Äôaddestramento della rete neurale, un‚Äôaltra considerazione importante. Ad esempio, ci sono generalmente rendimenti decrescenti nei benefici della convergenza con dimensioni di batch estremamente grandi (ad esempio, &gt; 16384). Al contrario, dimensioni di batch estremamente grandi possono essere sempre pi√π vantaggiose da una prospettiva di intensit√† hardware/aritmetica; l‚Äôutilizzo di batch cos√¨ grandi potrebbe non tradursi in una convergenza pi√π rapida rispetto al tempo a causa dei loro benefici decrescenti per la convergenza. Questi compromessi fanno parte delle decisioni di progettazione fondamentali per i sistemi per il tipo di ricerca basata sull‚Äôapprendimento automatico.</p>
</section>
<section id="dimensione-del-batch" class="level4">
<h4 class="anchored" data-anchor-id="dimensione-del-batch">Dimensione del Batch</h4>
<p>La dimensione del batch utilizzata durante l‚Äôaddestramento e l‚Äôinferenza della rete neurale ha un impatto significativo sul fatto che la moltiplicazione di matrici rappresenti un collo di bottiglia computazionale o di memoria. In concreto, la dimensione del batch si riferisce al numero di campioni propagati assieme attraverso la rete in un passaggio avanti/indietro. La moltiplicazione di matrici equivale a dimensioni di matrice maggiori.</p>
<p>In particolare, diamo un‚Äôocchiata all‚Äôintensit√† aritmetica della moltiplicazione di matrici durante l‚Äôaddestramento della rete neurale. Questa misura il rapporto tra operazioni computazionali e trasferimenti di memoria. La moltiplicazione di due matrici di dimensione <span class="math inline">\(N \times M\)</span> e <span class="math inline">\(M \times B\)</span> richiede <span class="math inline">\(N \times M \times B\)</span> operazioni di moltiplicazione-accumulo, ma solo trasferimenti di <span class="math inline">\(N \times M + M \times B\)</span> elementi di matrice.</p>
<p>Man mano che aumentiamo la dimensione del batch <span class="math inline">\(B\)</span>, il numero di operazioni aritmetiche cresce pi√π velocemente dei trasferimenti di memoria. Ad esempio, con una dimensione del batch di 1, abbiamo bisogno di <span class="math inline">\(N \times M\)</span> operazioni e <span class="math inline">\(N + M\)</span> trasferimenti, dando un rapporto di intensit√† aritmetica di circa <span class="math inline">\(\frac{N \times M}{N+M}\)</span>. Ma con una dimensione del batch di grandi dimensioni di 128, il rapporto di intensit√† diventa <span class="math inline">\(\frac{128 \times N \times M}{N \times M + M \times 128} \approx 128\)</span>.</p>
<p>L‚Äôutilizzo di una dimensione del batch pi√π grande sposta il calcolo complessivo da vincolato alla memoria a pi√π vincolato al calcolo. L‚Äôaddestramento IA utilizza grandi dimensioni del batch ed √® generalmente limitato dalle massime prestazioni di calcolo aritmetiche, ovvero l‚ÄôApplicazione 3 in <a href="#fig-roofline" class="quarto-xref">Figura&nbsp;<span>7.7</span></a>. Pertanto, la moltiplicazione di matrici in batch √® molto pi√π intensiva dal punto di vista computazionale rispetto al limite di accesso alla memoria. Ci√≤ ha implicazioni per la progettazione hardware e le ottimizzazioni software, che tratteremo in seguito. L‚Äôintuizione chiave √® che possiamo modificare in modo significativo il profilo computazionale e i colli di bottiglia posti dall‚Äôaddestramento e dall‚Äôinferenza della rete neurale regolando la dimensione del batch.</p>
<div id="fig-roofline" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-roofline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/aitrainingroof.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-roofline-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.7: Modello a profilo a di tetto per il training di IA.
</figcaption>
</figure>
</div>
</section>
<section id="caratteristiche-hardware" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="caratteristiche-hardware">Caratteristiche Hardware</h4>
<p>L‚Äôhardware moderno come CPU e GPU √® altamente ottimizzato per la produttivit√† computazionale piuttosto che per la larghezza di banda della memoria. Ad esempio, le GPU H100 Tensor Core di fascia alta possono fornire oltre 60 TFLOPS di prestazioni a doppia precisione, ma forniscono solo fino a 3 TB/s di larghezza di banda della memoria. Ci√≤ significa che c‚Äô√® uno squilibrio di quasi 20 volte tra unit√† aritmetiche e accesso alla memoria; di conseguenza, per hardware come gli acceleratori GPU, i carichi di lavoro di addestramento della rete neurale devono essere resi il pi√π intensivi possibile dal punto di vista computazionale per utilizzare appieno le risorse disponibili.</p>
<p>Ci√≤ motiva ulteriormente la necessit√† di utilizzare batch di grandi dimensioni durante l‚Äôaddestramento. Quando si utilizza un batch di piccole dimensioni, la moltiplicazione della matrice √® limitata dalla larghezza di banda della memoria, sottoutilizzando le abbondanti risorse di elaborazione. Tuttavia, possiamo spostare il collo di bottiglia verso l‚Äôelaborazione e ottenere un‚Äôintensit√† aritmetica molto pi√π elevata con batch sufficientemente grandi. Ad esempio, potrebbero essere necessari batch di 256 o 512 campioni per saturare una GPU di fascia alta. Lo svantaggio √® che batch pi√π grandi forniscono aggiornamenti dei parametri meno frequenti, il che pu√≤ influire sulla convergenza. Tuttavia, il parametro funge da importante manopola di sintonizzazione per bilanciare le limitazioni di memoria e quelle di elaborazione.</p>
<p>Pertanto, date le architetture di elaborazione-memoria sbilanciate dell‚Äôhardware moderno, l‚Äôimpiego di batch di grandi dimensioni √® essenziale per alleviare i colli di bottiglia e massimizzare la produttivit√†. Come accennato, anche il software e gli algoritmi successivi devono adattarsi a tali dimensioni di batch, poich√© dimensioni di batch pi√π grandi possono avere rendimenti decrescenti verso la convergenza della rete. L‚Äôutilizzo di dimensioni di batch molto piccole pu√≤ portare a un utilizzo non ottimale dell‚Äôhardware, limitando in ultima analisi l‚Äôefficienza del training. L‚Äôaumento di dimensioni dei batch di grandi dimensioni √® un argomento di ricerca esplorato in vari lavori che mirano a eseguire una training su larga scala <span class="citation" data-cites="yang2018imagenet">(<a href="../../../references.it.html#ref-yang2018imagenet" role="doc-biblioref">You et al. 2017</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-yang2018imagenet" class="csl-entry" role="listitem">
You, Yang, Zhao Zhang, Cho-Jui Hsieh, James Demmel, e Kurt Keutzer. 2017. <span>¬´ImageNet Training in Minutes¬ª</span>, settembre. <a href="http://arxiv.org/abs/1709.05011v10">http://arxiv.org/abs/1709.05011v10</a>.
</div></div></section>
<section id="architetture-dei-modelli" class="level4">
<h4 class="anchored" data-anchor-id="architetture-dei-modelli">Architetture dei Modelli</h4>
<p>L‚Äôarchitettura della rete neurale influisce anche sul fatto che la moltiplicazione di matrici rappresenti un collo di bottiglia computazionale o di memoria maggiore durante l‚Äôesecuzione. I trasformatori e gli MLP sono molto pi√π vincolati al calcolo rispetto alle reti neurali convoluzionali CNN. Ci√≤ deriva dai tipi di operazioni di moltiplicazione di matrici coinvolte in ciascun modello. I trasformatori si basano sull‚Äôauto-attenzione, moltiplicando grandi matrici di attivazione per enormi matrici di parametri per correlare gli elementi. Gli MLP impilano layer completamente connessi, richiedendo anche grandi moltiplicazioni matriciali.</p>
<p>Al contrario, i layer convoluzionali nelle CNN hanno una finestra scorrevole che riutilizza attivazioni e parametri nell‚Äôinput, il che significa che sono necessarie meno operazioni matriciali univoche. Tuttavia, le convoluzioni richiedono l‚Äôaccesso ripetuto a piccole parti di input e lo spostamento di somme parziali per popolare ciascuna finestra. Sebbene le operazioni aritmetiche nelle convoluzioni siano intense, questo spostamento di dati e la manipolazione del buffer impongono enormi overhead di accesso alla memoria. Le CNN comprendono diverse fasi a strati, quindi gli output intermedi devono materializzarsi frequentemente nella memoria.</p>
<p>Di conseguenza, l‚Äôaddestramento CNN tende a essere pi√π vincolato alla larghezza di banda della memoria rispetto al limite aritmetico in confronto a Transformers e MLP. Pertanto, il profilo di moltiplicazione della matrice e, a sua volta, il collo di bottiglia posto, varia in modo significativo in base alla scelta del modello. Hardware e sistemi devono essere progettati con un appropriato equilibrio di larghezza di banda di elaborazione-memoria a seconda dell‚Äôimplementazione del modello target. I modelli che si basano maggiormente sull‚Äôattenzione e sui layer MLP richiedono una maggiore produttivit√† aritmetica rispetto alle CNN, il che richiede un‚Äôelevata larghezza di banda della memoria.</p>
</section>
</section>
</section>
<section id="parallelizzazione-del-training" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="parallelizzazione-del-training"><span class="header-section-number">7.11</span> Parallelizzazione del Training</h2>
<p>L‚Äôaddestramento delle reti neurali comporta richieste di calcolo e memoria intensive. L‚Äôalgoritmo di backpropagation per il calcolo dei gradienti e l‚Äôaggiornamento dei pesi consiste in ripetute moltiplicazioni di matrici e operazioni aritmetiche sull‚Äôintero set di dati. Ad esempio, un passaggio di backpropagation scala in complessit√† temporale con <span class="math inline">\(O(num\_parameters \times batch\_size \times sequence\_length)\)</span>.</p>
<p>I requisiti di calcolo aumentano rapidamente con l‚Äôaumento delle dimensioni del modello in parametri e layer. Inoltre, l‚Äôalgoritmo richiede l‚Äôarchiviazione di output di attivazione e parametri del modello per la fase di backward, che cresce con le dimensioni del modello.</p>
<p>I modelli pi√π grandi non possono adattarsi e addestrarsi su un singolo dispositivo acceleratore come una GPU e l‚Äôingombro di memoria diventa proibitivo. Pertanto, dobbiamo parallelizzare l‚Äôaddestramento del modello su pi√π dispositivi per fornire elaborazione e memoria sufficienti per addestrare reti neurali all‚Äôavanguardia.</p>
<p>Come mostrato in <a href="#fig-training-parallelism" class="quarto-xref">Figura&nbsp;<span>7.8</span></a>, i due approcci principali sono il parallelismo dei dati, che replica il modello su pi√π dispositivi suddividendo i dati di input in batch, e il parallelismo del modello, che suddivide l‚Äôarchitettura del modello stesso su diversi dispositivi. Tramite il training in parallelo, possiamo sfruttare maggiori risorse aggregate di elaborazione e memoria per superare le limitazioni del sistema e accelerare i carichi di lavoro di deep learning.</p>
<div id="fig-training-parallelism" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-training-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/aitrainingpara.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-training-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;7.8: Parallelismo dei dati e parallelismo del modello.
</figcaption>
</figure>
</div>
<section id="parallelismo-dei-dati" class="level3" data-number="7.11.1">
<h3 data-number="7.11.1" class="anchored" data-anchor-id="parallelismo-dei-dati"><span class="header-section-number">7.11.1</span> Parallelismo dei Dati</h3>
<p>La parallelizzazione dei dati √® un approccio comune per parallelizzare il training di apprendimento automatico su pi√π unit√† di elaborazione, come GPU o risorse di elaborazione distribuite. Il set di dati di addestramento √® suddiviso in batch nel parallelismo dei dati e un‚Äôunit√† di elaborazione separata elabora ogni batch. I parametri del modello vengono poi aggiornati in base ai gradienti calcolati dall‚Äôelaborazione di ogni batch. Ecco una descrizione dettagliata della parallelizzazione dei dati per il training ML:</p>
<ol type="1">
<li><p><strong>Divisione del Dataset:</strong> Il set di dati di addestramento √® suddiviso in batch pi√π piccoli, ciascuno contenente un sottoinsieme degli esempi di training.</p></li>
<li><p><strong>Replica del Modello:</strong> Il modello di rete neurale √® replicato su tutte le unit√† di elaborazione e ogni unit√† di elaborazione ha la sua copia.</p></li>
<li><p><strong>Calcolo Parallelo:</strong> Ogni unit√† di elaborazione prende un batch diverso e calcola in modo indipendente i passaggi in forward e backward. Durante il passaggio forward [in avanti], il modello fa delle previsioni sui dati di input. La funzione di loss [perdita] determina i gradienti per i parametri del modello durante il passaggio backward [all‚Äôindietro].</p></li>
<li><p><strong>Aggregazione dei Gradienti:</strong> Dopo l‚Äôelaborazione dei rispettivi batch, i gradienti di ogni unit√† di elaborazione vengono aggregati. I metodi di aggregazione comuni includono la sommatoria o la media dei gradienti.</p></li>
<li><p><strong>Aggiornamento dei Parametri:</strong> I gradienti aggregati aggiornano i parametri del modello. L‚Äôaggiornamento pu√≤ essere eseguito utilizzando algoritmi di ottimizzazione come SGD o varianti come Adam.</p></li>
<li><p><strong>Sincronizzazione:</strong> Dopo l‚Äôaggiornamento, tutte le unit√† di elaborazione sincronizzano i parametri del modello, assicurandosi che ciascuna ne abbia la versione pi√π recente.</p></li>
</ol>
<p>I passaggi precedenti vengono ripetuti per diverse iterazioni o fino alla convergenza.</p>
<p>Prendiamo un esempio specifico. Abbiamo 256 dimensioni di batch e 8 GPU; ogni GPU ricever√† un micro-batch di 32 campioni. I loro passaggi forward e backward calcolano perdite e gradienti solo in base ai 32 campioni locali. I gradienti vengono aggregati tra i dispositivi con un server dei parametri o una libreria di comunicazioni collettiva per ottenere il gradiente effettivo per il batch globale. Gli aggiornamenti dei pesi avvengono indipendentemente su ogni GPU in base a questi gradienti. Dopo un numero configurato di iterazioni, i pesi aggiornati si sincronizzano e si equalizzano tra i dispositivi prima di passare alle iterazioni successive.</p>
<p>Il parallelismo dei dati √® efficace quando il modello √® grande e il set di dati √® sostanziale, poich√© consente l‚Äôelaborazione parallela di diverse parti dei dati. √à ampiamente utilizzato in framework e librerie di deep learning che supportano il training distribuito, come TensorFlow e PyTorch. Tuttavia, per garantire una parallelizzazione efficiente, √® necessario prestare attenzione a gestire problemi come l sovraccarico della comunicazione, bilanciamento del carico e sincronizzazione.</p>
</section>
<section id="parallelismo-del-modello" class="level3" data-number="7.11.2">
<h3 data-number="7.11.2" class="anchored" data-anchor-id="parallelismo-del-modello"><span class="header-section-number">7.11.2</span> Parallelismo del Modello</h3>
<p>Il parallelismo del modello si riferisce alla distribuzione del modello di rete neurale su pi√π dispositivi anzich√© alla replica del modello completo come il parallelismo dei dati. Ci√≤ √® particolarmente utile quando un modello √® troppo grande per essere inserito nella memoria di una singola GPU o di un dispositivo acceleratore. Sebbene ci√≤ potrebbe non essere specificamente applicabile per casi d‚Äôuso embedded o TinyML poich√© la maggior parte dei modelli √® relativamente piccola, √® comunque utile saperlo.</p>
<p>Nell‚Äôaddestramento parallelo del modello, diverse parti o layer del modello vengono assegnati a dispositivi separati. Le attivazioni di input e gli output intermedi vengono partizionati e passati tra questi dispositivi durante i passaggi forward e backward per coordinare i calcoli del gradiente tra le partizioni del modello.</p>
<p>Il ‚Äúfootprint‚Äù [impronta] di memoria e le operazioni di calcolo vengono distribuite suddividendo l‚Äôarchitettura del modello su pi√π dispositivi anzich√© concentrarsi su uno. Ci√≤ consente l‚Äôaddestramento di modelli molto grandi con miliardi di parametri che altrimenti supererebbero la capacit√† di un singolo dispositivo. Esistono diversi modi in cui possiamo eseguire il partizionamento:</p>
<ul>
<li><p><strong>Parallelismo di Layer:</strong> I layer consecutivi sono distribuiti su dispositivi diversi. Ad esempio, il dispositivo 1 contiene i layer 1-3; il dispositivo 2 contiene i layer 4-6. Le attivazioni di output dal layer 3 verrebbero trasferite al dispositivo 2 per avviare i layer successivi per i calcoli della fase di forward.</p></li>
<li><p><strong>Parallelismo a Livello di Filtro:</strong> Nei layer convoluzionali, i filtri di output possono essere suddivisi tra pi√π dispositivi. Ogni dispositivo calcola gli output di attivazione per un sottoinsieme di filtri, che vengono concatenati prima di propagarsi ulteriormente.</p></li>
<li><p><strong>Parallelismo Spaziale:</strong> Le immagini di input vengono divise spazialmente, quindi ogni dispositivo elabora una determinata regione come il quarto in alto a sinistra delle immagini. Le regioni di output si combinano poi per formare l‚Äôoutput completo.</p></li>
</ul>
<p>Inoltre, le combinazioni ibride possono suddividere il modello a livello di layer e i dati in batch. Il tipo appropriato di parallelismo del modello dipende dai vincoli specifici dell‚Äôarchitettura neurale e dalla configurazione hardware. Ottimizzare il partizionamento e la comunicazione per la topologia del modello √® fondamentale per ridurre al minimo il sovraccarico.</p>
<p>Tuttavia, poich√© le parti del modello vengono eseguite su dispositivi fisicamente separati, devono comunicare e sincronizzare i loro parametri durante ogni fase di addestramento. La fase di backward deve garantire che gli aggiornamenti del gradiente si propaghino accuratamente tra le partizioni del modello. Quindi, il coordinamento e l‚Äôinterconnessione ad alta velocit√† tra i dispositivi sono fondamentali per ottimizzare le prestazioni dell‚Äôaddestramento parallelo. Sono necessari dei buoni protocolli di partizionamento e comunicazione per ridurre al minimo il sovraccarico di trasferimento.</p>
</section>
<section id="confronto" class="level3" data-number="7.11.3">
<h3 data-number="7.11.3" class="anchored" data-anchor-id="confronto"><span class="header-section-number">7.11.3</span> Confronto</h3>
<p>Riassumendo, <a href="#tbl-parallelism" class="quarto-xref">Tabella&nbsp;<span>7.5</span></a> illustra alcune delle caratteristiche chiave per confrontare il parallelismo dei dati e quello dei modelli.</p>
<div id="tbl-parallelism" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;7.5: Confronto tra parallelismo dei dati e parallelismo del modello.
</figcaption>
<div aria-describedby="tbl-parallelism-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 45%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Caratteristica</th>
<th style="text-align: left;">Parallelismo dei dati</th>
<th style="text-align: left;">Parallelismo del modello</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Definizione</td>
<td style="text-align: left;">Distribuisce i dati tra i dispositivi con repliche</td>
<td style="text-align: left;">Distribuisce il modello tra i dispositivi</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obiettivo</td>
<td style="text-align: left;">Accelera il training tramite il ridimensionamento del calcolo</td>
<td style="text-align: left;">Abilita un training del modello pi√π ampio</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Metodo di Ridimensionamento</td>
<td style="text-align: left;">Dispositivi/workers in scala</td>
<td style="text-align: left;">Dimensioni modello in scala</td>
</tr>
<tr class="even">
<td style="text-align: left;">Vincolo Principale</td>
<td style="text-align: left;">Dimensione del modello per ogni dispositivo</td>
<td style="text-align: left;">Overhead di coordinamento dispositivo</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Requisiti Hardware</td>
<td style="text-align: left;">Pi√π GPU/TPU</td>
<td style="text-align: left;">Spesso interconnessione specializzata</td>
</tr>
<tr class="even">
<td style="text-align: left;">Difficolt√† Principale</td>
<td style="text-align: left;">Sincronizzazione dei parametri</td>
<td style="text-align: left;">Partizionamento e comunicazione complicati</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Tipi</td>
<td style="text-align: left;">N/D</td>
<td style="text-align: left;">Per livello, per filtro, spaziale</td>
</tr>
<tr class="even">
<td style="text-align: left;">Complessit√† del Codice</td>
<td style="text-align: left;">Modifiche minime</td>
<td style="text-align: left;">Intervento pi√π significativa sul modello</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Librerie Popolari</td>
<td style="text-align: left;">Horovod, PyTorch Distributed</td>
<td style="text-align: left;">Mesh TensorFlow</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="conclusione" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="conclusione"><span class="header-section-number">7.12</span> Conclusione</h2>
<p>In questo capitolo abbiamo trattato le basi fondamentali che consentono un training efficace dei modelli di intelligenza artificiale. Abbiamo esplorato concetti matematici come funzioni di perdita, backpropagation e discesa del gradiente che rendono possibile l‚Äôottimizzazione delle reti neurali. Abbiamo anche discusso tecniche pratiche per sfruttare i dati di training, la regolarizzazione, la messa a punto degli iperparametri, l‚Äôinizializzazione dei pesi e strategie di parallelizzazione distribuita che migliorano convergenza, generalizzazione e scalabilit√†.</p>
<p>Queste metodologie costituiscono il fondamento attraverso cui √® stato raggiunto il successo del deep learning nell‚Äôultimo decennio. Padroneggiare questi fondamenti prepara i professionisti a progettare sistemi e perfezionare modelli su misura per il loro contesto. Tuttavia, man mano che modelli e set di dati crescono in modo esponenziale, i sistemi di training devono ottimizzare parametri come tempo, costo e ‚Äúcarbon footprint‚Äù [impatto ambientale]. Il ridimensionamento hardware tramite grosse warehouse consente un throughput computazionale enorme, ma le ottimizzazioni relative a efficienza e specializzazione saranno fondamentali. Tecniche software come compressione e sfruttamento delle matrici sparse possono aumentare i guadagni hardware. Ne discuteremo diverse nei prossimi capitoli.</p>
<p>Nel complesso, i fondamenti trattati in questo capitolo preparano i professionisti a costruire, perfezionare e distribuire modelli. Tuttavia, le competenze interdisciplinari che abbracciano teoria, sistemi e hardware differenzieranno gli esperti in grado di portare l‚ÄôIA al livello successivo in modo sostenibile e responsabile, come richiesto dalla societ√†. Comprendere l‚Äôefficienza insieme all‚Äôaccuratezza costituisce l‚Äôapproccio ingegneristico bilanciato necessario per addestrare sistemi intelligenti che si integrano senza problemi in molti contesti del mondo reale.</p>
</section>
<section id="sec-ai-training-resource" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="sec-ai-training-resource"><span class="header-section-number">7.13</span> Risorse</h2>
<p>Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Stiamo lavorando costantemente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale secondo il proprio ritmo. Incoraggiamo studenti e docenti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1X92JqVkUY7k6yJXQcT2u83dpdrx5UzGFAJkkDMDfKe0/edit#slide=id.g94db9f9f78_0_2">Thinking About Loss.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1x3xbZHo4VtaZgoXfueCbOGGXuWRYj0nOsKwAAoGsrD0/edit#slide=id.g94db9f9f78_0_2">Minimizing Loss.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1G56D0-qG9YWnzQQeje9LMpcLSotMgBCiMyfj53yz7lY/edit?usp=drive_link">Training, Validation, and Test Data.</a></p></li>
<li><p>Continuous Training:</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1jtkcAnFot3VoY6dm8wARtIRPhM1Cfoe8S_8lMMox2To/edit?usp=drive_link">Retraining Trigger.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1vW4jFv5mqpLo2_G2JXQrKLPMNoWoOvSXhFYotUbg3B0/edit?usp=drive_link">Data Processing Overview.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1e7_JGZH2X9Ha99-UsFy0bgpC4g-Msq1zXogrbQVBKfQ/edit?usp=drive_link">Data Ingestion.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1PjilfceaDFp-spnZpTyqfcdvTbbfT0_95Hteqr-twk8/edit?usp=drive_link">Data Validation.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1cWMcFTl30Yl1XBYJZcND1USYKtS05TkfFkvwxfImOfY/edit?usp=drive_link">Data Transformation.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1SYjvCe_LZ0S3F5MdiDvAiGflpWmffmq7vAgruyXtaHk/edit?usp=drive_link&amp;resourcekey=0-uu6gpFHmuCx56J89oguWMQ">Training with AutoML.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/12Hhq1WGobzsLdVUzRRD-S1Mm2Z5dINGWtbB6RBmv87c/edit?usp=drive_link">Continuous Training with Transfer Learning.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1ShpXTuUsf44TW0vXuv1Mk_REeRcAIpQRO2J2EFuWP0g/edit?usp=drive_link&amp;resourcekey=0-6wnzPJ0mFlnJnpzTMGzN3w">Continuous Training Use Case Metrics.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/16kQd5BBCA41gvUauznQRd1ZdW5NI6OgiJVB9cuEmk14/edit#slide=id.g94db9f9f78_0_2">Continuous Training Impact on MLOps.</a></p></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="#vid-train-dev-test" class="quarto-xref">Video&nbsp;<span>7.1</span></a></p></li>
<li><p><a href="#vid-bias" class="quarto-xref">Video&nbsp;<span>7.2</span></a></p></li>
<li><p><a href="#vid-hyperparameter" class="quarto-xref">Video&nbsp;<span>7.3</span></a></p></li>
<li><p><a href="#vid-regularization" class="quarto-xref">Video&nbsp;<span>7.4</span></a></p></li>
<li><p><a href="#vid-whyreg" class="quarto-xref">Video&nbsp;<span>7.5</span></a></p></li>
<li><p><a href="#vid-dropout" class="quarto-xref">Video&nbsp;<span>7.6</span></a></p></li>
<li><p><a href="#vid-otherregs" class="quarto-xref">Video&nbsp;<span>7.7</span></a></p></li>
<li><p><a href="#vid-weightinit" class="quarto-xref">Video&nbsp;<span>7.8</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.</p>
<ul>
<li><p><a href="#exr-nn" class="quarto-xref">Esercizio&nbsp;<span>7.1</span></a></p></li>
<li><p><a href="#exr-hpt" class="quarto-xref">Esercizio&nbsp;<span>7.2</span></a></p></li>
<li><p><a href="#exr-r" class="quarto-xref">Esercizio&nbsp;<span>7.3</span></a></p></li>
<li><p><a href="#exr-wi" class="quarto-xref">Esercizio&nbsp;<span>7.5</span></a></p></li>
<li><p><a href="#exr-af" class="quarto-xref">Esercizio&nbsp;<span>7.4</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Laboratori
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Oltre agli esercizi, offriamo una serie di laboratori pratici che consentono agli studenti di acquisire esperienza pratica con le tecnologie di intelligenza artificiale embedded. Questi laboratori forniscono una guida passo dopo passo, consentendo agli studenti di sviluppare le proprie competenze in un ambiente strutturato e di supporto. Siamo lieti di annunciare che presto saranno disponibili nuovi laboratori, che arricchiranno ulteriormente l‚Äôesperienza di apprendimento.</p>
<ul>
<li><em>Prossimamente.</em></li>
</ul>
</div>
</div>
</div>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../contents/core/frameworks/frameworks.it.html" class="pagination-link" aria-label="Framework di IA">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../contents/core/efficient_ai/efficient_ai.it.html" class="pagination-link" aria-label="IA Efficiente">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University). Traduzione di <a href="https://github.com/BravoBaldo">Baldassarre Cesarano</a></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/core/training/training.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/core/training/training.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>