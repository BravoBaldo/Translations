<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12&nbsp; Apprendimento On-Device ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../contents/ops/ops.it.html" rel="next">
<link href="../../contents/benchmarking/benchmarking.it.html" rel="prev">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/benchmarking/benchmarking.it.html">Deployment</a></li><li class="breadcrumb-item"><a href="../../contents/ondevice_learning/ondevice_learning.it.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2d6cdf6fc58f1105ce2a5c5c28a11153" class="alert alert-info hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>üåü Aiutaci a raggiungere 1.000 stelle GitHub! üåü Per ogni 25 stelle, Arduino e SEEED doneranno una NiclaVision o una XIAO ESP32S3 per l‚Äôistruzione sull‚Äôintelligenza artificiale. <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per una ‚≠ê</a></p>
</div></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">PREFAZIONE</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dedication.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/contributors.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collaboratori e Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/copyright.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">PARTE PRINCIPALE</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Nozioni Fondamentali</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Workflow</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di Intelligenza Artificiale</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Training</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Argomenti Avanzati</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/generative_ai/generative_ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Generative AI</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Impatto Sociale</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ai_for_good/ai_for_good.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Chiusura</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/conclusion/conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusion</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">LABS</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/labs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/getting_started.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Getting Started</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/arduino/nicla_vision/nicla_vision.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/setup/setup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Image Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Object Detection</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/kws/kws.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Motion Classification and Anomaly Detection</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/shared/shared.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Shared Labs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/shared/kws_feature_eng/kws_feature_eng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">DSP Spectral Features</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true">
 <span class="menu-text">REFERENCES</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tools</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/learning_resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Resources</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/community.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Communities</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/case_studies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Case Studies</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">12.1</span> Introduzione</a></li>
  <li><a href="#vantaggi-e-limiti" id="toc-vantaggi-e-limiti" class="nav-link" data-scroll-target="#vantaggi-e-limiti"><span class="header-section-number">12.2</span> Vantaggi e Limiti</a>
  <ul>
  <li><a href="#vantaggi" id="toc-vantaggi" class="nav-link" data-scroll-target="#vantaggi"><span class="header-section-number">12.2.1</span> Vantaggi</a>
  <ul class="collapse">
  <li><a href="#privacy-e-sicurezza-dei-dati" id="toc-privacy-e-sicurezza-dei-dati" class="nav-link" data-scroll-target="#privacy-e-sicurezza-dei-dati">Privacy e Sicurezza dei Dati</a></li>
  <li><a href="#normativa-di-conformit√†" id="toc-normativa-di-conformit√†" class="nav-link" data-scroll-target="#normativa-di-conformit√†">Normativa di Conformit√†</a></li>
  <li><a href="#riduzione-della-larghezza-di-banda-dei-costi-e-maggiore-efficienza" id="toc-riduzione-della-larghezza-di-banda-dei-costi-e-maggiore-efficienza" class="nav-link" data-scroll-target="#riduzione-della-larghezza-di-banda-dei-costi-e-maggiore-efficienza">Riduzione della Larghezza di Banda, dei Costi e Maggiore Efficienza</a></li>
  </ul></li>
  <li><a href="#limitazioni" id="toc-limitazioni" class="nav-link" data-scroll-target="#limitazioni"><span class="header-section-number">12.2.2</span> Limitazioni</a>
  <ul class="collapse">
  <li><a href="#risorse-di-elaborazione" id="toc-risorse-di-elaborazione" class="nav-link" data-scroll-target="#risorse-di-elaborazione">Risorse di elaborazione</a></li>
  <li><a href="#dimensioni-accuratezza-e-generalizzazione-del-dataset" id="toc-dimensioni-accuratezza-e-generalizzazione-del-dataset" class="nav-link" data-scroll-target="#dimensioni-accuratezza-e-generalizzazione-del-dataset">Dimensioni, Accuratezza e Generalizzazione del Dataset</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#adattamento-on-device" id="toc-adattamento-on-device" class="nav-link" data-scroll-target="#adattamento-on-device"><span class="header-section-number">12.3</span> Adattamento On-device</a>
  <ul>
  <li><a href="#riduzione-della-complessit√†-del-modello" id="toc-riduzione-della-complessit√†-del-modello" class="nav-link" data-scroll-target="#riduzione-della-complessit√†-del-modello"><span class="header-section-number">12.3.1</span> Riduzione della Complessit√† del Modello</a>
  <ul class="collapse">
  <li><a href="#algoritmi-ml-tradizionali" id="toc-algoritmi-ml-tradizionali" class="nav-link" data-scroll-target="#algoritmi-ml-tradizionali">Algoritmi ML tradizionali</a></li>
  <li><a href="#pruning" id="toc-pruning" class="nav-link" data-scroll-target="#pruning">Pruning</a></li>
  <li><a href="#riduzione-della-complessit√†-dei-modelli-di-deep-learning" id="toc-riduzione-della-complessit√†-dei-modelli-di-deep-learning" class="nav-link" data-scroll-target="#riduzione-della-complessit√†-dei-modelli-di-deep-learning">Riduzione della Complessit√† dei Modelli di Deep Learning</a></li>
  </ul></li>
  <li><a href="#modifica-dei-processi-di-ottimizzazione" id="toc-modifica-dei-processi-di-ottimizzazione" class="nav-link" data-scroll-target="#modifica-dei-processi-di-ottimizzazione"><span class="header-section-number">12.3.2</span> Modifica dei Processi di Ottimizzazione</a>
  <ul class="collapse">
  <li><a href="#quantization-aware-scaling" id="toc-quantization-aware-scaling" class="nav-link" data-scroll-target="#quantization-aware-scaling">Quantization-Aware Scaling</a></li>
  <li><a href="#aggiornamenti-sparsi" id="toc-aggiornamenti-sparsi" class="nav-link" data-scroll-target="#aggiornamenti-sparsi">Aggiornamenti Sparsi</a></li>
  <li><a href="#training-layer-wise" id="toc-training-layer-wise" class="nav-link" data-scroll-target="#training-layer-wise">Training Layer-Wise</a></li>
  <li><a href="#trading-computation-for-memory" id="toc-trading-computation-for-memory" class="nav-link" data-scroll-target="#trading-computation-for-memory">Trading Computation for Memory</a></li>
  </ul></li>
  <li><a href="#sviluppo-di-nuove-rappresentazioni-dei-dati" id="toc-sviluppo-di-nuove-rappresentazioni-dei-dati" class="nav-link" data-scroll-target="#sviluppo-di-nuove-rappresentazioni-dei-dati"><span class="header-section-number">12.3.3</span> Sviluppo di Nuove Rappresentazioni dei Dati</a>
  <ul class="collapse">
  <li><a href="#compressione-dei-dati" id="toc-compressione-dei-dati" class="nav-link" data-scroll-target="#compressione-dei-dati">Compressione dei Dati</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#il-transfer-learning" id="toc-il-transfer-learning" class="nav-link" data-scroll-target="#il-transfer-learning"><span class="header-section-number">12.4</span> Il Transfer Learning</a>
  <ul>
  <li><a href="#specializzazione-pre-distribuzione" id="toc-specializzazione-pre-distribuzione" class="nav-link" data-scroll-target="#specializzazione-pre-distribuzione"><span class="header-section-number">12.4.1</span> Specializzazione Pre-Distribuzione</a></li>
  <li><a href="#adattamento-post-distribuzione" id="toc-adattamento-post-distribuzione" class="nav-link" data-scroll-target="#adattamento-post-distribuzione"><span class="header-section-number">12.4.2</span> Adattamento Post-Distribuzione</a></li>
  <li><a href="#vantaggi-1" id="toc-vantaggi-1" class="nav-link" data-scroll-target="#vantaggi-1"><span class="header-section-number">12.4.3</span> Vantaggi</a></li>
  <li><a href="#concetti-fondamentali" id="toc-concetti-fondamentali" class="nav-link" data-scroll-target="#concetti-fondamentali"><span class="header-section-number">12.4.4</span> Concetti Fondamentali</a>
  <ul class="collapse">
  <li><a href="#attivit√†-di-origine-e-di-destinazione" id="toc-attivit√†-di-origine-e-di-destinazione" class="nav-link" data-scroll-target="#attivit√†-di-origine-e-di-destinazione">Attivit√† di Origine e di Destinazione</a></li>
  <li><a href="#trasferimento-della-rappresentazione" id="toc-trasferimento-della-rappresentazione" class="nav-link" data-scroll-target="#trasferimento-della-rappresentazione">Trasferimento della Rappresentazione</a></li>
  <li><a href="#finetuning" id="toc-finetuning" class="nav-link" data-scroll-target="#finetuning">Finetuning</a></li>
  <li><a href="#estrazione-delle-feature" id="toc-estrazione-delle-feature" class="nav-link" data-scroll-target="#estrazione-delle-feature">Estrazione delle Feature</a></li>
  </ul></li>
  <li><a href="#tipi-di-apprendimento-tramite-trasferimento" id="toc-tipi-di-apprendimento-tramite-trasferimento" class="nav-link" data-scroll-target="#tipi-di-apprendimento-tramite-trasferimento"><span class="header-section-number">12.4.5</span> Tipi di Apprendimento Tramite Trasferimento</a>
  <ul class="collapse">
  <li><a href="#apprendimento-tramite-trasferimento-induttivo" id="toc-apprendimento-tramite-trasferimento-induttivo" class="nav-link" data-scroll-target="#apprendimento-tramite-trasferimento-induttivo">Apprendimento Tramite Trasferimento Induttivo</a></li>
  <li><a href="#apprendimento-tramite-trasferimento-transduttivo" id="toc-apprendimento-tramite-trasferimento-transduttivo" class="nav-link" data-scroll-target="#apprendimento-tramite-trasferimento-transduttivo">Apprendimento Tramite Trasferimento Transduttivo</a></li>
  <li><a href="#apprendimento-con-trasferimento-non-supervisionato" id="toc-apprendimento-con-trasferimento-non-supervisionato" class="nav-link" data-scroll-target="#apprendimento-con-trasferimento-non-supervisionato">Apprendimento con Trasferimento Non Supervisionato</a></li>
  <li><a href="#confronto-e-compromessi" id="toc-confronto-e-compromessi" class="nav-link" data-scroll-target="#confronto-e-compromessi">Confronto e Compromessi</a></li>
  </ul></li>
  <li><a href="#vincoli-e-considerazioni" id="toc-vincoli-e-considerazioni" class="nav-link" data-scroll-target="#vincoli-e-considerazioni"><span class="header-section-number">12.4.6</span> Vincoli e Considerazioni</a>
  <ul class="collapse">
  <li><a href="#somiglianza-dei-domini" id="toc-somiglianza-dei-domini" class="nav-link" data-scroll-target="#somiglianza-dei-domini">Somiglianza dei Domini</a></li>
  <li><a href="#similarit√†-dellattivit√†" id="toc-similarit√†-dellattivit√†" class="nav-link" data-scroll-target="#similarit√†-dellattivit√†">Similarit√† dell‚ÄôAttivit√†</a></li>
  <li><a href="#qualit√†-e-quantit√†-dei-dati" id="toc-qualit√†-e-quantit√†-dei-dati" class="nav-link" data-scroll-target="#qualit√†-e-quantit√†-dei-dati">Qualit√† e Quantit√† dei Dati</a></li>
  <li><a href="#sovrapposizione-dello-spazio-delle-feature" id="toc-sovrapposizione-dello-spazio-delle-feature" class="nav-link" data-scroll-target="#sovrapposizione-dello-spazio-delle-feature">Sovrapposizione dello Spazio delle Feature</a></li>
  <li><a href="#complessit√†-del-modello" id="toc-complessit√†-del-modello" class="nav-link" data-scroll-target="#complessit√†-del-modello">Complessit√† del Modello</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec-fl" id="toc-sec-fl" class="nav-link" data-scroll-target="#sec-fl"><span class="header-section-number">12.5</span> Apprendimento Automatico Federato</a>
  <ul>
  <li><a href="#efficienza-della-comunicazione" id="toc-efficienza-della-comunicazione" class="nav-link" data-scroll-target="#efficienza-della-comunicazione"><span class="header-section-number">12.5.1</span> Efficienza della Comunicazione</a></li>
  <li><a href="#compressione-del-modello" id="toc-compressione-del-modello" class="nav-link" data-scroll-target="#compressione-del-modello"><span class="header-section-number">12.5.2</span> Compressione del Modello</a></li>
  <li><a href="#condivisione-selettiva-degli-aggiornamenti" id="toc-condivisione-selettiva-degli-aggiornamenti" class="nav-link" data-scroll-target="#condivisione-selettiva-degli-aggiornamenti"><span class="header-section-number">12.5.3</span> Condivisione Selettiva degli Aggiornamenti</a></li>
  <li><a href="#aggregazione-ottimizzata" id="toc-aggregazione-ottimizzata" class="nav-link" data-scroll-target="#aggregazione-ottimizzata"><span class="header-section-number">12.5.4</span> Aggregazione Ottimizzata</a></li>
  <li><a href="#gestione-dei-dati-non-iid" id="toc-gestione-dei-dati-non-iid" class="nav-link" data-scroll-target="#gestione-dei-dati-non-iid"><span class="header-section-number">12.5.5</span> Gestione dei Dati non-IID</a></li>
  <li><a href="#selezione-del-client" id="toc-selezione-del-client" class="nav-link" data-scroll-target="#selezione-del-client"><span class="header-section-number">12.5.6</span> Selezione del Client</a></li>
  <li><a href="#un-esempio-di-apprendimento-federato-distribuito-g-board" id="toc-un-esempio-di-apprendimento-federato-distribuito-g-board" class="nav-link" data-scroll-target="#un-esempio-di-apprendimento-federato-distribuito-g-board"><span class="header-section-number">12.5.7</span> Un Esempio di Apprendimento Federato Distribuito: G board</a></li>
  <li><a href="#benchmarking-per-lapprendimento-federato-medperf" id="toc-benchmarking-per-lapprendimento-federato-medperf" class="nav-link" data-scroll-target="#benchmarking-per-lapprendimento-federato-medperf"><span class="header-section-number">12.5.8</span> Benchmarking per l‚ÄôApprendimento Federato: MedPerf</a></li>
  </ul></li>
  <li><a href="#problemi-di-sicurezza" id="toc-problemi-di-sicurezza" class="nav-link" data-scroll-target="#problemi-di-sicurezza"><span class="header-section-number">12.6</span> Problemi di Sicurezza</a>
  <ul>
  <li><a href="#avvelenamento-dei-dati" id="toc-avvelenamento-dei-dati" class="nav-link" data-scroll-target="#avvelenamento-dei-dati"><span class="header-section-number">12.6.1</span> Avvelenamento dei Dati</a></li>
  <li><a href="#attacchi-avversari" id="toc-attacchi-avversari" class="nav-link" data-scroll-target="#attacchi-avversari"><span class="header-section-number">12.6.2</span> Attacchi Avversari</a></li>
  <li><a href="#inversione-del-modello" id="toc-inversione-del-modello" class="nav-link" data-scroll-target="#inversione-del-modello"><span class="header-section-number">12.6.3</span> Inversione del Modello</a></li>
  <li><a href="#problemi-di-sicurezza-dellapprendimento-on-device" id="toc-problemi-di-sicurezza-dellapprendimento-on-device" class="nav-link" data-scroll-target="#problemi-di-sicurezza-dellapprendimento-on-device"><span class="header-section-number">12.6.4</span> Problemi di Sicurezza dell‚ÄôApprendimento On-Device</a></li>
  <li><a href="#attenuazione-dei-rischi-dellapprendimento-on-device" id="toc-attenuazione-dei-rischi-dellapprendimento-on-device" class="nav-link" data-scroll-target="#attenuazione-dei-rischi-dellapprendimento-on-device"><span class="header-section-number">12.6.5</span> Attenuazione dei Rischi dell‚ÄôApprendimento On-Device</a></li>
  <li><a href="#protezione-dei-dati-di-training" id="toc-protezione-dei-dati-di-training" class="nav-link" data-scroll-target="#protezione-dei-dati-di-training"><span class="header-section-number">12.6.6</span> Protezione dei Dati di Training</a>
  <ul class="collapse">
  <li><a href="#crittografia" id="toc-crittografia" class="nav-link" data-scroll-target="#crittografia">Crittografia</a></li>
  <li><a href="#privacy-differenziale" id="toc-privacy-differenziale" class="nav-link" data-scroll-target="#privacy-differenziale">Privacy Differenziale</a></li>
  <li><a href="#rilevamento-delle-anomalie" id="toc-rilevamento-delle-anomalie" class="nav-link" data-scroll-target="#rilevamento-delle-anomalie">Rilevamento delle Anomalie</a></li>
  <li><a href="#validazione-dei-dati-di-input" id="toc-validazione-dei-dati-di-input" class="nav-link" data-scroll-target="#validazione-dei-dati-di-input">Validazione dei Dati di Input</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#framework-di-training-on-device" id="toc-framework-di-training-on-device" class="nav-link" data-scroll-target="#framework-di-training-on-device"><span class="header-section-number">12.7</span> Framework di Training On-Device</a>
  <ul>
  <li><a href="#tiny-training-engine" id="toc-tiny-training-engine" class="nav-link" data-scroll-target="#tiny-training-engine"><span class="header-section-number">12.7.1</span> Tiny Training Engine</a></li>
  <li><a href="#tiny-transfer-learning" id="toc-tiny-transfer-learning" class="nav-link" data-scroll-target="#tiny-transfer-learning"><span class="header-section-number">12.7.2</span> Tiny Transfer Learning</a></li>
  <li><a href="#tiny-train" id="toc-tiny-train" class="nav-link" data-scroll-target="#tiny-train"><span class="header-section-number">12.7.3</span> Tiny Train</a></li>
  <li><a href="#confronto" id="toc-confronto" class="nav-link" data-scroll-target="#confronto"><span class="header-section-number">12.7.4</span> Confronto</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione"><span class="header-section-number">12.8</span> Conclusione</a></li>
  <li><a href="#sec-on-device-learning-resource" id="toc-sec-on-device-learning-resource" class="nav-link" data-scroll-target="#sec-on-device-learning-resource"><span class="header-section-number">12.9</span> Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/ondevice_learning/ondevice_learning.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/ondevice_learning/ondevice_learning.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/benchmarking/benchmarking.it.html">Deployment</a></li><li class="breadcrumb-item"><a href="../../contents/ondevice_learning/ondevice_learning.it.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-ondevice_learning" class="quarto-section-identifier"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Risorse: <a href="#sec-on-device-learning-resource">Slide</a>, <a href="#sec-on-device-learning-resource">Video</a>, <a href="#sec-on-device-learning-resource">Esercizi</a>, <a href="#sec-on-device-learning-resource">Laboratori</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/cover_ondevice_learning.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E 3 Prompt: Disegno di uno smartphone con i suoi componenti interni esposti, che mostra diversi ingegneri in miniatura di diversi sessi e tonalit√† di pelle che lavorano attivamente sul modello di ML. Gli ingegneri, tra cui uomini, donne e individui non binari, stanno regolando i parametri, riparando le connessioni e migliorando la rete al volo. I dati fluiscono nel modello ML, vengono elaborati in tempo reale e generano inferenze di output.</em></figcaption>
</figure>
</div>
<p>L‚Äôapprendimento ‚ÄúOn-device‚Äù [sul dispositivo] rappresenta un‚Äôinnovazione significativa per i dispositivi IoT embedded ed edge, consentendo ai modelli di addestrarsi e aggiornarsi direttamente su piccoli dispositivi locali. Ci√≤ contrasta con i metodi tradizionali, in cui i modelli vengono addestrati su ampie risorse di cloud computing prima della distribuzione. Con l‚Äôapprendimento On-Device, dispositivi come smart speaker, dispositivi indossabili e sensori industriali possono perfezionare i modelli in tempo reale in base ai dati locali senza dover trasmettere dati esternamente. Ad esempio, uno smart speaker con comando vocale potrebbe apprendere e adattarsi ai modelli di linguaggio e al vocabolario del suo proprietario direttamente sul dispositivo. Tuttavia, non esiste un ‚Äúpranzo gratis‚Äù; pertanto, in questo capitolo, discuteremo sia i vantaggi che i limiti dell‚Äôapprendimento sul dispositivo.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Obiettivi dell‚ÄôApprendimento
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Comprendere l‚Äôapprendimento sul dispositivo e in che modo differisce dal training basato su cloud</p></li>
<li><p>Riconoscere i vantaggi e i limiti dell‚Äôapprendimento sul dispositivo</p></li>
<li><p>Esaminare le strategie per adattare i modelli tramite riduzione della complessit√†, ottimizzazione e compressione dei dati</p></li>
<li><p>Comprendere concetti correlati come apprendimento federato e apprendimento tramite trasferimento</p></li>
<li><p>Analizzare le implicazioni della sicurezza dell‚Äôapprendimento sul dispositivo e delle strategie di mitigazione</p></li>
</ul>
</div>
</div>
<section id="introduzione" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">12.1</span> Introduzione</h2>
<p>L‚Äôapprendimento su dispositivo si riferisce all‚Äôaddestramento di modelli ML direttamente sul dispositivo in cui vengono distribuiti, al contrario dei metodi tradizionali in cui i modelli vengono addestrati su server potenti e poi distribuiti sui dispositivi. Questo metodo √® particolarmente rilevante per TinyML, in cui i sistemi ML sono integrati in dispositivi minuscoli e con risorse limitate.</p>
<p>Un esempio di apprendimento su dispositivo pu√≤ essere visto in un termostato intelligente che si adatta al comportamento dell‚Äôutente nel tempo. Inizialmente, il termostato pu√≤ avere un modello generico che comprende modelli di utilizzo di base. Tuttavia, poich√© √® esposto a pi√π dati, come gli orari in cui l‚Äôutente √® a casa o fuori, le temperature preferite e le condizioni meteorologiche esterne, il termostato pu√≤ perfezionare il suo modello direttamente sul dispositivo per fornire un‚Äôesperienza personalizzata. Tutto ci√≤ avviene senza inviare dati a un server centrale per l‚Äôelaborazione.</p>
<p>Un altro esempio √® nel testo predittivo sugli smartphone. Mentre gli utenti digitano, il telefono impara dai modelli linguistici dell‚Äôutente e suggerisce parole o frasi che probabilmente verranno utilizzate in seguito. Questo apprendimento avviene direttamente sul dispositivo e il modello si aggiorna in tempo reale man mano che vengono raccolti pi√π dati. Un esempio pratico di apprendimento su dispositivo ampiamente utilizzato √® Gboard. Su un telefono Android, Gboard impara da modelli di digitazione e dettatura per migliorare l‚Äôesperienza per tutti gli utenti. L‚Äôapprendimento ‚ÄúOn-device‚Äù √® anche chiamato ‚Äúapprendimento federato‚Äù. <a href="#fig-federated-cycle" class="quarto-xref">Figura&nbsp;<span>12.1</span></a> mostra il ciclo di apprendimento federato sui dispositivi mobili: A. il dispositivo impara dai modelli utente; B. gli aggiornamenti del modello locale vengono comunicati al cloud; C. il server cloud aggiorna il modello globale e invia il nuovo modello a tutti i dispositivi.</p>
<div id="fig-federated-cycle" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-federated-cycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_intro.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-federated-cycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.1: Ciclo di apprendimento federato. Fonte: <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">Google Research.</a>
</figcaption>
</figure>
</div>
</section>
<section id="vantaggi-e-limiti" class="level2 page-columns page-full" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="vantaggi-e-limiti"><span class="header-section-number">12.2</span> Vantaggi e Limiti</h2>
<p>L‚Äôapprendimento su dispositivo offre diversi vantaggi rispetto al tradizionale ML basato su cloud. Mantenendo dati e modelli sul dispositivo, elimina la necessit√† di costose trasmissioni di dati e risolve i problemi di privacy. Ci√≤ consente esperienze pi√π personalizzate e reattive, poich√© il modello pu√≤ adattarsi in tempo reale al comportamento dell‚Äôutente.</p>
<p>Tuttavia, l‚Äôapprendimento su dispositivo presenta anche dei compromessi. Le limitate risorse di elaborazione sui dispositivi dei consumatori possono rendere difficile l‚Äôesecuzione di modelli complessi in locale. Anche i set di dati sono pi√π limitati poich√© sono costituiti solo da dati generati dall‚Äôutente da un singolo dispositivo. Inoltre, l‚Äôaggiornamento dei modelli richiede l‚Äôinvio di nuove versioni anzich√© aggiornamenti cloud senza interruzioni.</p>
<p>L‚Äôapprendimento su dispositivo apre nuove possibilit√† abilitando l‚Äôintelligenza artificiale offline mantenendo al contempo la privacy dell‚Äôutente. Tuttavia, richiede una gestione attenta della complessit√† dei modelli e dei dati entro i limiti dei dispositivi dei consumatori. Trovare il giusto equilibrio tra localizzazione e offload dal cloud √® fondamentale per ottimizzare le esperienze su dispositivo.</p>
<section id="vantaggi" class="level3 page-columns page-full" data-number="12.2.1">
<h3 data-number="12.2.1" class="anchored" data-anchor-id="vantaggi"><span class="header-section-number">12.2.1</span> Vantaggi</h3>
<section id="privacy-e-sicurezza-dei-dati" class="level4">
<h4 class="anchored" data-anchor-id="privacy-e-sicurezza-dei-dati">Privacy e Sicurezza dei Dati</h4>
<p>Uno dei vantaggi significativi dell‚Äôapprendimento sul dispositivo √® la maggiore privacy e sicurezza dei dati degli utenti. Ad esempio, si consideri uno smartwatch che monitora parametri sanitari sensibili come la frequenza cardiaca e la pressione sanguigna. Elaborando i dati e adattando i modelli direttamente sul dispositivo, i dati biometrici rimangono localizzati, aggirando la necessit√† di trasmettere dati grezzi ai server cloud dove potrebbero essere soggetti a violazioni.</p>
<p>Le violazioni dei server sono tutt‚Äôaltro che rare, con milioni di record compromessi ogni anno. Ad esempio, la violazione di Equifax del 2017 ha esposto i dati personali di 147 milioni di persone. Mantenendo i dati sul dispositivo, il rischio di tali esposizioni √® drasticamente ridotto. L‚Äôapprendimento sul dispositivo elimina la dipendenza dall‚Äôarchiviazione cloud centralizzata e protegge dall‚Äôaccesso non autorizzato da varie minacce, tra cui attori malintenzionati, minacce interne ed esposizione accidentale.</p>
<p>Regolamenti come l‚ÄôHealth Insurance Portability and Accountability Act (<a href="https://www.cdc.gov/phlp/publications/topic/hipaa.html">HIPAA</a>) e il General Data Protection Regulation (<a href="https://gdpr.eu/tag/gdpr/">GDPR</a>) impongono rigorosi requisiti di riservatezza dei dati che l‚Äôapprendimento sul dispositivo affronta abilmente. Garantendo che i dati rimangano localizzati e non vengano trasferiti ad altri sistemi, l‚Äôapprendimento sul dispositivo facilita la <a href="https://www.researchgate.net/publication/321515854_The_EU_General_Data_Protection_Regulation_GDPR_A_Practical_Guide">conformit√† a tali regolamenti</a>.</p>
<p>L‚Äôapprendimento sul dispositivo non √® solo vantaggioso per i singoli utenti; ha implicazioni significative per le organizzazioni e i settori che gestiscono dati altamente sensibili. Ad esempio, in ambito militare, l‚Äôapprendimento sul dispositivo consente ai sistemi di prima linea di adattare modelli e funzioni indipendentemente dalle connessioni ai server centrali che potrebbero essere potenzialmente compromessi. Le informazioni critiche e sensibili sono saldamente protette dalla localizzazione dell‚Äôelaborazione e dell‚Äôapprendimento dei dati. Tuttavia, ci√≤ comporta il compromesso che i singoli dispositivi assumono pi√π valore e possono incentivare furti o distruzioni poich√© diventano gli unici vettori di modelli di intelligenza artificiale specializzati. √à necessario prestare attenzione alla protezione dei dispositivi stessi durante la transizione all‚Äôapprendimento sul dispositivo.</p>
<p>√à inoltre importante preservare la privacy, la sicurezza e la conformit√† normativa dei dati personali e sensibili. Invece che nel cloud, i modelli di training e operativi aumentano sostanzialmente le misure di privacy a livello locale, assicurando che i dati degli utenti siano protetti da potenziali minacce.</p>
<p>Tuttavia, questo √® solo parzialmente intuitivo perch√© l‚Äôapprendimento sul dispositivo potrebbe invece esporre i sistemi a nuovi attacchi alla privacy. Con preziosi riepiloghi dei dati e aggiornamenti dei modelli archiviati in modo permanente su singoli dispositivi, potrebbe essere molto pi√π difficile proteggerli fisicamente e digitalmente rispetto a un grande cluster di elaborazione. Mentre l‚Äôapprendimento sul dispositivo riduce la quantit√† di dati compromessi in una qualsiasi violazione, potrebbe anche introdurre nuovi pericoli disperdendo informazioni sensibili su molti terminali decentralizzati. Le pratiche di sicurezza attente sono ancora essenziali per i sistemi ‚Äúon-device‚Äù.</p>
</section>
<section id="normativa-di-conformit√†" class="level4">
<h4 class="anchored" data-anchor-id="normativa-di-conformit√†">Normativa di Conformit√†</h4>
<p>L‚Äôapprendimento sul dispositivo aiuta ad affrontare le principali normative sulla privacy come <a href="https://gdpr.eu/tag/gdpr/">GDPR</a>)e <a href="https://oag.ca.gov/privacy/ccpa">CCPA</a>. Queste normative richiedono la localizzazione dei dati, limitando i trasferimenti di dati transfrontalieri a paesi approvati con controlli adeguati. Il GDPR impone inoltre requisiti di ‚Äúprivacy by design‚Äù e consenso per la raccolta dei dati. Mantenendo l‚Äôelaborazione dei dati e il training del modello localizzati sul dispositivo, i dati sensibili degli utenti non vengono trasferiti altrove. Ci√≤ evita importanti grattacapi di conformit√† per le organizzazioni.</p>
<p>Ad esempio, un fornitore di servizi sanitari che monitora i parametri vitali dei pazienti con dispositivi indossabili deve garantire che i trasferimenti di dati transfrontalieri siano conformi a HIPAA e GDPR se utilizza il cloud. Determinare le leggi del paese applicabili e garantire le approvazioni per i flussi di dati internazionali introduce oneri legali e ingegneristici. Con l‚Äôapprendimento on-device, nessun dato lascia il dispositivo, semplificando la conformit√†. Il tempo e le risorse spesi per la conformit√† vengono ridotti in modo significativo.</p>
<p>Settori come sanit√†, finanza e governo, che hanno dati altamente regolamentati, possono trarre grandi vantaggi dal training sul dispositivo. Localizzando i dati e l‚Äôapprendimento, i requisiti normativi di privacy e sovranit√† dei dati vengono soddisfatti pi√π facilmente. Le soluzioni su dispositivo forniscono un modo efficiente per creare applicazioni di IA conformi.</p>
<p>Le principali normative sulla privacy impongono restrizioni sullo spostamento transfrontaliero dei dati che l‚Äôapprendimento su dispositivo affronta intrinsecamente tramite elaborazione localizzata. Ci√≤ riduce l‚Äôonere di conformit√† per le organizzazioni che lavorano con dati regolamentati.</p>
</section>
<section id="riduzione-della-larghezza-di-banda-dei-costi-e-maggiore-efficienza" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="riduzione-della-larghezza-di-banda-dei-costi-e-maggiore-efficienza">Riduzione della Larghezza di Banda, dei Costi e Maggiore Efficienza</h4>
<p>Uno dei principali vantaggi dell‚Äôapprendimento su dispositivo √® la significativa riduzione dell‚Äôutilizzo della larghezza di banda e dei costi associati all‚Äôinfrastruttura cloud. Mantenendo i dati localizzati per l‚Äôaddestramento del modello anzich√© trasmettere dati grezzi al cloud, l‚Äôapprendimento su dispositivo pu√≤ comportare notevoli risparmi di larghezza di banda. Ad esempio, una rete di telecamere che analizzano i filmati video pu√≤ ottenere significative riduzioni nel trasferimento di dati addestrando i modelli sul dispositivo anzich√© trasmettere in streaming tutti i filmati video al cloud per l‚Äôelaborazione.</p>
<p>Questa riduzione nella trasmissione dei dati consente di risparmiare larghezza di banda e si traduce in costi inferiori per server, reti e archiviazione dei dati nel cloud. Le grandi organizzazioni, che potrebbero spendere milioni in infrastrutture cloud per addestrare modelli di dati sui dispositivi, possono sperimentare drastiche riduzioni dei costi tramite l‚Äôapprendimento on-device. Nell‚Äôera dell‚Äôintelligenza artificiale generativa, in cui <a href="https://epochai.org/blog/trends-in-the-dollar-training-cost-of-machine-learning-systems">i costi sono aumentati in modo significativo</a>, trovare modi per contenere le spese √® diventato sempre pi√π importante.</p>
<p>Inoltre, anche i costi energetici e ambientali della gestione di grandi server farm sono diminuiti. I data center consumano grandi quantit√† di energia, contribuendo alle emissioni di gas serra. Riducendo la necessit√† di un‚Äôampia infrastruttura basata su cloud, l‚Äôapprendimento sui dispositivi contribuisce a mitigare l‚Äôimpatto ambientale dell‚Äôelaborazione dei dati <span class="citation" data-cites="wu2022sustainable">(<a href="../../references.html#ref-wu2022sustainable" role="doc-biblioref">Wu et al. 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-wu2022sustainable" class="csl-entry" role="listitem">
Wu, Carole-Jean, Ramya Raghavendra, Udit Gupta, Bilge Acun, Newsha Ardalani, Kiwan Maeng, Gloria Chang, et al. 2022. <span>¬´Sustainable ai: <span>Environmental</span> implications, challenges and opportunities¬ª</span>. <em>Proceedings of Machine Learning and Systems</em> 4: 795‚Äì813.
</div></div><p>Specificamente per le applicazioni endpoint [finali], l‚Äôapprendimento sui dispositivi riduce al minimo il numero di chiamate API di rete necessarie per eseguire l‚Äôinferenza tramite un provider cloud. I costi cumulativi associati alla larghezza di banda e alle chiamate API possono aumentare rapidamente per le applicazioni con milioni di utenti. Al contrario, eseguire training e inferenze localmente √® notevolmente pi√π efficiente e conveniente. Con ottimizzazioni all‚Äôavanguardia, √® stato dimostrato che l‚Äôapprendimento on-device riduce i requisiti di memoria del training, migliora drasticamente l‚Äôefficienza della memoria e riduce fino al 20% la latenza per iterazione <span class="citation" data-cites="dhar2021survey">(<a href="../../references.html#ref-dhar2021survey" role="doc-biblioref">Dhar et al. 2021</a>)</span>.</p>
<p>Un altro vantaggio fondamentale dell‚Äôapprendimento sul dispositivo √® la possibilit√† per i dispositivi IoT di adattare continuamente il loro modello ML a nuovi dati per un apprendimento continuo e permanente. I modelli sul dispositivo possono rapidamente diventare obsoleti man mano che il comportamento dell‚Äôutente, i modelli di dati e le preferenze cambiano. L‚Äôapprendimento continuo consente al modello di adattarsi in modo efficiente a nuovi dati e miglioramenti e di mantenere elevate prestazioni del modello nel tempo.</p>
</section>
</section>
<section id="limitazioni" class="level3 page-columns page-full" data-number="12.2.2">
<h3 data-number="12.2.2" class="anchored" data-anchor-id="limitazioni"><span class="header-section-number">12.2.2</span> Limitazioni</h3>
<p>Mentre i tradizionali sistemi ML basati su cloud hanno accesso a risorse di elaborazione pressoch√© infinite, l‚Äôapprendimento sul dispositivo √® spesso limitato nella potenza di elaborazione e di archiviazione del dispositivo edge su cui viene addestrato il modello. Per definizione, un <a href="http://arxiv.org/abs/1911.00623">dispositivo edge</a> √® un dispositivo con risorse di elaborazione, memoria ed energia limitate che non possono essere facilmente aumentate o diminuite. Pertanto, la dipendenza dai dispositivi edge pu√≤ limitare la complessit√†, l‚Äôefficienza e le dimensioni dei modelli ML sul dispositivo.</p>
<section id="risorse-di-elaborazione" class="level4">
<h4 class="anchored" data-anchor-id="risorse-di-elaborazione">Risorse di elaborazione</h4>
<p>I tradizionali sistemi ML basati su cloud utilizzano grandi server con pi√π GPU o TPU di fascia alta, che forniscono una potenza di calcolo e una memoria pressoch√© infinite. Ad esempio, servizi come Amazon Web Services (AWS) <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html">EC2</a> consentono di configurare cluster di istanze GPU per un training parallelo massiccio.</p>
<p>Al contrario, l‚Äôapprendimento sul dispositivo √® limitato dall‚Äôhardware del dispositivo edge su cui viene eseguito. I dispositivi edge si riferiscono a endpoint come smartphone, elettronica embedded e dispositivi IoT. Per definizione, questi dispositivi hanno risorse di elaborazione, memoria ed energia molto limitate rispetto al cloud.</p>
<p>Ad esempio, uno smartphone tipico o Raspberry Pi pu√≤ avere solo pochi core CPU, pochi GB di RAM e una piccola batteria. Ancora pi√π limitati in termini di risorse sono i dispositivi microcontrollore TinyML come <a href="https://store-usa.arduino.cc/products/arduino-nano-33-ble-sense">Arduino Nano BLE Sense</a>. Le risorse sono fisse su questi dispositivi e non possono essere facilmente aumentate su richiesta, come il ridimensionamento dell‚Äôinfrastruttura cloud. Questa dipendenza dai dispositivi edge limita direttamente la complessit√†, l‚Äôefficienza e le dimensioni dei modelli che possono essere distribuiti per l‚Äôaddestramento sul dispositivo:</p>
<ul>
<li><strong>Complessit√†:</strong> I limiti di memoria, elaborazione e potenza limitano la progettazione dell‚Äôarchitettura del modello, cos√¨ come il numero di layer e dei parametri.</li>
<li><strong>Efficienza:</strong> I modelli devono essere fortemente ottimizzati tramite metodi come la quantizzazione e la potatura per essere eseguiti pi√π velocemente e consumare meno energia.</li>
<li><strong>Dimensioni:</strong> I file del modello effettivo devono essere compressi il pi√π possibile per rientrare nei limiti di archiviazione dei dispositivi edge.</li>
</ul>
<p>Pertanto, mentre il cloud offre una scalabilit√† infinita, l‚Äôapprendimento sul dispositivo deve operare entro i rigidi vincoli di risorse dell‚Äôhardware. Ci√≤ richiede un‚Äôattenta progettazione congiunta di modelli semplificati, metodi di addestramento e ottimizzazioni su misura specificamente per i dispositivi edge.</p>
</section>
<section id="dimensioni-accuratezza-e-generalizzazione-del-dataset" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="dimensioni-accuratezza-e-generalizzazione-del-dataset">Dimensioni, Accuratezza e Generalizzazione del Dataset</h4>
<p>Oltre alle risorse di elaborazione limitate, l‚Äôapprendimento sul dispositivo √® anche limitato dal set di dati disponibile per i modelli di training.</p>
<p>Nel cloud, i modelli vengono addestrati su dataset enormi e diversi come ImageNet o Common Crawl. Ad esempio, ImageNet contiene oltre 14 milioni di immagini attentamente categorizzate in migliaia di classi.</p>
<p>L‚Äôapprendimento sul dispositivo si basa invece su ‚Äúdata silos‚Äù pi√π piccoli e decentralizzati, unici per ogni dispositivo. Il rullino fotografico di uno smartphone potrebbe contenere solo migliaia di foto degli interessi e degli ambienti degli utenti.</p>
<p>Questi dati decentralizzati portano alla necessit√† di dati IID (indipendenti e distribuiti in modo identico). Ad esempio, due amici potrebbero scattare molte foto degli stessi luoghi e oggetti, il che significa che le loro distribuzioni di dati sono altamente correlate piuttosto che indipendenti.</p>
<p>Motivi per cui i dati potrebbero essere non IID nelle impostazioni sul dispositivo:</p>
<ul>
<li><strong>Eterogeneit√† degli utenti:</strong> Utenti diversi hanno interessi e ambienti diversi.</li>
<li><strong>Differenze tra dispositivi:</strong> Sensori, regioni e dati demografici influenzano i dati.</li>
<li><strong>Effetti temporali:</strong> Ora del giorno, impatti stagionali sui dati.</li>
</ul>
<p>L‚Äôefficacia del ML si basa in gran parte su dati di training ampi e diversificati. Con set di dati piccoli e localizzati, i modelli on-device potrebbero non riuscire a generalizzare tra diverse popolazioni di utenti e ambienti. Ad esempio, un modello di rilevamento delle malattie addestrato solo su immagini di un singolo ospedale non si generalizzerebbe bene ad altri dati demografici dei pazienti. Le prestazioni nel mondo reale non potranno che migliorare con progressi medici estesi e diversificati. Quindi, mentre l‚Äôapprendimento basato su cloud sfrutta enormi set di dati, l‚Äôapprendimento su dispositivo si basa su ‚Äúsilo di dati‚Äù decentralizzati molto pi√π piccoli, unici per ogni utente.</p>
<p>I dati limitati e le ottimizzazioni richieste per l‚Äôapprendimento on-device possono avere un impatto negativo sulla precisione e sulla generalizzazione del modello:</p>
<ul>
<li>I piccoli dataset aumentano il rischio di overfitting. Ad esempio, un classificatore di frutta addestrato su 100 immagini rischia di overfitting rispetto a uno addestrato su 1 milione di immagini diverse.</li>
<li>I dati rumorosi generati dall‚Äôutente riducono la qualit√†. Il rumore del sensore o l‚Äôetichettatura impropria dei dati da parte di non esperti possono degradare l‚Äôaddestramento.</li>
<li>Ottimizzazioni come la potatura e la quantizzazione compromettono la precisione per l‚Äôefficienza. Un modello quantizzato a 8 bit funziona pi√π velocemente ma meno accuratamente di un modello a 32 bit.</li>
</ul>
<p>Quindi, mentre i modelli cloud raggiungono un‚Äôelevata precisione con enormi set di dati e senza vincoli, i modelli su dispositivo possono avere difficolt√† a generalizzare. Alcuni studi dimostrano che il training sul dispositivo corrisponde all‚Äôaccuratezza del cloud su determinate attivit√†. Tuttavia, le prestazioni sui carichi di lavoro reali richiedono ulteriori studi <span class="citation" data-cites="lin2022device">(<a href="../../references.html#ref-lin2022device" role="doc-biblioref">Lin et al. 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>Ad esempio, un modello cloud pu√≤ rilevare con precisione la polmonite nelle radiografie del torace di migliaia di ospedali. Tuttavia, un modello sul dispositivo addestrato solo su una piccola popolazione locale di pazienti potrebbe non riuscire a generalizzare.</p>
<p>Un‚Äôaccuratezza inaffidabile limita l‚Äôapplicabilit√† nel mondo reale dell‚Äôapprendimento sul dispositivo per usi critici come la diagnosi di malattie o i veicoli a guida autonoma.</p>
<p>Il training sul dispositivo √® anche pi√π lento del cloud a causa delle risorse limitate. Anche se ogni iterazione √® pi√π veloce, il processo di training complessivo richiede pi√π tempo.</p>
<p>Ad esempio, un‚Äôapplicazione di robotica in tempo reale potrebbe richiedere aggiornamenti del modello entro millisecondi. L‚ÄôOn-device training su un piccolo hardware embedded potrebbe richiedere secondi o minuti per l‚Äôaggiornamento, troppo lento per l‚Äôuso in tempo reale.</p>
<p>Le sfide relative a precisione, generalizzazione e velocit√† pongono ostacoli all‚Äôadozione dell‚Äôapprendimento on-device per sistemi di produzione reali, soprattutto quando affidabilit√† e bassa latenza sono fondamentali.</p>
</section>
</section>
</section>
<section id="adattamento-on-device" class="level2 page-columns page-full" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="adattamento-on-device"><span class="header-section-number">12.3</span> Adattamento On-device</h2>
<p>In un‚Äôattivit√† ML, il consumo di risorse proviene <a href="http://arxiv.org/abs/1911.00623">principalmente</a> da tre fonti:</p>
<ul>
<li>Il modello ML stesso;</li>
<li>Il processo di ottimizzazione durante l‚Äôapprendimento del modello</li>
<li>Archiviazione ed elaborazione del dataset utilizzato per l‚Äôapprendimento.</li>
</ul>
<p>Di conseguenza, ci sono tre approcci per adattare gli algoritmi ML esistenti su dispositivi con risorse limitate:</p>
<ul>
<li>Riduzione della complessit√† del modello ML</li>
<li>Modifica delle ottimizzazioni per ridurre i requisiti delle risorse di training</li>
<li>Creazione di nuove rappresentazioni dei dati pi√π efficienti in termini di archiviazione</li>
</ul>
<p>Nella sezione seguente, esamineremo questi metodi di adattamento dell‚Äôapprendimento on-device. Il capitolo <a href="../optimizations/optimizations.qmd">Ottimizzazioni dei Modelli</a> fornisce maggiori dettagli sulle ottimizzazioni del modello.</p>
<section id="riduzione-della-complessit√†-del-modello" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="riduzione-della-complessit√†-del-modello"><span class="header-section-number">12.3.1</span> Riduzione della Complessit√† del Modello</h3>
<p>In questa sezione, discuteremo brevemente i modi per ridurre la complessit√† del modello quando si adattano i modelli ML sul dispositivo. Per i dettagli sulla riduzione della complessit√† del modello, fare riferimento al capitolo Ottimizzazioni dei Modelli.</p>
<section id="algoritmi-ml-tradizionali" class="level4">
<h4 class="anchored" data-anchor-id="algoritmi-ml-tradizionali">Algoritmi ML tradizionali</h4>
<p>A causa delle limitazioni di elaborazione e memoria dei dispositivi edge, alcuni algoritmi ML tradizionali sono ottimi candidati per applicazioni di apprendimento on-device grazie alla loro natura leggera. Alcuni esempi di algoritmi con basso impatto sulle risorse includono Naive Bayes Classifiers, Support Vector Machines (SVM), Linear Regression, Logistic Regression e algoritmi Decision Tree selezionati.</p>
<p>Con alcuni perfezionamenti, questi algoritmi ML classici possono essere adattati a specifiche architetture hardware ed eseguire attivit√† semplici. I loro bassi requisiti di prestazioni semplificano l‚Äôintegrazione dell‚Äôapprendimento continuo anche su dispositivi edge.</p>
</section>
<section id="pruning" class="level4">
<h4 class="anchored" data-anchor-id="pruning">Pruning</h4>
<p>Il ‚Äúpruning‚Äù [potatura] √® una tecnica per ridurre le dimensioni e la complessit√† di un modello ML per migliorarne l‚Äôefficienza e le prestazioni di generalizzazione. Ci√≤ √® utile per l‚Äôaddestramento di modelli su dispositivi edge, in cui vogliamo ridurre al minimo l‚Äôutilizzo delle risorse mantenendo un‚Äôaccuratezza competitiva.</p>
<p>L‚Äôobiettivo principale della potatura √® rimuovere parti del modello che non contribuiscono in modo significativo al suo potere predittivo, mantenendo al contempo gli aspetti pi√π informativi. Nel contesto degli alberi decisionali, la potatura comporta la rimozione di alcuni rami (sottoalberi) dall‚Äôalbero, portando a un albero pi√π piccolo e semplice. Nel contesto di DNN, la potatura viene utilizzata per ridurre il numero di neuroni (unit√†) o connessioni nella rete, come mostrato in <a href="#fig-ondevice-pruning" class="quarto-xref">Figura&nbsp;<span>12.2</span></a>.</p>
<div id="fig-ondevice-pruning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ondevice-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/pruning.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ondevice-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.2: Potatura della rete.
</figcaption>
</figure>
</div>
</section>
<section id="riduzione-della-complessit√†-dei-modelli-di-deep-learning" class="level4">
<h4 class="anchored" data-anchor-id="riduzione-della-complessit√†-dei-modelli-di-deep-learning">Riduzione della Complessit√† dei Modelli di Deep Learning</h4>
<p>I framework DNN tradizionali basati su cloud hanno un sovraccarico di memoria troppo elevato per essere utilizzati sul dispositivo. <a href="http://arxiv.org/abs/2206.15472">Ad esempio</a>, i sistemi di deep learning come PyTorch e TensorFlow richiedono centinaia di megabyte di overhead di memoria durante l‚Äôaddestramento di modelli come <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html">MobilenetV2</a> e l‚Äôoverhead aumenta con l‚Äôaumentare del numero di parametri di addestramento.</p>
<p>La ricerca attuale per DNN leggeri esplora principalmente architetture CNN. Esistono anche diversi framework ‚Äúbare-metal‚Äù [tutto in hardware] progettati per eseguire reti neurali su MCU mantenendo bassi l‚Äôoverhead computazionale e l‚Äôingombro di memoria. Alcuni esempi includono MNN, TVM e TensorFlow Lite. Tuttavia, possono eseguire l‚Äôinferenza solo durante i passaggi in avanti e non supportano la backpropagation. Sebbene questi modelli siano progettati per l‚Äôimplementazione edge, la loro riduzione nei pesi del modello e nelle connessioni architettoniche ha portato a minori requisiti di risorse per l‚Äôapprendimento continuo.</p>
<p>Il compromesso tra prestazioni e supporto del modello √® chiaro quando si adattano i sistemi DNN pi√π diffusi. Come adattiamo i modelli DNN esistenti a impostazioni con risorse limitate mantenendo il supporto per la backpropagation e l‚Äôapprendimento continuo? Le ultime ricerche suggeriscono tecniche di progettazione congiunta di algoritmi e sistemi che aiutano a ridurre il consumo di risorse dell‚Äôaddestramento ML sui dispositivi edge. Utilizzando tecniche come il ‚Äúquantization-aware scaling‚Äù (QAS) [ridimensionamento consapevole della quantizzazione], aggiornamenti sparsi e altre tecniche all‚Äôavanguardia, l‚Äôapprendimento sul dispositivo √® possibile su sistemi embedded con poche centinaia di kilobyte di RAM senza memoria aggiuntiva mantenendo <a href="http://arxiv.org/abs/2206.15472">un‚Äôelevata precisione</a>.</p>
</section>
</section>
<section id="modifica-dei-processi-di-ottimizzazione" class="level3 page-columns page-full" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="modifica-dei-processi-di-ottimizzazione"><span class="header-section-number">12.3.2</span> Modifica dei Processi di Ottimizzazione</h3>
<p>La scelta della giusta strategia di ottimizzazione √® importante per l‚Äôaddestramento DNN su un dispositivo, poich√© consente di trovare un buon minimo locale. Poich√© l‚Äôaddestramento avviene su un dispositivo, questa strategia deve anche considerare la memoria e la potenza limitate.</p>
<section id="quantization-aware-scaling" class="level4">
<h4 class="anchored" data-anchor-id="quantization-aware-scaling">Quantization-Aware Scaling</h4>
<p>La quantizzazione √® un metodo comune per ridurre l‚Äôimpronta di memoria dell‚Äôaddestramento DNN. Sebbene ci√≤ possa introdurre nuovi errori, questi possono essere mitigati progettando un modello per caratterizzare questo errore statistico. Ad esempio, i modelli potrebbero utilizzare l‚Äôarrotondamento stocastico o introdurre l‚Äôerrore di quantizzazione negli aggiornamenti del gradiente.</p>
<p>Una tecnica algoritmica specifica √® Quantization-Aware Scaling (QAS), che migliora le prestazioni delle reti neurali su hardware a bassa precisione, come dispositivi edge, dispositivi mobili o sistemi TinyML, regolando i fattori di scala durante il processo di quantizzazione.</p>
<p>Come abbiamo discusso nel capitolo Ottimizzazioni del modello, la quantizzazione √® il processo di mappatura di un intervallo continuo di valori su un set discreto di valori. Nel contesto delle reti neurali, la quantizzazione spesso comporta la riduzione della precisione dei pesi e delle attivazioni da virgola mobile a 32 bit a formati a precisione inferiore come numeri interi a 8 bit. Questa riduzione di precisione pu√≤ diminuire significativamente il costo computazionale e l‚Äôingombro di memoria del modello, rendendolo adatto per l‚Äôimplementazione su hardware a bassa precisione. <a href="#fig-float-int-quantization" class="quarto-xref">Figura&nbsp;<span>12.3</span></a> √® un esempio di quantizzazione float-to-integer.</p>
<div id="fig-float-int-quantization" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-float-int-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_quantization_matrix.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-float-int-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.3: Quantizzazione float-to-integer. Fonte: <a href="https://developer-blogs.nvidia.com/wp-content/uploads/2021/07/qat-training-precision.png">Nvidia.</a>
</figcaption>
</figure>
</div>
<p>Tuttavia, il processo di quantizzazione pu√≤ anche introdurre errori di quantizzazione che possono degradare le prestazioni del modello. La scalatura basata sulla quantizzazione √® una tecnica che riduce al minimo questi errori regolando i fattori di scala utilizzati nel processo di quantizzazione.</p>
<p>Il processo QAS prevede due fasi principali:</p>
<ul>
<li><p><strong>Addestramento basato sulla quantizzazione:</strong> In questa fase, la rete neurale viene addestrata tenendo conto della quantizzazione, simulandola per imitarne gli effetti durante i passaggi ‚Äúforward‚Äù e ‚Äúbackward‚Äù. Ci√≤ consente al modello di imparare a compensare gli errori di quantizzazione e migliorarne le prestazioni su hardware a bassa precisione. Per i dettagli, fare riferimento alla sezione QAT in Ottimizzazioni del modello.</p></li>
<li><p><strong>Quantizzazione e ridimensionamento:</strong> Dopo l‚Äôaddestramento, il modello viene quantizzato in un formato a bassa precisione e i fattori di scala vengono regolati per ridurre al minimo gli errori di quantizzazione. I fattori di scala vengono scelti in base alla distribuzione dei pesi e delle attivazioni nel modello e vengono regolati per garantire che i valori quantizzati siano compresi nell‚Äôintervallo del formato a bassa precisione.</p></li>
</ul>
<p>QAS viene utilizzato per superare le difficolt√† di ottimizzazione dei modelli su dispositivi minuscoli senza dover effettuare la messa a punto degli iperparametri; QAS ridimensiona automaticamente i gradienti tensoriali con varie precisioni di bit. Ci√≤ stabilizza il processo di addestramento e corrisponde all‚Äôaccuratezza della precisione in virgola mobile.</p>
</section>
<section id="aggiornamenti-sparsi" class="level4">
<h4 class="anchored" data-anchor-id="aggiornamenti-sparsi">Aggiornamenti Sparsi</h4>
<p>Sebbene QAS consenta l‚Äôottimizzazione di un modello quantizzato, utilizza una grande quantit√† di memoria, il che non √® realistico per l‚Äôaddestramento sul dispositivo. Quindi, gli aggiornamenti ‚Äúspare‚Äù vengono utilizzati per ridurre l‚Äôingombro di memoria del calcolo ‚Äúfull backward‚Äù. Invece di potare i pesi per l‚Äôinferenza, l‚Äôaggiornamento sparso pota il gradiente durante la ‚Äúbackward propagation‚Äù [propagazione all‚Äôindietro] per aggiornare il modello in modo sparso. In altre parole, l‚Äôaggiornamento sparso salta i gradienti del calcolo di layer e sottotensori meno importanti.</p>
<p>Tuttavia, determinare lo schema di un aggiornamento sparso ottimale dato un budget di memoria vincolante pu√≤ essere difficile a causa dell‚Äôampio spazio di ricerca. Ad esempio, il modello MCUNet ha 43 layer convoluzionali e uno spazio di ricerca di circa 1030. Una tecnica per affrontare questo problema √® l‚Äôanalisi del contributo. L‚Äôanalisi del contributo misura il miglioramento dell‚Äôaccuratezza dai bias (aggiornamento degli ultimi bias rispetto al solo aggiornamento del classificatore) e pesi (aggiornamento del peso di un layer extra rispetto al solo aggiornamento del bias). Cercando di massimizzare questi miglioramenti, l‚Äôanalisi del contributo deriva automaticamente uno schema di aggiornamento sparso ottimale per abilitare l‚Äôaddestramento sul dispositivo.</p>
</section>
<section id="training-layer-wise" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="training-layer-wise">Training Layer-Wise</h4>
<p>Altri metodi oltre alla quantizzazione possono aiutare a ottimizzare le routine. Uno di questi metodi √® l‚Äôaddestramento ‚Äúlayer-wise‚Äù. Un consumatore significativo di memoria dell‚Äôaddestramento DNN √® la backpropagation end-to-end, che richiede che tutte le feature map intermedie siano archiviate in modo che il modello possa calcolare i gradienti. Un‚Äôalternativa a questo approccio che riduce l‚Äôimpronta di memoria dell‚Äôaddestramento DNN √® l‚Äôaddestramento sequenziale ‚Äúlayer-by-layer‚Äù <span class="citation" data-cites="chen2016training">(<a href="../../references.html#ref-chen2016training" role="doc-biblioref">T. Chen et al. 2016</a>)</span>. Invece dell‚Äôaddestramento end-to-end, l‚Äôaddestramento di un singolo layer alla volta aiuta a evitare di dover archiviare le feature map intermedie.</p>
<div class="no-row-height column-margin column-container"><div id="ref-chen2016training" class="csl-entry" role="listitem">
Chen, Tianqi, Bing Xu, Chiyuan Zhang, e Carlos Guestrin. 2016. <span>¬´Training deep nets with sublinear memory cost¬ª</span>. <em>ArXiv preprint</em> abs/1604.06174. <a href="https://arxiv.org/abs/1604.06174">https://arxiv.org/abs/1604.06174</a>.
</div></div></section>
<section id="trading-computation-for-memory" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="trading-computation-for-memory">Trading Computation for Memory</h4>
<p>La strategia ‚Äútrading computation for memory‚Äù [scambio di elaborazione per memoria] comporta il rilascio di parte della memoria utilizzata per archiviare i risultati intermedi. Invece, questi risultati possono essere ricalcolati in base alle necessit√†. √à stato dimostrato che la riduzione della memoria in cambio di pi√π elaborazione riduce l‚Äôimpronta di memoria dell‚Äôaddestramento DNN per adattarsi a quasi tutti i budget, riducendo al minimo anche i costi di elaborazione <span class="citation" data-cites="gruslys2016memory">(<a href="../../references.html#ref-gruslys2016memory" role="doc-biblioref">Gruslys et al. 2016</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-gruslys2016memory" class="csl-entry" role="listitem">
Gruslys, Audrunas, R√©mi Munos, Ivo Danihelka, Marc Lanctot, e Alex Graves. 2016. <span>¬´Memory-Efficient Backpropagation Through Time¬ª</span>. In <em>Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain</em>, a cura di Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, e Roman Garnett, 4125‚Äì33. <a href="https://proceedings.neurips.cc/paper/2016/hash/a501bebf79d570651ff601788ea9d16d-Abstract.html">https://proceedings.neurips.cc/paper/2016/hash/a501bebf79d570651ff601788ea9d16d-Abstract.html</a>.
</div></div></section>
</section>
<section id="sviluppo-di-nuove-rappresentazioni-dei-dati" class="level3 page-columns page-full" data-number="12.3.3">
<h3 data-number="12.3.3" class="anchored" data-anchor-id="sviluppo-di-nuove-rappresentazioni-dei-dati"><span class="header-section-number">12.3.3</span> Sviluppo di Nuove Rappresentazioni dei Dati</h3>
<p>La dimensionalit√† e il volume dei dati di training possono avere un impatto significativo sull‚Äôadattamento sul dispositivo. Quindi, un‚Äôaltra tecnica per adattare i modelli su dispositivi con risorse limitate √® quella di rappresentare i set di dati in modo pi√π efficiente.</p>
<section id="compressione-dei-dati" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="compressione-dei-dati">Compressione dei Dati</h4>
<p>L‚Äôobiettivo della compressione dei dati √® raggiungere elevate precisioni limitando al contempo la quantit√† di dati di training. Un metodo per raggiungere questo obiettivo √® dare priorit√† alla complessit√† del campione: la quantit√† di dati di training necessari affinch√© l‚Äôalgoritmo raggiunga una precisione target <span class="citation" data-cites="dhar2021survey">(<a href="../../references.html#ref-dhar2021survey" role="doc-biblioref">Dhar et al. 2021</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-dhar2021survey" class="csl-entry" role="listitem">
Dhar, Sauptik, Junyao Guo, Jiayi (Jason) Liu, Samarth Tripathi, Unmesh Kurup, e Mohak Shah. 2021. <span>¬´A Survey of On-Device Machine Learning: An Algorithms and Learning Theory Perspective¬ª</span>. <em>ACM Transactions on Internet of Things</em> 2 (3): 1‚Äì49. <a href="https://doi.org/10.1145/3450494">https://doi.org/10.1145/3450494</a>.
</div><div id="ref-rouhani2017tinydl" class="csl-entry" role="listitem">
Darvish Rouhani, Bita, Azalia Mirhoseini, e Farinaz Koushanfar. 2017. <span>¬´<span>TinyDL:</span> <span>Just-in-time</span> deep learning solution for constrained embedded systems¬ª</span>. In <em>2017 IEEE International Symposium on Circuits and Systems (ISCAS)</em>, 1‚Äì4. IEEE. <a href="https://doi.org/10.1109/iscas.2017.8050343">https://doi.org/10.1109/iscas.2017.8050343</a>.
</div><div id="ref-li2016lightrnn" class="csl-entry" role="listitem">
Li, Xiang, Tao Qin, Jian Yang, e Tie-Yan Liu. 2016. <span>¬´<span>LightRNN:</span> <span>Memory</span> and Computation-Efficient Recurrent Neural Networks¬ª</span>. In <em>Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain</em>, a cura di Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, e Roman Garnett, 4385‚Äì93. <a href="https://proceedings.neurips.cc/paper/2016/hash/c3e4035af2a1cde9f21e1ae1951ac80b-Abstract.html">https://proceedings.neurips.cc/paper/2016/hash/c3e4035af2a1cde9f21e1ae1951ac80b-Abstract.html</a>.
</div></div><p>Altri metodi pi√π comuni di compressione dei dati si concentrano sulla riduzione della dimensionalit√† e del volume dei dati di training. Ad esempio, un approccio potrebbe sfruttare la sparsit√† della matrice per ridurre l‚Äôingombro di memoria per l‚Äôarchiviazione dei dati di training. I dati di training possono essere trasformati in un embedding a dimensione inferiore e fattorizzati in una matrice di dizionario moltiplicata per una matrice di coefficienti blocchi sparsi <span class="citation" data-cites="rouhani2017tinydl">(<a href="../../references.html#ref-rouhani2017tinydl" role="doc-biblioref">Darvish Rouhani, Mirhoseini, e Koushanfar 2017</a>)</span>. Un altro esempio potrebbe riguardare la rappresentazione di parole provenienti da un ampio set di dati di training linguistica in un formato vettoriale pi√π compresso <span class="citation" data-cites="li2016lightrnn">(<a href="../../references.html#ref-li2016lightrnn" role="doc-biblioref">Li et al. 2016</a>)</span>.</p>
</section>
</section>
</section>
<section id="il-transfer-learning" class="level2 page-columns page-full" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="il-transfer-learning"><span class="header-section-number">12.4</span> Il Transfer Learning</h2>
<p>Il transfer learning √® una tecnica di ML in cui un modello sviluppato per un‚Äôattivit√† specifica viene riutilizzato come punto di partenza per un modello su una seconda attivit√†. Nel contesto dell‚Äôintelligenza artificiale su dispositivi, il transfer learning ci consente di sfruttare modelli pre-addestrati che hanno gi√† appreso rappresentazioni utili da grandi set di dati e di perfezionarli per attivit√† specifiche utilizzando set di dati pi√π piccoli direttamente sul dispositivo. Ci√≤ pu√≤ ridurre significativamente le risorse di calcolo e il tempo necessari per l‚Äôaddestramento dei modelli da zero.</p>
<p><a href="#fig-transfer-learning-apps" class="quarto-xref">Figura&nbsp;<span>12.4</span></a> include alcuni esempi intuitivi di transfer learning dal mondo reale. Ad esempio, sapendo andare in bicicletta, si sa come bilanciarsi su veicoli a due ruote. Quindi, risulterebbe pi√π facile imparare ad andare in moto rispetto a chi non sa andare in bicicletta.</p>
<div id="fig-transfer-learning-apps" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-transfer-learning-apps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_transfer_learning_apps.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-transfer-learning-apps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.4: Trasferimento di conoscenze tra attivit√†. Fonte: <span class="citation" data-cites="zhuang2021comprehensive">Zhuang et al. (<a href="../../references.html#ref-zhuang2021comprehensive" role="doc-biblioref">2021</a>)</span>.
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-zhuang2021comprehensive" class="csl-entry" role="listitem">
Zhuang, Fuzhen, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, e Qing He. 2021. <span>¬´A Comprehensive Survey on Transfer Learning¬ª</span>. <em>Proc. IEEE</em> 109 (1): 43‚Äì76. <a href="https://doi.org/10.1109/jproc.2020.3004555">https://doi.org/10.1109/jproc.2020.3004555</a>.
</div></div></figure>
</div>
<p>Prendiamo l‚Äôesempio di un‚Äôapplicazione di sensore intelligente che utilizza l‚Äôintelligenza artificiale on-device per riconoscere gli oggetti nelle immagini acquisite dal dispositivo. Tradizionalmente, ci√≤ richiederebbe l‚Äôinvio dei dati dell‚Äôimmagine a un server, dove un ampio modello di rete neurale elabora i dati e invia i risultati. Con l‚Äôintelligenza artificiale on-device, il modello viene archiviato ed eseguito direttamente sul dispositivo, eliminando la necessit√† di inviare dati a un server.</p>
<p>Per personalizzare il modello per le caratteristiche on-device, addestrare un modello di rete neurale da zero sul dispositivo sarebbe poco pratico a causa delle risorse di calcolo limitate e della durata della batteria. √à qui che entra in gioco il ‚Äútransfer learning‚Äù [apprendimento tramite trasferimento]. Invece di addestrare un modello da zero, possiamo prendere un modello pre-addestrato, come una rete neurale convoluzionale (CNN) o una rete di trasformatori addestrata su un ampio set di dati di immagini, e perfezionarlo per la nostra specifica attivit√† di riconoscimento degli oggetti. Questa messa a punto pu√≤ essere eseguita direttamente sul dispositivo utilizzando un set di dati pi√π piccolo di immagini pertinenti all‚Äôattivit√†. Sfruttando il modello pre-addestrato, possiamo ridurre le risorse di calcolo e il tempo necessari per il training, ottenendo comunque un‚Äôelevata precisione per l‚Äôattivit√† di riconoscimento degli oggetti.</p>
<p>Il transfer learning √® importante per rendere praticabile l‚Äôintelligenza artificiale on-device, consentendoci di sfruttare modelli pre-addestrati e di perfezionarli per attivit√† specifiche, riducendo cos√¨ le risorse di calcolo e il tempo necessari per il training. La combinazione di intelligenza artificiale sul dispositivo e il ‚Äútransfer learning‚Äù apre nuove possibilit√† per applicazioni di intelligenza artificiale pi√π attente alla privacy e pi√π reattive alle esigenze degli utenti.</p>
<p>Il transfer learning ha rivoluzionato il modo in cui i modelli vengono sviluppati e distribuiti, sia nel cloud che nell‚Äôedge. Il transfer learning viene utilizzato nel mondo reale. Un esempio del genere √® l‚Äôuso del transfer learning per sviluppare modelli di intelligenza artificiale in grado di rilevare e diagnosticare malattie da immagini mediche, come raggi X, scansioni MRI [risonanza magnetica] e TAC. Ad esempio, i ricercatori della Stanford University hanno sviluppato un modello di apprendimento di trasferimento in grado di rilevare il cancro nelle immagini della pelle con una precisione del 97% <span class="citation" data-cites="esteva2017dermatologist">(<a href="../../references.html#ref-esteva2017dermatologist" role="doc-biblioref">Esteva et al. 2017</a>)</span>. Questo modello √® stato pre-addestrato su 1.28 milioni di immagini per classificare un‚Äôampia gamma di oggetti e poi specializzato per il rilevamento del cancro tramite l‚Äôaddestramento su un set di dati di immagini della pelle curato da dermatologi.</p>
<div class="no-row-height column-margin column-container"><div id="ref-esteva2017dermatologist" class="csl-entry" role="listitem">
Esteva, Andre, Brett Kuprel, Roberto A. Novoa, Justin Ko, Susan M. Swetter, Helen M. Blau, e Sebastian Thrun. 2017. <span>¬´Dermatologist-level classification of skin cancer with deep neural networks¬ª</span>. <em>Nature</em> 542 (7639): 115‚Äì18. <a href="https://doi.org/10.1038/nature21056">https://doi.org/10.1038/nature21056</a>.
</div></div><p>L‚Äôimplementazione negli scenari di produzione pu√≤ essere ampiamente categorizzata in due fasi: pre-distribuzione e post-distribuzione.</p>
<section id="specializzazione-pre-distribuzione" class="level3 page-columns page-full" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="specializzazione-pre-distribuzione"><span class="header-section-number">12.4.1</span> Specializzazione Pre-Distribuzione</h3>
<p>Nella fase di pre-implementazione, il transfer learning funge da catalizzatore per accelerare il processo di sviluppo. Ecco come funziona tipicamente: Si immagini di creare un sistema per riconoscere diverse razze di cani. Invece di partire da zero, possiamo utilizzare un modello pre-addestrato che ha gi√† padroneggiato il compito pi√π ampio di riconoscere gli animali nelle immagini.</p>
<p>Questo modello pre-addestrato funge da solida base e contiene una vasta conoscenza acquisita da dati estesi. Quindi perfezioniamo questo modello utilizzando un set di dati specializzato contenente immagini di varie razze di cani. Questo processo di messa a punto adatta il modello alle nostre esigenze specifiche, ovvero identificare con precisione le razze di cani. Una volta perfezionato e convalidato per soddisfare i criteri di prestazione, questo modello specializzato √® pronto per l‚Äôimplementazione.</p>
<p>Ecco come funziona in pratica:</p>
<ul>
<li><strong>Inizia con un Modello Pre-Addestrato:</strong> Si inizia selezionando un modello che √® gi√† stato addestrato su un set di dati completo, solitamente correlato a un‚Äôattivit√† generale. Questo modello funge da base per l‚Äôattivit√† in questione.</li>
<li><strong>Finetuning:</strong> Il modello pre-addestrato viene quindi perfezionato su un set di dati pi√π piccolo e specifico per l‚Äôattivit√† desiderata. Questo passaggio consente al modello di adattare e specializzare la sua conoscenza ai requisiti specifici dell‚Äôapplicazione.</li>
<li><strong>Validazione:</strong> Dopo la messa a punto, il modello viene convalidato per garantire che soddisfi i criteri di prestazione per l‚Äôattivit√† specializzata.</li>
<li><strong>Deployment:</strong> Una volta convalidato, il modello specializzato viene distribuito nell‚Äôambiente di produzione.</li>
</ul>
<p>Questo metodo riduce significativamente il tempo e le risorse di calcolo necessarie per addestrare un modello da zero <span class="citation" data-cites="pan2009survey">(<a href="../../references.html#ref-pan2009survey" role="doc-biblioref">Pan e Yang 2010</a>)</span>. Adottando l‚Äôapprendimento tramite trasferimento, i sistemi embedded possono raggiungere un‚Äôelevata precisione su attivit√† specializzate senza la necessit√† di raccogliere dati estesi o di impiegare risorse di calcolo significative per l‚Äôaddestramento da zero.</p>
<div class="no-row-height column-margin column-container"><div id="ref-pan2009survey" class="csl-entry" role="listitem">
Pan, Sinno Jialin, e Qiang Yang. 2010. <span>¬´A Survey on Transfer Learning¬ª</span>. <em>IEEE Trans. Knowl. Data Eng.</em> 22 (10): 1345‚Äì59. <a href="https://doi.org/10.1109/tkde.2009.191">https://doi.org/10.1109/tkde.2009.191</a>.
</div></div></section>
<section id="adattamento-post-distribuzione" class="level3" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="adattamento-post-distribuzione"><span class="header-section-number">12.4.2</span> Adattamento Post-Distribuzione</h3>
<p>L‚Äôimplementazione su un dispositivo non deve necessariamente segnare il culmine del percorso educativo di un modello ML. Con l‚Äôavvento dell‚Äôapprendimento per trasferimento, apriamo le porte all‚Äôimplementazione di modelli ML adattivi in scenari del mondo reale, soddisfacendo le esigenze personalizzate degli utenti.</p>
<p>Consideriamo un‚Äôapplicazione reale in cui un genitore desidera identificare il proprio figlio in una raccolta di immagini di un evento scolastico sul proprio smartphone. In questo scenario, il genitore si trova di fronte alla sfida di localizzare il proprio figlio in mezzo alle immagini di molti altri bambini. L‚Äôapprendimento per trasferimento pu√≤ essere impiegato qui per perfezionare il modello di un sistema embedded per questo compito unico e specializzato. Inizialmente, il sistema potrebbe utilizzare un modello generico addestrato per riconoscere i volti nelle immagini. Tuttavia, con l‚Äôapprendimento per trasferimento, il sistema pu√≤ adattare questo modello per riconoscere le caratteristiche specifiche del figlio dell‚Äôutente.</p>
<p>Ecco come funziona:</p>
<ol type="1">
<li><strong>Raccolta Dati:</strong> Il sistema embedded raccoglie immagini che includono il bambino, idealmente con l‚Äôinput del genitore per garantire accuratezza e pertinenza. Ci√≤ pu√≤ essere fatto direttamente sul dispositivo, mantenendo la privacy dei dati dell‚Äôutente.</li>
<li><strong>Fine Tuning del Modello:</strong> Il modello di riconoscimento facciale preesistente, che √® stato addestrato su un set di dati ampio e diversificato, viene quindi perfezionato utilizzando le immagini del bambino appena raccolte. Questo processo adatta il modello per riconoscere le caratteristiche facciali specifiche del bambino, distinguendolo dagli altri bambini nelle immagini.</li>
<li><strong>Validazione:</strong> Il modello rifinito viene poi convalidato per garantire che riconosca accuratamente il bambino in varie immagini. Ci√≤ pu√≤ comportare che il genitore verifichi le prestazioni del modello e fornisca feedback per ulteriori miglioramenti.</li>
<li><strong>Deployment:</strong> Una volta convalidato, il modello adattato viene distribuito sul dispositivo, consentendo al genitore di identificare facilmente il proprio figlio nelle immagini senza doverle esaminare manualmente.</li>
</ol>
<p>Questa personalizzazione al volo migliora l‚Äôefficacia del modello per il singolo utente, assicurando che tragga vantaggio dalla personalizzazione ML. Questo √®, in parte, il modo in cui iPhotos o Google Photos funzionano quando ci chiedono di riconoscere un volto e poi, in base a queste informazioni, indicizzano tutte le foto di quel volto. Poich√© l‚Äôapprendimento e l‚Äôadattamento avvengono sul dispositivo stesso, non ci sono rischi per la privacy personale. Le immagini dei genitori non vengono caricate su un server cloud o condivise con terze parti, proteggendo la privacy della famiglia e continuando a raccogliere i benefici di un modello ML personalizzato. Questo approccio rappresenta un significativo passo avanti nella ricerca per fornire agli utenti soluzioni ML personalizzate che rispettino e sostengano la loro privacy.</p>
</section>
<section id="vantaggi-1" class="level3" data-number="12.4.3">
<h3 data-number="12.4.3" class="anchored" data-anchor-id="vantaggi-1"><span class="header-section-number">12.4.3</span> Vantaggi</h3>
<p>Il transfer learning √® diventato una tecnica importante in ML e intelligenza artificiale, ed √® particolarmente prezioso per diversi motivi.</p>
<ol type="1">
<li><strong>Scarsit√† di Dati:</strong> In molti scenari reali, acquisire un set di dati etichettato sufficientemente grande per addestrare un modello ML da zero √® complicato. Il transfer learning mitiga questo problema consentendo l‚Äôuso di modelli pre-addestrati che hanno gi√† appreso funzionalit√† preziose da un vasto set di dati.</li>
<li><strong>Spese Computazionali:</strong> Addestrare un modello da zero richiede risorse computazionali e tempo significativi, specialmente per modelli complessi come reti neurali profonde. Utilizzando il transfer learning, possiamo sfruttare il calcolo che √® gi√† stato eseguito durante l‚Äôaddestramento del modello sorgente, risparmiando cos√¨ tempo e potenza computazionale.</li>
<li><strong>Dati Annotati Limitati:</strong> Per alcune attivit√† specifiche, potrebbero essere disponibili ampi dati grezzi, ma il processo di etichettatura di tali dati per l‚Äôapprendimento supervisionato pu√≤ essere costoso e richiedere molto tempo. Il transfer learning ci consente di utilizzare modelli pre-addestrati su un‚Äôattivit√† correlata con dati etichettati, quindi richiedendo meno dati annotati per la nuova attivit√†.</li>
</ol>
<p>Ci sono vantaggi nel riutilizzare le funzionalit√†:</p>
<ol type="1">
<li><strong>Hierarchical Feature Learning:</strong> I modelli di deep learning, in particolare le reti neurali convoluzionali (CNN), possono apprendere funzionalit√† gerarchiche. I layer inferiori in genere apprendono funzionalit√† generiche come bordi e forme, mentre quelli superiori apprendono funzionalit√† pi√π complesse e specifiche per l‚Äôattivit√†. Il transfer learning ci consente di riutilizzare le funzionalit√† generiche apprese da un modello e di perfezionare i livelli superiori per la nostra attivit√† specifica.</li>
<li><strong>Aumento delle Prestazioni:</strong> √à stato dimostrato che il transfer learning aumenta le prestazioni dei modelli su attivit√† con dati limitati. La conoscenza acquisita dall‚Äôattivit√† dall‚Äôattivit√† sorgente pu√≤ fornire un prezioso punto di partenza e portare a una convergenza pi√π rapida e a una maggiore accuratezza nell‚Äôattivit√† target.</li>
</ol>
<div id="exr-tlb" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;12.1: Il Transfer Learning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Si immagini di addestrare un‚ÄôIA a riconoscere i fiori come un professionista, ma senza aver bisogno di un milione di immagini di fiori! Questo √® il potere del transfer learning. In questo Colab, prenderemo un‚ÄôIA che conosce gi√† le immagini e le insegneremo a diventare un‚Äôesperta di fiori con meno sforzo. Prepararsi a rendere la propria IA pi√π intelligente, non √® pi√π difficile!</p>
<p><a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb?force_kitty_mode=1&amp;force_corgi_mode=1"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
<section id="concetti-fondamentali" class="level3" data-number="12.4.4">
<h3 data-number="12.4.4" class="anchored" data-anchor-id="concetti-fondamentali"><span class="header-section-number">12.4.4</span> Concetti Fondamentali</h3>
<p>Comprendere i concetti fondamentali del transfer learning √® essenziale per utilizzare efficacemente questo potente approccio in ML. Qui, analizzeremo alcuni dei principi e dei componenti principali che stanno alla base del processo di transfer learning.</p>
<section id="attivit√†-di-origine-e-di-destinazione" class="level4">
<h4 class="anchored" data-anchor-id="attivit√†-di-origine-e-di-destinazione">Attivit√† di Origine e di Destinazione</h4>
<p>Nel transfer learning, sono coinvolte due attivit√† principali: l‚Äôattivit√† di origine e quella di destinazione. L‚Äôattivit√† di origine √® quella per la quale il modello √® gi√† stato addestrato e ha appreso informazioni preziose. L‚Äôattivit√† di destinazione √® la nuova attivit√† che vogliamo che il modello esegua. L‚Äôobiettivo del transfer learning √® sfruttare le conoscenze acquisite dall‚Äôattivit√† di origine per migliorare le prestazioni nell‚Äôattivit√† di destinazione.</p>
<p>Supponiamo di avere un modello addestrato per riconoscere vari frutti nelle immagini (attivit√† di origine) e di voler creare un nuovo modello per riconoscere diverse verdure nelle immagini (attivit√† di destinazione). In tal caso, possiamo utilizzare il transfer learning per sfruttare le conoscenze acquisite durante l‚Äôattivit√† di riconoscimento della frutta per migliorare le prestazioni del modello di riconoscimento della verdura.</p>
</section>
<section id="trasferimento-della-rappresentazione" class="level4">
<h4 class="anchored" data-anchor-id="trasferimento-della-rappresentazione">Trasferimento della Rappresentazione</h4>
<p>Il trasferimento della rappresentazione riguarda le rappresentazioni apprese (caratteristiche) dall‚Äôattivit√† di origine all‚Äôattivit√† di destinazione. Esistono tre tipi principali di trasferimento della rappresentazione:</p>
<ul>
<li><strong>Trasferimento di Istanza:</strong> Implica il riutilizzo delle istanze di dati dall‚Äôattivit√† di origine nell‚Äôattivit√† di destinazione.</li>
<li><strong>Trasferimento della Rappresentazione delle Feature:</strong> Implica il trasferimento delle rappresentazioni di Feature [funzionalit√†] apprese dall‚Äôattivit√† di origine all‚Äôattivit√† di destinazione.</li>
<li><strong>Trasferimento di Parametri:</strong> Implica il trasferimento dei parametri appresi del modello (pesi) dall‚Äôattivit√† di origine all‚Äôattivit√† di destinazione.</li>
</ul>
<p>Nell‚Äôelaborazione del linguaggio naturale, un modello addestrato per comprendere la sintassi e la grammatica di una lingua (attivit√† di origine) pu√≤ trasferire le sue rappresentazioni apprese a un nuovo modello progettato per eseguire l‚Äôanalisi del sentiment (attivit√† di destinazione).</p>
</section>
<section id="finetuning" class="level4">
<h4 class="anchored" data-anchor-id="finetuning">Finetuning</h4>
<p>Il ‚Äúfinetuning‚Äù [messa a punto] √® il processo di regolazione dei parametri di un modello pre-addestrato per adattarlo all‚Äôattivit√† di destinazione. In genere, ci√≤ comporta l‚Äôaggiornamento dei pesi dei layer del modello, in particolare degli ultimi layer, per rendere il modello pi√π pertinente per la nuova attivit√†. Nella classificazione delle immagini, un modello pre-addestrato su un set di dati generale come ImageNet (attivit√† di origine) pu√≤ essere messo a punto regolando i pesi dei suoi livelli per ottenere buone prestazioni in un‚Äôattivit√† di classificazione specifica, come il riconoscimento di specie animali specifiche (attivit√† di destinazione).</p>
</section>
<section id="estrazione-delle-feature" class="level4">
<h4 class="anchored" data-anchor-id="estrazione-delle-feature">Estrazione delle Feature</h4>
<p>L‚Äôestrazione delle ‚Äúfeature‚Äù [caratteristiche] comporta l‚Äôutilizzo di un modello pre-addestrato come estrattore di feature fisse, in cui l‚Äôoutput dei layer intermedi del modello viene utilizzato come feature per l‚Äôattivit√† di destinazione. Questo approccio √® particolarmente utile quando l‚Äôattivit√† di destinazione ha un set di dati di piccole dimensioni, poich√© le feature apprese dal modello pre-addestrato possono migliorare significativamente le prestazioni. Nell‚Äôanalisi delle immagini mediche, un modello pre-addestrato su un ampio set di dati di immagini mediche generali (attivit√† di origine) pu√≤ essere utilizzato come estrattore di feature per fornire funzionalit√† preziose per un nuovo modello progettato per riconoscere specifici tipi di tumori nelle immagini radiografiche (attivit√† di destinazione).</p>
</section>
</section>
<section id="tipi-di-apprendimento-tramite-trasferimento" class="level3" data-number="12.4.5">
<h3 data-number="12.4.5" class="anchored" data-anchor-id="tipi-di-apprendimento-tramite-trasferimento"><span class="header-section-number">12.4.5</span> Tipi di Apprendimento Tramite Trasferimento</h3>
<p>L‚Äôapprendimento tramite trasferimento pu√≤ essere classificato in tre tipi principali in base alla natura delle attivit√† e dei dati di origine e di destinazione. Esploriamo ciascun tipo in dettaglio:</p>
<section id="apprendimento-tramite-trasferimento-induttivo" class="level4">
<h4 class="anchored" data-anchor-id="apprendimento-tramite-trasferimento-induttivo">Apprendimento Tramite Trasferimento Induttivo</h4>
<p>Nell‚Äôapprendimento tramite trasferimento induttivo, l‚Äôobiettivo √® apprendere la funzione predittiva di destinazione con l‚Äôaiuto dei dati di origine. In genere comporta la messa a punto di un modello pre-addestrato sull‚Äôattivit√† di destinazione con dati etichettati disponibili. Un esempio comune di apprendimento tramite trasferimento induttivo sono le attivit√† di classificazione delle immagini. Ad esempio, un modello pre-addestrato sul set di dati ImageNet (attivit√† di origine) pu√≤ essere messo a punto per classificare tipi specifici di uccelli (attivit√† di destinazione) utilizzando un set di dati etichettato pi√π piccolo di immagini di uccelli.</p>
</section>
<section id="apprendimento-tramite-trasferimento-transduttivo" class="level4">
<h4 class="anchored" data-anchor-id="apprendimento-tramite-trasferimento-transduttivo">Apprendimento Tramite Trasferimento Transduttivo</h4>
<p>L‚Äôapprendimento tramite trasferimento transduttivo comporta l‚Äôutilizzo di dati di origine e destinazione, ma solo dell‚Äôattivit√† di origine. L‚Äôobiettivo principale √® trasferire la conoscenza dal dominio di origine al dominio di destinazione, anche se le attivit√† rimangono le stesse. L‚Äôanalisi del ‚Äúsentiment‚Äù per diverse lingue pu√≤ servire come esempio di apprendimento tramite trasferimento transduttivo. Un modello addestrato per eseguire l‚Äôanalisi del sentiment in inglese (attivit√† di origine) pu√≤ essere adattato per eseguire l‚Äôanalisi del sentiment in un‚Äôaltra lingua, come il francese (attivit√† di destinazione), sfruttando set di dati paralleli di frasi in inglese e francese con gli stessi sentimenti.</p>
</section>
<section id="apprendimento-con-trasferimento-non-supervisionato" class="level4">
<h4 class="anchored" data-anchor-id="apprendimento-con-trasferimento-non-supervisionato">Apprendimento con Trasferimento Non Supervisionato</h4>
<p>L‚Äôapprendimento con trasferimento non supervisionato viene utilizzato quando le attivit√† di origine e di destinazione sono correlate, ma non sono disponibili dati etichettati per l‚Äôattivit√† di destinazione. L‚Äôobiettivo √® sfruttare la conoscenza acquisita dall‚Äôattivit√† di origine per migliorare le prestazioni nell‚Äôattivit√† di destinazione, anche senza dati etichettati. Un esempio di apprendimento di trasferimento non supervisionato √® la modellazione degli argomenti nei dati di testo. Un modello addestrato per estrarre argomenti da articoli di notizie (attivit√† di origine) pu√≤ essere adattato per estrarre argomenti da post sui social media (attivit√† di destinazione) senza aver bisogno di dati etichettati per i post sui social media.</p>
</section>
<section id="confronto-e-compromessi" class="level4">
<h4 class="anchored" data-anchor-id="confronto-e-compromessi">Confronto e Compromessi</h4>
<p>Sfruttando questi diversi tipi di apprendimento per trasferimento, i professionisti possono scegliere l‚Äôapproccio che meglio si adatta alla natura dei loro compiti e ai dati disponibili, portando infine a modelli di ML pi√π efficaci ed efficienti. Quindi, in sintesi:</p>
<ul>
<li><strong>Induttivo:</strong> Diversi compiti di origine e destinazione, domini diversi</li>
<li><strong>Trasduttivo:</strong> diversi compiti di origine e destinazione, stesso dominio</li>
<li><strong>Non supervisionato:</strong> dati di origine non etichettati, trasferisce le rappresentazioni delle feature</li>
</ul>
<p><a href="#tbl-tltypes" class="quarto-xref">Tabella&nbsp;<span>12.1</span></a> presenta una matrice che delinea in modo un po‚Äô pi√π dettagliato le somiglianze e le differenze tra i tipi di apprendimento per trasferimento:</p>
<div id="tbl-tltypes" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-tltypes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;12.1: Confronto dei tipi di apprendimento per trasferimento.
</figcaption>
<div aria-describedby="tbl-tltypes-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 17%">
<col style="width: 23%">
<col style="width: 22%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspetto</th>
<th style="text-align: left;">Apprendimento Induttivo per Trasferimento</th>
<th style="text-align: left;">Apprendimento Trasduttivo per Trasferimento</th>
<th style="text-align: left;">Apprendimento Non Supervisionato</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Dati Etichettati per l‚ÄôAttivit√† di Destinazione</td>
<td style="text-align: left;">Obbligatorio</td>
<td style="text-align: left;">Non obbligatorio</td>
<td style="text-align: left;">Non obbligatorio</td>
</tr>
<tr class="even">
<td style="text-align: left;">Attivit√† di origine</td>
<td style="text-align: left;">Pu√≤ essere diversa</td>
<td style="text-align: left;">Lo stesso</td>
<td style="text-align: left;">Lo stesso o diverso</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Attivit√† di destinazione</td>
<td style="text-align: left;">Pu√≤ essere diversa</td>
<td style="text-align: left;">Lo stesso</td>
<td style="text-align: left;">Pu√≤ essere diverso</td>
</tr>
<tr class="even">
<td style="text-align: left;">Obiettivo</td>
<td style="text-align: left;">Migliorare le prestazioni dell‚Äôattivit√† target con i dati sorgente</td>
<td style="text-align: left;">Trasferisci la conoscenza dal dominio sorgente a quello target</td>
<td style="text-align: left;">Sfrutta l‚Äôattivit√† sorgente per migliorare le prestazioni dell‚Äôattivit√† target senza dati etichettati</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Esempio</td>
<td style="text-align: left;">Da ImageNet alla classificazione degli uccelli</td>
<td style="text-align: left;">Analisi del sentiment in diverse lingue</td>
<td style="text-align: left;">Modellazione degli argomenti per diversi dati di testo</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="vincoli-e-considerazioni" class="level3" data-number="12.4.6">
<h3 data-number="12.4.6" class="anchored" data-anchor-id="vincoli-e-considerazioni"><span class="header-section-number">12.4.6</span> Vincoli e Considerazioni</h3>
<p>Quando si intraprende un apprendimento per trasferimento, ci sono diversi fattori che devono essere considerati per garantire un trasferimento di conoscenze di successo e prestazioni del modello. Ecco una ripartizione di alcuni fattori chiave:</p>
<section id="somiglianza-dei-domini" class="level4">
<h4 class="anchored" data-anchor-id="somiglianza-dei-domini">Somiglianza dei Domini</h4>
<p>La similarit√† di dominio si riferisce a quanto strettamente correlati sono i domini di origine e di destinazione. Pi√π simili sono i domini, pi√π √® probabile che l‚Äôapprendimento per trasferimento abbia successo. Trasferire la conoscenza da un modello addestrato su immagini di scene esterne (dominio di origine) a un nuovo compito che prevede il riconoscimento di oggetti in scene interne (dominio di destinazione) potrebbe avere pi√π successo rispetto al trasferire la conoscenza da scene esterne a un compito che prevede l‚Äôanalisi del testo, poich√© i domini (immagini vs.&nbsp;testo) sono piuttosto diversi.</p>
</section>
<section id="similarit√†-dellattivit√†" class="level4">
<h4 class="anchored" data-anchor-id="similarit√†-dellattivit√†">Similarit√† dell‚ÄôAttivit√†</h4>
<p>La similarit√† dell‚Äôattivit√† si riferisce a quanto strettamente correlati sono le attivit√† di origine e di destinazione. √à probabile che attivit√† simili traggano maggiori benefici dall‚Äôapprendimento per trasferimento. Un modello addestrato per riconoscere diverse razze di cani (attivit√† di origine) pu√≤ essere adattato pi√π facilmente per riconoscere diverse razze di gatti (attivit√† di destinazione) rispetto a quanto possa essere adattato per eseguire un‚Äôattivit√† completamente diversa come la traduzione di una lingua.</p>
</section>
<section id="qualit√†-e-quantit√†-dei-dati" class="level4">
<h4 class="anchored" data-anchor-id="qualit√†-e-quantit√†-dei-dati">Qualit√† e Quantit√† dei Dati</h4>
<p>La qualit√† e la quantit√† dei dati disponibili per il compito di destinazione possono avere un impatto significativo sul successo dell‚Äôapprendimento per trasferimento. Pi√π dati di alta qualit√† possono comportare migliori prestazioni del modello. Supponiamo di avere un ampio set di dati con immagini chiare e ben etichettate per riconoscere specie di uccelli specifiche. In tal caso, il processo di apprendimento per trasferimento avr√† probabilmente pi√π successo rispetto a un set di dati piccolo e rumoroso.</p>
</section>
<section id="sovrapposizione-dello-spazio-delle-feature" class="level4">
<h4 class="anchored" data-anchor-id="sovrapposizione-dello-spazio-delle-feature">Sovrapposizione dello Spazio delle Feature</h4>
<p>La sovrapposizione dello spazio delle feature si riferisce a quanto bene le feature apprese dal modello sorgente si allineano con quelle necessarie per l‚Äôattivit√† di destinazione. Una maggiore sovrapposizione pu√≤ portare a un apprendimento per trasferimento pi√π efficace. Un modello addestrato su immagini ad alta risoluzione (attivit√† di origine) potrebbe non trasferirsi bene a un‚Äôattivit√† di destinazione che coinvolge immagini a bassa risoluzione, poich√© lo spazio delle feature (alta risoluzione rispetto a bassa risoluzione) √® diverso.</p>
</section>
<section id="complessit√†-del-modello" class="level4">
<h4 class="anchored" data-anchor-id="complessit√†-del-modello">Complessit√† del Modello</h4>
<p>Anche la complessit√† del modello sorgente pu√≤ influire sul successo dell‚Äôapprendimento per trasferimento. A volte, un modello pi√π semplice potrebbe trasferirsi meglio di uno complesso, poich√© √® meno probabile che si adatti eccessivamente all‚Äôattivit√† di origine. Ad esempio, un semplice modello di rete neurale convoluzionale (CNN) addestrato su dati di immagini (attivit√† di origine) pu√≤ essere trasferito con maggiore successo a una nuova attivit√† di classificazione di immagini (attivit√† di destinazione) rispetto a una CNN complessa con molti layer, poich√© √® meno probabile che il modello pi√π semplice si adatti eccessivamente all‚Äôattivit√† di origine.</p>
<p>Considerando questi fattori, i professionisti del ML possono prendere decisioni informate su quando e come utilizzare l‚Äôapprendimento per trasferimento, portando infine a prestazioni del modello pi√π efficaci nell‚Äôattivit√† di destinazione. Il successo dell‚Äôapprendimento per trasferimento dipende dal grado di similarit√† tra i domini di origine e di destinazione. L‚Äôoverfitting [adattamento eccessivo] √® rischioso, soprattutto quando la messa a punto avviene su un set di dati limitato. Sul fronte computazionale, alcuni modelli pre-addestrati, a causa delle loro dimensioni, potrebbero non adattarsi comodamente ai vincoli di memoria di alcuni dispositivi o potrebbero essere eseguiti in modo proibitivamente lento. Nel tempo, con l‚Äôevoluzione dei dati, c‚Äô√® il potenziale per la ‚Äúdrift‚Äù [deriva] del modello, che indica la necessit√† di un riaddestramento periodico o di un adattamento continuo.</p>
<p>Scoprire di pi√π sull‚Äôapprendimento per trasferimento in <a href="#vid-tl" class="quarto-xref">Video&nbsp;<span>12.1</span></a> di seguito.</p>
<div id="vid-tl" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;12.1: Il Transfer Learning
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/FQM13HkEfBk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
</section>
</section>
</section>
<section id="sec-fl" class="level2 page-columns page-full" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="sec-fl"><span class="header-section-number">12.5</span> Apprendimento Automatico Federato</h2>
<p>Panoramica dell‚ÄôApprendimento Federato</p>
<p>L‚ÄôInternet moderna √® piena di grandi reti di dispositivi connessi. Che si tratti di telefoni cellulari, termostati, smart speaker o altri prodotti IoT, innumerevoli dispositivi edge sono una miniera d‚Äôoro per dati iperpersonalizzati e ricchi. Tuttavia, con quei dati ricchi arriva una serie di problemi con il trasferimento delle informazioni e la privacy. Costruire un set di dati di training nel cloud da questi dispositivi comporterebbe un‚Äôampia larghezza di banda, costi per il trasferimento dati e violazione della privacy degli utenti.</p>
<p>L‚Äôapprendimento federato offre una soluzione a questi problemi: addestrare i modelli parzialmente sui dispositivi edge e comunicare solo gli aggiornamenti al cloud. Nel 2016, un team di Google ha progettato un‚Äôarchitettura per l‚Äôapprendimento federato che tenta di risolvere questi problemi.</p>
<p>Nel loro articolo iniziale, Google delinea un principio di algoritmo di apprendimento federato chiamato FederatedAveraging, che √® mostrato in <a href="#fig-federated-avg-algo" class="quarto-xref">Figura&nbsp;<span>12.5</span></a>. In particolare, FederatedAveraging esegue la ‚Äústochastic gradient descent (SGD) [discesa del gradiente stocastico] su diversi dispositivi edge. In questo processo, ogni dispositivo calcola un gradiente <span class="math inline">\(g_k = \nabla F_k(w_t)\)</span> che viene poi applicato per aggiornare i pesi lato server come (con <span class="math inline">\(\eta\)</span> come tasso di apprendimento su <span class="math inline">\(k\)</span> client): <span class="math display">\[
w_{t+1} \rightarrow w_t - \eta \sum_{k=1}^{K} \frac{n_k}{n}g_k
\]</span> Questo riassume l‚Äôalgoritmo di base per l‚Äôapprendimento federato sulla destra. Per ogni round di addestramento, il server prende un set casuale di dispositivi client e chiama ogni client per addestrare sul suo batch locale usando i pesi lato server pi√π recenti. Tali pesi vengono poi restituiti al server, dove vengono raccolti individualmente e calcolati per aggiornare i pesi del modello globale.</p>
<div id="fig-federated-avg-algo" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-federated-avg-algo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_fed_averaging.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-federated-avg-algo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.5: Algoritmo FederatedAverage proposto da Google. Fonte: McMahan et al.&nbsp;(<a href="https://arxiv.org/abs/1602.05629">2017</a>).
</figcaption>
</figure>
</div>
<p>Con questa struttura proposta, ci sono alcuni vettori chiave per ottimizzare ulteriormente l‚Äôapprendimento federato. Descriveremo ciascuno di essi nelle seguenti sottosezioni.</p>
<p><a href="#vid-fl" class="quarto-xref">Video&nbsp;<span>12.2</span></a> fornisce una panoramica dell‚Äôapprendimento federato.</p>
<div id="vid-fl" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;12.2: Il Transfer Learning
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/zqv1eELa7fs" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<section id="efficienza-della-comunicazione" class="level3" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="efficienza-della-comunicazione"><span class="header-section-number">12.5.1</span> Efficienza della Comunicazione</h3>
<p>Uno dei principali colli di bottiglia nell‚Äôapprendimento federato √® la comunicazione. Ogni volta che un client addestra il modello, deve comunicare i propri aggiornamenti al server. Analogamente, una volta che il server ha calcolato la media di tutti gli aggiornamenti, deve inviarli al client. Ci√≤ comporta enormi costi di larghezza di banda e risorse su grandi reti di milioni di dispositivi. Con l‚Äôavanzare del campo dell‚Äôapprendimento federato, sono state sviluppate alcune ottimizzazioni per ridurre al minimo questa comunicazione. Per affrontare l‚Äôingombro del modello, i ricercatori hanno sviluppato tecniche di compressione del modello. Nel protocollo client-server, l‚Äôapprendimento federato pu√≤ anche ridurre al minimo la comunicazione tramite la condivisione selettiva degli aggiornamenti sui client. Infine, anche tecniche di aggregazione efficienti possono semplificare il processo di comunicazione.</p>
</section>
<section id="compressione-del-modello" class="level3 page-columns page-full" data-number="12.5.2">
<h3 data-number="12.5.2" class="anchored" data-anchor-id="compressione-del-modello"><span class="header-section-number">12.5.2</span> Compressione del Modello</h3>
<p>Nell‚Äôapprendimento federato standard, il server comunica l‚Äôintero modello a ciascun client, quindi il client invia tutti i pesi aggiornati. Ci√≤ significa che il modo pi√π semplice per ridurre l‚Äôingombro di memoria e comunicazione del client √® ridurre al minimo le dimensioni del modello che deve essere comunicato. Possiamo impiegare tutte le strategie di ottimizzazione del modello discusse in precedenza per farlo.</p>
<p>Nel 2022, un altro team di Google ha proposto che ogni client comunichi tramite un formato compresso e decomprima il modello al volo per l‚Äôaddestramento <span class="citation" data-cites="yang2023online">(<a href="../../references.html#ref-yang2023online" role="doc-biblioref">Yang et al. 2023</a>)</span>, allocando e deallocando l‚Äôintera memoria per il modello solo per un breve periodo durante l‚Äôaddestramento. Il modello viene compresso tramite una gamma di diverse strategie di quantizzazione elaborate nel loro documento. Nel frattempo, il server pu√≤ aggiornare il modello non compresso decomprimendolo e applicando gli aggiornamenti man mano che arrivano.</p>
<div class="no-row-height column-margin column-container"><div id="ref-yang2023online" class="csl-entry" role="listitem">
Yang, Tien-Ju, Yonghui Xiao, Giovanni Motta, Fran√ßoise Beaufays, Rajiv Mathews, e Mingqing Chen. 2023. <span>¬´Online Model Compression for Federated Learning with Large Models¬ª</span>. In <em>ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 1‚Äì5. IEEE; IEEE. <a href="https://doi.org/10.1109/icassp49357.2023.10097124">https://doi.org/10.1109/icassp49357.2023.10097124</a>.
</div></div></section>
<section id="condivisione-selettiva-degli-aggiornamenti" class="level3 page-columns page-full" data-number="12.5.3">
<h3 data-number="12.5.3" class="anchored" data-anchor-id="condivisione-selettiva-degli-aggiornamenti"><span class="header-section-number">12.5.3</span> Condivisione Selettiva degli Aggiornamenti</h3>
<p>Esistono molti metodi per condividere selettivamente gli aggiornamenti. Il principio generale √® che la riduzione della porzione del modello che i client stanno addestrando lato edge riduce la memoria necessaria per l‚Äôaddestramento e la dimensione della comunicazione con il server. Nell‚Äôapprendimento federato di base, il client addestra l‚Äôintero modello. Ci√≤ significa che quando un client invia un aggiornamento al server, ha gradienti per ogni peso nella rete.</p>
<p>Tuttavia, non possiamo semplicemente ridurre la comunicazione inviando parti di quei gradienti da ogni client al server perch√© i gradienti fanno parte di un intero aggiornamento necessario per migliorare il modello. Invece, si deve progettare architettonicamente il modello in modo che ogni client addestri solo una piccola parte del modello pi√π ampio, riducendo la comunicazione totale e ottenendo comunque il vantaggio dell‚Äôaddestramento sui dati del client. Un articolo <span class="citation" data-cites="shi2022data">(<a href="../../references.html#ref-shi2022data" role="doc-biblioref">Shi e Radu 2022</a>)</span> dell‚ÄôUniversit√† di Sheffield applica questo concetto a una CNN suddividendo il modello globale in due parti: una parte superiore e una inferiore, come mostrato in <span class="citation" data-cites="chen2023learning">Z. Chen e Xu (<a href="../../references.html#ref-chen2023learning" role="doc-biblioref">2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-shi2022data" class="csl-entry" role="listitem">
Shi, Hongrui, e Valentin Radu. 2022. <span>¬´Data selection for efficient model update in federated learning¬ª</span>. In <em>Proceedings of the 2nd European Workshop on Machine Learning and Systems</em>, 72‚Äì78. ACM. <a href="https://doi.org/10.1145/3517207.3526980">https://doi.org/10.1145/3517207.3526980</a>.
</div></div><div id="fig-split-model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-split-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_split_model.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-split-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.6: Suddivisione dell‚Äôarchitettura del modello per la condivisione selettiva. Fonte: Shi et al., (<a href="https://doi.org/10.1145/3517207.3526980">2022</a>).
</figcaption>
</figure>
</div>
<p>La parte inferiore √® progettata per concentrarsi sulle funzionalit√† generiche nel set di dati, mentre la parte superiore, addestrata su tali funzionalit√† generiche, √® progettata per essere pi√π sensibile alle mappe di attivazione. Ci√≤ significa che la parte inferiore del modello viene addestrata tramite la media federata standard su tutti i client. Nel frattempo, la parte superiore del modello viene addestrata interamente sul lato server dalle mappe di attivazione generate dai client. Questo approccio riduce drasticamente la comunicazione per il modello, rendendo comunque la rete robusta a vari tipi di input trovati nei dati sui dispositivi client.</p>
</section>
<section id="aggregazione-ottimizzata" class="level3 page-columns page-full" data-number="12.5.4">
<h3 data-number="12.5.4" class="anchored" data-anchor-id="aggregazione-ottimizzata"><span class="header-section-number">12.5.4</span> Aggregazione Ottimizzata</h3>
<p>Oltre a ridurre il sovraccarico di comunicazione, l‚Äôottimizzazione della funzione di aggregazione pu√≤ migliorare la velocit√† e l‚Äôaccuratezza dell‚Äôaddestramento del modello in determinati casi d‚Äôuso di apprendimento federato. Mentre lo standard per l‚Äôaggregazione √® solo la media, vari altri approcci possono migliorare l‚Äôefficienza, l‚Äôaccuratezza e la sicurezza del modello. Un‚Äôalternativa √® la ‚Äúmedia ritagliata‚Äù, che limita gli aggiornamenti del modello entro un intervallo specifico. Un‚Äôaltra strategia per preservare la sicurezza √® l‚Äôaggregazione media della privacy differenziale. Questo approccio integra la privacy differenziale nella fase di aggregazione per proteggere le identit√† dei client. Ogni client aggiunge uno strato di rumore casuale ai propri aggiornamenti prima di comunicare al server. Il server si aggiorna quindi con gli aggiornamenti rumorosi, il che significa che la quantit√† di rumore deve essere regolata attentamente per bilanciare privacy e precisione.</p>
<p>Oltre ai metodi di aggregazione che migliorano la sicurezza, ci sono diverse modifiche ai metodi di aggregazione che possono migliorare la velocit√† di training e le prestazioni aggiungendo metadati client insieme agli aggiornamenti del peso. Il ‚ÄúMomentum aggregation‚Äù √® una tecnica che aiuta ad affrontare il problema della convergenza. Nell‚Äôapprendimento federato, i dati client possono essere estremamente eterogenei a seconda dei diversi ambienti in cui vengono utilizzati i dispositivi. Ci√≤ significa che molti modelli con dati eterogenei potrebbero aver bisogno di aiuto per convergere. Ogni client memorizza localmente un termine di ‚Äúmomentum‚Äù, che traccia il ritmo del cambiamento su diversi aggiornamenti. Con i client che comunicano questo ‚Äúmomentum‚Äù, il server pu√≤ tenere conto della velocit√† di cambiamento di ogni aggiornamento quando si modifica il modello globale per accelerare la convergenza. Allo stesso modo, l‚Äôaggregazione ponderata pu√≤ tenere conto delle prestazioni del client o di altri parametri come il tipo di dispositivo o la potenza della connessione di rete per regolare il peso con cui il server dovrebbe incorporare gli aggiornamenti del modello. Ulteriori descrizioni di algoritmi di aggregazione specifici sono fornite da <span class="citation" data-cites="moshawrab2023reviewing">Moshawrab et al. (<a href="../../references.html#ref-moshawrab2023reviewing" role="doc-biblioref">2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-moshawrab2023reviewing" class="csl-entry" role="listitem">
Moshawrab, Mohammad, Mehdi Adda, Abdenour Bouzouane, Hussein Ibrahim, e Ali Raad. 2023. <span>¬´Reviewing Federated Learning Aggregation Algorithms; Strategies, Contributions, Limitations and Future Perspectives¬ª</span>. <em>Electronics</em> 12 (10): 2287. <a href="https://doi.org/10.3390/electronics12102287">https://doi.org/10.3390/electronics12102287</a>.
</div></div></section>
<section id="gestione-dei-dati-non-iid" class="level3 page-columns page-full" data-number="12.5.5">
<h3 data-number="12.5.5" class="anchored" data-anchor-id="gestione-dei-dati-non-iid"><span class="header-section-number">12.5.5</span> Gestione dei Dati non-IID</h3>
<p>Quando si utilizza l‚Äôapprendimento federato per addestrare un modello su molti dispositivi client, √® conveniente considerare i dati come indipendenti e distribuiti in modo identico (IID) su tutti i client. Quando i dati sono IID, il modello converger√† pi√π velocemente e funzioner√† meglio perch√© ogni aggiornamento locale su un dato client √® pi√π rappresentativo del set di dati pi√π ampio. Questo semplifica l‚Äôaggregazione, poich√© √® possibile calcolare direttamente la media di tutti i client. Tuttavia, differisce dal modo in cui i dati spesso appaiono nel mondo reale. Si considerino alcuni dei seguenti modi in cui i dati possono essere non IID:</p>
<ul>
<li><p>Imparando su un set di dispositivi di monitoraggio sanitari, diversi modelli di dispositivi potrebbero significare diverse qualit√† e propriet√† dei sensori. Ci√≤ significa che sensori e dispositivi di bassa qualit√† possono produrre dati e, pertanto, aggiornamenti del modello nettamente diversi da quelli di alta qualit√†</p></li>
<li><p>Una tastiera intelligente addestrata per eseguire la correzione automatica. Se si ha una quantit√† sproporzionata di dispositivi da una determinata regione, lo slang, la struttura della frase o persino il linguaggio che stavano usando potrebbero deviare pi√π aggiornamenti verso un certo stile di digitazione</p></li>
<li><p>Se si hanno sensori per la fauna selvatica in aree remote, la connettivit√† potrebbe non essere distribuita equamente, facendo s√¨ che alcuni client in determinate regioni non siano in grado di inviare pi√π aggiornamenti rispetto ad altri. Se quelle regioni hanno un‚Äôattivit√† di fauna selvatica diversa da alcune specie, ci√≤ potrebbe distorcere gli aggiornamenti verso quegli animali</p></li>
</ul>
<p>Esistono alcuni approcci per affrontare i dati non IID nell‚Äôapprendimento federato. Uno potrebbe essere quello di modificare l‚Äôalgoritmo di aggregazione. Se si utilizza un algoritmo di aggregazione ponderato, √® possibile regolarlo in base a diverse propriet√† del client come regione, propriet√† del sensore o connettivit√† <span class="citation" data-cites="zhao2018federated">(<a href="../../references.html#ref-zhao2018federated" role="doc-biblioref">Zhao et al. 2018</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-zhao2018federated" class="csl-entry" role="listitem">
Zhao, Yue, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, e Vikas Chandra. 2018. <span>¬´Federated learning with non-iid data¬ª</span>. <em>ArXiv preprint</em> abs/1806.00582. <a href="https://arxiv.org/abs/1806.00582">https://arxiv.org/abs/1806.00582</a>.
</div></div></section>
<section id="selezione-del-client" class="level3" data-number="12.5.6">
<h3 data-number="12.5.6" class="anchored" data-anchor-id="selezione-del-client"><span class="header-section-number">12.5.6</span> Selezione del Client</h3>
<p>Considerando tutti i fattori che influenzano l‚Äôefficacia dell‚Äôapprendimento federato, come i dati IID e la comunicazione, la selezione del client √® una componente chiave per garantire che un sistema si alleni bene. La selezione dei client sbagliati pu√≤ distorcere il dataset, con conseguenti dati non IID. Analogamente, la scelta casuale di client con cattive connessioni di rete pu√≤ rallentare la comunicazione. Pertanto, √® necessario considerare diverse caratteristiche chiave quando si seleziona il sottoinsieme corretto di client.</p>
<p>Quando si selezionano i client, ci sono tre componenti principali da considerare: eterogeneit√† dei dati, allocazione delle risorse e costo della comunicazione. Possiamo selezionare i client in base alle metriche proposte in precedenza nella sezione non IID per affrontare l‚Äôeterogeneit√† dei dati. Nell‚Äôapprendimento federato, tutti i dispositivi possono avere diverse quantit√† di elaborazione, con il risultato che alcuni sono pi√π inefficienti di altri nell‚Äôaddestramento. Quando si seleziona un sottoinsieme di client per l‚Äôaddestramento, si deve considerare un equilibrio tra eterogeneit√† dei dati e risorse disponibili. In uno scenario ideale, √® sempre possibile selezionare il sottoinsieme di client con le maggiori risorse. Tuttavia, questo potrebbe distorcere il set di dati, quindi √® necessario trovare un equilibrio. Le differenze di comunicazione aggiungono un altro layer; si desidera evitare di essere bloccati dall‚Äôattesa che i dispositivi con connessioni scadenti trasmettano tutti i loro aggiornamenti. Pertanto, √® anche necessario considerare la scelta di un sottoinsieme di dispositivi diversi ma ben collegati.</p>
</section>
<section id="un-esempio-di-apprendimento-federato-distribuito-g-board" class="level3 page-columns page-full" data-number="12.5.7">
<h3 data-number="12.5.7" class="anchored" data-anchor-id="un-esempio-di-apprendimento-federato-distribuito-g-board"><span class="header-section-number">12.5.7</span> Un Esempio di Apprendimento Federato Distribuito: G board</h3>
<p>Un esempio primario di un sistema di apprendimento federato distribuito √® la tastiera di Google, Gboard, per dispositivi Android. Nell‚Äôimplementare l‚Äôapprendimento federato per la tastiera, Google si √® concentrata sull‚Äôimpiego di tecniche di privacy differenziali per proteggere i dati e l‚Äôidentit√† dell‚Äôutente. Gboard sfrutta modelli linguistici per diverse funzionalit√† chiave, come Next Word Prediction (NWP), Smart Compose (SC) e On-The-Fly rescoring (OTF) <span class="citation" data-cites="xu2023federated">(<a href="../../references.html#ref-xu2023federated" role="doc-biblioref">Xu et al. 2023</a>)</span>, come mostrato in <a href="#fig-gboard-features" class="quarto-xref">Figura&nbsp;<span>12.7</span></a>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-xu2023federated" class="csl-entry" role="listitem">
Xu, Zheng, Yanxiang Zhang, Galen Andrew, Christopher A Choquette-Choo, Peter Kairouz, H Brendan McMahan, Jesse Rosenstock, e Yuanbo Zhang. 2023. <span>¬´Federated Learning of Gboard Language Models with Differential Privacy¬ª</span>. <em>ArXiv preprint</em> abs/2305.18465. <a href="https://arxiv.org/abs/2305.18465">https://arxiv.org/abs/2305.18465</a>.
</div></div><p>NWP anticiper√† la parola successiva che l‚Äôutente tenta di digitare in base a quella precedente. SC fornisce suggerimenti in linea per velocizzare la digitazione in base a ciascun carattere. OTF riclassificher√† le parole successive proposte in base al processo di digitazione attivo. Tutti e tre questi modelli devono essere eseguiti rapidamente sull‚Äôedge e l‚Äôapprendimento federato pu√≤ accelerare l‚Äôaddestramento sui dati degli utenti. Tuttavia, caricare ogni parola digitata da un utente sul cloud per l‚Äôaddestramento costituirebbe una violazione massiccia della privacy. Pertanto, l‚Äôapprendimento federato enfatizza la privacy differenziale, che protegge l‚Äôutente consentendo al contempo una migliore esperienza utente.</p>
<div id="fig-gboard-features" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-gboard-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_gboard_example.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-gboard-features-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.7: Funzionalit√† di Google G Board. Fonte: Zheng et al., (<a href="https://arxiv.org/abs/2305.18465">2023</a>).
</figcaption>
</figure>
</div>
<p>Per raggiungere questo obiettivo, Google ha impiegato il suo algoritmo DP-FTRL, che fornisce una garanzia formale che i modelli addestrati non memorizzeranno dati o identit√† utente specifici. La progettazione del sistema dell‚Äôalgoritmo √® mostrata in <a href="#fig-differential-privacy" class="quarto-xref">Figura&nbsp;<span>12.8</span></a>. DP-FTRL, combinato con l‚Äôaggregazione sicura, crittografa gli aggiornamenti del modello e fornisce un equilibrio ottimale tra privacy e utilit√†. Inoltre, il clipping adattivo viene applicato nel processo di aggregazione per limitare l‚Äôimpatto dei singoli utenti sul modello globale (passaggio 3 in <a href="#fig-differential-privacy" class="quarto-xref">Figura&nbsp;<span>12.8</span></a>). Combinando tutte queste tecniche, Google pu√≤ perfezionare continuamente la sua tastiera preservando al contempo la privacy dell‚Äôutente in un modo formalmente dimostrabile.</p>
<div id="fig-differential-privacy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-differential-privacy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_gboard_approach.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-differential-privacy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.8: Privacy Differenziale in G Board. Fonte: Zheng et al., (<a href="https://arxiv.org/abs/2305.18465">2023</a>).
</figcaption>
</figure>
</div>
<div id="exr-flg" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;12.2: Apprendimento Federato - Generazione di Testo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Avete mai usato quelle tastiere intelligenti che suggeriscono la parola successiva? Con l‚Äôapprendimento federato, possiamo renderle ancora migliori senza sacrificare la privacy. In questo Colab, insegneremo a un‚ÄôIA a prevedere le parole tramite l‚Äôaddestramento su dati di testo distribuiti su pi√π dispositivi. Prepariamoci a rendere la digitazione ancora pi√π fluida!</p>
<p><a href="https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/federated_learning_for_text_generation.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
<div id="exr-fli" class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizio&nbsp;12.3: Apprendimento Federato - Classificazione delle Immagini
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Vogliamo addestrare un‚ÄôIA esperta di immagini senza inviare le proprie foto al cloud? L‚Äôapprendimento federato √® la risposta! In questo Colab, addestreremo un modello su pi√π dispositivi, ognuno dei quali apprende dalle proprie immagini. La privacy √® protetta e il lavoro di squadra fa funzionare il sogno dell‚ÄôIA!</p>
<p><a href="https://colab.research.google.com/github/tensorflow/federated/blob/v0.5.0/docs/tutorials/federated_learning_for_image_classification.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.png" class="img-fluid"></a></p>
</div>
</div>
</div>
</section>
<section id="benchmarking-per-lapprendimento-federato-medperf" class="level3 page-columns page-full" data-number="12.5.8">
<h3 data-number="12.5.8" class="anchored" data-anchor-id="benchmarking-per-lapprendimento-federato-medperf"><span class="header-section-number">12.5.8</span> Benchmarking per l‚ÄôApprendimento Federato: MedPerf</h3>
<p>Uno degli esempi pi√π ricchi di dati edge sono i dispositivi medici. Questi dispositivi memorizzano alcuni dei dati pi√π personali degli utenti, ma offrono enormi progressi nel trattamento personalizzato e una migliore accuratezza nell‚Äôintelligenza artificiale medica. Dati questi due fattori, i dispositivi medici sono il caso d‚Äôuso perfetto per l‚Äôapprendimento federato. <a href="https://doi.org/10.1038/s42256-023-00652-2">MedPerf</a> √® una piattaforma open source utilizzata per confrontare i modelli utilizzando la valutazione federata <span class="citation" data-cites="karargyris2023federated">(<a href="../../references.html#ref-karargyris2023federated" role="doc-biblioref">Karargyris et al. 2023</a>)</span>. Invece di addestrare semplicemente i modelli tramite apprendimento federato, MedPerf porta il modello sui dispositivi edge per testarlo rispetto ai dati personalizzati, preservando al contempo la privacy. In questo modo, un comitato di benchmark pu√≤ valutare vari modelli nel mondo reale sui dispositivi edge, preservando comunque l‚Äôanonimato del paziente.</p>
<div class="no-row-height column-margin column-container"><div id="ref-karargyris2023federated" class="csl-entry" role="listitem">
Karargyris, Alexandros, Renato Umeton, Micah J Sheller, Alejandro Aristizabal, Johnu George, Anna Wuest, Sarthak Pati, et al. 2023. <span>¬´Federated benchmarking of medical artificial intelligence with <span>MedPerf</span>¬ª</span>. <em>Nature Machine Intelligence</em> 5 (7): 799‚Äì810. <a href="https://doi.org/10.1038/s42256-023-00652-2">https://doi.org/10.1038/s42256-023-00652-2</a>.
</div></div></section>
</section>
<section id="problemi-di-sicurezza" class="level2 page-columns page-full" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="problemi-di-sicurezza"><span class="header-section-number">12.6</span> Problemi di Sicurezza</h2>
<p>L‚Äôesecuzione di training e adattamento del modello ML sui dispositivi degli utenti finali introduce anche rischi per la sicurezza che devono essere affrontati. Alcune preoccupazioni chiave per la sicurezza includono:</p>
<ul>
<li><strong>Esposizione di dati privati:</strong> I dati di training potrebbero essere trapelati o rubati dai dispositivi</li>
<li><strong>Avvelenamento dei dati:</strong> Gli avversari possono manipolare i dati di training per degradare le prestazioni del modello</li>
<li><strong>Estrazione del modello:</strong> Degli aggressori potrebbero tentare di rubare i parametri del modello addestrato</li>
<li><strong>Inferenza di appartenenza:</strong> I modelli potrebbero rivelare la partecipazione di dati di utenti specifici</li>
<li><strong>Attacchi di evasione:</strong> Input appositamente creati possono causare una classificazione errata</li>
</ul>
<p>Qualsiasi sistema che esegue l‚Äôapprendimento sul dispositivo introduce preoccupazioni per la sicurezza, poich√© potrebbe esporre vulnerabilit√† in modelli su larga scala. Numerosi rischi per la sicurezza sono associati a qualsiasi modello ML, ma questi rischi hanno conseguenze specifiche per l‚Äôapprendimento on-device. Fortunatamente, esistono metodi per mitigare questi rischi e migliorare le prestazioni reali dell‚Äôapprendimento su dispositivo.</p>
<section id="avvelenamento-dei-dati" class="level3 page-columns page-full" data-number="12.6.1">
<h3 data-number="12.6.1" class="anchored" data-anchor-id="avvelenamento-dei-dati"><span class="header-section-number">12.6.1</span> Avvelenamento dei Dati</h3>
<p>L‚Äôapprendimento automatico on-device introduce sfide uniche per la sicurezza dei dati rispetto all‚Äôaddestramento tradizionale basato su cloud. In particolare, gli attacchi di avvelenamento dei dati rappresentano una seria minaccia durante l‚Äôapprendimento su dispositivo. Gli avversari possono manipolare i dati di training per degradare le prestazioni del modello quando vengono distribuiti.</p>
<p>Esistono diverse tecniche di attacco di avvelenamento dei dati:</p>
<ul>
<li><strong>Label Flipping:</strong> Comporta l‚Äôapplicazione di etichette errate ai campioni. Ad esempio, nella classificazione delle immagini, le foto di gatti possono essere etichettate come cani per confondere il modello. Anche capovolgere il <a href="https://proceedings.mlr.press/v139/schwarzschild21a.html">10% delle etichette</a> pu√≤ avere conseguenze significative sul modello.</li>
<li><strong>Inserimento dei Dati:</strong> Introduce input falsi o distorti nel set di training. Ci√≤ potrebbe includere immagini pixelate, audio rumoroso o testo distorto.</li>
<li><strong>Corruzione Logica:</strong> Altera i [pattern] sottostanti (<a href="https://www.worldscientific.com/doi/10.1142/S0218001414600027" class="uri">https://www.worldscientific.com/doi/10.1142/S0218001414600027</a>) nei dati per fuorviare il modello. Nell‚Äôanalisi del ‚Äúsentiment‚Äù, le recensioni altamente negative possono essere contrassegnate come positive tramite questa tecnica. Per questo motivo, recenti sondaggi hanno dimostrato che molte aziende hanno pi√π <a href="https://proceedings.mlr.press/v139/schwarzschild21a.html">paura dell‚Äôavvelenamento dei dati</a> rispetto ad altre preoccupazioni di ML avversarie.</li>
</ul>
<p>Ci√≤ che rende l‚Äôavvelenamento dei dati allarmante √® il modo in cui sfrutta la discrepanza tra set di dati curati e dati di training in tempo reale. Consideriamo un set di dati di foto di gatti raccolti da Internet. Nelle settimane successive, quando questi dati addestrano un modello on-device, le nuove foto di gatti sul Web differiscono in modo significativo.</p>
<p>Con l‚Äôavvelenamento dei dati, gli aggressori acquistano domini e caricano contenuti che influenzano una parte dei dati di training. Anche piccole modifiche ai dati hanno un impatto significativo sul comportamento appreso dal modello. Di conseguenza, l‚Äôavvelenamento pu√≤ instillare pregiudizi razzisti, sessisti o altri pregiudizi dannosi se non controllato.</p>
<p><a href="https://en.wikipedia.org/wiki/Tay_(chatbot)">Microsoft Tay</a> √® un chatbot lanciato da Microsoft nel 2016. √à stato progettato per imparare dalle sue interazioni con gli utenti su piattaforme di social media come Twitter. Sfortunatamente, Microsoft Tay √® diventato un esempio lampante di avvelenamento dei dati nei modelli di ML. Entro 24 ore dal suo lancio, Microsoft ha dovuto mettere Tay offline perch√© aveva iniziato a produrre messaggi offensivi e inappropriati, tra cui incitamento all‚Äôodio e commenti razzisti. Ci√≤ √® accaduto perch√© alcuni utenti sui social media hanno intenzionalmente fornito a Tay input dannosi e offensivi, da cui il chatbot ha poi imparato e incorporato nelle sue risposte.</p>
<p>Questo incidente √® un chiaro esempio di avvelenamento dei dati, poich√© i malintenzionati hanno intenzionalmente manipolato i dati utilizzati per addestrare il chatbot e modellarne le risposte. L‚Äôavvelenamento dei dati ha portato il chatbot ad adottare pregiudizi dannosi e a produrre output che i suoi sviluppatori non avevano previsto. Dimostra come anche piccole quantit√† di dati creati in modo dannoso possano avere un impatto significativo sul comportamento dei modelli ML e sottolinea l‚Äôimportanza di implementare solidi meccanismi di filtraggio e convalida dei dati per impedire che tali incidenti si verifichino.</p>
<p>Tali pregiudizi potrebbero avere pericolosi impatti nel mondo reale. La convalida rigorosa dei dati, il rilevamento delle anomalie e il monitoraggio della provenienza dei dati sono misure difensive fondamentali. L‚Äôadozione di framework come Five Safes garantisce che i modelli siano addestrati su dati rappresentativi di alta qualit√† <span class="citation" data-cites="desai2016five">(<a href="../../references.html#ref-desai2016five" role="doc-biblioref">Desai et al. 2016</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-desai2016five" class="csl-entry" role="listitem">
Desai, Tanvi, Felix Ritchie, Richard Welpton, et al. 2016. <span>¬´Five Safes: <span>Designing</span> data access for research¬ª</span>. <em>Economics Working Paper Series</em> 1601: 28.
</div></div><p>L‚Äôavvelenamento dei dati √® una preoccupazione urgente per l‚Äôapprendimento sicuro sul dispositivo poich√© i dati dell‚Äôendpoint non possono essere facilmente monitorati in tempo reale. Se ai modelli viene consentito di adattarsi da soli, corriamo il rischio che il dispositivo agisca in modo dannoso. Tuttavia, √® necessaria una ricerca continua sull‚Äôapprendimento automatico avversario per sviluppare soluzioni efficaci per rilevare e mitigare tali attacchi ai dati.</p>
</section>
<section id="attacchi-avversari" class="level3" data-number="12.6.2">
<h3 data-number="12.6.2" class="anchored" data-anchor-id="attacchi-avversari"><span class="header-section-number">12.6.2</span> Attacchi Avversari</h3>
<p>Durante la fase di addestramento, gli aggressori potrebbero iniettare dati dannosi nel dataset di training, il che pu√≤ alterare sottilmente il comportamento del modello. Ad esempio, un aggressore potrebbe aggiungere immagini di gatti etichettati come cani a un set di dati utilizzato per addestrare un modello di classificazione delle immagini. Se fatto in modo intelligente, l‚Äôaccuratezza del modello potrebbe non diminuire in modo significativo e l‚Äôattacco potrebbe essere notato. Il modello classificherebbe quindi erroneamente alcuni gatti come cani, il che potrebbe avere conseguenze a seconda dell‚Äôapplicazione.</p>
<p>In un sistema di telecamere di sicurezza embedded, ad esempio, ci√≤ potrebbe consentire a un intruso di evitare il rilevamento indossando uno specifico pattern che il modello √® stato ingannato a classificare come non minaccioso.</p>
<p>Durante la fase di inferenza, gli aggressori possono utilizzare esempi avversari per ingannare il modello. Gli esempi avversari sono input che sono stati leggermente alterati in un modo da far s√¨ che il modello faccia previsioni errate. Ad esempio, un aggressore potrebbe aggiungere una piccola quantit√† di rumore a un‚Äôimmagine in un modo che un sistema di riconoscimento facciale identifichi erroneamente una persona. Questi attacchi possono essere particolarmente preoccupanti nelle applicazioni in cui √® in gioco la sicurezza, come i veicoli autonomi. Un esempio concreto di ci√≤ √® quando i ricercatori sono riusciti a far s√¨ che un sistema di riconoscimento della segnaletica stradale classificasse erroneamente un segnale di stop come un segnale di limite di velocit√†. Questo tipo di classificazione errata potrebbe causare incidenti se si verificasse in un sistema di guida autonoma nel mondo reale.</p>
<p>Per mitigare questi rischi, possono essere impiegate diverse difese:</p>
<ul>
<li><strong>Validazione e Sanificazione dei Dati:</strong> Prima di incorporare nuovi dati nel dataset di addestramento, questi devono essere convalidati e sanificati a fondo per garantire che non siano dannosi.</li>
<li><strong>Addestramento Avversario:</strong> Il modello pu√≤ essere addestrato su esempi avversari per renderlo pi√π robusto a questi tipi di attacchi.</li>
<li><strong>Validazione degli Input:</strong> Durante l‚Äôinferenza, gli input devono essere convalidati per garantire che non siano stati manipolati per creare esempi avversari.</li>
<li><strong>Audit e Monitoraggio Regolari:</strong> L‚Äôaudit e il monitoraggio regolari del comportamento del modello possono aiutare a rilevare e mitigare gli attacchi avversari. Tuttavia, √® pi√π facile a dirsi che a farsi nel contesto di piccoli sistemi ML. Spesso √® difficile monitorare i sistemi ML embedded all‚Äôendpoint a causa delle limitazioni della larghezza di banda della comunicazione, di cui parleremo nel capitolo MLOps.</li>
</ul>
<p>Comprendendo i potenziali rischi e implementando queste difese, possiamo contribuire a proteggere il training on-device all‚Äôendpoint/edge e mitigare l‚Äôimpatto degli attacchi avversari. La maggior parte delle persone confonde facilmente l‚Äôavvelenamento dei dati e gli attacchi avversari. Quindi <a href="#tbl-attacks" class="quarto-xref">Tabella&nbsp;<span>12.2</span></a> confronta l‚Äôavvelenamento dei dati e gli attacchi avversari:</p>
<div id="tbl-attacks" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-attacks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;12.2: Confronto tra avvelenamento dei dati e attacchi avversari.
</figcaption>
<div aria-describedby="tbl-attacks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 44%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspetto</th>
<th style="text-align: left;">Avvelenamento dei dati</th>
<th style="text-align: left;">Attacchi avversari</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Tempistica</td>
<td style="text-align: left;">Fase di addestramento</td>
<td style="text-align: left;">Fase di inferenza</td>
</tr>
<tr class="even">
<td style="text-align: left;">Target</td>
<td style="text-align: left;">Dati di addestramento</td>
<td style="text-align: left;">Dati di input</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Obiettivo</td>
<td style="text-align: left;">Influenza negativamente le prestazioni del modello</td>
<td style="text-align: left;">Causa previsioni errate</td>
</tr>
<tr class="even">
<td style="text-align: left;">Metodo</td>
<td style="text-align: left;">Inserire esempi dannosi nei dati di training, spesso con etichette errate</td>
<td style="text-align: left;">Aggiungere rumore attentamente elaborato ai dati di input</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Esempio</td>
<td style="text-align: left;">Aggiungere immagini di gatti etichettati come cani a un set di dati utilizzato per addestrare un modello di classificazione delle immagini</td>
<td style="text-align: left;">Aggiungere una piccola quantit√† di rumore a un‚Äôimmagine in modo che un sistema di riconoscimento facciale identifichi erroneamente una persona</td>
</tr>
<tr class="even">
<td style="text-align: left;">Effetti Potenziali</td>
<td style="text-align: left;">Il modello apprende modelli errati e fa previsioni errate</td>
<td style="text-align: left;">Previsioni errate immediate e potenzialmente pericolose</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Applicazioni Interessate</td>
<td style="text-align: left;">Qualsiasi modello ML</td>
<td style="text-align: left;">Veicoli autonomi, sistemi di sicurezza, ecc.</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="inversione-del-modello" class="level3 page-columns page-full" data-number="12.6.3">
<h3 data-number="12.6.3" class="anchored" data-anchor-id="inversione-del-modello"><span class="header-section-number">12.6.3</span> Inversione del Modello</h3>
<p>Gli attacchi di inversione del modello rappresentano una minaccia per la privacy dei modelli di machine learning su dispositivo addestrati su dati utente sensibili <span class="citation" data-cites="nguyen2023re">(<a href="../../references.html#ref-nguyen2023re" role="doc-biblioref">Nguyen et al. 2023</a>)</span>. Comprendere questo vettore di attacco e le strategie di mitigazione saranno importanti per creare un‚Äôintelligenza artificiale su dispositivo sicura ed etica. Ad esempio, si immagini un‚Äôapp per iPhone che utilizza l‚Äôapprendimento su dispositivo per categorizzare le foto in gruppi come ‚Äúspiaggia‚Äù, ‚Äúcibo‚Äù o ‚Äúselfie‚Äù per una ricerca pi√π semplice.</p>
<div class="no-row-height column-margin column-container"><div id="ref-nguyen2023re" class="csl-entry" role="listitem">
Nguyen, Ngoc-Bao, Keshigeyan Chandrasegaran, Milad Abdollahzadeh, e Ngai-Man Cheung. 2023. <span>¬´Re-Thinking Model Inversion Attacks Against Deep Neural Networks¬ª</span>. In <em>2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 16384‚Äì93. IEEE. <a href="https://doi.org/10.1109/cvpr52729.2023.01572">https://doi.org/10.1109/cvpr52729.2023.01572</a>.
</div></div><p>Il modello su dispositivo potrebbe essere addestrato da Apple su un set di dati di foto iCloud di utenti consenzienti. Un aggressore malintenzionato potrebbe tentare di estrarre parti di quelle foto di addestramento iCloud originali utilizzando l‚Äôinversione del modello. In particolare, l‚Äôaggressore inserisce input sintetici creati ad arte nel classificatore di foto su dispositivo. Modificando gli input sintetici e osservando come il modello li categorizza, possono perfezionare gli input fino a ricostruire copie dei dati di training originali, come una foto di una spiaggia dall‚ÄôiCloud di un utente. Ora, l‚Äôaggressore ha violato la privacy di quell‚Äôutente ottenendo una delle sue foto senza consenso. Questo dimostra perch√© l‚Äôinversione del modello √® pericolosa: pu√≤ potenzialmente far trapelare dati di training altamente sensibili.</p>
<p>Le foto sono un tipo di dati particolarmente rischioso perch√© spesso contengono persone identificabili, informazioni sulla posizione e momenti privati. Tuttavia, la stessa metodologia di attacco potrebbe essere applicata ad altri dati personali, come registrazioni audio, messaggi di testo o dati sanitari degli utenti.</p>
<p>Per difendersi dall‚Äôinversione del modello, sarebbe necessario prendere precauzioni come l‚Äôaggiunta di rumore agli output del modello o l‚Äôutilizzo di tecniche di apprendimento automatico che preservano la privacy come l‚Äô<a href="@sec-fl">apprendimento federato</a> per addestrare il modello sul dispositivo. L‚Äôobiettivo √® impedire agli aggressori di ricostruire i dati di training originali.</p>
</section>
<section id="problemi-di-sicurezza-dellapprendimento-on-device" class="level3" data-number="12.6.4">
<h3 data-number="12.6.4" class="anchored" data-anchor-id="problemi-di-sicurezza-dellapprendimento-on-device"><span class="header-section-number">12.6.4</span> Problemi di Sicurezza dell‚ÄôApprendimento On-Device</h3>
<p>Sebbene l‚Äôavvelenamento dei dati e gli attacchi avversari siano preoccupazioni comuni per i modelli ML in generale, l‚Äôapprendimento su dispositivo introduce rischi di sicurezza unici. Quando vengono pubblicate varianti su dispositivo di modelli su larga scala, gli avversari possono sfruttare questi modelli pi√π piccoli per attaccare le loro controparti pi√π grandi. La ricerca ha dimostrato che man mano che i modelli su dispositivo e i modelli su scala reale diventano pi√π simili, la vulnerabilit√† dei modelli originali su larga scala aumenta in modo significativo. Ad esempio, le valutazioni su 19 reti neurali profonde (DNN) hanno rivelato che lo sfruttamento dei modelli su dispositivo potrebbe aumentare la vulnerabilit√† dei modelli originali su larga scala di <a href="http://arxiv.org/abs/2212.13700">fino a 100 volte</a>.</p>
<p>Esistono tre tipi principali di rischi per la sicurezza specifici dell‚Äôapprendimento on-device:</p>
<ul>
<li><p><strong>Attacchi Basati sul Trasferimento:</strong> Questi attacchi sfruttano la propriet√† di trasferibilit√† tra un modello surrogato (un‚Äôapprossimazione del modello di destinazione, simile a un modello su dispositivo) e un modello di destinazione remoto (il modello originale su scala reale). Gli aggressori generano esempi avversari utilizzando il modello surrogato, che pu√≤ quindi essere utilizzato per ingannare il modello di destinazione. Ad esempio, si immagini un modello on-device progettato per identificare le e-mail di spam. Un aggressore potrebbe usare questo modello per generare un‚Äôe-mail di spam che non viene rilevata dal sistema di filtraggio pi√π grande e completo.</p></li>
<li><p><strong>Attacchi Basati sull‚ÄôOttimizzazione:</strong> Questi attacchi generano esempi avversari per attacchi basati sul trasferimento usando una qualche forma di funzione obiettivo e modificano iterativamente gli input per ottenere il risultato desiderato. Gli attacchi di stima del gradiente, ad esempio, approssimano il gradiente del modello usando output di query (come punteggi di confidenza softmax), mentre gli attacchi senza gradiente usano la decisione finale del modello (la classe prevista) per approssimare il gradiente, sebbene richiedano molte pi√π query.</p></li>
<li><p><strong>Attacchi di Query con Priorit√† di Trasferimento:</strong> Questi attacchi combinano elementi di attacchi basati sul trasferimento e basati sull‚Äôottimizzazione. Eseguono il reverse engineering dei modelli sul dispositivo per fungere da surrogati del modello completo di destinazione. In altre parole, gli aggressori usano il modello sul dispositivo pi√π piccolo per capire come funziona il modello pi√π grande e quindi usano questa conoscenza per attaccare il modello completo.</p></li>
</ul>
<p>Grazie alla comprensione di questi rischi specifici associati all‚Äôapprendimento on-device, possiamo sviluppare protocolli di sicurezza pi√π solidi per proteggere sia i modelli on-device che quelli su scala reale da potenziali attacchi.</p>
</section>
<section id="attenuazione-dei-rischi-dellapprendimento-on-device" class="level3 page-columns page-full" data-number="12.6.5">
<h3 data-number="12.6.5" class="anchored" data-anchor-id="attenuazione-dei-rischi-dellapprendimento-on-device"><span class="header-section-number">12.6.5</span> Attenuazione dei Rischi dell‚ÄôApprendimento On-Device</h3>
<p>Si possono impiegare vari metodi per mitigare i numerosi rischi per la sicurezza associati all‚Äôapprendimento on-device. Questi metodi possono essere specifici per il tipo di attacco o fungere da strumento generale per rafforzare la sicurezza.</p>
<p>Una strategia per ridurre i rischi per la sicurezza √® quella di ridurre la somiglianza tra modelli on-device e modelli su scala reale, riducendo cos√¨ la trasferibilit√† fino al 90%. Questo metodo, noto come similarity-unpairing, affronta il problema che si verifica quando gli avversari sfruttano la somiglianza del gradiente di input tra i due modelli. Ottimizzando il modello su scala reale per creare una nuova versione con accuratezza simile ma gradienti di input diversi, possiamo costruire il modello on-device quantizzando questo modello su scala reale aggiornato. Questa disassociazione riduce la vulnerabilit√† dei modelli su dispositivo limitando l‚Äôesposizione del modello su scala reale originale. √à importante notare che l‚Äôordine di ottimizzazione e quantizzazione pu√≤ essere variato pur ottenendo la mitigazione del rischio <span class="citation" data-cites="hong2023publishing">(<a href="../../references.html#ref-hong2023publishing" role="doc-biblioref">Hong, Carlini, e Kurakin 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"></div><p>Per contrastare l‚Äôavvelenamento dei dati, √® fondamentale reperire set di dati da <a href="https://www.eetimes.com/cybersecurity-threats-loom-over-endpoint-ai-systems/?_gl=1%2A17zgs0d%2A_ga%2AMTY0MzA1MTAyNS4xNjk4MDgyNzc1%2A_ga_ZLV02RYCZ8%2AMTY5ODA4Mjc3NS4xLjAuMTY5ODA4Mjc3NS42MC4wLjA">fornitori</a> affidabili e fidati.</p>
<p>Per combattere gli attacchi avversari, si possono impiegare diverse strategie. Un approccio proattivo prevede la generazione di esempi avversari e la loro incorporazione nel set di dati di training del modello, rafforzando cos√¨ il modello contro tali attacchi. Strumenti come <a href="http://github.com/cleverhans-lab/cleverhans">CleverHans</a>, una libreria di training open source, sono fondamentali per creare esempi avversari. La ‚ÄúDefense distillation‚Äù [distillazione della difesa] √® un‚Äôaltra strategia efficace, in cui il modello sul dispositivo genera probabilit√† di classificazioni diverse anzich√© decisioni definitive <span class="citation" data-cites="hong2023publishing">(<a href="../../references.html#ref-hong2023publishing" role="doc-biblioref">Hong, Carlini, e Kurakin 2023</a>)</span>, rendendo pi√π difficile per gli esempi avversari sfruttare il modello.</p>
<div class="no-row-height column-margin column-container"><div id="ref-hong2023publishing" class="csl-entry" role="listitem">
Hong, Sanghyun, Nicholas Carlini, e Alexey Kurakin. 2023. <span>¬´Publishing Efficient On-device Models Increases Adversarial Vulnerability¬ª</span>. In <em>2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)</em>, 271‚Äì90. IEEE; IEEE. <a href="https://doi.org/10.1109/satml54575.2023.00026">https://doi.org/10.1109/satml54575.2023.00026</a>.
</div></div><p>Il furto di propriet√† intellettuale √® un altro problema significativo quando si distribuiscono modelli on-device. Il furto di propriet√† intellettuale √® un problema quando si distribuiscono modelli on-device, poich√© gli avversari potrebbero tentare di sottoporre a reverse engineering il modello per rubare la tecnologia sottostante. Per proteggersi dal furto di propriet√† intellettuale, l‚Äôeseguibile binario del modello addestrato dovrebbe essere archiviato su un‚Äôunit√† microcontrollore con software crittografato e interfacce fisiche protette del chip. Inoltre, il set di dati finale utilizzato per l‚Äôaddestramento del modello dovrebbe essere mantenuto <a href="https://www.eetimes.com/cybersecurity-threats-loom-over-endpoint-ai-systems/?_gl=1%2A17zgs0d%2A_ga%2AMTY0MzA1MTAyNS4xNjk4MDgyNzc1%2A_ga_ZLV02RYCZ8%2AMTY5ODA4Mjc3NS4xLjAuMTY5ODA4Mjc3NS42MC4wLjA">privato</a>.</p>
<p>Inoltre, i modelli on-device utilizzano spesso set di dati noti o open source, come Visual Wake Words di MobileNet. Pertanto, √® importante mantenere la <a href="http://arxiv.org/abs/2212.13700">privacy del set di dati finale</a> utilizzato per l‚Äôaddestramento del modello. Inoltre, proteggere il processo di ‚Äúdata augmentation‚Äù e incorporare casi d‚Äôuso specifici pu√≤ ridurre al minimo il rischio di reverse engineering di un modello on-device.</p>
<p>Infine, l‚ÄôAdversarial Threat Landscape for Artificial Intelligence Systems (<a href="https://atlas.mitre.org/">ATLAS</a>) funge da prezioso strumento matriciale che aiuta a valutare il profilo di rischio dei modelli su dispositivo, consentendo agli sviluppatori di identificare e <a href="https://www.eetimes.com/cybersecurity-threats-loom-over-endpoint-ai-systems/?_gl=1%2A17zgs0d%2A_ga%2AMTY0MzA1MTAyNS4xNjk4MDgyNzc1%2A_ga_ZLV02RYCZ8%2AMTY5ODA4Mjc3NS4xLjAuMTY5ODA4Mjc3NS42MC4wLjA">mitigare</a> i potenziali rischi in modo proattivo.</p>
</section>
<section id="protezione-dei-dati-di-training" class="level3 page-columns page-full" data-number="12.6.6">
<h3 data-number="12.6.6" class="anchored" data-anchor-id="protezione-dei-dati-di-training"><span class="header-section-number">12.6.6</span> Protezione dei Dati di Training</h3>
<p>Esistono vari modi per proteggere i dati di training sul dispositivo. Ogni concetto √® molto profondo e potrebbe valere una lezione a s√© stante. Quindi, qui, faremo un breve accenno a quei concetti in modo che si sappia cosa approfondire.</p>
<section id="crittografia" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="crittografia">Crittografia</h4>
<p>La crittografia funge da prima linea di difesa per i dati di training. Ci√≤ comporta l‚Äôimplementazione della crittografia end-to-end per l‚Äôarchiviazione locale su dispositivi e canali di comunicazione per impedire l‚Äôaccesso non autorizzato ai dati di training grezzi. Ambienti di esecuzione affidabili, come <a href="https://www.intel.com/content/www/us/en/architecture-and-technology/software-guard-extensions.html">Intel SGX</a> e <a href="https://www.arm.com/technologies/trustzone-for-cortex-a#:~:text=Arm%20TrustZone%20technology%20offers%20an,trust%20based%20on%20PSA%20guidelines.">ARM TrustZone</a>, sono essenziali per facilitare il training sicuro su dati crittografati.</p>
<p>Inoltre, quando si aggregano aggiornamenti da pi√π dispositivi, √® possibile impiegare protocolli di elaborazione ‚Äúmulti-party‚Äù sicuri per migliorare la sicurezza <span class="citation" data-cites="kairouz2015secure">(<a href="../../references.html#ref-kairouz2015secure" role="doc-biblioref">Kairouz, Oh, e Viswanath 2015</a>)</span>; un‚Äôapplicazione pratica di ci√≤ √® nell‚Äôapprendimento collaborativo on-device, in cui √® possibile implementare l‚Äôaggregazione crittografica che preserva la privacy degli aggiornamenti del modello utente. Questa tecnica nasconde efficacemente i dati dei singoli utenti anche durante la fase di aggregazione.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kairouz2015secure" class="csl-entry" role="listitem">
Kairouz, Peter, Sewoong Oh, e Pramod Viswanath. 2015. <span>¬´Secure Multi-party Differential Privacy¬ª</span>. In <em>Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada</em>, a cura di Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, e Roman Garnett, 2008‚Äì16. <a href="https://proceedings.neurips.cc/paper/2015/hash/a01610228fe998f515a72dd730294d87-Abstract.html">https://proceedings.neurips.cc/paper/2015/hash/a01610228fe998f515a72dd730294d87-Abstract.html</a>.
</div></div></section>
<section id="privacy-differenziale" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="privacy-differenziale">Privacy Differenziale</h4>
<p>La privacy differenziale √® un‚Äôaltra strategia cruciale per proteggere i dati di training. Iniettando rumore statistico calibrato nei dati, possiamo mascherare i singoli record estraendo comunque preziosi pattern di popolazione <span class="citation" data-cites="dwork2014algorithmic">(<a href="../../references.html#ref-dwork2014algorithmic" role="doc-biblioref">Dwork e Roth 2013</a>)</span>. Anche la gestione del budget per la privacy su pi√π iterazioni di training e la riduzione del rumore man mano che il modello converge sono essenziali <span class="citation" data-cites="abadi2016deep">(<a href="../../references.html#ref-abadi2016deep" role="doc-biblioref">Abadi et al. 2016</a>)</span>. Possono essere impiegati metodi come la privacy differenziale formalmente dimostrabile, che pu√≤ includere l‚Äôaggiunta di rumore di Laplace o gaussiano scalato alla sensibilit√† del set di dati.</p>
<div class="no-row-height column-margin column-container"><div id="ref-dwork2014algorithmic" class="csl-entry" role="listitem">
Dwork, Cynthia, e Aaron Roth. 2013. <span>¬´The Algorithmic Foundations of Differential Privacy¬ª</span>. <em>Foundations and Trends<span></span> in Theoretical Computer Science</em> 9 (3-4): 211‚Äì407. <a href="https://doi.org/10.1561/0400000042">https://doi.org/10.1561/0400000042</a>.
</div><div id="ref-abadi2016deep" class="csl-entry" role="listitem">
Abadi, Martin, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, e Li Zhang. 2016. <span>¬´Deep Learning with Differential Privacy¬ª</span>. In <em>Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</em>, 308‚Äì18. CCS ‚Äô16. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/2976749.2978318">https://doi.org/10.1145/2976749.2978318</a>.
</div></div></section>
<section id="rilevamento-delle-anomalie" class="level4">
<h4 class="anchored" data-anchor-id="rilevamento-delle-anomalie">Rilevamento delle Anomalie</h4>
<p>Il rilevamento delle anomalie svolge un ruolo importante nell‚Äôidentificazione e nell‚Äôattenuazione di potenziali attacchi di avvelenamento dei dati. Ci√≤ pu√≤ essere ottenuto tramite analisi statistiche come la ‚ÄúPrincipal Component Analysis (PCA)‚Äù [analisi delle componenti principali] e il clustering, che aiutano a rilevare deviazioni nei dati di training aggregati. I metodi di serie temporali come i grafici <a href="https://en.wikipedia.org/wiki/CUSUM">Cumulative Sum (CUSUM)</a> sono utili per identificare spostamenti indicativi di potenziale avvelenamento. Anche il confronto delle distribuzioni dei dati correnti con distribuzioni di dati pulite precedentemente visualizzate pu√≤ aiutare a segnalare anomalie. Inoltre, i batch sospetti di essere avvelenati dovrebbero essere rimossi dal processo di aggregazione degli aggiornamenti di training. Ad esempio, √® possibile condurre controlli a campione su sottoinsiemi di immagini di training sui dispositivi utilizzando hash <a href="https://www.microsoft.com/en-us/photodna">photoDNA</a> per identificare input avvelenati.</p>
</section>
<section id="validazione-dei-dati-di-input" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="validazione-dei-dati-di-input">Validazione dei Dati di Input</h4>
<p>Infine, la convalida dei dati di input √® essenziale per garantire l‚Äôintegrit√† e la validit√† dei dati di input prima che vengano immessi nel modello di training, proteggendo cos√¨ dai payload avversari. Misure di similarit√†, come la distanza del coseno, possono essere impiegate per catturare input che si discostano in modo significativo dalla distribuzione prevista. Gli input sospetti che potrebbero contenere payload avversari devono essere messi in quarantena e sanificati. Inoltre, l‚Äôaccesso del parser ai dati di training deve essere limitato solo ai percorsi di codice convalidati. Sfruttare le funzionalit√† di sicurezza hardware, come ARM Pointer Authentication, pu√≤ impedire la corruzione della memoria (ARM Limited, 2023). Un esempio di ci√≤ √® l‚Äôimplementazione di controlli di integrit√† degli input sui dati di training audio utilizzati dagli smart speaker prima dell‚Äôelaborazione da parte del modello di riconoscimento vocale <span class="citation" data-cites="chen2023learning">(<a href="../../references.html#ref-chen2023learning" role="doc-biblioref">Z. Chen e Xu 2023</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-chen2023learning" class="csl-entry" role="listitem">
Chen, Zhiyong, e Shugong Xu. 2023. <span>¬´Learning domain-heterogeneous speaker recognition systems with personalized continual federated learning¬ª</span>. <em>EURASIP Journal on Audio, Speech, and Music Processing</em> 2023 (1): 33. <a href="https://doi.org/10.1186/s13636-023-00299-2">https://doi.org/10.1186/s13636-023-00299-2</a>.
</div></div></section>
</section>
</section>
<section id="framework-di-training-on-device" class="level2 page-columns page-full" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="framework-di-training-on-device"><span class="header-section-number">12.7</span> Framework di Training On-Device</h2>
<p>Framework di inferenza embedded come TF-Lite Micro <span class="citation" data-cites="david2021tensorflow">(<a href="../../references.html#ref-david2021tensorflow" role="doc-biblioref">David et al. 2021</a>)</span>, TVM <span class="citation" data-cites="chen2018tvm">(<a href="../../references.html#ref-chen2018tvm" role="doc-biblioref">T. Chen et al. 2018</a>)</span> e MCUNet <span class="citation" data-cites="lin2020mcunet">(<a href="../../references.html#ref-lin2020mcunet" role="doc-biblioref">Lin et al. 2020</a>)</span> forniscono un runtime snello per l‚Äôesecuzione di modelli di reti neurali su microcontrollori e altri dispositivi con risorse limitate. Tuttavia, non supportano l‚Äôaddestramento on-device. L‚Äôaddestramento richiede un proprio set di strumenti specializzati a causa dell‚Äôimpatto della quantizzazione sul calcolo del gradiente e dell‚Äôingombro di memoria della backpropagation <span class="citation" data-cites="lin2022device">(<a href="../../references.html#ref-lin2022device" role="doc-biblioref">Lin et al. 2022</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-david2021tensorflow" class="csl-entry" role="listitem">
David, Robert, Jared Duke, Advait Jain, Vijay Janapa Reddi, Nat Jeffries, Jian Li, Nick Kreeger, et al. 2021. <span>¬´Tensorflow lite micro: <span>Embedded</span> machine learning for tinyml systems¬ª</span>. <em>Proceedings of Machine Learning and Systems</em> 3: 800‚Äì811.
</div><div id="ref-chen2018tvm" class="csl-entry" role="listitem">
Chen, Tianqi, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Haichen Shen, Meghan Cowan, et al. 2018. <span>¬´<span>TVM:</span> <span>An</span> automated End-to-End optimizing compiler for deep learning¬ª</span>. In <em>13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)</em>, 578‚Äì94.
</div><div id="ref-lin2020mcunet" class="csl-entry" role="listitem">
Lin, Ji, Wei-Ming Chen, Yujun Lin, John Cohn, Chuang Gan, e Song Han. 2020. <span>¬´<span>MCUNet:</span> <span>Tiny</span> Deep Learning on <span>IoT</span> Devices¬ª</span>. In <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, a cura di Hugo Larochelle, Marc‚ÄôAurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, e Hsuan-Tien Lin. <a href="https://proceedings.neurips.cc/paper/2020/hash/86c51678350f656dcc7f490a43946ee5-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/86c51678350f656dcc7f490a43946ee5-Abstract.html</a>.
</div><div id="ref-lin2022device" class="csl-entry" role="listitem">
Lin, Ji, Ligeng Zhu, Wei-Ming Chen, Wei-Chen Wang, Chuang Gan, e Song Han. 2022. <span>¬´On-device training under 256kb memory¬ª</span>. <em>Adv. Neur. In.</em> 35: 22941‚Äì54.
</div></div><p>Negli ultimi anni, hanno iniziato a emergere una manciata di strumenti e framework che consentono l‚Äôaddestramento sul dispositivo. Tra questi Tiny Training Engine <span class="citation" data-cites="lin2022device">(<a href="../../references.html#ref-lin2022device" role="doc-biblioref">Lin et al. 2022</a>)</span>, TinyTL <span class="citation" data-cites="cai2020tinytl">(<a href="../../references.html#ref-cai2020tinytl" role="doc-biblioref">Cai et al. 2020</a>)</span> e TinyTrain <span class="citation" data-cites="kwon2023tinytrain">(<a href="../../references.html#ref-kwon2023tinytrain" role="doc-biblioref">Kwon et al. 2023</a>)</span>.</p>
<section id="tiny-training-engine" class="level3" data-number="12.7.1">
<h3 data-number="12.7.1" class="anchored" data-anchor-id="tiny-training-engine"><span class="header-section-number">12.7.1</span> Tiny Training Engine</h3>
<p>Tiny Training Engine (TTE) utilizza diverse tecniche per ottimizzare l‚Äôutilizzo della memoria e velocizzare il processo di training. Una panoramica del flusso di lavoro TTE √® mostrata in <a href="#fig-tte-workflow" class="quarto-xref">Figura&nbsp;<span>12.9</span></a>. Innanzitutto, TTE scarica la differenziazione automatica in fase di compilazione anzich√© in fase di runtime, riducendo significativamente il sovraccarico durante il training. In secondo luogo, TTE esegue l‚Äôottimizzazione del grafo come la potatura e gli aggiornamenti sparsi per ridurre i requisiti di memoria e accelerare i calcoli.</p>
<div id="fig-tte-workflow" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tte-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_training_flow.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tte-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.9: Flusso di lavoro di TTE.
</figcaption>
</figure>
</div>
<p>In particolare, TTE segue quattro passaggi principali:</p>
<ul>
<li>Durante la fase di compilazione, TTE traccia il grafo di propagazione ‚Äúforward‚Äù e deriva il grafo ‚Äúbackward‚Äù corrispondente per la backpropagation. Ci√≤ consente alla <a href="https://harvard-edge.github.io/cs249r_book/frameworks.html#differentiable-programming">differenziazione</a> di avvenire in fase di compilazione anzich√© in fase di esecuzione.</li>
<li>TTE elimina tutti i nodi che rappresentano pesi congelati dal grafo backward. I pesi congelati sono pesi che non vengono aggiornati durante l‚Äôaddestramento per ridurre l‚Äôimpatto di determinati neuroni. La potatura dei loro nodi consente di risparmiare memoria.</li>
<li>TTE riordina gli operatori di discesa del gradiente per intercalarli con i calcoli del passaggio del backward. Questa pianificazione riduce al minimo le ‚Äúimpronte‚Äù [occupazione] di memoria.</li>
<li>TTE utilizza la generazione di codice per compilare i grafi ‚Äúforward‚Äù e ‚Äúbackward‚Äù ottimizzati, che vengono poi distribuiti per l‚Äôaddestramento on-device.</li>
</ul>
</section>
<section id="tiny-transfer-learning" class="level3 page-columns page-full" data-number="12.7.2">
<h3 data-number="12.7.2" class="anchored" data-anchor-id="tiny-transfer-learning"><span class="header-section-number">12.7.2</span> Tiny Transfer Learning</h3>
<p>Tiny Transfer Learning (TinyTL) consente un training efficiente in termini di memoria sul dispositivo tramite una tecnica chiamata congelamento dei pesi. Durante il training, gran parte del collo di bottiglia della memoria deriva dall‚Äôarchiviazione delle attivazioni intermedie e dall‚Äôaggiornamento dei pesi nella rete neurale.</p>
<p>Per ridurre questo sovraccarico di memoria, TinyTL congela la maggior parte dei pesi in modo che non debbano essere aggiornati durante il training. Ci√≤ elimina la necessit√† di archiviare le attivazioni intermedie per le parti congelate della rete. TinyTL ottimizza solo i termini di bias, che sono molto pi√π piccoli dei pesi. Una panoramica del flusso di lavoro TinyTL √® mostrata in <a href="#fig-tinytl-workflow" class="quarto-xref">Figura&nbsp;<span>12.10</span></a>.</p>
<div id="fig-tinytl-workflow" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-tinytl-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_transfer_tinytl.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tinytl-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.10: Flusso di lavoro di TinyTL. Fonte: <span class="citation" data-cites="cai2020tinytl">Cai et al. (<a href="../../references.html#ref-cai2020tinytl" role="doc-biblioref">2020</a>)</span>.)
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-cai2020tinytl" class="csl-entry" role="listitem">
Cai, Han, Chuang Gan, Ligeng Zhu, e Song Han. 2020. <span>¬´<span>TinyTL:</span> <span>Reduce</span> Memory, Not Parameters for Efficient On-Device Learning¬ª</span>. In <em>Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, a cura di Hugo Larochelle, Marc‚ÄôAurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, e Hsuan-Tien Lin. <a href="https://proceedings.neurips.cc/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html</a>.
</div></div></figure>
</div>
<p>I pesi di congelamento si applicano a layer completamente connessi, nonch√© a layer di normalizzazione e convoluzionali. Tuttavia, solo l‚Äôadattamento dei bias limita la capacit√† del modello di apprendere e adattarsi a nuovi dati.</p>
<p>Per aumentare l‚Äôadattabilit√† senza molta memoria aggiuntiva, TinyTL utilizza un piccolo modello di apprendimento residuo. Questo affina le mappe delle feature intermedie per produrre output migliori, anche con pesi fissi. Il modello residuo introduce un overhead minimo, inferiore al 3,8% in pi√π rispetto al modello di base.</p>
<p>Congelando la maggior parte dei pesi, TinyTL riduce significativamente l‚Äôutilizzo della memoria durante l‚Äôaddestramento on-device. Il modello residuo consente quindi di adattarsi e apprendere in modo efficace per l‚Äôattivit√†. L‚Äôapproccio combinato fornisce un addestramento on-device efficiente in termini di memoria con un impatto minimo sulla precisione del modello.</p>
</section>
<section id="tiny-train" class="level3 page-columns page-full" data-number="12.7.3">
<h3 data-number="12.7.3" class="anchored" data-anchor-id="tiny-train"><span class="header-section-number">12.7.3</span> Tiny Train</h3>
<p>TinyTrain riduce significativamente il tempo necessario per l‚Äôaddestramento sul dispositivo aggiornando selettivamente solo determinate parti del modello. Ci√≤ avviene utilizzando una tecnica chiamata aggiornamento sparso adattivo all‚Äôattivit√†, come mostrato in <a href="#fig-tiny-train" class="quarto-xref">Figura&nbsp;<span>12.11</span></a>.</p>
<p>In base ai dati utente, alla memoria e al calcolo disponibili sul dispositivo, TinyTrain sceglie dinamicamente quali layer della rete neurale aggiornare durante l‚Äôaddestramento. Questa selezione di layer √® ottimizzata per ridurre l‚Äôutilizzo di calcolo e memoria mantenendo un‚Äôelevata accuratezza.</p>
<div id="fig-tiny-train" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-tiny-train-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/ondevice_pretraining.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tiny-train-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;12.11: Flusso di lavoro di TinyTrain. Fonte: <span class="citation" data-cites="kwon2023tinytrain">Kwon et al. (<a href="../../references.html#ref-kwon2023tinytrain" role="doc-biblioref">2023</a>)</span>.
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-kwon2023tinytrain" class="csl-entry" role="listitem">
Kwon, Young D, Rui Li, Stylianos I Venieris, Jagmohan Chauhan, Nicholas D Lane, e Cecilia Mascolo. 2023. <span>¬´<span>TinyTrain:</span> <span>Deep</span> Neural Network Training at the Extreme Edge¬ª</span>. <em>ArXiv preprint</em> abs/2307.09988. <a href="https://arxiv.org/abs/2307.09988">https://arxiv.org/abs/2307.09988</a>.
</div></div></figure>
</div>
<p>Pi√π specificamente, TinyTrain esegue prima il pre-addestramento offline del modello. Durante il pre-addestramento, non solo addestra il modello sui dati dell‚Äôattivit√†, ma anche il meta-addestramento del modello. Meta-addestramento significa addestrare il modello sui metadati relativi al processo di addestramento stesso. Questo meta-addestramento migliora la capacit√† del modello di adattarsi in modo accurato anche quando sono disponibili dati limitati per l‚Äôattivit√† target.</p>
<p>Poi, durante la fase di adattamento online, quando il modello viene personalizzato sul dispositivo, TinyTrain esegue aggiornamenti adattivi sparsi all‚Äôattivit√†. Utilizzando i criteri relativi alle capacit√† del dispositivo, seleziona solo determinati layer da aggiornare tramite backpropagation. I layer vengono scelti per bilanciare accuratezza, utilizzo della memoria e tempo di elaborazione.</p>
<p>Aggiornando in modo sparso i layer su misura per il dispositivo e l‚Äôattivit√†, TinyTrain riduce significativamente il tempo di addestramento sul dispositivo e l‚Äôutilizzo delle risorse. Il meta-training offline migliora anche l‚Äôaccuratezza quando si adatta a dati limitati. Insieme, questi metodi consentono un training on-device rapido, efficiente e accurato.</p>
</section>
<section id="confronto" class="level3" data-number="12.7.4">
<h3 data-number="12.7.4" class="anchored" data-anchor-id="confronto"><span class="header-section-number">12.7.4</span> Confronto</h3>
<p><a href="#tbl-framework-comparison" class="quarto-xref">Tabella&nbsp;<span>12.3</span></a> riassume le principali somiglianze e differenze tra i diversi framework.</p>
<div id="tbl-framework-comparison" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-framework-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;12.3: Confronto di framework per l‚Äôottimizzazione del training on-device.
</figcaption>
<div aria-describedby="tbl-framework-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 35%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Framework</th>
<th style="text-align: left;">Somiglianze</th>
<th style="text-align: left;">Differenze</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Tiny Training Engine</td>
<td style="text-align: left;"><ul>
<li>Addestramento sul dispositivo</li>
<li>Ottimizza memoria e calcolo</li>
<li>Sfrutta potatura, sparsit√†, ecc.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Traccia grafi forward &amp; backward</li>
<li>Elimina i pesi congelati</li>
<li>Interlaccia backprop e gradienti</li>
<li>Generazione di codice</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">TinyTL</td>
<td style="text-align: left;"><ul>
<li>Addestramento sul dispositivo</li>
<li>Ottimizza memoria e calcolo</li>
<li>Sfrutta congelamento, sparsit√†, ecc.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Congela la maggior parte dei pesi</li>
<li>Adatta solo i bias</li>
<li>Utilizza il modello residuo</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">TinyTrain</td>
<td style="text-align: left;"><ul>
<li>Addestramento sul dispositivo</li>
<li>Ottimizza memoria e calcolo</li>
<li>Sfrutta sparsit√†, ecc.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Meta-addestramento nel pre-addestramento</li>
<li>Aggiornamento sparse adattivo alle attivit√†</li>
<li>Aggiornamento selettivo dei layer</li>
</ul></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
</section>
<section id="conclusione" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="conclusione"><span class="header-section-number">12.8</span> Conclusione</h2>
<p>Il concetto di apprendimento on-device [su dispositivo] √® sempre pi√π importante per aumentare l‚Äôusabilit√† e la scalabilit√† di TinyML. Questo capitolo ha esplorato le complessit√† dell‚Äôapprendimento on-device, esplorandone vantaggi e limiti, strategie di adattamento, algoritmi e tecniche chiave correlate, implicazioni di sicurezza e framework di training on-device esistenti ed emergenti.</p>
<p>L‚Äôapprendimento su dispositivo √®, senza dubbio, un paradigma rivoluzionario che porta con s√© numerosi vantaggi per le distribuzioni ML embedded ed edge. Eseguendo il training direttamente sui dispositivi endpoint, si elimina la necessit√† di una connettivit√† cloud continua, rendendolo particolarmente adatto per applicazioni IoT ed edge computing. Presenta vantaggi quali maggiore privacy, facilit√† di conformit√† ed efficienza delle risorse. Allo stesso tempo, l‚Äôapprendimento su on-device deve affrontare limitazioni legate a vincoli hardware, dimensioni dei dati limitate e ridotta accuratezza e generalizzazione del modello.</p>
<p>Meccanismi quali la ridotta complessit√† del modello, tecniche di ottimizzazione e compressione dei dati e metodi di apprendimento correlati quali apprendimento tramite trasferimento e apprendimento federato consentono ai modelli di adattarsi per apprendere ed evolversi in base a vincoli di risorse, fungendo cos√¨ da fondamento per un efficace ML sui dispositivi edge.</p>
<p>Le problematiche critiche di sicurezza nell‚Äôapprendimento su dispositivo evidenziate in questo capitolo, che vanno dall‚Äôavvelenamento dei dati e dagli attacchi avversari ai rischi specifici introdotti dall‚Äôapprendimento on-device, devono essere affrontate in carichi di lavoro reali affinch√© l‚Äôapprendimento su dispositivo sia un paradigma praticabile. Strategie di mitigazione efficaci, quali convalida dei dati, crittografia, privacy differenziale, rilevamento delle anomalie e convalida dei dati di input, sono fondamentali per salvaguardare i sistemi di apprendimento on-device da queste minacce.</p>
<p>L‚Äôemergere di framework di training specializzati on-device, come Tiny Training Engine, Tiny Transfer Learning e Tiny Train, offre strumenti pratici che consentono un training efficiente sui dispositivi. Questi framework impiegano varie tecniche per ottimizzare l‚Äôutilizzo della memoria, ridurre il sovraccarico computazionale e semplificare il processo di training on-device.</p>
<p>In conclusione, l‚Äôapprendimento on-device √® in prima linea in TinyML, promettendo un futuro in cui i modelli possono acquisire autonomamente conoscenze e adattarsi ad ambienti mutevoli su dispositivi edge. L‚Äôapplicazione dell‚Äôapprendimento on-device ha il potenziale per rivoluzionare vari ambiti, tra cui sanit√†, IoT industriale e citt√† intelligenti. Tuttavia, il potenziale trasformativo dell‚Äôapprendimento on-device deve essere bilanciato con misure di sicurezza robuste per proteggere da violazioni dei dati e minacce avversarie. L‚Äôadozione di framework di training on-device innovativi e l‚Äôimplementazione di protocolli di sicurezza rigorosi sono passaggi chiave per sbloccare il pieno potenziale dell‚Äôapprendimento su dispositivo. Man mano che questa tecnologia continua a evolversi, promette di rendere i nostri dispositivi pi√π intelligenti, pi√π reattivi e meglio integrati nella nostra vita quotidiana.</p>
</section>
<section id="sec-on-device-learning-resource" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="sec-on-device-learning-resource"><span class="header-section-number">12.9</span> Risorse</h2>
<p>Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Lavoriamo continuamente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale al proprio ritmo. Incoraggiamo sia gli studenti che gli insegnanti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/19nF6CATRBqQWGBBv4uO4RzWpAwwuhmBAv8AQdBkkAVY/edit#slide=id.g94db9f9f78_0_2">Intro to TensorFlow Lite (TFLite).</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1JwP46J6eLFUebNy2vKDvPzExe20DuTL95Nw8ubCxNPg/edit#slide=id.g94db9f9f78_0_2">TFLite Optimization and Quantization.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1eSOyAOu8Vg_VfIHZ9gWRVjWnmFTOcZ4FavaNMc4reHQ/edit#slide=id.p1">TFLite Quantization-Aware Training.</a></p></li>
<li><p>Trasferimento dell‚ÄôApprendimento:</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1kVev1WwXG2MrpEMmRbiPjTBwQ6CSCE_K84SUlSbuUPM/edit#slide=id.ga654406365_0_127">Transfer Learning: with Visual Wake Words example.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1wou3qW4kXttufz6hR5lXAcZ3kXlwkl1O/edit?usp=sharing&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">On-device Training and Transfer Learning.</a></p></li>
</ul></li>
<li><p>Addestramento Distribuito:</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/19YyoXqFzLaywEGOb5ccLK4MeNqxvr-qo/edit?usp=drive_link&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">Distributed Training.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/16xSDyhiHoSgmnUNMzvcYSFMCg2LGF8Gu/edit?usp=drive_link&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">Distributed Training.</a></p></li>
</ul></li>
<li><p>Monitoraggio Continuo:</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1OuhwH5feIwPivEU6pTDyR3QMs7AFstHLiF_LB8T5qYQ/edit?usp=drive_link&amp;resourcekey=0-DZxIuVBUbJawuFh0AO-Pvw">Continuous Evaluation Challenges for TinyML.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1Q8M76smakrt5kTqggoPW8WFTrP0zIrV-cWj_BEfPxIA/edit?resourcekey=0-mPx0WwZOEVkHndVhr_MzMQ#slide=id.g94db9f9f78_0_2">Federated Learning Challenges.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1dHqWjKflisdLhX43jjOUmZCyM0tNhXTVgcch-Bcp-uo/edit?usp=drive_link&amp;resourcekey=0-AuuCxz6QKc-t3lXMPeX1Sg">Continuous Monitoring with Federated ML.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1D7qI7aLGnoUV7x3s5Dqa44CsJTQdDO5xtID5MBM0GxI/edit?usp=drive_link&amp;resourcekey=0-g7SB2RDsdGt01tPCI7VeUQ">Continuous Monitoring Impact on MLOps.</a></p></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><a href="#vid-tl" class="quarto-xref">Video&nbsp;<span>12.1</span></a></p></li>
<li><p><a href="#vid-fl" class="quarto-xref">Video&nbsp;<span>12.2</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.</p>
<ul>
<li><p><a href="#exr-tlb" class="quarto-xref">Esercizio&nbsp;<span>12.1</span></a></p></li>
<li><p><a href="#exr-flg" class="quarto-xref">Esercizio&nbsp;<span>12.2</span></a></p></li>
<li><p><a href="#exr-fli" class="quarto-xref">Esercizio&nbsp;<span>12.3</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Laboratori
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Oltre agli esercizi, offriamo anche una serie di laboratori pratici che consentono agli studenti di acquisire esperienza pratica con le tecnologie di intelligenza artificiale embedded. Questi laboratori forniscono una guida passo dopo passo, consentendo agli studenti di sviluppare le proprie competenze in un ambiente strutturato e di supporto. Siamo lieti di annunciare che presto saranno disponibili nuovi laboratori, che arricchiranno ulteriormente l‚Äôesperienza di apprendimento.</p>
<ul>
<li><em>Prossimamente.</em></li>
</ul>
</div>
</div>
</div>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../contents/benchmarking/benchmarking.it.html" class="pagination-link" aria-label="Benchmarking AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking AI</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../contents/ops/ops.it.html" class="pagination-link" aria-label="Operazioni di ML">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/ondevice_learning/ondevice_learning.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/ondevice_learning/ondevice_learning.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>