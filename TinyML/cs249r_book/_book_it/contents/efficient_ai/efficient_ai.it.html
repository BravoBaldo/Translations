<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="it" xml:lang="it"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; IA Efficiente ‚Äì Machine Learning Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../contents/optimizations/optimizations.it.html" rel="next">
<link href="../../contents/training/training.it.html" rel="prev">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "~",
    "/"
  ],
  "language": {
    "search-no-results-text": "Nessun risultato",
    "search-matching-documents-text": "documenti trovati",
    "search-copy-link-title": "Copiare il link nella ricerca",
    "search-hide-matches-text": "Nascondere i risultati aggiuntivi",
    "search-more-match-text": "ci sono altri risultati in questo documento",
    "search-more-matches-text": "ulteriori risultati in questo documento",
    "search-clear-button-title": "Pulire",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancellare",
    "search-submit-button-title": "Inviare",
    "search-label": "Ricerca"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-M21L0CBCVN', { 'anonymize_ip': true});
</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-M21L0CBCVN"></script>


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Machine Learning Systems</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-wide tools-end">
    <a href="https://github.com/harvard-edge/cs249r_book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="../../Machine-Learning-Systems.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Attiva/disattiva la modalit√† oscura"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Attiva/disattiva la modalit√† lettore">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/training/training.it.html">Training</a></li><li class="breadcrumb-item"><a href="../../contents/efficient_ai/efficient_ai.it.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Attiva/disattiva la barra laterale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Ricerca" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
  <div id="quarto-announcement" data-announcement-id="2d6cdf6fc58f1105ce2a5c5c28a11153" class="alert alert-info hidden"><i class="bi bi-star-half quarto-announcement-icon"></i><div class="quarto-announcement-content">
<p>üåü Aiutaci a raggiungere 1.000 stelle GitHub! üåü Per ogni 25 stelle, Arduino e SEEED doneranno una NiclaVision o una XIAO ESP32S3 per l‚Äôistruzione sull‚Äôintelligenza artificiale. <a href="https://github.com/harvard-edge/cs249r_book">Cliccare qui per una ‚≠ê</a></p>
</div></div>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Ricerca"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">PREFAZIONE</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dedication.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dedica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/acknowledgements/acknowledgements.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/contributors.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Collaboratori e Ringraziamenti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/copyright.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Copyright</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/about.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Informazioni sul Libro</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">
 <span class="menu-text">PARTE PRINCIPALE</span></span>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Nozioni Fondamentali</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/introduction/introduction.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduzione</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ml_systems/ml_systems.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Sistemi di ML</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/dl_primer/dl_primer.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Avvio al Deep Learning</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Workflow</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/workflow/workflow.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Workflow dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/data_engineering/data_engineering.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data Engineering</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/frameworks/frameworks.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Framework di IA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Training</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/training/training.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/efficient_ai/efficient_ai.it.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/optimizations/optimizations.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/hw_acceleration/hw_acceleration.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Accelerazione IA</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Deployment</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/benchmarking/benchmarking.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Benchmarking dell‚ÄôIA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ondevice_learning/ondevice_learning.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Apprendimento On-Device</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ops/ops.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Operazioni di ML</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Argomenti Avanzati</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/privacy_security/privacy_security.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Sicurezza e Privacy</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/responsible_ai/responsible_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">IA Responsabile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/sustainable_ai/sustainable_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">IA Sostenibile</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/robust_ai/robust_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">IA Robusta</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/generative_ai/generative_ai.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">IA Generativa</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Impatto Sociale</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/ai_for_good/ai_for_good.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">AI for Good</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true">
 <span class="menu-text">Chiusura</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/conclusion/conclusion.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Conclusione</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true">
 <span class="menu-text">LABS</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/labs.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Panoramica</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/getting_started.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Guida Introduttiva</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/arduino/nicla_vision/nicla_vision.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Nicla Vision</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/arduino/nicla_vision/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/seeed/xiao_esp32s3/xiao_esp32s3.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">XIAO ESP32S3</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/kws/kws.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Keyword Spotting (KWS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/seeed/xiao_esp32s3/motion_classification/motion_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione del Movimento e Rilevamento delle Anomalie</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/raspi/raspi.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Raspberry Pi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/raspi/setup/setup.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Setup</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/raspi/image_classification/image_classification.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classificazione delle Immagini</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/raspi/object_detection/object_detection.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Rilevamento degli Oggetti</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/raspi/llm/llm.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Small Language Models (SLM)</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../contents/labs/shared/shared.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab Condivisi</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-14" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-14" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/shared/kws_feature_eng/kws_feature_eng.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KWS Feature Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/labs/shared/dsp_spectral_features_block/dsp_spectral_features_block.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blocco delle Feature Spettrali DSP</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true">
 <span class="menu-text">RIFERIMENTI</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-15" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-15" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Riferimenti</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-16" role="navigation" aria-expanded="true" aria-label="Attiva/disattiva sezione">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-16" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/tools.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Tool</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_datasets.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Dataset</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/zoo_models.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Model Zoo</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/learning_resources.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Risorse</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/community.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Le Community</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../contents/case_studies.it.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Casi di Studio</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Indice</h2>
   
  <ul>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link active" data-scroll-target="#introduzione"><span class="header-section-number">8.1</span> Introduzione</a></li>
  <li><a href="#la-necessit√†-di-unia-efficiente" id="toc-la-necessit√†-di-unia-efficiente" class="nav-link" data-scroll-target="#la-necessit√†-di-unia-efficiente"><span class="header-section-number">8.2</span> La Necessit√† di un‚ÄôIA Efficiente</a></li>
  <li><a href="#architetture-di-modelli-efficienti" id="toc-architetture-di-modelli-efficienti" class="nav-link" data-scroll-target="#architetture-di-modelli-efficienti"><span class="header-section-number">8.3</span> Architetture di Modelli Efficienti</a></li>
  <li><a href="#sec-efficient-model-compression" id="toc-sec-efficient-model-compression" class="nav-link" data-scroll-target="#sec-efficient-model-compression"><span class="header-section-number">8.4</span> Compressione Efficiente del Modello</a></li>
  <li><a href="#hardware-di-inferenza-efficiente" id="toc-hardware-di-inferenza-efficiente" class="nav-link" data-scroll-target="#hardware-di-inferenza-efficiente"><span class="header-section-number">8.5</span> Hardware di Inferenza Efficiente</a></li>
  <li><a href="#sec-efficient-numerics" id="toc-sec-efficient-numerics" class="nav-link" data-scroll-target="#sec-efficient-numerics"><span class="header-section-number">8.6</span> Matematica Efficiente</a>
  <ul>
  <li><a href="#sec-numerical-formats" id="toc-sec-numerical-formats" class="nav-link" data-scroll-target="#sec-numerical-formats"><span class="header-section-number">8.6.1</span> Formati Numerici</a></li>
  <li><a href="#sec-efficiency-benefits" id="toc-sec-efficiency-benefits" class="nav-link" data-scroll-target="#sec-efficiency-benefits"><span class="header-section-number">8.6.2</span> Vantaggi dell‚ÄôEfficienza</a></li>
  </ul></li>
  <li><a href="#valutazione-dei-modelli" id="toc-valutazione-dei-modelli" class="nav-link" data-scroll-target="#valutazione-dei-modelli"><span class="header-section-number">8.7</span> Valutazione dei Modelli</a>
  <ul>
  <li><a href="#metriche-di-efficienza" id="toc-metriche-di-efficienza" class="nav-link" data-scroll-target="#metriche-di-efficienza"><span class="header-section-number">8.7.1</span> Metriche di Efficienza</a></li>
  <li><a href="#confronti-di-efficienza" id="toc-confronti-di-efficienza" class="nav-link" data-scroll-target="#confronti-di-efficienza"><span class="header-section-number">8.7.2</span> Confronti di Efficienza</a></li>
  </ul></li>
  <li><a href="#conclusione" id="toc-conclusione" class="nav-link" data-scroll-target="#conclusione"><span class="header-section-number">8.8</span> Conclusione</a></li>
  <li><a href="#sec-efficient-ai-resource" id="toc-sec-efficient-ai-resource" class="nav-link" data-scroll-target="#sec-efficient-ai-resource"><span class="header-section-number">8.9</span> Risorse</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/efficient_ai/efficient_ai.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/efficient_ai/efficient_ai.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../contents/training/training.it.html">Training</a></li><li class="breadcrumb-item"><a href="../../contents/efficient_ai/efficient_ai.it.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="sec-efficient_ai" class="quarto-section-identifier"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">IA Efficiente</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Risorse: <a href="#sec-efficient-ai-resource">Slide</a>, <a href="#sec-efficient-ai-resource">Video</a>, <a href="#sec-efficient-ai-resource">Esercizi</a>, <a href="#sec-efficient-ai-resource">Laboratori</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/png/cover_efficient_ai.png" class="img-fluid figure-img"></p>
<figcaption><em>DALL¬∑E 3 Prompt: Un‚Äôillustrazione concettuale che raffigura l‚Äôefficienza nell‚Äôintelligenza artificiale usando un‚Äôanalogia con il cantiere navale. La scena mostra un cantiere navale in fermento dove i container rappresentano bit o byte di dati. Questi container vengono spostati in modo efficiente da gru e veicoli, a simboleggiare l‚Äôelaborazione semplificata e rapida delle informazioni nei sistemi di intelligenza artificiale. Il cantiere navale √® organizzato meticolosamente, a dimostrazione del concetto di prestazioni ottimali entro i vincoli delle risorse limitate. Sullo sfondo, le navi sono attraccate, a rappresentare diverse piattaforme e scenari in cui viene applicata l‚Äôintelligenza artificiale. L‚Äôatmosfera dovrebbe trasmettere una tecnologia avanzata con la sostenibilit√† come tema di fondo e un‚Äôampia applicabilit√†.</em></figcaption>
</figure>
</div>
<p>L‚Äôefficienza nell‚Äôintelligenza artificiale (IA) non √® semplicemente un lusso, ma una necessit√†. In questo capitolo, approfondiamo i concetti chiave alla base dell‚Äôefficienza dei sistemi di IA. Le richieste computazionali sulle reti neurali possono essere scoraggianti, anche per i sistemi minimali. Per integrare perfettamente l‚ÄôIA nei dispositivi quotidiani e nei sistemi essenziali, deve funzionare in modo ottimale entro i vincoli delle risorse limitate, mantenendo al contempo la sua efficacia. La ricerca dell‚Äôefficienza garantisce che i modelli di IA siano semplificati, rapidi e sostenibili, ampliando cos√¨ la loro applicabilit√† su varie piattaforme e scenari.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Obiettivi dell‚ÄôApprendimento
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Riconoscere la necessit√† di un‚Äôintelligenza artificiale efficiente nei dispositivi TinyML/edge.</p></li>
<li><p>Comprendere la necessit√† di architetture di modelli efficienti come MobileNets e SqueezeNet.</p></li>
<li><p>Comprendere perch√© le tecniche per la compressione dei modelli sono importanti.</p></li>
<li><p>Apprezzare per il valore di un hardware AI efficiente.</p></li>
<li><p>Riconoscere l‚Äôimportanza delle rappresentazioni numeriche e della loro precisione.</p></li>
<li><p>Comprendere le sfumature del confronto dei modelli oltre la semplice accuratezza.</p></li>
<li><p>Riconoscere che il confronto dei modelli coinvolge memoria, elaborazione, potenza e velocit√†, non solo accuratezza.</p></li>
<li><p>Riconoscere che l‚Äôefficienza comprende tecnologia, costi ed etica.</p></li>
</ul>
</div>
</div>
<p>L‚Äôattenzione √® rivolta all‚Äôacquisizione di una comprensione concettuale delle motivazioni e del significato delle varie strategie per raggiungere un‚Äôintelligenza artificiale efficiente, sia in termini di tecniche che di prospettiva olistica. I capitoli successivi forniscono un‚Äôanalisi pi√π approfondita di questi molteplici concetti.</p>
<section id="introduzione" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">8.1</span> Introduzione</h2>
<p>I modelli di training possono consumare molta energia, a volte equivalente all‚Äôimpatto ambientale di processi industriali considerevoli. Tratteremo alcuni di questi dettagli sulla sostenibilit√† nel capitolo <a href="../sustainable_ai/sustainable_ai.qmd">Sostenibilit√† dell‚ÄôIA</a>. Dal punto di vista dell‚Äôimplementazione, se questi modelli non sono ottimizzati per l‚Äôefficienza, possono esaurire rapidamente le batterie dei dispositivi, richiedere una memoria eccessiva o non soddisfare le esigenze di elaborazione in tempo reale. In questo capitolo, miriamo a chiarire le sfumature dell‚Äôefficienza, gettando le basi per un‚Äôesplorazione completa nei capitoli successivi.</p>
</section>
<section id="la-necessit√†-di-unia-efficiente" class="level2 page-columns page-full" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="la-necessit√†-di-unia-efficiente"><span class="header-section-number">8.2</span> La Necessit√† di un‚ÄôIA Efficiente</h2>
<p>L‚Äôefficienza assume connotazioni diverse a seconda di dove si verificano i calcoli dell‚ÄôIA. Rivediamo Cloud, Edge e TinyML (come discusso in <a href="../ml_systems/ml_systems.qmd">Sistemi di ML</a>) e distinguiamoli in termini di efficienza. <a href="#fig-platforms" class="quarto-xref">Figura&nbsp;<span>8.1</span></a> fornisce un confronto generale delle tre diverse piattaforme.</p>
<div id="fig-platforms" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-platforms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://www.mdpi.com/futureinternet/futureinternet-14-00363/article_deploy/html/images/futureinternet-14-00363-g001-550.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-platforms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.1: Cloud, Mobile e TinyML. Fonte: <span class="citation" data-cites="schizas2022tinyml">Schizas et al. (<a href="../../references.it.html#ref-schizas2022tinyml" role="doc-biblioref">2022</a>)</span>.
</figcaption>
<div class="no-row-height column-margin column-container"><div id="ref-schizas2022tinyml" class="csl-entry" role="listitem">
Schizas, Nikolaos, Aristeidis Karras, Christos Karras, e Spyros Sioutas. 2022. <span>¬´<span>TinyML</span> for Ultra-Low Power <span>AI</span> and Large Scale <span>IoT</span> Deployments: <span>A</span> Systematic Review¬ª</span>. <em>Future Internet</em> 14 (12): 363. <a href="https://doi.org/10.3390/fi14120363">https://doi.org/10.3390/fi14120363</a>.
</div></div></figure>
</div>
<p><strong>IA Cloud:</strong> I modelli IA tradizionali vengono spesso eseguiti in data center su larga scala dotati di potenti GPU e TPU <span class="citation" data-cites="barroso2019datacenter">(<a href="../../references.it.html#ref-barroso2019datacenter" role="doc-biblioref">Barroso, H√∂lzle, e Ranganathan 2019</a>)</span>. Qui, l‚Äôefficienza riguarda l‚Äôottimizzazione delle risorse di calcolo, la riduzione dei costi e la garanzia di elaborazione e restituzione tempestive dei dati. Tuttavia, fare affidamento sul cloud introduce latenza, soprattutto quando si ha a che fare con flussi di dati di grandi dimensioni che richiedono caricamento, elaborazione e download.</p>
<div class="no-row-height column-margin column-container"><div id="ref-barroso2019datacenter" class="csl-entry" role="listitem">
Barroso, Luiz Andr√©, Urs H√∂lzle, e Parthasarathy Ranganathan. 2019. <em>The Datacenter as a Computer: Designing Warehouse-Scale Machines</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-031-01761-2">https://doi.org/10.1007/978-3-031-01761-2</a>.
</div><div id="ref-li2019edge" class="csl-entry" role="listitem">
Li, En, Liekang Zeng, Zhi Zhou, e Xu Chen. 2020. <span>¬´Edge <span>AI:</span> <span>On-demand</span> Accelerating Deep Neural Network Inference via Edge Computing¬ª</span>. <em>IEEE Trans. Wireless Commun.</em> 19 (1): 447‚Äì57. <a href="https://doi.org/10.1109/twc.2019.2946140">https://doi.org/10.1109/twc.2019.2946140</a>.
</div></div><p><strong>IA Edge:</strong> L‚Äôedge computing avvicina l‚Äôintelligenza artificiale alla fonte dei dati, elaborando le informazioni direttamente su dispositivi locali come smartphone, fotocamere o macchine industriali <span class="citation" data-cites="li2019edge">(<a href="../../references.it.html#ref-li2019edge" role="doc-biblioref">Li et al. 2020</a>)</span>. Qui, l‚Äôefficienza comprende risposte rapide in tempo reale e ridotte esigenze di trasmissione dei dati. Tuttavia, i vincoli sono pi√π severi: questi dispositivi, sebbene pi√π potenti dei microcontrollori, hanno una potenza di calcolo limitata rispetto alle configurazioni cloud.</p>
<p><strong>TinyML:</strong> TinyML supera i limiti consentendo ai modelli di intelligenza artificiale di funzionare su microcontrollori o ambienti con risorse estremamente limitate. La differenza di prestazioni del processore e della memoria tra TinyML e i sistemi cloud o mobili pu√≤ essere di diversi ordini di grandezza <span class="citation" data-cites="warden2019tinyml">(<a href="../../references.it.html#ref-warden2019tinyml" role="doc-biblioref">Warden e Situnayake 2019</a>)</span>. L‚Äôefficienza in TinyML consiste nell‚Äôassicurare che i modelli siano sufficientemente leggeri da adattarsi a questi dispositivi, consumino il minimo di energia (fondamentale per i dispositivi alimentati a batteria) e continuino a svolgere le loro attivit√† in modo efficace.</p>
<div class="no-row-height column-margin column-container"><div id="ref-warden2019tinyml" class="csl-entry" role="listitem">
Warden, Pete, e Daniel Situnayake. 2019. <em>Tinyml: <span>Machine</span> learning with tensorflow lite on arduino and ultra-low-power microcontrollers</em>. O‚ÄôReilly Media.
</div></div><p>Lo spettro da Cloud a TinyML rappresenta un passaggio da vaste risorse di elaborazione centralizzate ad ambienti distribuiti, localizzati e limitati. Passando dall‚Äôuno all‚Äôaltro, i problemi e le strategie relative all‚Äôefficienza evolvono, sottolineando la necessit√† di approcci specializzati su misura per ogni scenario. Dopo aver stabilito la necessit√† di un‚Äôintelligenza artificiale efficiente, in particolare nel contesto di TinyML, passeremo all‚Äôesplorazione delle metodologie ideate per rispondere a queste sfide. Le sezioni seguenti delineano i concetti principali che approfondiremo in seguito. Dimostreremo l‚Äôampiezza e la profondit√† dell‚Äôinnovazione necessarie per ottenere un‚Äôintelligenza artificiale efficiente mentre esploriamo queste strategie.</p>
</section>
<section id="architetture-di-modelli-efficienti" class="level2 page-columns page-full" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="architetture-di-modelli-efficienti"><span class="header-section-number">8.3</span> Architetture di Modelli Efficienti</h2>
<p>Selezionare un‚Äôarchitettura del modello ottimale √® tanto cruciale quanto ottimizzarla. Negli ultimi anni, i ricercatori hanno compiuto passi da gigante nell‚Äôesplorazione di architetture innovative che possono avere intrinsecamente meno parametri pur mantenendo prestazioni elevate.</p>
<p><strong>MobileNet:</strong> MobileNet sono modelli di applicazioni di visione mobile ed embedded efficienti <span class="citation" data-cites="howard2017mobilenets">(<a href="../../references.it.html#ref-howard2017mobilenets" role="doc-biblioref">Howard et al. 2017</a>)</span>. L‚Äôidea chiave che ha portato al loro successo sono le convoluzioni separabili in profondit√†, che riducono significativamente il numero di parametri e calcoli nella rete. MobileNetV2 e V3 migliorano ulteriormente questo design introducendo residui invertiti e colli di bottiglia lineari.</p>
<div class="no-row-height column-margin column-container"><div id="ref-howard2017mobilenets" class="csl-entry" role="listitem">
Howard, Andrew G., Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, e Hartwig Adam. 2017. <span>¬´<span>MobileNets:</span> <span>Efficient</span> Convolutional Neural Networks for Mobile Vision Applications¬ª</span>. <em>ArXiv preprint</em>. <a href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a>.
</div><div id="ref-iandola2016squeezenet" class="csl-entry" role="listitem">
Iandola, Forrest N, Song Han, Matthew W Moskewicz, Khalid Ashraf, William J Dally, e Kurt Keutzer. 2016. <span>¬´<span>SqueezeNet:</span> <span>Alexnet-level</span> accuracy with 50x fewer parameters and 0.5 <span>MB</span> model size¬ª</span>. <em>ArXiv preprint</em> abs/1602.07360. <a href="https://arxiv.org/abs/1602.07360">https://arxiv.org/abs/1602.07360</a>.
</div></div><p><strong>SqueezeNet:</strong> SqueezeNet √® una classe di modelli ML noti per le sue dimensioni ridotte senza sacrificare la precisione. Ci√≤ si ottiene utilizzando un ‚Äúmodulo fire‚Äù che riduce il numero di canali di input a filtri 3x3, riducendo cos√¨ i parametri <span class="citation" data-cites="iandola2016squeezenet">(<a href="../../references.it.html#ref-iandola2016squeezenet" role="doc-biblioref">Iandola et al. 2016</a>)</span>. Inoltre, impiega il downsampling [sottocampionamento] ritardato per aumentare la precisione mantenendo una mappa delle feature pi√π ampia.</p>
<p><strong>Varianti ResNet:</strong> L‚Äôarchitettura Residual Network (ResNet) consente l‚Äôintroduzione di connessioni skip o scorciatoie <span class="citation" data-cites="he2016deep">(<a href="../../references.it.html#ref-he2016deep" role="doc-biblioref">He et al. 2016</a>)</span>. Alcune varianti di ResNet sono progettate per essere pi√π efficienti. Ad esempio, ResNet-SE incorpora il meccanismo ‚Äúsqueeze and excitation‚Äù per ricalibrare le feature map <span class="citation" data-cites="hu2018squeeze">(<a href="../../references.it.html#ref-hu2018squeeze" role="doc-biblioref">Hu, Shen, e Sun 2018</a>)</span>, mentre ResNeXt offre convoluzioni raggruppate per l‚Äôefficienza <span class="citation" data-cites="xie2017aggregated">(<a href="../../references.it.html#ref-xie2017aggregated" role="doc-biblioref">Xie et al. 2017</a>)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-he2016deep" class="csl-entry" role="listitem">
He, Kaiming, Xiangyu Zhang, Shaoqing Ren, e Jian Sun. 2016. <span>¬´Deep Residual Learning for Image Recognition¬ª</span>. In <em>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 770‚Äì78. IEEE. <a href="https://doi.org/10.1109/cvpr.2016.90">https://doi.org/10.1109/cvpr.2016.90</a>.
</div><div id="ref-hu2018squeeze" class="csl-entry" role="listitem">
Hu, Jie, Li Shen, e Gang Sun. 2018. <span>¬´Squeeze-and-Excitation Networks¬ª</span>. In <em>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 7132‚Äì41. IEEE. <a href="https://doi.org/10.1109/cvpr.2018.00745">https://doi.org/10.1109/cvpr.2018.00745</a>.
</div><div id="ref-xie2017aggregated" class="csl-entry" role="listitem">
Xie, Saining, Ross Girshick, Piotr Dollar, Zhuowen Tu, e Kaiming He. 2017. <span>¬´Aggregated Residual Transformations for Deep Neural Networks¬ª</span>. In <em>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 1492‚Äì1500. IEEE. <a href="https://doi.org/10.1109/cvpr.2017.634">https://doi.org/10.1109/cvpr.2017.634</a>.
</div></div></section>
<section id="sec-efficient-model-compression" class="level2 page-columns page-full" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="sec-efficient-model-compression"><span class="header-section-number">8.4</span> Compressione Efficiente del Modello</h2>
<p>I metodi di compressione dei modelli sono essenziali per portare i modelli di apprendimento profondo su dispositivi con risorse limitate. Queste tecniche riducono le dimensioni dei modelli, il consumo energetico e le richieste di elaborazione senza perdere significativamente la precisione. Ad alto livello, i metodi possono essere categorizzati nei seguenti metodi fondamentali:</p>
<p><strong>Pruning:</strong> L‚ÄôAbbiamo menzionato un paio di volte nei capitoli precedenti, ma non l‚Äôabbiamo ancora formalmente introdotta. Il pruning √® simile alla potatura dei rami di un albero. Questo √® stato pensato per la prima volta nel documento <a href="https://proceedings.neurips.cc/paper/1989/file/6c9882bbac1c7093bd25041881277658-Paper.pdf">Optimal Brain Damage</a> <span class="citation" data-cites="lecun1989optimal">(<a href="../../references.it.html#ref-lecun1989optimal" role="doc-biblioref">LeCun, Denker, e Solla 1989</a>)</span> ed √® stato successivamente reso popolare nel contesto del deep learning da <span class="citation" data-cites="han2016deep">Han, Mao, e Dally (<a href="../../references.it.html#ref-han2016deep" role="doc-biblioref">2016</a>)</span>. Determinati pesi o interi neuroni vengono rimossi dalla rete nella potatura in base a criteri specifici. Questo pu√≤ ridurre significativamente le dimensioni del modello. In <a href="../optimizations/optimizations.it.html#sec-pruning" class="quarto-xref"><span>Sezione 9.2.1</span></a> esploreremo due delle principali strategie di potatura, quella strutturata e quella non-strutturata. <a href="#fig-pruning" class="quarto-xref">Figura&nbsp;<span>8.2</span></a> √® un esempio di potatura della rete neurale, in cui la rimozione di alcuni nodi negli strati interni (in base a criteri specifici) riduce il numero di rami tra i nodi e, a sua volta, le dimensioni del modello.</p>
<div class="no-row-height column-margin column-container"><div id="ref-lecun1989optimal" class="csl-entry" role="listitem">
LeCun, Yann, John Denker, e Sara Solla. 1989. <span>¬´Optimal brain damage¬ª</span>. <em>Adv Neural Inf Process Syst</em> 2.
</div><div id="ref-han2016deep" class="csl-entry" role="listitem">
Han, Song, Huizi Mao, e William J. Dally. 2016. <span>¬´Deep Compression: <span>Compressing</span> Deep Neural Networks with Pruning, Trained Quantization and <span>Huffman</span> Coding¬ª</span>. <a href="https://arxiv.org/abs/1510.00149">https://arxiv.org/abs/1510.00149</a>.
</div></div><div id="fig-pruning" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/pruning.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-pruning-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.2: Neural Network Pruning.
</figcaption>
</figure>
</div>
<p><strong>Quantizzazione:</strong> La quantizzazione √® il processo di limitazione di un input da un set ampio a un output in un set pi√π piccolo, principalmente nel deep learning; ci√≤ significa ridurre il numero di bit che rappresentano i pesi e i bias del modello. Ad esempio, l‚Äôutilizzo di rappresentazioni a 16 o 8 bit anzich√© a 32 bit pu√≤ ridurre la dimensione del modello e velocizzare i calcoli, con un piccolo compromesso in termini di accuratezza. Esploreremo questi aspetti pi√π in dettaglio in <a href="../optimizations/optimizations.it.html#sec-quant" class="quarto-xref"><span>Sezione 9.3.4</span></a>. <a href="#fig-quantization" class="quarto-xref">Figura&nbsp;<span>8.3</span></a> mostra un esempio di quantizzazione mediante arrotondamento al numero pi√π vicino. La conversione da virgola mobile a 32 bit a 16 bit riduce l‚Äôutilizzo della memoria del 50%. Passare da un intero a 32 bit a uno a 8 bit riduce l‚Äôutilizzo della memoria del 75%. Mentre la perdita di precisione numerica e, di conseguenza, di prestazioni del modello √® minima, l‚Äôefficienza nell‚Äôutilizzo della memoria √® significativa.</p>
<div id="fig-quantization" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/quantization.jpeg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-quantization-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.3: Diverse forme di quantizzazione.
</figcaption>
</figure>
</div>
<p><strong>Knowledge Distillation:</strong> La ‚Äúdistillazione della conoscenza‚Äù comporta l‚Äôaddestramento di un modello pi√π piccolo (studente) per replicare il comportamento di un modello pi√π grande (insegnante). L‚Äôidea √® quella di trasferire la conoscenza dal modello ingombrante a quello leggero. Quindi, il modello pi√π piccolo raggiunge prestazioni vicine alla sua controparte pi√π grande ma con parametri significativamente inferiori. <a href="#fig-knowledge-dist" class="quarto-xref">Figura&nbsp;<span>8.4</span></a> mostra la struttura tutor-studente per la distillazione della conoscenza. Esploreremo la ‚Äúdistillazione della conoscenza‚Äù in modo pi√π dettagliato in <a href="../optimizations/optimizations.it.html#sec-kd" class="quarto-xref"><span>Sezione 9.2.2.1</span></a>.</p>
<div id="fig-knowledge-dist" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-knowledge-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/knowledgedistillation.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-knowledge-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.4: Il framework tutor-studente per la distillazione della conoscenza. Fonte: <a href="URL:https://chukwubuikexo.medium.com/knowledge-distillation-approaches-in-machine-learning-5841a41a346a">Medium</a>
</figcaption>
</figure>
</div>
</section>
<section id="hardware-di-inferenza-efficiente" class="level2 page-columns page-full" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="hardware-di-inferenza-efficiente"><span class="header-section-number">8.5</span> Hardware di Inferenza Efficiente</h2>
<p>Nel capitolo <a href="../training/training.qmd">Training</a>, abbiamo discusso il processo di training dei modelli di intelligenza artificiale. Ora, dal punto di vista dell‚Äôefficienza, √® importante notare che il training √® un‚Äôattivit√† che richiede molte risorse e molto tempo, spesso richiede hardware potente e impiega da ore a settimane per essere completato. L‚Äôinferenza, d‚Äôaltra parte, deve essere il pi√π veloce possibile, soprattutto nelle applicazioni in tempo reale. √à qui che entra in gioco un hardware di inferenza efficiente. Ottimizzando l‚Äôhardware specificamente per le attivit√† di inferenza, possiamo ottenere tempi di risposta rapidi e un funzionamento efficiente dal punto di vista energetico, il che √® particolarmente cruciale per i dispositivi edge e i sistemi embedded.</p>
<p><strong>TPU (Tensor Processing Unit):</strong> Le <a href="https://cloud.google.com/tpu">TPU</a> sono ASIC (Application-Specific Integrated Circuits) personalizzati da Google per accelerare i carichi di lavoro di apprendimento automatico <span class="citation" data-cites="jouppi2017datacenter">(<a href="../../references.it.html#ref-jouppi2017datacenter" role="doc-biblioref">Jouppi et al. 2017</a>)</span>. Sono ottimizzate per le operazioni tensoriali, offrono un throughput elevato per l‚Äôaritmetica a bassa precisione e sono progettate specificamente per il machine learning delle reti neurali. Le TPU accelerano significativamente l‚Äôaddestramento e l‚Äôinferenza del modello rispetto alle GPU/CPU generiche. Questo potenziamento si traduce in un addestramento pi√π rapido dei modelli e in capacit√† di inferenza in tempo reale o quasi reale, fondamentali per applicazioni come la ricerca vocale e la realt√† aumentata.</p>
<div class="no-row-height column-margin column-container"><div id="ref-jouppi2017datacenter" class="csl-entry" role="listitem">
Jouppi, Norman P., Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, et al. 2017. <span>¬´In-Datacenter Performance Analysis of a Tensor Processing Unit¬ª</span>. In <em>Proceedings of the 44th Annual International Symposium on Computer Architecture</em>, 1‚Äì12. ISCA ‚Äô17. New York, NY, USA: ACM. <a href="https://doi.org/10.1145/3079856.3080246">https://doi.org/10.1145/3079856.3080246</a>.
</div></div><p>Le <a href="https://cloud.google.com/edge-tpu">Edge TPU</a> sono una versione pi√π piccola e a basso consumo delle TPU di Google, studiate appositamente per i dispositivi edge. Forniscono un‚Äôinferenza ML veloce sul dispositivo per i modelli TensorFlow Lite. Le Edge TPU consentono un‚Äôinferenza a bassa latenza e ad alta efficienza su dispositivi edge come smartphone, dispositivi IoT e sistemi embedded. Le capacit√† di IA possono essere implementate in applicazioni in tempo reale senza comunicare con un server centrale, risparmiando cos√¨ larghezza di banda e riducendo la latenza. Si consideri la tabella in <a href="#fig-edge-tpu-perf" class="quarto-xref">Figura&nbsp;<span>8.5</span></a>. Mostra le differenze di prestazioni tra l‚Äôesecuzione di modelli diversi su CPU rispetto a un acceleratore Coral USB. L‚Äôacceleratore Coral USB √® un accessorio della piattaforma Coral AI di Google che consente agli sviluppatori di collegare le Edge TPU ai computer Linux. L‚Äôesecuzione dell‚Äôinferenza sulle Edge TPU √® stata da 70 a 100 volte pi√π veloce rispetto alle CPU.</p>
<div id="fig-edge-tpu-perf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edge-tpu-perf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/tflite_edge_tpu_perf.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edge-tpu-perf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.5: Confronto delle prestazioni tra acceleratore e CPU in diverse configurazioni hardware. Desktop CPU: 64-bit Intel(R) Xeon(R) E5-1650 v4 @ 3.60GHz. Embedded CPU: Quad-core Cortex-A53 @ 1.5GHz, ‚Ä†Dev Board: Quad-core Cortex-A53 @ 1.5GHz + Edge TPU. Fonte: <a href="https://blog.tensorflow.org/2019/03/build-ai-that-works-offline-with-coral.html">TensorFlow Blog.</a>
</figcaption>
</figure>
</div>
<p><strong>Acceleratori NN (Neural Network):</strong> Gli acceleratori di reti neurali a funzione fissa sono acceleratori hardware progettati esplicitamente per i calcoli di reti neurali. Possono essere chip standalone o far parte di una soluzione di system-on-chip (SoC) pi√π ampia. Ottimizzando l‚Äôhardware per le operazioni specifiche richieste dalle reti neurali, come moltiplicazioni di matrici e convoluzioni, gli acceleratori NN possono ottenere tempi di inferenza pi√π rapidi e consumi energetici inferiori rispetto alle CPU e alle GPU per uso generico. Sono particolarmente utili nei dispositivi TinyML con vincoli di potenza o termici, come smartwatch, micro-droni o robotica.</p>
<p>Ma questi sono solo gli esempi pi√π comuni. Stanno emergendo diversi altri tipi di hardware che hanno il potenziale per offrire vantaggi significativi per l‚Äôinferenza. Questi includono, ma non solo, hardware neuromorfico, elaborazione fotonica, ecc. In <a href="../hw_acceleration/hw_acceleration.it.html#sec-aihw" class="quarto-xref"><span>Sezione 10.3</span></a>, esploreremo questi aspetti in modo pi√π dettagliato.</p>
<p>Un hardware efficiente per l‚Äôinferenza velocizza il processo, risparmia energia, prolunga la durata della batteria e pu√≤ funzionare in condizioni di tempo reale. Man mano che l‚Äôintelligenza artificiale viene integrata in innumerevoli applicazioni, dalle telecamere intelligenti agli assistenti vocali, il ruolo dell‚Äôhardware ottimizzato diventer√† sempre pi√π importante. Sfruttando questi componenti hardware specializzati, sviluppatori e ingegneri possono portare la potenza dell‚Äôintelligenza artificiale a dispositivi e situazioni che prima erano impensabili.</p>
</section>
<section id="sec-efficient-numerics" class="level2 page-columns page-full" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="sec-efficient-numerics"><span class="header-section-number">8.6</span> Matematica Efficiente</h2>
<p>L‚Äôapprendimento automatico, e in particolare il deep learning, comporta enormi quantit√† di elaborazione. I modelli possono avere milioni o miliardi di parametri, spesso addestrati su vasti set di dati. Ogni operazione, ogni moltiplicazione o addizione, richiede risorse di elaborazione. Pertanto, la precisione dei numeri utilizzati in queste operazioni pu√≤ avere un impatto significativo sulla velocit√† di elaborazione, sul consumo di energia e sui requisiti di memoria. √à qui che entra in gioco il concetto di numeri efficienti.</p>
<section id="sec-numerical-formats" class="level3 page-columns page-full" data-number="8.6.1">
<h3 data-number="8.6.1" class="anchored" data-anchor-id="sec-numerical-formats"><span class="header-section-number">8.6.1</span> Formati Numerici</h3>
<p>Esistono molti tipi diversi di numeri. I numeri hanno una lunga storia nei sistemi di elaborazione.</p>
<p><strong>Floating point:</strong> Noto come ‚Äúvirgola mobile‚Äù a precisione singola, FP32 utilizza 32 bit per rappresentare un numero, incorporandone segno, esponente e mantissa. Comprendere come i numeri in virgola mobile sono rappresentati in modo approfondito √® fondamentale per comprendere le varie ottimizzazioni possibili nei calcoli numerici. Il bit del segno determina se il numero √® positivo o negativo, l‚Äôesponente controlla l‚Äôintervallo di valori che possono essere rappresentati e la mantissa determina la precisione del numero. La combinazione di questi componenti consente ai numeri in virgola mobile di rappresentare un‚Äôampia gamma di valori con vari gradi di precisione.</p>
<p><a href="#vid-floating-point-numbers" class="quarto-xref">Video&nbsp;<span>8.1</span></a> fornisce una panoramica completa di questi tre componenti principali, segno, esponente e mantissa, e di come funzionano insieme per rappresentare i numeri in virgola mobile.</p>
<div id="vid-floating-point-numbers" class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video&nbsp;8.1: Numeri in Virgola Mobile
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gc1Nl3mmCuY?si=nImcymfbE5H392vu" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</div>
</div>
<p>FP32 √® ampiamente adottato in molti framework di deep learning e bilancia accuratezza e requisiti computazionali. √à prevalente nella fase di training per molte reti neurali grazie alla sua sufficiente precisione nel catturare dettagli minuti durante gli aggiornamenti dei pesi. Noto anche come virgola mobile a mezza precisione, FP16 utilizza 16 bit per rappresentare un numero, inclusi il segno, l‚Äôesponente e la frazione. Offre un buon equilibrio tra precisione e risparmio di memoria. FP16 √® particolarmente popolare nella training di deep learning su GPU che supportano l‚Äôaritmetica a precisione mista, combinando i vantaggi di velocit√† di FP16 con la precisione di FP32 quando necessario.</p>
<p>Diversi altri formati numerici rientrano in una classe esotica. Un esempio esotico √® BF16 o Brain Floating Point. √à un formato numerico a 16 bit progettato esplicitamente per applicazioni di deep learning. √à un compromesso tra FP32 e FP16, che mantiene l‚Äôesponente a 8 bit di FP32 riducendo la mantissa a 7 bit (rispetto alla mantissa a 23 bit di FP32). Questa struttura d√† priorit√† al range rispetto alla precisione. BF16 ha ottenuto risultati di training paragonabili in accuratezza a FP32, utilizzando significativamente meno memoria e risorse computazionali <span class="citation" data-cites="kalamkar2019study">(<a href="../../references.it.html#ref-kalamkar2019study" role="doc-biblioref">Kalamkar et al. 2019</a>)</span>. Ci√≤ lo rende adatto non solo per l‚Äôinferenza, ma anche per il training di reti neurali profonde.</p>
<div class="no-row-height column-margin column-container"><div id="ref-kalamkar2019study" class="csl-entry" role="listitem">
Kalamkar, Dhiraj, Dheevatsa Mudigere, Naveen Mellempudi, Dipankar Das, Kunal Banerjee, Sasikanth Avancha, Dharma Teja Vooturi, et al. 2019. <span>¬´A Study of <span>BFLOAT16</span> for Deep Learning Training¬ª</span>. <a href="https://arxiv.org/abs/1905.12322">https://arxiv.org/abs/1905.12322</a>.
</div></div><p>Mantenendo l‚Äôesponente a 8 bit di FP32, BF16 offre un range simile, che √® fondamentale per le attivit√† di deep learning in cui determinate operazioni possono generare numeri molto grandi o molto piccoli. Allo stesso tempo, troncando la precisione, BF16 consente requisiti di memoria e computazionali ridotti rispetto a FP32. BF16 √® emerso come una promettente via di mezzo nel panorama dei formati numerici per il deep learning, fornendo un‚Äôalternativa efficiente ed efficace ai formati FP32 e FP16 pi√π tradizionali.</p>
<p><a href="#fig-float-point-formats" class="quarto-xref">Figura&nbsp;<span>8.6</span></a> mostra tre diversi formati in virgola mobile: Float32, Float16 e BFloat16.</p>
<div id="fig-float-point-formats" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-float-point-formats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/png/three_float_types.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-float-point-formats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.6: Tre formati a virgola mobile.
</figcaption>
</figure>
</div>
<p><strong>Intero:</strong> Si tratta di rappresentazioni di numeri interi che utilizzano 8, 4 e 2 bit. Vengono spesso utilizzati durante la fase di inferenza delle reti neurali, in cui i pesi e le attivazioni del modello sono quantizzati a queste precisioni inferiori. Le rappresentazioni intere sono deterministiche e offrono notevoli vantaggi in termini di velocit√† e memoria rispetto alle rappresentazioni in virgola mobile. Per molte attivit√† di inferenza, in particolare sui dispositivi edge, la leggera perdita di accuratezza dovuta alla quantizzazione √® spesso accettabile, dati i guadagni di efficienza. Una forma estrema di numeri interi √® per le reti neurali binarie (BNN), in cui pesi e attivazioni sono vincolati a uno dei due valori: +1 o -1.</p>
<p><strong>Larghezze di bit variabili:</strong> Oltre alle larghezze standard, sono in corso ricerche su numeri con larghezze di bit estremamente basse, persino fino a rappresentazioni binarie o ternarie. Le operazioni con larghezze di bit estremamente basse possono offrire accelerazioni significative e ridurre ulteriormente il consumo di energia. Sebbene permangano dei problemi nel mantenere l‚Äôaccuratezza del modello con una quantizzazione cos√¨ drastica, si continuano a fare progressi in quest‚Äôarea.</p>
<p>L‚Äôefficienza numerica non riguarda solo la riduzione della larghezza di bit dei numeri, ma anche la comprensione dei compromessi tra accuratezza ed efficienza. Man mano che i modelli di apprendimento automatico diventano pi√π pervasivi, soprattutto in ambienti reali con risorse limitate, l‚Äôattenzione su una numerica efficiente continuer√† a crescere. Selezionando e sfruttando attentamente la precisione numerica appropriata, √® possibile ottenere prestazioni di modello robuste ottimizzando al contempo velocit√†, memoria ed energia. <a href="#tbl-precision" class="quarto-xref">Tabella&nbsp;<span>8.1</span></a> riassume questi compromessi.</p>
<div id="tbl-precision" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-precision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tabella&nbsp;8.1: Confronto dei livelli di precisione nel deep learning.
</figcaption>
<div aria-describedby="tbl-precision-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 9%">
<col style="width: 40%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Precisione</th>
<th style="text-align: left;">Pro</th>
<th style="text-align: left;">Contro</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">FP32 (virgola mobile a 32 bit)</td>
<td style="text-align: left;"><ul>
<li>Precisione standard utilizzata nella maggior parte dei framework di deep learning.</li>
<li>Elevata accuratezza grazie all‚Äôampia capacit√† di rappresentazione.</li>
<li>Adatto per il training</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Elevato utilizzo di memoria.</li>
<li>Tempi di inferenza pi√π lenti rispetto ai modelli quantizzati.</li>
<li>Maggiore consumo energetico.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">FP16 (virgola mobile a 16 bit)</td>
<td style="text-align: left;"><ul>
<li>Riduce l‚Äôutilizzo di memoria rispetto a FP32.</li>
<li>Velocizza i calcoli su hardware che supporta FP16.</li>
<li>Spesso utilizzato nel training a precisione mista per bilanciare velocit√† e accuratezza.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Minore capacit√† di rappresentazione rispetto a FP32.</li>
<li>Rischio di instabilit√† numerica in alcuni modelli o livelli.</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">INT8 (intero a 8 bit)</td>
<td style="text-align: left;"><ul>
<li>Impronta di memoria notevolmente ridotta rispetto alle rappresentazioni in virgola mobile.</li>
<li>Inferenza pi√π rapida se l‚Äôhardware supporta i calcoli INT8.</li>
<li>Adatto a molti scenari di quantizzazione post-training.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>La quantizzazione pu√≤ comportare una certa perdita di accuratezza.</li>
<li>Richiede una calibrazione attenta durante la quantizzazione per ridurre al minimo il degrado della precisione.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">INT4 (intero a 4 bit)</td>
<td style="text-align: left;"><ul>
<li>Utilizzo di memoria ancora inferiore rispetto a INT8.</li>
<li>Ulteriore potenziale di accelerazione per l‚Äôinferenza.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Rischio di perdita di precisione pi√π elevato rispetto a INT8.</li>
<li>La calibrazione durante la quantizzazione diventa pi√π critica.</li>
</ul></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Binario</td>
<td style="text-align: left;"><ul>
<li>Ingombro di memoria minimo (solo 1 bit per parametro).</li>
<li>Inferenza estremamente rapida grazie alle operazioni bit a bit.</li>
<li>Efficienza energetica.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>Calo significativo della precisione per molte attivit√†.</li>
<li>Dinamiche di training complesse grazie alla quantizzazione estrema.</li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: left;">Ternario</td>
<td style="text-align: left;"><ul>
<li>Basso utilizzo di memoria ma leggermente superiore a quello binario.</li>
<li>Offre una via di mezzo tra rappresentazione ed efficienza.</li>
</ul></td>
<td style="text-align: left;"><ul>
<li>L‚Äôaccuratezza potrebbe essere ancora inferiore a quella dei modelli di precisione pi√π elevata.</li>
<li>Le dinamiche di addestramento possono essere complesse.</li>
</ul></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="sec-efficiency-benefits" class="level3" data-number="8.6.2">
<h3 data-number="8.6.2" class="anchored" data-anchor-id="sec-efficiency-benefits"><span class="header-section-number">8.6.2</span> Vantaggi dell‚ÄôEfficienza</h3>
<p>L‚Äôefficienza numerica √® importante per i carichi di lavoro di machine learning per diversi motivi:</p>
<p><strong>Efficienza Computazionale:</strong> I calcoli ad alta precisione (come FP32 o FP64) possono essere lenti e richiedere molte risorse. Ridurre la precisione numerica pu√≤ ottenere tempi di calcolo pi√π rapidi, specialmente su hardware specializzato che supporta una precisione inferiore.</p>
<p><strong>Efficienza della Memoria:</strong> I requisiti di archiviazione diminuiscono con una precisione numerica ridotta. Ad esempio, FP16 richiede met√† della memoria di FP32. Ci√≤ √® fondamentale quando si distribuiscono modelli su dispositivi edge con memoria limitata o si lavora con modelli di grandi dimensioni.</p>
<p><strong>Efficienza Energetica:</strong> I calcoli a precisione inferiore spesso consumano meno energia, il che √® particolarmente importante per i dispositivi alimentati a batteria.</p>
<p><strong>Introduzione del Rumore:</strong> √à interessante notare che il rumore introdotto utilizzando una precisione inferiore pu√≤ talvolta fungere da regolarizzatore, contribuendo a prevenire l‚Äôoverfitting in alcuni modelli.</p>
<p><strong>Accelerazione Hardware:</strong> Molti acceleratori di IA e GPU moderni sono ottimizzati per operazioni di precisione inferiore, sfruttando i vantaggi dell‚Äôefficienza di tali numeri.</p>
</section>
</section>
<section id="valutazione-dei-modelli" class="level2 page-columns page-full" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="valutazione-dei-modelli"><span class="header-section-number">8.7</span> Valutazione dei Modelli</h2>
<p>Vale la pena notare che i vantaggi e i compromessi effettivi possono variare in base all‚Äôarchitettura specifica della rete neurale, al set di dati, all‚Äôattivit√† e all‚Äôhardware utilizzato. Prima di decidere una precisione numerica, √® consigliabile eseguire esperimenti per valutare l‚Äôimpatto sull‚Äôapplicazione desiderata.</p>
<section id="metriche-di-efficienza" class="level3" data-number="8.7.1">
<h3 data-number="8.7.1" class="anchored" data-anchor-id="metriche-di-efficienza"><span class="header-section-number">8.7.1</span> Metriche di Efficienza</h3>
<p>Una profonda comprensione dei metodi di valutazione dei modelli √® importante per guidare questo processo in modo sistematico. Quando si valuta l‚Äôefficacia e l‚Äôidoneit√† dei modelli di intelligenza artificiale per varie applicazioni, le metriche di efficienza vengono in primo piano.</p>
<p>I <strong>FLOP (Floating Point Operations)</strong>, introdotti in <a href="../training/training.html">Training</a>, misurano le esigenze computazionali di un modello. Ad esempio, una moderna rete neurale come BERT ha miliardi di FLOP, che potrebbero essere gestibili su un potente server cloud ma sarebbero gravosi su uno smartphone. FLOP pi√π elevati possono portare a tempi di inferenza pi√π prolungati e a un notevole consumo di energia, soprattutto su dispositivi senza acceleratori hardware specializzati. Quindi, per applicazioni in tempo reale come lo streaming video o i giochi, potrebbero essere pi√π desiderabili modelli con FLOP pi√π bassi.</p>
<p>L‚Äô<strong>Utilizzo della Memoria</strong> riguarda la quantit√† di spazio di archiviazione richiesta dal modello, che influisce sia sullo spazio di archiviazione del dispositivo che sulla RAM. Si prenda in considerazione l‚Äôimplementazione di un modello su uno smartphone: un modello che occupa diversi gigabyte di spazio non solo consuma prezioso spazio di archiviazione, ma potrebbe anche essere pi√π lento a causa della necessit√† di caricare grandi pesi nella memoria. Ci√≤ diventa particolarmente cruciale per dispositivi edge come telecamere di sicurezza o droni, dove impronte di memoria minime sono vitali per l‚Äôarchiviazione e l‚Äôelaborazione rapida dei dati.</p>
<p>Il <strong>Consumo Energetico</strong> diventa particolarmente cruciale per i dispositivi che si basano sulle batterie. Ad esempio, un monitor sanitario indossabile che utilizza un modello ad alto consumo energetico potrebbe esaurire la batteria in poche ore, rendendolo poco pratico per il monitoraggio continuo. L‚Äôottimizzazione dei modelli per un basso consumo energetico diventa essenziale mentre ci muoviamo verso un‚Äôera dominata dai dispositivi IoT, dove molti dispositivi funzionano a batteria.</p>
<p>Il <strong>Tempo di Inferenza</strong> riguarda la rapidit√† con cui un modello pu√≤ produrre risultati. In applicazioni come la guida autonoma, dove decisioni in frazioni di secondo fanno la differenza tra sicurezza e calamit√†, i modelli devono funzionare rapidamente. Se il modello di un‚Äôauto a guida autonoma impiega anche solo pochi secondi in pi√π per riconoscere un ostacolo, le conseguenze potrebbero essere disastrose. Quindi, garantire che il tempo di inferenza di un modello sia allineato con le richieste in tempo reale della sua applicazione √® fondamentale.</p>
<p>In sostanza, queste metriche di efficienza sono pi√π che dei numeri che stabiliscono dove e come un modello pu√≤ essere distribuito in modo efficace. Un modello potrebbe vantare un‚Äôelevata accuratezza, ma se i suoi FLOP, l‚Äôutilizzo della memoria, il consumo energetico o il tempo di inferenza lo rendono inadatto alla piattaforma prevista o agli scenari del mondo reale, la sua utilit√† pratica diventa limitata.</p>
</section>
<section id="confronti-di-efficienza" class="level3 page-columns page-full" data-number="8.7.2">
<h3 data-number="8.7.2" class="anchored" data-anchor-id="confronti-di-efficienza"><span class="header-section-number">8.7.2</span> Confronti di Efficienza</h3>
<p>Il panorama dei modelli di machine learning √® vasto, con ogni modello che offre un set unico di punti di forza e considerazioni di implementazione. Sebbene le cifre di accuratezza grezza o le velocit√† di training e inferenza possano essere parametri di riferimento allettanti, forniscono un quadro incompleto. Un‚Äôanalisi comparativa pi√π approfondita rivela diversi fattori critici che influenzano l‚Äôidoneit√† di un modello per le applicazioni TinyML. Spesso, incontriamo il delicato equilibrio tra accuratezza ed efficienza. Ad esempio, mentre un modello di deep learning e denso e una variante MobileNet leggera potrebbero eccellere nella classificazione delle immagini, le loro richieste di calcolo potrebbero essere ad estremi opposti. Questa differenziazione √® particolarmente pronunciata quando si confrontano le distribuzioni su server cloud con risorse abbondanti rispetto ai limitati dispositivi TinyML. In molti scenari del mondo reale, i guadagni marginali in termini di accuratezza potrebbero essere oscurati dalle inefficienze di un modello ad alta intensit√† di risorse richieste.</p>
<p>Inoltre, la scelta del modello ottimale non √® sempre universale, ma spesso dipende dalle specifiche di un‚Äôapplicazione. Ad esempio, un modello che eccelle in scenari di rilevamento di oggetti generali potrebbe avere difficolt√† in ambienti di nicchia, come il rilevamento di difetti di fabbricazione in una fabbrica. Questa adattabilit√†, o la sua mancanza, pu√≤ influenzare l‚Äôutilit√† reale di un modello.</p>
<p>Un‚Äôaltra considerazione importante √® la relazione tra la complessit√† del modello e i suoi vantaggi pratici. Prendiamo gli assistenti attivati tramite comando vocale, come ‚ÄúAlexa‚Äù o ‚ÄúOK Google‚Äù. Mentre un modello complesso potrebbe dimostrare una comprensione marginalmente superiore del parlato dell‚Äôutente se √® pi√π lento a rispondere rispetto a una controparte pi√π semplice, l‚Äôesperienza utente potrebbe essere compromessa. Pertanto, l‚Äôaggiunta di layer o parametri solo a volte equivale a risultati migliori nel mondo reale.</p>
<p>Un‚Äôaltra considerazione importante √® la relazione tra la complessit√† del modello e i suoi vantaggi pratici. Prendiamo gli assistenti vocali come ‚ÄúAlexa‚Äù o ‚ÄúOK Google‚Äù. Mentre un modello complesso potrebbe dimostrare una comprensione leggermente superiore del parlato dell‚Äôutente se √® pi√π lento a rispondere rispetto a una controparte pi√π semplice, l‚Äôesperienza utente potrebbe essere compromessa. Pertanto, l‚Äôaggiunta di layer o parametri solo a volte equivale a risultati migliori nel mondo reale.</p>
<p>Inoltre, mentre i set di dati di riferimento, come ImageNet <span class="citation" data-cites="russakovsky2015imagenet">(<a href="../../references.it.html#ref-russakovsky2015imagenet" role="doc-biblioref">Russakovsky et al. 2015</a>)</span>, COCO <span class="citation" data-cites="lin2014microsoft">(<a href="../../references.it.html#ref-lin2014microsoft" role="doc-biblioref">Lin et al. 2014</a>)</span>, Visual Wake Words <span class="citation" data-cites="chowdhery2019visual">(<a href="../../references.it.html#ref-chowdhery2019visual" role="doc-biblioref">Wang e Zhan 2019</a>)</span>, Google Speech Commands <span class="citation" data-cites="warden2018speech">(<a href="../../references.it.html#ref-warden2018speech" role="doc-biblioref">Warden 2018</a>)</span>, ecc. forniscono una metrica di prestazioni standardizzata, potrebbero non catturare la diversit√† e l‚Äôimprevedibilit√† dei dati del mondo reale. Due modelli di riconoscimento facciale con punteggi di riferimento simili potrebbero mostrare competenze diverse quando si trovano di fronte a background etnici diversi o condizioni di illuminazione difficili. Tali disparit√† sottolineano l‚Äôimportanza di robustezza e coerenza tra dati diversi. Ad esempio, <a href="#fig-stoves" class="quarto-xref">Figura&nbsp;<span>8.7</span></a> dal set di dati Dollar Street mostra immagini di stufe su redditi mensili estremi. Le stufe hanno forme e livelli tecnologici diversi in diverse regioni e livelli di reddito. Un modello che non √® addestrato su set di dati diversi potrebbe funzionare bene su un benchmark ma fallire nelle applicazioni del mondo reale. Quindi, se un modello fosse addestrato solo su immagini di stufe trovate nei paesi ricchi, non riuscirebbe a riconoscere le stufe delle regioni pi√π povere.</p>
<div class="no-row-height column-margin column-container"><div id="ref-russakovsky2015imagenet" class="csl-entry" role="listitem">
Russakovsky, Olga, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, et al. 2015. <span>¬´<span>ImageNet</span> Large Scale Visual Recognition Challenge¬ª</span>. <em>Int. J. Comput. Vision</em> 115 (3): 211‚Äì52. <a href="https://doi.org/10.1007/s11263-015-0816-y">https://doi.org/10.1007/s11263-015-0816-y</a>.
</div><div id="ref-lin2014microsoft" class="csl-entry" role="listitem">
Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll√°r, e C Lawrence Zitnick. 2014. <span>¬´Microsoft coco: <span>Common</span> objects in context¬ª</span>. In <em>Computer Vision<span></span>ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13</em>, 740‚Äì55. Springer.
</div><div id="ref-chowdhery2019visual" class="csl-entry" role="listitem">
Wang, LingFeng, e YaQing Zhan. 2019. <span>¬´A conceptual peer review model for <span>arXiv</span> and other preprint databases¬ª</span>. <em>Learn. Publ.</em> 32 (3): 213‚Äì19. <a href="https://doi.org/10.1002/leap.1229">https://doi.org/10.1002/leap.1229</a>.
</div><div id="ref-warden2018speech" class="csl-entry" role="listitem">
Warden, Pete. 2018. <span>¬´Speech commands: <span>A</span> dataset for limited-vocabulary speech recognition¬ª</span>. <em>arXiv preprint arXiv:1804.03209</em>.
</div></div><div id="fig-stoves" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-stoves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="images/jpg/ds_stoves.jpg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-stoves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;8.7: Diversi tipi di stufe. Fonte: Immagini di stufe di Dollar Street.
</figcaption>
</figure>
</div>
<p>In sostanza, un‚Äôanalisi comparativa approfondita trascende le metriche numeriche. √à una valutazione olistica intrecciata con applicazioni del mondo reale, costi e le intricate sottigliezze che ogni modello porta con s√©. Ecco perch√© avere parametri di riferimento e metriche standard ampiamente stabiliti e adottati dalla comunit√† diventa importante.</p>
</section>
</section>
<section id="conclusione" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="conclusione"><span class="header-section-number">8.8</span> Conclusione</h2>
<p>L‚Äôintelligenza artificiale efficiente √® fondamentale mentre ci spingiamo verso un‚Äôimplementazione pi√π ampia e diversificata del machine learning nel mondo reale. Questo capitolo ha fornito una panoramica, esplorando le varie metodologie e considerazioni alla base del raggiungimento di un‚Äôintelligenza artificiale efficiente, a partire dall‚Äôesigenza fondamentale, dalle somiglianze e dalle differenze tra i sistemi cloud, Edge e TinyML.</p>
<p>Abbiamo esaminato le architetture dei modelli efficienti e la loro utilit√† per l‚Äôottimizzazione. Le tecniche di compressione dei modelli come pruning, quantizzazione e distillazione della conoscenza esistono per aiutare a ridurre le richieste di calcolo e l‚Äôingombro della memoria senza influire in modo significativo sulla precisione. Hardware specializzati come TPU e acceleratori NN offrono chip ottimizzati per le operazioni di rete neurale e il flusso di dati. I numeri efficienti bilanciano precisione ed efficienza, consentendo ai modelli di ottenere prestazioni robuste utilizzando risorse minime. Esploreremo questi argomenti in modo approfondito e dettagliato nei capitoli successivi.</p>
<p>Insieme, questi formano un quadro olistico per un‚Äôintelligenza artificiale efficiente. Ma il viaggio non finisce qui. Il raggiungimento di un‚Äôintelligenza efficiente in modo ottimale richiede ricerca e innovazione continue. Man mano che i modelli diventano pi√π sofisticati, i set di dati crescono e le applicazioni si diversificano in domini specializzati, l‚Äôefficienza deve evolversi di pari passo. La misura dell‚Äôimpatto nel mondo reale richiede parametri di riferimento adatti e metriche standardizzate che vadano oltre le semplicistiche cifre dell‚Äôaccuratezza.</p>
<p>Inoltre, l‚Äôintelligenza artificiale efficiente si espande oltre l‚Äôottimizzazione tecnologica e comprende costi, impatto ambientale e considerazioni etiche per il bene della societ√† in senso pi√π ampio. Man mano che l‚Äôintelligenza artificiale permea i settori e la vita quotidiana, una prospettiva completa sull‚Äôefficienza sostiene il suo progresso sostenibile e responsabile. I capitoli successivi si baseranno su questi concetti fondamentali, fornendo approfondimenti concreti e norme pratiche per lo sviluppo e l‚Äôimplementazione di soluzioni di intelligenza artificiale efficienti.</p>
</section>
<section id="sec-efficient-ai-resource" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="sec-efficient-ai-resource"><span class="header-section-number">8.9</span> Risorse</h2>
<p>Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Lavoriamo continuamente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Slide
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale secondo il proprio ritmo. Incoraggiamo studenti e docenti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.</p>
<ul>
<li><p><a href="https://docs.google.com/presentation/d/1tvSiOfQ1lYPXsvHcFVs8R1lYZPei_Nb7/edit?usp=drive_link&amp;ouid=102419556060649178683&amp;rtpof=true&amp;sd=true">Deploying on Edge Devices: challenges and techniques.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1jdBnIxgNovG3b8frTl3DwqiIOw_K4jvp3kyv2GoKfYQ/edit?usp=drive_link&amp;resourcekey=0-PN8sYpltO1nP_xePynJn9w">Model Evaluation.</a></p></li>
<li><p><a href="https://docs.google.com/presentation/d/1OuhwH5feIwPivEU6pTDyR3QMs7AFstHLiF_LB8T5qYQ/edit?usp=drive_link&amp;resourcekey=0-DZxIuVBUbJawuFh0AO-Pvw">Continuous Evaluation Challenges for TinyML.</a></p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Video
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><em>Prossimamente.</em></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Esercizi
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.</p>
<ul>
<li><em>Prossimamente.</em></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Laboratori
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Oltre agli esercizi, offriamo una serie di laboratori pratici che consentono agli studenti di acquisire esperienza pratica con le tecnologie di intelligenza artificiale embedded. Questi laboratori forniscono una guida passo dopo passo, consentendo agli studenti di sviluppare le proprie competenze in un ambiente strutturato e di supporto. Siamo lieti di annunciare che presto saranno disponibili nuovi laboratori, che arricchiranno ulteriormente l‚Äôesperienza di apprendimento.</p>
<ul>
<li><em>Prossimamente.</em></li>
</ul>
</div>
</div>
</div>



</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiato!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiato!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
});
</script>
<script src="https://giscus.app/client.js" data-repo="harvard-edge/cs249r_book" data-repo-id="R_kgDOKQSOaw" data-category="General" data-category-id="DIC_kwDOKQSOa84CZ8Ry" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../contents/training/training.it.html" class="pagination-link" aria-label="Addestramento dell'IA">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Addestramento dell‚ÄôIA</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../contents/optimizations/optimizations.it.html" class="pagination-link" aria-label="Ottimizzazioni dei Modelli">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Ottimizzazioni dei Modelli</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Scritto, modificato e curato dal Prof.&nbsp;Vijay Janapa Reddi (Harvard University)</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/harvard-edge/cs249r_book/edit/dev/contents/efficient_ai/efficient_ai.it.qmd" class="toc-action"><i class="bi bi-github"></i>Modifica questa pagina</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/issues/new" class="toc-action"><i class="bi empty"></i>Segnala un problema</a></li><li><a href="https://github.com/harvard-edge/cs249r_book/blob/dev/contents/efficient_ai/efficient_ai.it.qmd" class="toc-action"><i class="bi empty"></i>Mostra il codice</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>Questo libro √® stato creato con <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>