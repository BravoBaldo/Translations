---
bibliography: introduction.bib
---

# Introduzione {#sec-introduction}

![_DALL·E 3 Prompt: Un'illustrazione 2D dettagliata, rettangolare e piatta che raffigura una roadmap dei capitoli di un libro sui sistemi di apprendimento automatico, su uno sfondo bianco nitido e pulito. L'immagine presenta una strada tortuosa che attraversa vari punti di riferimento simbolici. Ogni punto di riferimento rappresenta un argomento del capitolo: Introduzione, Sistemi di ML, Avvio al Deep Learning, Workflow dell'IA, Data Engineering, Framework di IA, Addestramento dell'IA, IA Efficiente, Ottimizzazioni dei Modelli, Accelerazione IA, Benchmarking dell'IA, Apprendimento On-Device, Operazioni di ML, Sicurezza e Privacy, IA Responsabile, IA Sostenibile, AI for Good, IA Robusta, IA Generativa. Lo stile è pulito, moderno e piatto, adatto a un libro tecnico, con ogni punto di riferimento chiaramente etichettato con il titolo del capitolo._](images/png/cover_introduction.png)

## Panoramica

All'inizio degli anni '90, [Mark Weiser](https://en.wikipedia.org/wiki/Mark_Weiser), un pioniere dell'informatica, ha introdotto il mondo a un concetto rivoluzionario che avrebbe cambiato per sempre il modo in cui interagiamo con la tecnologia. Tutto ciò è stato sintetizzato nell'articolo da lui scritto su "Il computer per il 21° secolo" (@fig-ubiqutous). Immaginava un futuro in cui l'informatica sarebbe stata perfettamente integrata nei nostri ambienti, diventando una parte invisibile e integrante della vita quotidiana. Questa visione, che lui chiamava "ubiquitous computing" [informatica ovunque], prometteva un mondo in cui la tecnologia ci avrebbe servito senza richiedere la nostra costante attenzione o interazione. Facciamo un salto in avanti fino a oggi, e ci troviamo sul punto di realizzare la visione di Weiser, grazie all'avvento e alla proliferazione dei sistemi di machine learning [apprendimento automatico].

![Ubiqutous computing.](images/png/21st_computer.png){#fig-ubiqutous width=50%}

Nella visione dell'ubiquitous computing [@weiser1991computer], l'integrazione dei processori negli oggetti di uso quotidiano è solo un aspetto di un più ampio cambiamento di paradigma. La vera essenza di questa visione risiede nella creazione di un ambiente intelligente in grado di anticipare le nostre esigenze e agire per nostro conto, migliorando le nostre esperienze senza richiedere comandi espliciti. Per raggiungere questo livello di intelligenza pervasiva, è fondamentale sviluppare e distribuire sistemi di machine learning che coprano l'intero ecosistema, dal cloud all'edge e persino ai più piccoli dispositivi IoT.

Distribuendo le capacità di apprendimento automatico lungo tutto il "continuum informatico", dal cloud all'edge fino ai sistemi embedded che ci circondano, possiamo sfruttare i punti di forza di ogni layer mitigandone al contempo i limiti. Il cloud, con le sue vaste risorse di elaborazione e capacità di archiviazione, è ideale per addestrare modelli complessi su grandi set di dati ed eseguire attività che richiedono molte risorse. I dispositivi edge, come gateway e smartphone, possono elaborare i dati localmente, consentendo tempi di risposta più rapidi, una migliore privacy e requisiti di larghezza di banda ridotti. Infine, i dispositivi IoT più piccoli, dotati di capacità di apprendimento automatico, possono prendere decisioni rapide in base ai dati dei sensori, consentendo sistemi altamente reattivi ed efficienti.

Questa intelligenza distribuita è particolarmente cruciale per le applicazioni che richiedono elaborazione in tempo reale, come veicoli autonomi, automazione industriale e assistenza sanitaria smart [intelligente]. Elaborando i dati al livello più appropriato del continuum informatico, possiamo garantire che le decisioni vengano prese in modo rapido e accurato, senza fare affidamento su una comunicazione costante con un server centrale.

La migrazione dell'intelligenza di apprendimento automatico nell'ecosistema consente inoltre esperienze più personalizzate e consapevoli del contesto. Imparando dal comportamento e dalle preferenze degli utenti all'edge, i dispositivi possono adattarsi alle esigenze individuali senza compromettere la privacy. Questa intelligenza localizzata può quindi essere aggregata e perfezionata nel cloud, creando un ciclo di feedback che migliora costantemente il sistema complessivo.

Tuttavia, l'implementazione di sistemi di apprendimento automatico nel continuum informatico presenta diverse sfide. Garantire l'interoperabilità e l'integrazione senza soluzione di continuità di questi sistemi richiede protocolli e interfacce standardizzati. È inoltre necessario affrontare i problemi di sicurezza e privacy, poiché la distribuzione dell'intelligenza su più livelli aumenta la superficie di attacco e il potenziale di violazioni dei dati.

Inoltre, le diverse capacità computazionali e i vincoli energetici dei dispositivi a diversi livelli del continuum informatico richiedono lo sviluppo di modelli di apprendimento automatico efficienti e adattabili. Tecniche come la compressione del modello, il "federated learning" [apprendimento federato] e il transfer learning [apprendimento tramite trasferimento] possono aiutare ad affrontare queste sfide, consentendo l'implementazione dell'intelligenza su un'ampia gamma di dispositivi.

Mentre ci avviciniamo alla realizzazione della visione di Weiser dell'ubiquitous computing, lo sviluppo e l'implementazione di sistemi di apprendimento automatico nell'intero ecosistema saranno fondamentali. Sfruttando i punti di forza di ogni layer [livello] del continuum informatico, possiamo creare un ambiente intelligente che si integra perfettamente con la nostra vita quotidiana, anticipando le nostre esigenze e migliorando le nostre esperienze in modi che un tempo erano inimmaginabili. Mentre continuiamo a spingere i confini di ciò che è possibile con l'apprendimento automatico distribuito, ci avviciniamo sempre di più a un futuro in cui la tecnologia diventa una parte invisibile ma integrante del nostro mondo. @fig-applications-of-ml illustra alcune applicazioni comuni dell'IA intorno a noi.

![Applicazioni comuni di Machine Learning. Fonte: [EDUCBA](https://www.educba.com/applications-of-machine-learning/)](images/png/mlapplications.png){#fig-applications-of-ml}

## Cosa c'è nel Libro

In questo libro, esploreremo le basi tecniche dei sistemi di apprendimento automatico onnipresenti, le sfide della creazione e distribuzione di questi sistemi nel continuum informatico e la vasta gamma di applicazioni che consentono. Un aspetto unico di questo libro è la sua funzione di canale verso opere accademiche fondamentali e documenti di ricerca accademica, mirati ad arricchire la comprensione del lettore e incoraggiare un'esplorazione più approfondita dell'argomento. Questo approccio cerca di colmare il divario tra materiali pedagogici e tendenze di ricerca all'avanguardia, offrendo una guida completa che è al passo con l'evoluzione del campo dell'apprendimento automatico applicato.

Per migliorare l'esperienza di apprendimento, abbiamo incluso una varietà di materiali supplementari. In tutto il libro, si troveranno slide che riassumono i concetti chiave, video che forniscono spiegazioni e dimostrazioni approfondite, esercizi che rafforzano la comprensione ed esercizi pratici che offrono esperienza pratica con gli strumenti e le tecniche discussi. Queste risorse aggiuntive sono progettate per soddisfare diversi stili di apprendimento e contribuire ad acquisire una comprensione più profonda e pratica dell'argomento.

Iniziamo con i fondamenti, introducendo concetti chiave nei sistemi e nell'apprendimento automatico e fornendo un avvio al deep learning. Poi guidiamo attraverso il flusso di lavoro dell'IA, dall'ingegneria dei dati alla selezione dei framework di IA giusti. La sezione sul training copre le diverse tecniche di training dell'IA efficienti, ottimizzazioni dei modelli e accelerazione dell'IA tramite hardware specializzato. Successivamente si affronta il deployment [distribuzione], con capitoli sul benchmarking dell'IA, l'apprendimento distribuito e le operazioni di ML. Argomenti avanzati come sicurezza, privacy, IA responsabile, IA sostenibile, IA robusta e IA generativa vengono quindi esplorati in profondità. Il libro si conclude evidenziando l'impatto positivo dell'IA e il suo potenziale per il bene. @fig-ml-lifecycle delinea il ciclo di vita di un progetto di apprendimento automatico.

![Ciclo di vita del progetto di apprendimento automatico. Fonte:[Medium](https://ihsanulpro.medium.com/complete-machine-learning-project-flowchart-explained-0f55e52b9381)](images/png/mlprojectlifecycle.png){#fig-ml-lifecycle}

## Come Orientarsi in Questo Libro

Per ottenere il massimo da questo libro, consigliamo un approccio di apprendimento strutturato che sfrutti le varie risorse fornite. Ogni capitolo include slide, video, esercizi e laboratori per soddisfare diversi stili di apprendimento e rafforzare la comprensione. Inoltre, un bot tutor AI (SocratiQ AI) è prontamente disponibile per guidare attraverso i contenuti e fornire assistenza personalizzata.

1. **I Fondamenti (Capitoli 1-3):** Si inizia costruendo una solida base con i primi capitoli, che forniscono un'introduzione all'IA embedded e trattano argomenti fondamentali come sistemi di IA e deep learning.

2. **Flusso di Lavoro (Capitoli 4-6):** Con questa base, si passa ai capitoli incentrati sugli aspetti pratici del processo di creazione del modello AI come flussi di lavoro, ingegneria dei dati e framework.

3. **Training (Capitoli 7-10):** Questi capitoli offrono approfondimenti su come addestrare efficacemente i modelli AI, comprese tecniche per efficienza, ottimizzazioni e accelerazione.

4. **Deployment (Capitoli 11-13):** Si esamina come distribuire l'IA sui dispositivi e monitorarne l'operatività tramite metodi come benchmarking, on-device learning e MLOps.

5. **Argomenti Avanzati (Capitoli 14-18):** Si esaminano criticamente argomenti come sicurezza, privacy, etica, sostenibilità, robustezza e IA generativa.

6. **Impatto Sociale (Capitolo 19):** Esplora le applicazioni positive e il potenziale dell'IA per il bene della società.

7. **Conclusione (Capitolo 20):** Riflessioni sui principali risultati e sulle direzioni future dei sistemi di IA.

Sebbene il libro sia progettato per un apprendimento progressivo, incoraggiamo un approccio di apprendimento interconnesso che consente di navigare tra i capitoli in base ai propri interessi e alle proprie esigenze. In tutto il libro si trovano casi di studio ed esercizi pratici che aiuteranno a mettere in relazione la teoria con le applicazioni del mondo reale. Consigliamo inoltre di partecipare a forum e gruppi per partecipare a [discussioni](https://github.com/harvard-edge/cs249r_book/discussions), discutere concetti e condividere approfondimenti con altri studenti. Rivedere regolarmente i capitoli può aiutare a rafforzare l'apprendimento e offrire nuove prospettive sui concetti trattati. Adottando questo approccio strutturato ma flessibile e interagendo attivamente con i contenuti e la community, si farà un'esperienza di apprendimento appagante e arricchente che massimizza la comprensione.

## Suddivisione dei Capitoli

Ecco uno sguardo più da vicino a cosa tratta ogni capitolo. Abbiamo strutturato il libro in sei sezioni principali: Nozioni Fondamentali, Flusso di lavoro, Training, Deployment, Argomenti avanzati e Impatto. Queste sezioni riflettono da vicino i componenti principali di una tipica pipeline di machine learning, dalla comprensione dei concetti di base al la deploy e alla manutenzione dei sistemi di intelligenza artificiale in applicazioni del mondo reale. Organizzando il contenuto in questo modo, puntiamo a fornire una progressione logica che rispecchi il processo effettivo di sviluppo e implementazione dei sistemi di intelligenza artificiale.

### Nozioni Fondamentali

Nella sezione Nozioni Fondamentali, poniamo le basi per comprendere l'intelligenza artificiale. Questo è ben lungi dall'essere un'immersione profonda negli algoritmi, ma puntiamo a introdurre concetti chiave, fornire una panoramica dei sistemi di apprendimento automatico e approfondire i principi e gli algoritmi di deep learning che alimentano le applicazioni di IA nei loro sistemi associati. Questa sezione fornisce le conoscenze essenziali necessarie per comprendere i capitoli successivi.

1. **[Introduzione:](../introduction/introduction.qmd)** Questo capitolo prepara il terreno, fornendo una panoramica dell'intelligenza artificiale e gettando le basi per i capitoli successivi.
2. **[Sistemi di ML:](../ml_systems/ml_systems.qmd)** Introduciamo le basi dei sistemi di machine learning [apprendimento automatico], le piattaforme in cui gli algoritmi di intelligenza artificiale sono ampiamente applicati.
3. **[Avvio al Deep Learning:](../dl_primer/dl_primer.qmd)** Questo capitolo offre una breve introduzione agli algoritmi e ai principi alla base delle applicazioni di IA nei sistemi di apprendimento automatico.

### Workflow

La sezione Workflow [Flusso di lavoro] guida attraverso gli aspetti pratici della creazione di modelli AI. Analizziamo il flusso di lavoro AI, discutiamo le "best practice" di data engineering e passiamo in rassegna i framework AI più diffusi. Alla fine di questa sezione, si avrà una chiara comprensione dei passaggi coinvolti nello sviluppo di applicazioni AI competenti e degli strumenti disponibili per semplificare il processo.

4. **[Workflow IA:](../workflow/workflow.qmd)** Questo capitolo analizza il flusso di lavoro di apprendimento automatico, offrendo approfondimenti sui passaggi che portano ad applicazioni AI competenti.
5. **[Ingegneria dei Dati:](../data_engineering/data_engineering.qmd)** Ci concentriamo sull'importanza dei dati nei sistemi di IA, discutendo su come gestire e organizzare efficacemente i dati.
6. **[Framework di IA:](../frameworks/frameworks.qmd)** Questo capitolo esamina diversi framework per lo sviluppo di modelli di apprendimento automatico, guidando nella scelta di quello più adatto ai propri progetti.

### Training

Nella sezione Training, esploriamo tecniche per il training efficiente e affidabile di modelli di IA. Trattiamo strategie per raggiungere efficienza, ottimizzazioni dei modelli e il ruolo dell'hardware specializzato nell'accelerazione IA. Questa sezione fornisce le conoscenze necessarie per sviluppare modelli ad alte prestazioni che possono essere integrati perfettamente nei sistemi di IA.

7. **[Training IA:](../training/training.qmd)** Questo capitolo approfondisce il training [addestramento] dei modelli, esplorando tecniche per sviluppare modelli efficienti e affidabili.
8. **[IA Efficiente:](../efficient_ai/efficient_ai.qmd)** Qui, discutiamo strategie per raggiungere l'efficienza nelle applicazioni di IA, dall'ottimizzazione delle risorse computazionali al miglioramento delle prestazioni.
9. **[Ottimizzazioni dei Modelli:](../optimizations/optimizations.qmd)** Esploriamo vari percorsi per ottimizzare i modelli di IA per un'integrazione senza soluzione di continuità nei sistemi di IA.
10. **[Accelerazione dell'IA:](../hw_acceleration/hw_acceleration.qmd)** Discutiamo il ruolo dell'hardware specializzato nel migliorare le prestazioni dei sistemi di IA.

### Deployment

La sezione Deployment [distribuzione] si concentra sulle sfide e sulle soluzioni per l'implementazione di modelli di IA. Discutiamo metodi di benchmarking per valutare le prestazioni del sistema AI, tecniche per l'apprendimento "on-device " per migliorare l'efficienza e la privacy e i processi coinvolti nelle operazioni di ML. Questa sezione fornisce le competenze per implementare e gestire in modo efficace le funzionalità di IA nei sistemi di intelligenza artificiale.

11. **[Benchmark dell'IA:](../benchmarking/benchmarking.qmd)** Questo capitolo si concentra su come valutare i sistemi di IA tramite metodi di benchmarking sistematici.
12. **[Apprendimento On-Device:](../ondevice_learning/ondevice_learning.qmd)** Esploriamo tecniche per l'apprendimento localizzato, che migliora sia l'efficienza che la privacy.
13. **[Operazioni di ML:](../ops/ops.qmd)** Questo capitolo esamina i processi coinvolti nell'integrazione, nel monitoraggio e nella manutenzione senza soluzione di continuità delle funzionalità di IA.

### Argomenti Avanzati

Nella sezione Argomenti avanzati, studieremo le problematiche critiche che circondano l'IA. Affrontiamo le preoccupazioni relative a privacy e sicurezza, esploriamo i principi etici dell'intelligenza artificiale responsabile, discutiamo strategie per uno sviluppo sostenibile dell'intelligenza artificiale, esaminiamo tecniche per la creazione di modelli di intelligenza artificiale solidi e introduciamo l'entusiasmante campo dell'intelligenza artificiale generativa. Questa sezione amplia la comprensione del complesso panorama dell'IA e prepara ad affrontarne le sfide.

14. **[Sicurezza e Privacy:](../privacy_security/privacy_security.qmd)** Man mano che l'intelligenza artificiale diventa sempre più onnipresente, questo capitolo affronta gli aspetti cruciali della privacy e della sicurezza nei sistemi di IA.
15. **[IA Responsabile:](../responsible_ai/responsible_ai.qmd)** Discutiamo i principi etici che guidano l'uso responsabile dell'intelligenza artificiale, concentrandoci sulla correttezza, responsabilità e trasparenza.
16. **[IA Sostenibile:](../sustainable_ai/sustainable_ai.qmd)** Questo capitolo esplora pratiche e strategie per un'intelligenza artificiale sostenibile, garantendo fattibilità a lungo termine e un impatto ambientale ridotto.
17. **[IA Robusta:](../robust_ai/robust_ai.qmd)** Parliamo di tecniche per sviluppare modelli di IA affidabili e robusti che possano funzionare in modo coerente in varie condizioni.
18. **[IA Generativa:](../generative_ai/generative_ai.qmd)** Questo capitolo esplora gli algoritmi e le tecniche alla base dell'IA generativa, aprendo strade all'innovazione e alla creatività.

### Impatto Sociale

La sezione Impatto Sociale evidenzia il potenziale trasformativo dell'IA in vari domini. Presentiamo applicazioni reali di TinyML in sanità, agricoltura, conservazione e altre aree in cui l'IA sta facendo una positiva differenza. Questa sezione invoglia a sfruttare la potenza dell'AI per il bene della società e a contribuire allo sviluppo di soluzioni di impatto.

19. **[AI for Good:](../ai_for_good/ai_for_good.qmd)** Evidenziamo applicazioni positive di TinyML in aree come sanità, agricoltura e la conservazione.

### Chiusura

Nella sezione Chiusura, riflettiamo sugli insegnamenti chiave del libro e guardiamo al futuro dell'IA. Sintetizziamo i concetti trattati, discutiamo le tendenze emergenti e forniamo indicazioni su come proseguire nel percorso di apprendimento in questo campo in rapida evoluzione. Questa sezione lascia con una comprensione completa dell'IA e l'entusiasmo di applicare le conoscenze in modi innovativi.

20. **[Conclusione:](../conclusion/conclusion.qmd)** Il libro si conclude con una riflessione sugli apprendimenti chiave e sulle direzioni future nel campo dell'IA.

## Contributi dei Lettori

L'apprendimento nel mondo frenetico dell'intelligenza artificiale è un viaggio collaborativo. Ci siamo prefissati di coltivare una vivace comunità di studenti, innovatori e collaboratori. Esplorando i concetti e impegnandosi con gli esercizi, incoraggiamo a condividere le intuizioni ed esperienze personali. Che si tratti di un approccio innovativo, di un'applicazione interessante o di una domanda stimolante, i contributi dei singoli possono arricchire l'ecosistema di apprendimento. Partecipare alle discussioni, offrire e cercare indicazioni e collaborare a progetti per promuovere una cultura di crescita e apprendimento reciproci. Condividendo la conoscenza, si svolge un ruolo importante nel promuovere una comunità connessa, informata e potenziata a livello globale.
