---
bibliography: benchmarking.bib
---

# Benchmarking dell'IA {#sec-benchmarking_ai}

::: {.content-visible when-format="html"}
Risorse: [Slide](#sec-benchmarking-ai-resource), [Video](#sec-benchmarking-ai-resource), [Esercizi](#sec-benchmarking-ai-resource)
:::

![_DALL·E 3 Prompt: Foto di un podio su uno sfondo a tema tecnologico. Su ogni piattaforma del podio ci sono chip AI con design intricati. Il chip in alto ha una medaglia d'oro appesa, il secondo una medaglia d'argento e il terzo una medaglia di bronzo. Sullo sfondo sono ben visibili striscioni con la scritta "AI Olympics"._](images/png/cover_ai_benchmarking.png)

Il benchmarking è fondamentale per lo sviluppo e la distribuzione di sistemi di machine learning, in particolare applicazioni TinyML. I benchmark consentono agli sviluppatori di misurare e confrontare le prestazioni di diverse architetture di modelli, procedure di training e strategie di distribuzione. Ciò fornisce informazioni chiave su quali approcci funzionano meglio per il problema in questione e sui vincoli dell'ambiente di distribuzione.

Questo capitolo fornirà una panoramica dei benchmark ML più diffusi, le best practice e come utilizzarli per migliorare lo sviluppo del modello e le prestazioni del sistema. Fornire agli sviluppatori gli strumenti e le conoscenze adeguati per effettuare test di benchmark e ottimizzare in modo efficace i propri sistemi, in particolare quelli TinyML.

::: {.callout-tip}

## Obiettivi dell'Apprendimento

* Comprendere lo scopo e gli obiettivi del benchmarking dei sistemi di intelligenza artificiale, tra cui valutazione delle prestazioni, valutazione delle risorse, validazione e altro ancora.

* Scoprire i principali parametri di riferimento, le metriche e le tendenze dei modelli, tra cui accuratezza, equità, complessità, prestazioni ed efficienza energetica.

* Acquisire familiarità con i componenti chiave di un benchmark di intelligenza artificiale, tra cui set di dati, attività, metriche, linee di base, regole di riproducibilità e altro ancora.

* Comprendere la distinzione tra training e inferenza e come ogni fase giustifichi il benchmarking specializzato dei sistemi ML.

* Scoprire i concetti di benchmarking del sistema come produttività, latenza, potenza ed efficienza computazionale.

* Apprezzare l'evoluzione del benchmarking del modello dall'accuratezza a metriche più olistiche come correttezza, robustezza e applicabilità nel mondo reale.

* Riconoscere il ruolo crescente del benchmarking dei dati nella valutazione di problemi come bias, rumore, equilibrio e diversità.

* Comprendere i limiti della valutazione di modelli, dati e sistemi in isolamento e l'esigenza emergente di benchmarking integrato.

:::

## Panoramica

Il benchmarking fornisce le misure essenziali necessarie per guidare il progresso dell'apprendimento automatico e comprendere veramente le prestazioni del sistema. Come ha affermato il fisico Lord Kelvin, "Misurare è conoscere". I benchmark ci consentono di conoscere quantitativamente le capacità di diversi modelli, software e hardware. Consentono agli sviluppatori di ML di misurare il tempo di inferenza, l'utilizzo della memoria, il consumo energetico e altre metriche che caratterizzano un sistema. Inoltre, i benchmark creano processi standardizzati per la misurazione, consentendo confronti equi tra diverse soluzioni.

Quando i benchmark vengono mantenuti nel tempo, diventano fondamentali per catturare i progressi attraverso generazioni di algoritmi, set di dati e hardware. I modelli e le tecniche che stabiliscono nuovi record sui benchmark di ML da un anno all'altro dimostrano miglioramenti tangibili in ciò che è possibile per l'apprendimento automatico "on-device". Utilizzando i benchmark per misurare, i professionisti di ML possono conoscere le capacità reali dei loro sistemi e avere la certezza che ogni passaggio rifletta un progresso autentico verso lo stato dell'arte.

Il benchmarking ha diversi obiettivi e scopi importanti che guidano la sua implementazione per i sistemi di apprendimento automatico.

* **Valutazione delle prestazioni.** Ciò comporta la valutazione di parametri chiave come la velocità, l'accuratezza e l'efficienza di un dato modello. Ad esempio, in un contesto TinyML, è fondamentale confrontare la rapidità con cui un assistente vocale può riconoscere i comandi, poiché ciò valuta le prestazioni in tempo reale.

* **Valutazione della potenza.** Valutare la potenza assorbita da un carico di lavoro insieme alle sue prestazioni equivale alla sua efficienza energetica. Poiché l'impatto ambientale dell'elaborazione ML continua a crescere, il benchmarking dell'energia può consentirci di ottimizzare meglio i sistemi per la sostenibilità.

* **Valutazione delle risorse.** Ciò significa valutare l'impatto del modello sulle risorse critiche del sistema, tra cui durata della batteria, utilizzo della memoria e sovraccarico computazionale. Un esempio rilevante è il confronto del consumo della batteria di due diversi algoritmi di riconoscimento delle immagini in esecuzione su un dispositivo indossabile.

* **Validazione e verifica.** Il benchmarking aiuta a garantire che il sistema funzioni correttamente e soddisfi i requisiti specificati. Un modo è quello di controllare l'accuratezza di un algoritmo, come un cardiofrequenzimetro su uno smartwatch, rispetto alle letture di apparecchiature di livello medico come forma di validazione clinica.

* **Analisi competitiva.** Ciò consente di confrontare le soluzioni con le offerte concorrenti sul mercato. Ad esempio, il benchmarking di un modello personalizzato di rilevamento di oggetti rispetto ai benchmark TinyML comuni come MobileNet e Tiny-YOLO.

* **Credibilità.** I benchmark accurati sostengono la credibilità delle soluzioni AI e delle organizzazioni che le sviluppano. Dimostrano un impegno verso trasparenza, onestà e qualità, essenziali per creare fiducia con utenti e stakeholder.

* **Regolamentazione e Standardizzazione**. Man mano che il settore dell'AI continua a crescere, cresce anche la necessità di regolamentazione e standardizzazione per garantire che le soluzioni AI siano sicure, etiche ed efficaci. I benchmark accurati e affidabili sono essenziali per questo quadro normativo, poiché forniscono i dati e le prove necessari per valutare la conformità con gli standard del settore e i requisiti legali.

Questo capitolo tratterà i 3 tipi di benchmark AI, le metriche standard, gli strumenti e le tecniche che i progettisti utilizzano per ottimizzare i loro sistemi e le sfide e le tendenze nel benchmarking.

## Contesto Storico

### Benchmark delle Prestazioni

L'evoluzione dei benchmark nell'informatica illustra vividamente l'incessante ricerca dell'eccellenza e dell'innovazione da parte del settore. Nei primi giorni dell'informatica, negli anni '60 e '70, i benchmark erano rudimentali e progettati per i mainframe. Ad esempio, il [benchmark Whetstone](https://en.wikipedia.org/wiki/Whetstone_(benchmark)), che prende il nome dal compilatore Whetstone ALGOL, è stato uno dei primi test standardizzati per misurare le prestazioni aritmetiche in virgola mobile di una CPU. Questi benchmark pionieristici hanno spinto i produttori a perfezionare le loro architetture e algoritmi per ottenere punteggi di benchmark migliori.

Gli anni '80 hanno segnato un cambiamento significativo con l'ascesa dei personal computer. Mentre aziende come IBM, Apple e Commodore gareggiavano per quote di mercato, i benchmark sono diventati strumenti essenziali per consentire una concorrenza leale. I [benchmark CPU SPEC](https://www.spec.org/cpu/), introdotti dalla [System Performance Evaluation Cooperative (SPEC)](https://www.spec.org/), hanno stabilito test standardizzati che consentono confronti oggettivi tra diverse macchine. Questa standardizzazione ha creato un ambiente competitivo, spingendo i produttori di chip e i creatori di sistemi a migliorare continuamente le loro offerte hardware e software.

Gli anni '90 hanno portato l'era delle applicazioni e dei videogiochi "graphics-intensive". La necessità di benchmark per valutare le prestazioni delle schede grafiche ha portato alla creazione di [3DMark](https://www.3dmark.com/) da parte di Futuremark. Mentre i giocatori e i professionisti cercavano schede grafiche ad alte prestazioni, aziende come NVIDIA e AMD sono state spinte a una rapida innovazione, portando a importanti progressi nella tecnologia GPU come gli shader programmabili.

Gli anni 2000 hanno visto un'impennata di telefoni cellulari e dispositivi portatili come i tablet. Con la portabilità è arrivata la sfida di bilanciare prestazioni e consumo energetico. Benchmark come [MobileMark](https://bapco.com/products/mobilemark-2014/) di BAPCo hanno valutato velocità e durata della batteria. Ciò ha spinto le aziende a sviluppare System-on-Chip (SOC) più efficienti dal punto di vista energetico, portando all'emergere di architetture come ARM che hanno dato priorità all'efficienza energetica.

L'attenzione dell'ultimo decennio si è spostata verso il cloud computing, i big data e l'intelligenza artificiale. I provider di servizi cloud come Amazon Web Services e Google Cloud competono su prestazioni, scalabilità e convenienza. I benchmark specifici del cloud come [CloudSuite](http://cloudsuite.ch/) sono diventati essenziali, spingendo i provider a ottimizzare la propria infrastruttura per servizi migliori.

### Benchmark Energetici

Il consumo energetico e le preoccupazioni ambientali hanno acquisito importanza negli ultimi anni, rendendo il benchmarking energetico sempre più importante nel settore. Questo cambiamento è iniziato a metà degli anni 2000, quando i processori e i sistemi hanno iniziato a raggiungere i limiti di raffreddamento e la scalabilità è diventata un aspetto cruciale della costruzione di sistemi su larga scala grazie ai progressi di Internet. Da allora, le considerazioni energetiche si sono espanse fino a comprendere tutte le aree dell'informatica, dai dispositivi personali ai data center su larga scala.

Il benchmarking energetico mira a misurare l'efficienza energetica dei sistemi informatici, valutando le prestazioni in relazione al consumo energetico. Ciò è fondamentale per diversi motivi:

* **Impatto ambientale:** Con la crescente impronta di carbonio del settore tecnologico, c'è un'urgente necessità di ridurre il consumo energetico.
* **Costi operativi:** Le spese energetiche costituiscono una parte significativa dei costi operativi del data center.
* **Longevità del dispositivo:** Per i dispositivi mobili, l'efficienza energetica ha un impatto diretto sulla durata della batteria e sull'esperienza utente.

In questo ambito sono emersi diversi benchmark chiave:

* **SPEC Power:** Introdotto nel 2007, [SPEC Power](https://www.spec.org/power/) è stato uno dei primi benchmark standard del settore per la valutazione delle caratteristiche di potenza e prestazioni dei server.
* **Green500:** L'elenco [Green500](https://top500.org/lists/green500/) classifica i supercomputer in base all'efficienza energetica, integrando l'elenco TOP500 incentrato sulle prestazioni.
* **Energy Star:** Pur non essendo un benchmark in sé, il programma di certificazione [ENERGY STAR for Computers](https://www.energystar.gov/products/computers) ha spinto i produttori a migliorare l'efficienza energetica dell'elettronica di consumo.

Il benchmarking energetico affronta sfide uniche, come la contabilizzazione di diversi carichi di lavoro e configurazioni di sistema e la misura accurata del consumo energetico su una gamma di hardware che varia da microWatt a megawatt nel consumo energetico. Man mano che l'IA e l'edge computing continuano a crescere, è probabile che il benchmarking energetico diventi ancora più critico, guidando lo sviluppo di ottimizzazioni hardware e software AI specializzate ed efficienti dal punto di vista energetico.

### Benchmark Personalizzati

Oltre ai benchmark standard del settore, ci sono benchmark personalizzati specificamente progettati per soddisfare i requisiti unici di una particolare applicazione o attività. Sono personalizzati in base alle esigenze specifiche dell'utente o dello sviluppatore, assicurando che le metriche delle prestazioni siano direttamente pertinenti all'uso previsto del modello o del sistema di intelligenza artificiale. I benchmark personalizzati possono essere creati da singole organizzazioni, ricercatori o sviluppatori e sono spesso utilizzati insieme ai benchmark standard del settore per fornire una valutazione completa delle prestazioni dell'intelligenza artificiale.

Ad esempio, un ospedale potrebbe sviluppare un benchmark per valutare un modello di intelligenza artificiale per prevedere la riammissione dei pazienti. Questo benchmark incorporerebbe metriche pertinenti alla popolazione di pazienti dell'ospedale, come dati demografici, anamnesi e fattori sociali. Allo stesso modo, il benchmark di rilevamento delle frodi di un istituto finanziario potrebbe concentrarsi sull'identificazione accurata delle transazioni fraudolente riducendo al minimo i falsi positivi. Nel settore automobilistico, un benchmark di veicoli autonomi potrebbe dare priorità alle prestazioni in diverse condizioni, alla risposta agli ostacoli e alla sicurezza. I rivenditori potrebbero confrontare i sistemi di raccomandazione utilizzando il tasso di clic, il tasso di conversione e la soddisfazione del cliente. Le aziende manifatturiere potrebbero confrontare i sistemi di controllo qualità in base all'identificazione dei difetti, all'efficienza e alla riduzione degli sprechi. In ogni settore, i benchmark personalizzati forniscono alle organizzazioni criteri di valutazione su misura per le loro esigenze e il loro contesto unici. Ciò consente una valutazione più significativa di quanto i sistemi di intelligenza artificiale soddisfino i requisiti.

Il vantaggio dei benchmark personalizzati risiede nella loro flessibilità e pertinenza. Possono essere progettati per testare aspetti specifici delle prestazioni critici per il successo della soluzione di intelligenza artificiale nella sua applicazione prevista. Ciò consente una valutazione più mirata e accurata delle capacità del modello o del sistema di intelligenza artificiale. I benchmark personalizzati forniscono anche informazioni preziose sulle prestazioni delle soluzioni di intelligenza artificiale in scenari reali, il che può essere cruciale per identificare potenziali problemi e aree di miglioramento.

Nell'intelligenza artificiale, i benchmark svolgono un ruolo cruciale nel guidare il progresso e l'innovazione. Sebbene i benchmark siano stati a lungo utilizzati nell'informatica, la loro applicazione all'apprendimento automatico è relativamente recente. I benchmark incentrati sull'intelligenza artificiale forniscono metriche standardizzate per valutare e confrontare le prestazioni di diversi algoritmi, architetture di modelli e piattaforme hardware.

### Consenso della Comunità

Una prerogativa fondamentale affinché un benchmark abbia un impatto è che deve riflettere le priorità e i valori condivisi della più ampia comunità di ricerca. I benchmark progettati in modo isolato rischiano di non ottenere accettazione se trascurano metriche chiave considerate importanti dai gruppi leader. Attraverso uno sviluppo collaborativo con la partecipazione aperta di laboratori accademici, aziende e altri stakeholder, i benchmark possono incorporare un contributo collettivo su capacità critiche che vale la pena misurare. Ciò aiuta a garantire che i benchmark valutino aspetti che la comunità concorda siano essenziali per far progredire il campo. Il processo di raggiungimento dell'allineamento su attività e metriche supporta di per sé la convergenza su ciò che conta di più.

Inoltre, i benchmark pubblicati con ampia co-paternità da istituzioni rispettate hanno autorità e validità che convincono la comunità ad adottarli come standard affidabili. I benchmark percepiti come distorti da particolari interessi aziendali o istituzionali generano scetticismo. Anche il coinvolgimento continuo della comunità attraverso workshop e sfide è fondamentale dopo la versione iniziale, ed è ciò che, ad esempio, ha portato al successo di ImageNet. Col progredire della ricerca, la partecipazione collettiva consente un continuo perfezionamento ed espansione dei benchmark nel tempo.

Infine, rilasciare benchmark sviluppati dalla comunità con accesso aperto ne promuove l'adozione e l'uso coerente. Fornendo codice open source, documentazione, modelli e infrastrutture, riduciamo le barriere all'ingresso, consentendo ai gruppi di confrontare le soluzioni su un piano di parità con le implementazioni standardizzate. Questa coerenza è essenziale per confronti equi. Senza coordinamento, laboratori e aziende potrebbero implementare i benchmark in modo diverso, il che può compromettere la riproducibilità e la comparabilità dei risultati.

Il consenso della comunità conferisce ai benchmark una rilevanza duratura, mentre la frammentazione confonde. Attraverso lo sviluppo collaborativo e un funzionamento trasparente, i benchmark possono diventare standard autorevoli per monitorare i progressi. Molti dei benchmark di cui parliamo in questo capitolo sono stati sviluppati e creati dalla comunità, per la comunità, ed è questo che alla fine ha portato al loro successo.

## Benchmark AI: Sistema, Modello e Dati

La necessità di un benchmarking completo diventa fondamentale man mano che i sistemi AI diventano più complessi e onnipresenti. In questo contesto, i benchmark sono spesso classificati in tre categorie principali: Hardware, Modello e Dati. Analizziamo perché ognuno di questi gruppi è essenziale e il significato della valutazione dell'AI da queste tre dimensioni distinte:

### Benchmark di Sistema

I calcoli AI, in particolare quelli nel deep learning, richiedono molte risorse. L'hardware su cui vengono eseguiti questi calcoli svolge un ruolo importante nel determinare la velocità, l'efficienza e la scalabilità delle soluzioni AI. Di conseguenza, i benchmark hardware aiutano a valutare le prestazioni di CPU, GPU, TPU e altri acceleratori nelle attività AI. Comprendendone le prestazioni, gli sviluppatori possono scegliere quali piattaforme hardware si adattano meglio a specifiche applicazioni AI. Inoltre, i produttori di hardware utilizzano questi benchmark per identificare aree di miglioramento, guidando l'innovazione nei progetti di chip specifici per AI.

### Benchmark del Modello

L'architettura, le dimensioni e la complessità dei modelli AI variano notevolmente. Modelli diversi hanno diverse esigenze di calcolo e offrono diversi livelli di accuratezza ed efficienza. I benchmark dei modelli aiutano a valutare le prestazioni di varie architetture AI su attività standardizzate. Forniscono informazioni sulla velocità, l'accuratezza e le richieste di risorse di diversi modelli. Eseguendo il benchmarking dei modelli, i ricercatori possono identificare le architetture più performanti per attività specifiche, guidando la comunità AI verso soluzioni più efficienti ed efficaci. Inoltre, questi benchmark aiutano a monitorare i progressi della ricerca sull'intelligenza artificiale, mostrando i progressi nella progettazione e nell'ottimizzazione dei modelli.

### Benchmark dei Dati

Nell'apprendimento automatico, i dati sono fondamentali perché la qualità, la scala e la diversità dei set di dati influiscono direttamente sull'efficacia e sulla generalizzazione del modello. I benchmark dei dati si concentrano sui set di dati utilizzati nel training e nella valutazione. Forniscono set di dati standardizzati che la comunità può utilizzare per addestrare e testare i modelli, garantendo parità di condizioni per i confronti. Inoltre, questi parametri di riferimento evidenziano le sfide relative alla qualità dei dati, alla diversità e alla rappresentazione, spingendo la comunità ad affrontare i "bias" [pregiudizi] e i "gap" [lacune] nei dati di addestramento. Comprendendo i benchmark dei dati, i ricercatori possono anche valutare come i modelli potrebbero comportarsi in scenari reali, garantendo robustezza e affidabilità.

Nelle restanti sezioni, discuteremo ciascuno di questi tipi di benchmark. L'attenzione sarà rivolta a un'esplorazione approfondita dei benchmark di sistema, poiché sono fondamentali per comprendere e migliorare le prestazioni del sistema di apprendimento automatico. Parleremo brevemente dei benchmark dei modelli e dei dati per una prospettiva completa, ma l'enfasi e la maggior parte del contenuto saranno dedicati ai benchmark di sistema.

## Benchmarking di Sistema

### Granularità

Il benchmarking del sistema di apprendimento automatico fornisce un approccio strutturato e sistematico per valutare le prestazioni di un sistema in diverse dimensioni. Data la complessità dei sistemi ML, possiamo analizzare le loro prestazioni attraverso diversi livelli di granularità e ottenere una visione completa dell'efficienza del sistema, identificare potenziali colli di bottiglia e individuare le aree di miglioramento. A tal fine, nel corso degli anni si sono evoluti vari tipi di benchmark che continuano a persistere.

@fig-granularity illustra i diversi livelli di granularità di un sistema ML. A livello di applicazione, i benchmark end-to-end valutano le prestazioni complessive del sistema, considerando fattori come la pre-elaborazione dei dati, l'addestramento del modello e l'inferenza. Mentre a livello di modello, i benchmark si concentrano sulla valutazione dell'efficienza e dell'accuratezza di modelli specifici. Ciò include la valutazione di quanto bene i modelli si generalizzano a nuovi dati e della loro efficienza computazionale durante l'addestramento e l'inferenza. Inoltre, il benchmarking può estendersi all'infrastruttura hardware e software, esaminando le prestazioni di singoli componenti come GPU o TPU.


![Granularità del sistema ML.](images/png/end2end.png){#fig-granularity}

#### Micro Benchmark

I micro-benchmark sono specializzati e valutano componenti distinti o operazioni specifiche all'interno di un processo di apprendimento automatico più ampio. Questi benchmark si concentrano su singole attività, offrendo approfondimenti sulle richieste computazionali di un particolare layer di rete neurale, l'efficienza di un'unica tecnica di ottimizzazione o la produttività di una specifica funzione di attivazione. Ad esempio, i professionisti potrebbero utilizzare i micro-benchmark per misurare il tempo di calcolo richiesto da un layer convoluzionale in un modello di deep learning o per valutare la velocità di preelaborazione che alimenta i dati nel modello. Tali valutazioni granulari sono fondamentali per la messa a punto e l'ottimizzazione di aspetti discreti dei modelli, assicurando che ogni componente funzioni al massimo del suo potenziale.

Questi tipi di microbenchmark includono lo zoom su operazioni o componenti molto specifiche della pipeline AI, come le seguenti:

* **Operazioni Tensoriali:** Librerie come [cuDNN](https://developer.nvidia.com/cudnn) (di NVIDIA) spesso hanno benchmark per misurare le prestazioni di singole operazioni tensoriali, come convoluzioni o moltiplicazioni di matrici, che sono fondamentali per i calcoli del deep learning.

* **Funzioni di Attivazione:** Benchmark che misurano la velocità e l'efficienza di varie funzioni di attivazione come ReLU, Sigmoid o Tanh in isolamento.

* **Benchmark di Layer:** Valutazioni dell'efficienza computazionale di distinti layer di rete neurale, come blocchi LSTM o Transformer, quando si opera su dimensioni di input standardizzate.

Esempio: [DeepBench](https://github.com/baidu-research/DeepBench), introdotto da Baidu, è un buon benchmark che valuta le operazioni fondamentali di deep learning, come quelle menzionate sopra. DeepBench valuta le prestazioni delle operazioni di base nei modelli di deep learning, fornendo informazioni su come diverse piattaforme hardware gestiscono l'addestramento e l'inferenza delle reti neurali.

:::{#exr-cuda .callout-caution collapse="true"}

### Benchmarking di Sistema - Operazioni Tensoriali

Ci si è mai chiesto come mai i filtri immagine diventano così veloci? Librerie speciali come cuDNN potenziano quei calcoli su determinati hardware. In questo Colab, useremo cuDNN con PyTorch per velocizzare il filtraggio delle immagini. Lo si consideri un piccolo benchmark, che mostra come il software giusto può sbloccare la potenza della GPU!

[![](https://colab.research.google.com/assets/colab-badge.png)](https://colab.research.google.com/github/RyanHartzell/cudnn-image-filtering/blob/master/notebooks/CuDNN%20Image%20Filtering%20Tutorial%20Using%20PyTorch.ipynb#scrollTo=1sWeXdYsATrr)

:::

#### Macro Benchmark

I macro benchmark forniscono una visione olistica, valutando le prestazioni end-to-end di interi modelli di apprendimento automatico o sistemi di ML completi. Invece di concentrarsi sulle singole operazioni, i macro benchmark valutano l'efficacia collettiva dei modelli in scenari o attività del mondo reale. Ad esempio, un macro benchmark potrebbe valutare le prestazioni complete di un modello di apprendimento profondo che esegue la classificazione delle immagini su un set di dati come [ImageNet](https://www.image-net.org/). Ciò include la misura dell'accuratezza, della velocità di calcolo e del consumo di risorse. Allo stesso modo, si potrebbero misurare il tempo e le risorse cumulativi necessari per addestrare un modello di elaborazione del linguaggio naturale su corpora di testo estesi o valutare le prestazioni di un intero sistema di raccomandazione, dall'inserimento dei dati agli output finali specifici dell'utente.

Esempi: Questi benchmark valutano il modello di intelligenza artificiale:

* [MLPerf Inference](https://github.com/mlcommons/inference) [@reddi2020mlperf]: Un set di benchmark standard per misurare le prestazioni di software e hardware di apprendimento automatico. MLPerf ha una suite di benchmark dedicati per scale specifiche, come [MLPerf Mobile](https://github.com/mlcommons/mobile_app_open) per dispositivi di classe mobile e [MLPerf Tiny](https://github.com/mlcommons/tiny), che si concentra su microcontrollori e altri dispositivi con risorse limitate.

* [MLMark di EEMBC](https://github.com/eembc/mlmark): Una suite di benchmarking per valutare le prestazioni e l'efficienza energetica dei dispositivi embedded che eseguono carichi di lavoro di apprendimento automatico. Questo benchmark fornisce informazioni su come diverse piattaforme hardware gestiscono attività come il riconoscimento delle immagini o l'elaborazione audio.

* [AI-Benchmark](https://ai-benchmark.com/) [@ignatov2018ai]: Uno strumento di benchmarking progettato per dispositivi Android, valuta le prestazioni delle attività di intelligenza artificiale sui dispositivi mobili, comprendendo vari scenari del mondo reale come il riconoscimento delle immagini, l'analisi dei volti e il riconoscimento ottico dei caratteri.

#### Benchmark end-to-end

I benchmark end-to-end forniscono una valutazione completa che si estende oltre i confini del modello di ML stesso. Invece di concentrarsi esclusivamente sull'efficienza o l'accuratezza computazionale di un modello di apprendimento automatico, questi benchmark comprendono l'intera pipeline di un sistema di IA. Ciò include la pre-elaborazione iniziale dei dati, le prestazioni del modello principale, la post-elaborazione degli output del modello e altri componenti integrali come l'archiviazione e le interazioni di rete.

La pre-elaborazione dei dati è la prima fase in molti sistemi di IA, trasformando i dati grezzi in un formato adatto per l'addestramento o l'inferenza del modello. L'efficienza, la scalabilità e l'accuratezza di queste fasi di pre-elaborazione sono vitali per le prestazioni complessive del sistema. I benchmark end-to-end valutano questa fase, assicurando che la pulizia dei dati, la normalizzazione, l'aumento o qualsiasi altro processo di trasformazione non diventi un collo di bottiglia.

Anche la fase di post-elaborazione è al centro dell'attenzione. Ciò comporta l'interpretazione degli output grezzi del modello, eventualmente la conversione dei punteggi in categorie significative, il filtraggio dei risultati o persino l'integrazione con altri sistemi. Nelle applicazioni del mondo reale, questa fase è fondamentale per fornire informazioni fruibili e i benchmark end-to-end ne garantiscono l'efficienza e l'efficacia.

Oltre alle operazioni di base dell'IA, altri componenti del sistema sono importanti per le prestazioni complessive e l'esperienza utente. Le soluzioni di archiviazione, basate su cloud, on-premise o ibride, possono avere un impatto significativo sui tempi di recupero e archiviazione dei dati, in particolare con vasti set di dati di IA. Allo stesso modo, le interazioni di rete, vitali per le soluzioni di IA basate su cloud o per i sistemi distribuiti, possono diventare colli di bottiglia delle prestazioni se non ottimizzate. I benchmark end-to-end valutano in modo olistico questi componenti, assicurando che l'intero sistema funzioni senza problemi, dal recupero dei dati alla consegna dell'output finale.

Ad oggi, non esistono benchmark end-to-end pubblici che tengano conto del ruolo dell'archiviazione dei dati, della rete e delle prestazioni di elaborazione. Si può sostenere che MLPerf Training and Inference si avvicini all'idea di un benchmark end-to-end, ma si concentrano esclusivamente sulle prestazioni del modello ML e non rappresentano scenari di distribuzione nel mondo reale di come i modelli vengono utilizzati sul campo. Tuttavia, forniscono un segnale molto utile che aiuta a valutare le prestazioni del sistema AI.

Data la specificità intrinseca del benchmarking end-to-end, viene in genere eseguito internamente in un'azienda "strumentando" [inserendo punti di controllo] distribuzioni di produzione reali di AI. Ciò consente agli ingegneri di avere una comprensione e una ripartizione realistiche delle prestazioni, ma data la sensibilità e la specificità delle informazioni, raramente vengono segnalate all'esterno dell'azienda.

#### Comprendere i Compromessi

Diversi problemi sorgono nelle diverse fasi di un sistema di intelligenza artificiale. I micro-benchmark aiutano a mettere a punto i singoli componenti, i macro-benchmark aiutano a perfezionare le architetture o gli algoritmi del modello e i benchmark end-to-end guidano l'ottimizzazione dell'intero flusso di lavoro. Comprendendo dove si trova un problema, gli sviluppatori possono applicare ottimizzazioni mirate.

Inoltre, mentre i singoli componenti di un sistema di intelligenza artificiale potrebbero funzionare in modo ottimale in isolamento, possono emergere colli di bottiglia quando interagiscono. I benchmark end-to-end, in particolare, sono fondamentali per garantire che l'intero sistema, quando funziona collettivamente, soddisfi gli standard di prestazioni ed efficienza desiderati.

Infine, le organizzazioni possono prendere decisioni informate su dove allocare le risorse individuando colli di bottiglia o inefficienze nelle prestazioni. Ad esempio, se i micro-benchmark rivelano inefficienze in specifiche operazioni tensoriali, gli investimenti possono essere indirizzati verso acceleratori hardware specializzati. Al contrario, se i benchmark end-to-end indicano problemi di recupero dei dati, gli investimenti potrebbero essere incanalati verso soluzioni di archiviazione migliori.

### Componenti dei Benchmark

In sostanza, un benchmark AI è più di un semplice test o punteggio; è un framework di valutazione completo. Per comprenderlo in modo approfondito, analizziamo i componenti tipici che compongono un benchmark AI.

#### Dataset Standardizzati

I set di dati fungono da base per la maggior parte dei benchmark AI. Forniscono un set di dati coerente su cui i modelli vengono addestrati e valutati, garantendo parità di condizioni per i confronti.

Esempio: ImageNet, un set di dati su larga scala contenente milioni di immagini etichettate che abbracciano migliaia di categorie, è uno standard di benchmarking popolare per le attività di classificazione delle immagini.

#### Attività Predefinite

Un benchmark dovrebbe avere un obiettivo o un compito chiaro che i modelli mirano a raggiungere. Questo compito definisce il problema che il sistema AI sta cercando di risolvere.

Esempio: I compiti per i benchmark di elaborazione del linguaggio naturale potrebbero includere analisi del "sentiment", riconoscimento di entità denominate o traduzione automatica.

#### Metriche di Valutazione

Una volta definito un task, i benchmark richiedono parametri per quantificare le prestazioni. Questi parametri offrono misure oggettive per confrontare diversi modelli o sistemi. Nei task di classificazione, parametri come accuratezza, precisione, richiamo e [punteggio F1](https://en.wikipedia.org/wiki/F-score) sono comunemente utilizzati. Errori quadratici medi o assoluti potrebbero essere utilizzati per i task di regressione. Possiamo anche misurare la potenza consumata dall'esecuzione del benchmark per calcolare l'efficienza energetica.

#### Baseline e Modelli Baseline

I benchmark spesso includono modelli "baseline" o implementazioni di riferimento. Di solito servono come punti di partenza o standard minimi di prestazione per confrontare nuovi modelli o nuove tecniche. I modelli "baseline" aiutano i ricercatori a misurare l'efficacia di nuovi algoritmi.

Nelle suite di benchmark, modelli semplici come la regressione lineare o le reti neurali di base sono spesso le baseline comuni. Queste forniscono un contesto quando si valutano modelli più complessi. Confrontando questi modelli più semplici, i ricercatori possono quantificare i miglioramenti derivanti da approcci avanzati.

Le metriche delle prestazioni variano in base all'attività, ma ecco alcuni esempi:

* Le attività di classificazione utilizzano metriche come accuratezza, precisione, richiamo e punteggio F1.
* Le attività di regressione utilizzano spesso l'errore quadratico medio o l'errore assoluto medio.

#### Specifiche Hardware e Software

Data la variabilità introdotta da diverse configurazioni hardware e software, i benchmark spesso specificano o documentano gli ambienti hardware e software in cui vengono condotti i test.

Esempio: Un benchmark AI potrebbe indicare che le valutazioni sono state condotte su una GPU NVIDIA Tesla V100 utilizzando TensorFlow v2.4.

#### Condizioni Ambientali

Poiché fattori esterni possono influenzare i risultati del benchmark, è essenziale controllare o documentare condizioni come temperatura, fonte di alimentazione o processi di background del sistema.

Esempio: I benchmark AI mobili potrebbero specificare che i test sono stati condotti a temperatura ambiente con dispositivi collegati a una fonte di alimentazione per eliminare le variazioni del livello della batteria.

#### Regole di Riproducibilità

Per garantire che i benchmark siano credibili e possano essere replicati da altri nella comunità, spesso includono protocolli dettagliati che coprono tutto, dai "random seed" utilizzati agli iperparametri esatti.

Esempio: Un benchmark per un'attività di learning di rinforzo potrebbe specificare gli episodi esatti dell'addestramento, i rapporti di esplorazione-sfruttamento e le strutture di ricompensa utilizzate.

#### Linee Guida per l'Interpretazione dei Risultati

Oltre ai punteggi o alle metriche pure, i benchmark spesso forniscono linee guida o contesto per interpretare i risultati, aiutando i professionisti a comprendere le implicazioni più ampie.

Esempio: Un benchmark potrebbe evidenziare che, sebbene il Modello A abbia ottenuto un punteggio più alto del Modello B in termini di accuratezza, offre migliori prestazioni in tempo reale, rendendolo più adatto per applicazioni sensibili al fattore tempo.

### I Benchmark del Training

Il ciclo di vita dello sviluppo di un modello di apprendimento automatico prevede due fasi critiche: addestramento e inferenza. Il training [addestramento] rappresenta la fase in cui il sistema elabora e assimila dati grezzi per adattare e perfezionare i propri parametri. Il benchmarking della fase di training rivela come le scelte nella pipeline di dati, soluzioni di storage, architetture di modelli, risorse di elaborazione, impostazioni di iperparametri e algoritmi di ottimizzazione influiscono sull'efficienza e sulle richieste di risorse del training del modello. L'obiettivo è garantire che il sistema ML possa apprendere in modo efficiente dai dati, ottimizzando sia le prestazioni del modello sia l'utilizzo delle risorse del sistema.

#### Scopo

Dal punto di vista dei sistemi, l'addestramento dei modelli di apprendimento automatico richiede molte risorse, soprattutto quando si lavora con modelli di grandi dimensioni. Questi modelli spesso contengono miliardi o addirittura trilioni di parametri addestrabili e richiedono enormi quantità di dati, spesso su una scala di molti terabyte. Ad esempio, [GPT-3 di OpenAI](https://arxiv.org/abs/2005.14165) [@brown2020language] ha 175 miliardi di parametri, è stato addestrato su 45 TB di dati compressi in testo normale e ha richiesto 3.640 petaflop-giorni di elaborazione per il pre-addestramento. I benchmark di training ML valutano i sistemi e le risorse necessari per gestire il carico computazionale dell'addestramento di tali modelli.

Anche l'archiviazione e la distribuzione efficienti dei dati durante l'addestramento svolgono un ruolo importante nel processo di addestramento. Ad esempio, in un modello di apprendimento automatico che prevede riquadri di delimitazione attorno agli oggetti in un'immagine, potrebbero essere necessarie migliaia di immagini. Tuttavia, caricare un intero set di dati di immagini nella memoria è in genere irrealizzabile, quindi i professionisti si affidano ai caricatori di dati (come discusso in @sec-frameworks-data-loaders) dai framework ML. Il training di successo del modello dipende dalla consegna tempestiva ed efficiente dei dati, rendendo essenziale il benchmarking di strumenti come caricatori di dati, pipeline di dati, velocità di pre-elaborazione e tempi di recupero dell'archiviazione per comprenderne l'impatto sulle prestazioni del training.

La selezione dell'hardware è un altro fattore chiave nel training dei sistemi di machine learning, in quanto può avere un impatto significativo sui tempi. I benchmark di training valutano l'utilizzo di CPU, GPU, memoria e rete durante la fase di training per guidare le ottimizzazioni del sistema. È essenziale comprendere come vengono utilizzate le risorse: le GPU vengono sfruttate appieno? C'è un sovraccarico di memoria non necessario? I benchmark possono scoprire colli di bottiglia o inefficienze nell'utilizzo delle risorse, con conseguenti risparmi sui costi e miglioramenti delle prestazioni.

In molti casi, l'utilizzo di un singolo acceleratore hardware, come una singola GPU, non è sufficiente per soddisfare le esigenze computazionali del training di modelli su larga scala. I modelli di apprendimento automatico vengono spesso addestrati in data center con più GPU o TPU, dove il calcolo distribuito consente l'elaborazione parallela tra i nodi. I benchmark di addestramento valutano l'efficienza con cui il sistema si ridimensiona su più nodi, gestisce lo sharding dei dati e gestisce sfide come guasti o taglio dei nodi durante l'addestramento.

#### Metriche

Se viste da una prospettiva di sistema, le metriche di training offrono informazioni che trascendono gli indicatori di prestazioni algoritmiche convenzionali. Queste metriche misurano l'efficacia di apprendimento del modello e misurano l'efficienza, la scalabilità e la robustezza dell'intero sistema ML durante la fase di training. Analizziamo più a fondo queste metriche e il loro significato.

Le seguenti metriche sono spesso considerate importanti:

1. **Tempo di training:** Il tempo necessario per addestrare un modello da zero fino a raggiungere un livello di prestazioni soddisfacente. Misura direttamente le risorse di elaborazione necessarie per addestrare un modello. Ad esempio, [il BERT di Google](https://arxiv.org/abs/1810.04805) [@devlin2018bert] è un modello di elaborazione del linguaggio naturale che richiede diversi giorni per l'addestramento su un corpus enorme di dati di testo utilizzando più GPU. Il lungo tempo di training è una sfida significativa in termini di consumo di risorse e costi. In alcuni casi, i benchmark possono invece misurare la produttività del training (campioni di training per unità di tempo). La produttività può essere calcolata molto più velocemente e facilmente del tempo di addestramento, ma potrebbe oscurare le metriche che ci interessano davvero (ad esempio, il tempo di addestramento).

2. **Scalabilità:** Quanto bene il processo di addestramento può gestire gli aumenti delle dimensioni dei dati o della complessità del modello. La scalabilità può essere valutata misurando il tempo di addestramento, l'utilizzo della memoria e altri consumi di risorse all'aumentare delle dimensioni dei dati o della complessità del modello. Ad esempio, l'addestramento del GPT-3 di OpenAI ha richiesto notevoli sforzi ingegneristici per adattare il processo di training a numerosi nodi GPU, in modo da gestire le enormi dimensioni del modello. Ciò ha comportato l'utilizzo di hardware specializzato, addestramento distribuito e altre tecniche per garantire che il modello potesse essere addestrato in modo efficiente.

3. **Utilizzo delle Risorse:** La misura in cui il processo di addestramento utilizza le risorse di calcolo disponibili come CPU, GPU, memoria e I/O del disco. Un elevato utilizzo delle risorse può indicare un processo di training efficiente, mentre un basso utilizzo può suggerire colli di bottiglia o inefficienze. Ad esempio, il training di una rete neurale convoluzionale (CNN) per la classificazione delle immagini richiede notevoli risorse GPU. L'utilizzo di configurazioni multi-GPU e l'ottimizzazione del codice di training per l'accelerazione GPU possono migliorare notevolmente l'utilizzo delle risorse e l'efficienza del training.

4. **Consumo di Memoria:** La quantità di memoria utilizzata dal processo di training. Il consumo di memoria può essere un fattore limitante per il training di modelli o set di dati di grandi dimensioni. Ad esempio, i ricercatori di Google hanno dovuto affrontare notevoli sfide di consumo di memoria durante il training di BERT. Il modello ha centinaia di milioni di parametri, che richiedono grandi quantità di memoria. I ricercatori hanno dovuto sviluppare tecniche per ridurre il consumo di memoria, come il checkpointing del gradiente e il parallelismo del modello.

5. **Consumo Energetico:** L'energia consumata durante il training. Man mano che i modelli di apprendimento automatico diventano più complessi, il consumo energetico è diventato un fattore importante da considerare. Il training di grandi modelli di apprendimento automatico può consumare molta energia, e quindi molto carbonio. Ad esempio, si è stimato che l'addestramento di GPT-3 di OpenAI abbia un'impronta di carbonio equivalente a un viaggio in auto di 700.000 chilometri (~435,000 miglia).

6. **Throughput:** l numero di campioni di addestramento elaborati per unità di tempo. Un throughput [produttività] più elevato indica generalmente un processo di addestramento più efficiente. La produttività è una metrica importante da considerare quando si addestra un sistema di raccomandazione per una piattaforma di e-commerce. Una produttività elevata assicura che il modello possa elaborare rapidamente grandi volumi di dati di interazione dell'utente, il che è fondamentale per mantenere la pertinenza e l'accuratezza delle raccomandazioni. Ma è anche importante capire come bilanciare la produttività con i limiti di latenza. Pertanto, un vincolo di produttività limitato dalla latenza viene spesso imposto agli accordi sul livello di servizio per le distribuzioni di applicazioni del data center.

7. **Costo:** Il costo della training di un modello può includere sia risorse computazionali che umane. Il costo è importante quando si considera la praticità e la fattibilità del training di modelli grandi o complessi. Si stima che l'addestramento di modelli di linguaggio grandi come GPT-3 costi milioni di dollari. Questo costo include risorse computazionali, elettriche e umane necessarie per lo sviluppo e l'addestramento del modello.

8. **Tolleranza agli Errori e Robustezza:** La capacità del processo di training di gestire guasti o errori senza bloccarsi o produrre risultati errati. Questo è importante per garantire l'affidabilità del processo di addestramento. Errori di rete o malfunzionamenti hardware possono verificarsi in uno scenario reale in cui un modello di apprendimento automatico viene addestrato su un sistema distribuito. Negli ultimi anni, è diventato abbondantemente chiaro che gli errori derivanti dalla corruzione "silenziosa" dei dati sono emersi come un problema importante. Un processo di addestramento affidabile e tollerante agli errori può recuperare da tali errori senza compromettere l'integrità del modello.

9. **Facilità d'Uso e Flessibilità:** La facilità con cui il processo di addestramento può essere impostato e utilizzato e la sua flessibilità nella gestione di diversi tipi di dati e modelli. In aziende come Google, l'efficienza può talvolta essere misurata dal numero di anni di "Software Engineer (SWE)" risparmiati poiché ciò si traduce direttamente in impatto. La facilità d'uso e la flessibilità possono ridurre il tempo e lo sforzo necessari per addestrare un modello. TensorFlow e PyTorch sono popolari framework di apprendimento automatico che forniscono interfacce intuitive e API flessibili per la creazione e l'addestramento di modelli di machine-learning. Questi framework supportano molte architetture di modelli e sono dotati di strumenti che semplificano il processo di addestramento.

10. **Riproducibilità:** La capacità di riprodurre i risultati del processo di training. La riproducibilità è importante per verificare la correttezza e la validità di un modello. Tuttavia, le variazioni dovute alle caratteristiche stocastiche della rete spesso rendono difficile riprodurre il comportamento preciso delle applicazioni in fase di addestramento, il che può rappresentare una sfida per il benchmarking.

Eseguendo il benchmarking per questi tipi di metriche, possiamo ottenere una visione completa delle prestazioni e dell'efficienza del processo di training da una prospettiva di sistema. Ciò può aiutare a identificare le aree di miglioramento e garantire che le risorse siano utilizzate in modo efficace.

#### I Benchmark

Ecco alcuni lavori originali che hanno gettato le basi fondamentali per lo sviluppo di benchmark sistematici per l'addestramento di sistemi di apprendimento automatico.

**[MLPerf Training Benchmark](https://github.com/mlcommons/training)**: MLPerf è una suite di benchmark progettata per misurare le prestazioni di hardware, software e servizi di apprendimento automatico. Il benchmark di MLPerf Training [@mattson2020mlperf] si concentra sul tempo necessario per addestrare i modelli a una metrica di qualità target. Include carichi di lavoro diversi, come classificazione delle immagini, rilevamento di oggetti, traduzione e apprendimento per rinforzo. @fig-perf-trend evidenzia i miglioramenti delle prestazioni nelle versioni progressive dei benchmark di MLPerf Training, che hanno tutti superato la legge di Moore. L'utilizzo di trend di benchmarking standardizzati ci consente di mostrare rigorosamente la rapida evoluzione del ML computing.

![Tendenze delle prestazioni di MLPerf Training. Fonte: @mattson2020mlperf.](images/png/mlperf_perf_trend.png){#fig-perf-trend}

Metriche:

* Tempo di training per la qualità target
* Throughput (esempi al secondo)
* Utilizzo delle risorse (CPU, GPU, memoria, I/O del disco)

**[DAWNBench](https://dawn.cs.stanford.edu/benchmark/)**: DAWNBench [@coleman2017dawnbench] è una suite di benchmark incentrata sui tempi di training end-to-end del deep learning e sulle prestazioni di inferenza. Include attività comuni come la classificazione delle immagini e la risposta alle domande.

Metriche:

* Tempo di training per la precisione target
* Latenza dell'inferenza
* Costo (in termini di risorse di cloud computing e storage)

**[Fathom](https://github.com/rdadolf/fathom)**: Fathom [@adolf2016fathom] è un benchmark dell'Università di Harvard che valuta le prestazioni dei modelli di deep learning utilizzando un set diversificato di carichi di lavoro. Questi includono attività comuni come la classificazione delle immagini, il riconoscimento vocale e la modellazione del linguaggio.

Metriche:

* Operazioni al secondo (per misurare l'efficienza computazionale)
* Tempo di completamento per ogni carico di lavoro
* Larghezza di banda della memoria

#### Caso d'Uso di Esempio

Si immagini di essere stati incaricati di effettuare il benchmarking delle prestazioni di training di un modello di classificazione delle immagini su una piattaforma hardware specifica. Analizziamo come si potrebbe affrontare questa situazione:

1. **Definire l'Attività**: Per prima cosa, si sceglie un modello e un set di dati. In questo caso, si allenerà una CNN per classificare le immagini nel set di dati [CIFAR-10](https://www.cs.toronto.edu/kriz/cifar.html), un benchmark ampiamente utilizzato nella visione artificiale.

2. **Selezionare il benchmark**: La scelta di un benchmark ampiamente accettato aiuta a garantire che la configurazione sia confrontabile con altre valutazioni del mondo reale. Si potrebbe scegliere di utilizzare il benchmark di training MLPerf perché fornisce un carico di lavoro di classificazione delle immagini strutturato, rendendolo un'opzione pertinente e standardizzata per valutare le prestazioni di training su CIFAR-10. L'utilizzo di MLPerf consente di valutare il sistema rispetto a metriche standard del settore, contribuendo a garantire che i risultati siano significativi e confrontabili con quelli ottenuti su altre piattaforme hardware.

3. **Identificare le Metriche Chiave**: Ora, si decidono le metriche che aiuteranno a valutare le prestazioni di training del sistema. Per questo esempio, si potrebbero tracciare:
   - **Tempo di Training**: Quanto tempo ci vuole per raggiungere il 90% di accuratezza?
   - **Produttività**: Quante immagini vengono elaborate al secondo?
   - **Utilizzo delle Risorse**: Qual è l'utilizzo di GPU e CPU durante il training?

Analizzando queste metriche, si otterranno informazioni sulle prestazioni di training del modello sulla piattaforma hardware scelta. Valutare se il tempo di training soddisfa le aspettative, se ci sono colli di bottiglia, come GPU sottoutilizzate o caricamento lento dei dati. Questo processo aiuta a identificare aree per una potenziale ottimizzazione, come il miglioramento della gestione dei dati o la regolazione dell'allocazione delle risorse, e può guidare le future decisioni di benchmarking.

### Benchmark di Inferenza

L'inferenza nell'apprendimento automatico si riferisce all'uso di un modello addestrato per fare previsioni su dati nuovi e mai visti prima. È la fase in cui il modello applica le conoscenze apprese per risolvere il problema per cui è stato progettato, come la classificazione di immagini, il riconoscimento vocale o la traduzione di testo.

#### Scopo

Quando creiamo modelli di machine learning, il nostro obiettivo finale è di distribuirli in applicazioni del mondo reale in cui possano fornire previsioni accurate e affidabili su dati nuovi e mai visti. Questo processo di utilizzo di un modello addestrato per fare previsioni è noto come inferenza. Le prestazioni reali di un modello di apprendimento automatico possono differire in modo significativo dalle sue prestazioni su set di dati di addestramento o validazione, il che rende l'inferenza di benchmarking un passaggio cruciale nello sviluppo e nell'implementazione di modelli di machine learning.

Il benchmarking dell'inferenza ci consente di valutare quanto bene un modello di apprendimento automatico funziona in scenari del mondo reale. Questa valutazione garantisce che il modello sia pratico e affidabile quando distribuito in applicazioni, fornendo una comprensione più completa del comportamento del modello con dati reali. Inoltre, il benchmarking può aiutare a identificare potenziali colli di bottiglia o limitazioni nelle prestazioni del modello. Ad esempio, se un modello impiega troppo tempo per dedurre, potrebbe non essere pratico per applicazioni in tempo reale come la guida autonoma o gli assistenti vocali.

L'efficienza delle risorse è un altro aspetto critico dell'inferenza, poiché può essere computazionalmente intensiva e richiedere memoria e potenza di elaborazione significative. Il benchmarking aiuta a garantire che il modello sia efficiente per quanto riguarda l'utilizzo delle risorse, il che è particolarmente importante per i dispositivi edge con capacità computazionali limitate, come smartphone o dispositivi IoT. Inoltre, il benchmarking ci consente di confrontare le prestazioni del nostro modello con quelli concorrenti o versioni precedenti dello stesso modello. Questo confronto è essenziale per prendere decisioni informate su quale modello implementare in un'applicazione specifica.

Infine, è fondamentale garantire che le previsioni del modello non siano solo accurate, ma anche coerenti tra diversi dati. Il benchmarking aiuta a verificare l'accuratezza e la coerenza del modello, assicurando che soddisfi i requisiti dell'applicazione. Valuta inoltre la robustezza del modello, assicurando che possa gestire la variabilità dei dati del mondo reale e comunque fare previsioni accurate.

#### Metriche

1. **Precisione:** La precisione è una delle metriche più importanti quando si confrontano i modelli di machine learning. Quantifica la percentuale di previsioni corrette effettuate dal modello rispetto ai valori o alle etichette reali. Ad esempio, se un modello di rilevamento dello spam riesce a classificare correttamente 95 messaggi e-mail su 100, la sua precisione verrebbe calcolata al 95%.

2. **Latenza:** La latenza è una metrica delle prestazioni che calcola il ritardo o l'intervallo di tempo tra la ricezione dell'input e la produzione dell'output corrispondente da parte del sistema di apprendimento automatico. Un esempio che descrive chiaramente la latenza è un'applicazione di traduzione in tempo reale; se esiste un ritardo di mezzo secondo dal momento in cui un utente inserisce una frase al momento in cui l'app visualizza il testo tradotto, la latenza del sistema è di 0.5 secondi.

3. **Latency-Bounded Throughput:** Il throughput limitato dalla latenza è una metrica preziosa che combina gli aspetti di latenza e throughput, misurando il throughput massimo di un sistema pur rispettando un vincolo di latenza specificato. Ad esempio, in un'applicazione di streaming video che utilizza un modello di apprendimento automatico per generare e visualizzare automaticamente i sottotitoli, il throughput limitato dalla latenza misurerebbe quanti frame video il sistema può elaborare al secondo (throughput) garantendo al contempo che i sottotitoli vengano visualizzati con un ritardo non superiore a 1 secondo (latenza). Questa metrica è particolarmente importante nelle applicazioni in tempo reale in cui soddisfare i requisiti di latenza è fondamentale per l'esperienza utente.

4. **Throughput:** Il throughput valuta la capacità del sistema misurando il numero di inferenze o previsioni che un modello di apprendimento automatico può gestire entro un'unità di tempo specifica. Si consideri un sistema di riconoscimento vocale che utilizza una Recurrent Neural Network (RNN) come modello sottostante; se questo sistema riesce a elaborare e comprendere 50 diverse clip audio in un minuto, allora la sua velocità di elaborazione è di 50 clip al minuto.

5. **Efficienza energetica:** L'efficienza energetica è una metrica che determina la quantità di energia consumata dal modello di apprendimento automatico per eseguire una singola inferenza. Un esempio lampante di ciò sarebbe un modello di elaborazione del linguaggio naturale basato su un'architettura di rete Transformer; se utilizza 0,1 Joule di energia per tradurre una frase dall'inglese al francese, la sua efficienza energetica è misurata a 0,1 Joule per inferenza.

6. **Utilizzo della memoria:** L'utilizzo della memoria quantifica il volume di RAM necessario a un modello di apprendimento automatico per svolgere attività di inferenza. Un esempio rilevante per illustrare questo sarebbe un sistema di riconoscimento facciale basato su una CNN; se un tale sistema richiede 150 MB di RAM per elaborare e riconoscere i volti all'interno di un'immagine, il suo utilizzo della memoria è di 150 MB.

#### I Benchmark

Ecco alcuni lavori originali che hanno gettato le basi fondamentali per lo sviluppo di benchmark sistematici per sistemi di apprendimento automatico inferenziale.

**[MLPerf Inference Benchmark](https://github.com/mlcommons/inference):** MLPerf Inference è una suite di benchmark completa che valuta le prestazioni dei modelli di apprendimento automatico durante la fase di inferenza. Comprende una varietà di carichi di lavoro, tra cui classificazione delle immagini, rilevamento di oggetti ed elaborazione del linguaggio naturale, con l'obiettivo di fornire metriche standardizzate e approfondite per la valutazione di diversi sistemi di inferenza. Le sue metriche includono:

MLPerf Inference è una suite di benchmark completa che valuta le prestazioni dei modelli di apprendimento automatico durante la fase di inferenza. Comprende una varietà di carichi di lavoro, tra cui classificazione delle immagini, rilevamento di oggetti ed elaborazione del linguaggio naturale, con l'obiettivo di fornire metriche standardizzate e approfondite per la valutazione di diversi sistemi di inferenza.

Metriche:

* Tempo di inferenza
* Latenza
* Throughput [Produttività]
* Precisione
* Consumo energetico

**[AI Benchmark](https://ai-benchmark.com/):** AI Benchmark è uno strumento di benchmarking che valuta le prestazioni dei modelli di intelligenza artificiale e apprendimento automatico su dispositivi mobili e piattaforme di edge computing. Include test per attività di classificazione delle immagini, rilevamento di oggetti ed elaborazione del linguaggio naturale, fornendo un'analisi dettagliata delle prestazioni di inferenza su diverse piattaforme hardware. Le sue metriche includono:

AI Benchmark è uno strumento di benchmarking che valuta le prestazioni dei modelli di intelligenza artificiale e di apprendimento automatico su dispositivi mobili e piattaforme di edge computing. Include test per attività di classificazione delle immagini, rilevamento di oggetti ed elaborazione del linguaggio naturale, fornendo un'analisi dettagliata delle prestazioni di inferenza su diverse piattaforme hardware.

Metriche:

* Tempo di inferenza
* Latenza
* Consumo energetico
* Utilizzo della memoria
* Throughput [Produttività]

**[Toolkit OpenVINO](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html):** Il toolkit OpenVINO fornisce uno strumento di benchmark per misurare le prestazioni dei modelli di apprendimento profondo per varie attività, come la classificazione delle immagini, il rilevamento degli oggetti e il riconoscimento facciale, su hardware Intel. Offre approfondimenti dettagliati sulle prestazioni di inferenza dei modelli su diverse configurazioni hardware. Le sue metriche includono:

Metriche:

* Tempo di inferenza
* Throughput [Produttività]
* Latenza
* Utilizzo di CPU e GPU

#### Caso d'Uso di Esempio

Supponiamo che sia stato assegnato il compito di valutare le prestazioni di inferenza di un modello di rilevamento di oggetti su uno specifico dispositivo edge. Ecco come ci si potrebbe approcciare alla strutturazione di questo benchmark:

1. **Definire l'Attività**: In questo caso, l'attività è il rilevamento di oggetti in tempo reale su flussi video, identificando oggetti come veicoli, pedoni e segnali stradali.

2. **Selezionare il Benchmark**: Per allinearsi all'obiettivo di valutare l'inferenza su un dispositivo edge, l'AI Benchmark è una scelta adatta. Fornisce un framework standardizzato specificamente per valutare le prestazioni di inferenza su hardware edge, rendendolo rilevante per questo scenario.

3. **Identificare le Metriche Chiave**: Ora, si determinano le metriche che aiuteranno a valutare le prestazioni di inferenza del modello. Per questo esempio, si potrebbero tracciare:
   - **Tempo di Inferenza**: Quanto tempo ci vuole per elaborare ogni fotogramma video?
   - **Latenza**: Qual è il ritardo nella generazione di bounding box per gli oggetti rilevati?
   - **Consumo Energetico**: Quanta energia viene utilizzata durante l'inferenza?
   - **Produttività**: Quanti frame video vengono elaborati al secondo?

Misurando queste metriche, si otterranno informazioni su quanto bene funziona il modello di rilevamento degli oggetti sul dispositivo edge. Ciò può aiutare a identificare eventuali colli di bottiglia, come l'elaborazione lenta dei frame o l'elevato consumo energetico, e a evidenziare aree per una potenziale ottimizzazione per migliorare le prestazioni in tempo reale.

:::{#exr-perf .callout-caution collapse="true"}

### Benchmark di Inferenza - MLPerf

Prepararsi a mettere alla prova i propri modelli di intelligenza artificiale! MLPerf è come le Olimpiadi per le prestazioni del machine learning. In questo Colab, utilizzeremo un toolkit chiamato CK per eseguire benchmark MLPerf ufficiali, misurare la velocità e l'accuratezza di un proprio modello e persino utilizzare TVM per dargli una spinta super veloce. Pronti a vedere il modello vincere la sua medaglia?

[![](https://colab.research.google.com/assets/colab-badge.png)](https://colab.research.google.com/drive/1aywGlyD1ZRDtQTrQARVgL1882JcvmFK-?usp=sharing#scrollTo=tnyHAdErL72u)

:::


### Selezione delle Attività di Benchmark

La selezione di attività rappresentative per il benchmarking dei sistemi di machine learning è complessa a causa delle diverse applicazioni, tipi di dati e requisiti nei diversi domini. L'apprendimento automatico viene applicato in settori quali sanità, finanza, elaborazione del linguaggio naturale e visione artificiale, ognuno con attività uniche che potrebbero non essere pertinenti o paragonabili ad altre. Le principali sfide nella selezione delle attività includono:

1. **Diversità di Applicazioni e Tipi di Dati:** Le attività nei vari domini coinvolgono diversi tipi di dati (ad esempio testo, immagini, video) e qualità, rendendo difficile trovare benchmark che rappresentino universalmente le sfide dell'apprendimento automatico.
2. **Complessità delle Attività e Necessità di Risorse:** Le attività variano in complessità e richieste di risorse, con alcune che richiedono una notevole potenza di calcolo e modelli sofisticati, mentre altre possono essere affrontate con risorse e metodi più semplici.
3. **Problemi di Privacy:** Le attività che coinvolgono dati sensibili, come cartelle cliniche o informazioni personali, introducono problemi etici e di privacy, rendendole inadatte per benchmark generali.
4. **Metriche di Valutazione:** Le metriche delle prestazioni variano notevolmente tra le attività e i risultati di un'attività spesso non si generalizzano ad altre, complicando i confronti e limitando le informazioni da un'attività di benchmarking a un'altra.

Affrontare queste sfide è essenziale per progettare benchmark significativi che siano pertinenti tra le diverse attività incontrate nell'apprendimento automatico, assicurando che i benchmark forniscano informazioni utili e generalizzabili sia per la formazione che per l'inferenza.


### Misura dell'Efficienza Energetica

Con l'espansione delle capacità di apprendimento automatico, sia nel training che nell'inferenza, le preoccupazioni relative all'aumento del consumo energetico e al suo impatto ecologico si sono intensificate. Affrontare la sostenibilità dei sistemi ML, un argomento esplorato più approfonditamente nel capitolo [IA Sostenibile](../sustainable_ai/sustainable_ai.it.qmd), è quindi diventata una priorità fondamentale. Questa attenzione alla sostenibilità ha portato allo sviluppo di benchmark standardizzati progettati per misurare con precisione l'efficienza energetica. Tuttavia, la standardizzazione di queste metodologie pone delle sfide dovute alla necessità di adattarsi a scale molto diverse, dal consumo di microwatt dei dispositivi TinyML alle richieste di megawatt dei sistemi di training dei data center. Inoltre, per garantire che il benchmarking sia equo e riproducibile è necessario adattarsi alla vasta gamma di configurazioni hardware e architetture in uso oggi.

Un esempio è la metodologia di benchmarking MLPerf Power [@tschand2024mlperf], che affronta queste sfide adattando le metodologie per data center, edge inference e tiny inference systems, misurando al contempo il consumo energetico nel modo più completo possibile per ogni scala. Questa metodologia si adatta a una varietà di hardware, dalle CPU generiche agli acceleratori AI specializzati, mantenendo principi di misurazione uniformi per garantire che i confronti siano equi e accurati su diverse piattaforme.

@fig-power-diagram illustra i limiti di misurazione dell'alimentazione per diverse scale di sistema, dai dispositivi TinyML ai nodi di inferenza e ai rack di training. Ciascun esempio evidenzia i componenti all'interno del limite di misurazione e quelli al di fuori di esso. Questa configurazione consente una riflessione accurata dei veri costi energetici associati all'esecuzione di carichi di lavoro ML in vari scenari del mondo reale e garantisce che il benchmark catturi l'intero spettro di consumo energetico.

![Diagramma di misurazione del sistema MLPerf Power. Fonte: @tschand2024mlperf.](images/png/power_component_diagram.png){#fig-power-diagram}

È importante notare che l'ottimizzazione di un sistema per le prestazioni potrebbe non portare all'esecuzione più efficiente dal punto di vista energetico. Spesso, sacrificare una piccola quantità di prestazioni o accuratezza può portare a guadagni significativi nell'efficienza energetica, evidenziando l'importanza di un benchmarking accurato delle metriche della potenza. Le future intuizioni dal benchmarking dell'efficienza energetica e della sostenibilità ci consentiranno di ottimizzare per sistemi ML più sostenibili.

### Esempio di Benchmark

Per illustrare correttamente i componenti di un benchmark di sistema, possiamo esaminare il benchmark di individuazione delle parole chiave in MLPerf Tiny e spiegare la motivazione alla base di ogni decisione.

#### Task

L'individuazione delle parole chiave è stata selezionata come attività perché è un caso d'uso comune in TinyML che è stato ben consolidato per anni. Inoltre, l'hardware tipico utilizzato per l'individuazione delle parole chiave differisce sostanzialmente dalle offerte di altri benchmark, come l'attività di riconoscimento vocale di MLPerf Inference.

#### Il Dataset

[Google Speech Commands](https://www.tensorflow.org/datasets/catalog/speech_commands) [@warden2018speech] è stato selezionato come il miglior dataset per rappresentare l'attività. Il dataset è ben consolidato nella comunità di ricerca e ha una licenza permissiva, che consente di utilizzarlo facilmente in un benchmark.

#### Modello

Il componente principale successivo è il modello, che fungerà da carico di lavoro primario per il benchmark. Il modello dovrebbe essere ben consolidato come soluzione per l'attività selezionata piuttosto che una soluzione all'avanguardia. Il modello selezionato è un semplice modello di convoluzione separabile in profondità. Questa architettura non è la soluzione all'avanguardia per l'attività, ma è ben consolidata e non progettata per una piattaforma hardware specifica come molte soluzioni all'avanguardia. Nonostante sia un benchmark di inferenza, stabilisce anche una ricetta di training di riferimento per essere completamente riproducibile e trasparente.

#### Metriche

La latenza è stata selezionata come metrica primaria per il benchmark, poiché i sistemi di individuazione delle parole chiave devono reagire rapidamente per mantenere la soddisfazione dell'utente. Inoltre, dato che i sistemi TinyML sono spesso alimentati a batteria, il consumo energetico viene misurato per garantire l'efficienza della piattaforma hardware. L'accuratezza del modello viene misurata anche per garantire che le ottimizzazioni applicate da un submitter, come la quantizzazione, non degradino l'accuratezza oltre una soglia.

#### Benchmark Harness

MLPerf Tiny utilizza [EEMBCs EnergyRunner benchmark harness](https://github.com/eembc/energyrunner) per caricare gli input nel modello e isolare e misurare il consumo energetico del dispositivo. Quando si misura il consumo energetico, è fondamentale selezionare un "harness" [imbracatura] che sia accurato ai livelli di potenza previsti dei dispositivi sottoposti a test e sufficientemente semplice da non diventare un peso per i partecipanti al benchmark.

#### La Baseline

Gli invii di baseline sono fondamentali per contestualizzare i risultati e come punto di riferimento per aiutare i partecipanti a iniziare. L'invio di base dovrebbe dare priorità alla semplicità e alla leggibilità rispetto alle prestazioni avanzate. L'individuazione della parola chiave della baseline utilizza un [microcontrollore STM](https://www.st.com/en/microcontrollers-microprocessors.html) standard come hardware e [TensorFlow Lite come microcontrollore](https://www.tensorflow.org/lite/microcontrollers) [@david2021tensorflow] come framework di inferenza.

### Sfide e Limitazioni

Sebbene il benchmarking fornisca una metodologia strutturata per la valutazione delle prestazioni in domini complessi come l'intelligenza artificiale e l'informatica, il processo pone anche diverse sfide. Se non affrontati correttamente, questi ostacoli possono minare la credibilità e l'accuratezza dei risultati del benchmarking. Alcune delle difficoltà predominanti affrontate nel benchmarking includono quanto segue:

* **Copertura incompleta del problema:** Le attività di benchmarking potrebbero non rappresentare completamente lo spazio del problema. Ad esempio, i set di dati di classificazione delle immagini comuni come [CIFAR-10](https://www.cs.toronto.edu/kriz/cifar.html) hanno una diversità limitata nei tipi di immagini. Gli algoritmi ottimizzati per tali benchmark potrebbero non riuscire a generalizzare bene con i set di dati del mondo reale.

* **Insignificanza statistica:** I benchmark devono avere prove e campioni di dati sufficienti per produrre risultati statisticamente significativi. Ad esempio, il benchmarking di un modello OCR su solo poche scansioni di testo potrebbe non catturare adeguatamente i suoi veri tassi di errore.

* **Riproducibilità limitata:** Variazioni di hardware, versioni software, basi di codice e altri fattori possono ridurre la riproducibilità dei risultati di benchmark. MLPerf affronta questo problema fornendo implementazioni di riferimento e specifiche ambientali.

* **Disallineamento con gli obiettivi finali:** I benchmark che si concentrano solo su metriche di velocità o accuratezza possono disallineare gli obiettivi reali come costi ed efficienza energetica. I benchmark devono riflettere tutti gli assi prestazionali critici.

* **Rapida obsolescenza:** A causa del rapido ritmo dei progressi nell'intelligenza artificiale e nell'informatica, i benchmark e i loro set di dati possono rapidamente diventare obsoleti. Mantenere benchmark aggiornati è quindi una sfida persistente.

Ma di tutte queste, la sfida più importante è l'ingegneria dei benchmark.

#### Lotteria Hardware

La lotteria hardware, descritta per la prima volta da @10.1145/3467017, si riferisce alla situazione in cui il successo o l'efficienza di un modello di apprendimento automatico sono significativamente influenzati dalla sua compatibilità con l'hardware sottostante [@chu2021discovering]. Alcuni modelli hanno prestazioni eccezionali non perché sono intrinsecamente superiori, ma perché sono ottimizzati per caratteristiche hardware specifiche, come le capacità di elaborazione parallela delle unità di elaborazione grafica (GPU) o delle unità di elaborazione tensoriale (TPU).

Ad esempio, @fig-hardware-lottery confronta le prestazioni dei modelli su diverse piattaforme hardware. I modelli multi-hardware mostrano risultati comparabili a "MobileNetV3 Large min" sia sulle configurazioni CPU uint8 che GPU. Tuttavia, questi modelli multi-hardware dimostrano miglioramenti significativi delle prestazioni rispetto alla baseline MobileNetV3 Large quando eseguiti su hardware EdgeTPU e DSP. Ciò sottolinea l'efficienza variabile dei modelli multi-hardware in ambienti di elaborazione specializzati.

![Compromessi tra precisione e latenza di più modelli ML e modalità di funzionamento su vari hardware. Fonte: @chu2021discovering](images/png/hardware_lottery.png){#fig-hardware-lottery}

La lotteria hardware può introdurre sfide e pregiudizi nel benchmarking dei sistemi di apprendimento automatico, poiché le prestazioni del modello non dipendono esclusivamente dall'architettura o dall'algoritmo del modello ma anche dalla compatibilità e dalle sinergie con l'hardware sottostante. Ciò può rendere difficile confrontare equamente diversi modelli e identificare il modello migliore in base ai suoi meriti intrinseci. Può anche portare a una situazione in cui la comunità converge su modelli che sono adatti all'hardware più diffuso del momento, trascurando potenzialmente altri modelli che potrebbero essere superiori ma incompatibili con le attuali tendenze hardware.

#### Benchmark Engineering

La lotteria hardware si verifica quando un modello di apprendimento automatico funziona in modo eccezionalmente bene o male su una configurazione hardware specifica a causa di compatibilità o incompatibilità impreviste. Il modello non è esplicitamente progettato o ottimizzato per quell'hardware specifico dagli sviluppatori o dagli ingegneri; piuttosto, capita che si allinei o (non si allinei) con le capacità o le limitazioni dell'hardware. In questo caso, le prestazioni del modello sull'hardware sono un prodotto della coincidenza piuttosto che della progettazione.

Contrariamente alla lotteria hardware accidentale, il benchmark engineering implica l'ottimizzazione o la progettazione deliberata di un modello di apprendimento automatico per funzionare eccezionalmente bene su hardware specifico, spesso per vincere benchmark o competizioni. Questa ottimizzazione intenzionale potrebbe includere la modifica dell'architettura, degli algoritmi o dei parametri del modello per sfruttare appieno le funzionalità e le capacità dell'hardware.

##### Problema

Il benchmark engineering si riferisce alla modifica o all'ottimizzazione di un sistema di intelligenza artificiale per ottimizzare le prestazioni su test di benchmark specifici, spesso a scapito della generalizzabilità o delle prestazioni nel mondo reale. Ciò può includere la regolazione di iperparametri, dati di training o altri aspetti del sistema specificamente per ottenere punteggi elevati sulle metriche di benchmark senza necessariamente migliorare la funzionalità o l'utilità complessiva del sistema.

La motivazione alla base dell'ingegneria dei benchmark spesso deriva dal desiderio di ottenere punteggi di prestazioni elevate per scopi di marketing o competitivi. Punteggi di benchmark elevati possono dimostrare la superiorità di un sistema di intelligenza artificiale rispetto ai concorrenti e possono essere un argomento chiave per la vendita per potenziali utenti o investitori. Questa pressione per ottenere buoni risultati nei benchmark a volte porta a dare priorità alle ottimizzazioni specifiche del benchmark rispetto a miglioramenti più olistici del sistema.

Può comportare diversi rischi e sfide. Uno dei rischi principali è che il sistema di intelligenza artificiale possa funzionare meglio nelle applicazioni del mondo reale rispetto a quanto suggeriscono i punteggi di benchmark. Ciò può portare a insoddisfazione dell'utente, danni alla reputazione e potenziali problemi di sicurezza o etici. Inoltre, l'ingegneria dei benchmark può contribuire a una mancanza di trasparenza e responsabilità nella comunità dell'intelligenza artificiale, poiché può essere difficile discernere quanta parte delle prestazioni di un sistema di intelligenza artificiale sia dovuta a miglioramenti genuini rispetto a ottimizzazioni specifiche del benchmark.

La comunità AI deve dare priorità alla trasparenza e alla responsabilità per mitigare i rischi associati all'ingegneria dei benchmark. Ciò può includere la divulgazione di eventuali ottimizzazioni o modifiche apportate specificamente per i test di benchmark e la fornitura di valutazioni più complete dei sistemi AI che includono metriche delle prestazioni del mondo reale e punteggi di benchmark. I ricercatori e gli sviluppatori devono dare priorità a miglioramenti olistici dei sistemi AI che ne migliorino la generalizzabilità e la funzionalità in varie applicazioni anziché concentrarsi esclusivamente su ottimizzazioni specifiche del benchmark.

##### Problemi

Uno dei problemi principali dell'ingegneria del benchmark è che può compromettere le prestazioni reali dei sistemi di intelligenza artificiale. Quando gli sviluppatori si concentrano sull'ottimizzazione dei loro sistemi per ottenere punteggi elevati in specifici test di benchmark, potrebbero trascurare altri importanti aspetti delle prestazioni del sistema, cruciali nelle applicazioni del mondo reale. Ad esempio, un sistema di intelligenza artificiale progettato per il riconoscimento delle immagini potrebbe essere progettato per funzionare eccezionalmente bene in un test di benchmark che include un set specifico di immagini, ma necessita di aiuto per riconoscere accuratamente immagini leggermente diverse da quelle nel set di test.

Un'altra area di miglioramento con l'ingegneria di benchmark è che può comportare sistemi di intelligenza artificiale privi di generalizzabilità. In altre parole, mentre il sistema può funzionare bene nel test di benchmark, potrebbe aver bisogno di aiuto per gestire una vasta gamma di input o scenari. Ad esempio, un modello di intelligenza artificiale sviluppato per l'elaborazione del linguaggio naturale potrebbe essere progettato per ottenere punteggi elevati in un test di benchmark che include un tipo specifico di testo, ma non riesce a elaborare accuratamente il testo che non rientra in quel tipo specifico.

Può anche portare a risultati fuorvianti. Quando i sistemi di intelligenza artificiale sono progettati per funzionare bene nei test di benchmark, i risultati potrebbero non riflettere accuratamente le reali capacità del sistema. Questo può essere problematico per gli utenti o gli investitori che si affidano ai punteggi di benchmark per prendere decisioni informate su quali sistemi di intelligenza artificiale utilizzare o in cui investire. Ad esempio, un sistema di intelligenza artificiale progettato per ottenere punteggi elevati in un test di benchmark per il riconoscimento vocale potrebbe dover essere più in grado di riconoscere accuratamente il parlato in situazioni reali, portando gli utenti o gli investitori a prendere decisioni basate su informazioni imprecise.

##### Attenuazione

Esistono diversi modi per mitigare l'ingegneria dei benchmark. La trasparenza nel processo di benchmarking è fondamentale per mantenere l'accuratezza e l'affidabilità dei benchmark. Ciò implica la divulgazione chiara delle metodologie, dei set di dati e dei criteri di valutazione utilizzati nei test di benchmark, nonché di eventuali ottimizzazioni o modifiche apportate al sistema di intelligenza artificiale ai fini del benchmark.

Un modo per ottenere trasparenza è attraverso l'uso di benchmark open source. I benchmark open source vengono resi disponibili al pubblico, consentendo a ricercatori, sviluppatori e altre parti interessate di esaminarli, criticarli e contribuire, garantendone così l'accuratezza e l'affidabilità. Questo approccio collaborativo facilita anche la condivisione delle "best practice" e lo sviluppo di benchmark più solidi e completi.

Il design modulare di MLPerf Tiny si collega al problema dell'ingegneria dei benchmark fornendo un approccio strutturato ma flessibile che incoraggia una valutazione equilibrata di TinyML. Nell'ingegneria dei benchmark, i sistemi possono essere eccessivamente ottimizzati per benchmark specifici, portando a punteggi di prestazioni gonfiati che non si traducono necessariamente in efficacia nel mondo reale. Il design modulare di MLPerf Tiny mira ad affrontare questo problema consentendo ai collaboratori di scambiare e testare componenti specifici all'interno di un framework standardizzato, come hardware, tecniche di quantizzazione o modelli di inferenza. Le implementazioni di riferimento, evidenziate in verde e arancione in @fig-ml-perf, forniscono una base di riferimento per i risultati, consentendo test flessibili ma controllati specificando quali componenti possono essere modificati. Questa struttura supporta trasparenza e flessibilità, consentendo di concentrarsi su miglioramenti genuini piuttosto che su ottimizzazioni specifiche del benchmark.

![Design modulare del benchmark MLPerf Tiny, che mostra l'implementazione di riferimento con componenti modificabili. Questo approccio modulare consente test flessibili e mirati mantenendo una base di riferimento standardizzata. Fonte: @banbury2021mlperf.](images/png/mlperf_tiny.png){#fig-ml-perf}

Un altro metodo per ottenere trasparenza è attraverso la revisione paritaria dei benchmark. Ciò comporta che esperti indipendenti esaminino e convalidino la metodologia, i set di dati e i risultati del benchmark per garantirne la credibilità e l'affidabilità. La revisione paritaria può fornire un mezzo prezioso per verificare l'accuratezza dei test di benchmark e contribuire a creare fiducia nei risultati.

La standardizzazione dei benchmark è un'altra importante soluzione per mitigare l'ingegneria dei benchmark. I benchmark standardizzati forniscono un quadro comune per la valutazione dei sistemi di intelligenza artificiale, garantendo coerenza e comparabilità tra diversi sistemi e applicazioni. Ciò può essere ottenuto sviluppando standard e "best practice" per l'intero settore per il benchmarking e tramite metriche e criteri di valutazione comuni.

Anche la verifica da parte di terze parti dei risultati può essere preziosa per mitigare l'ingegneria dei benchmark. Ciò comporta che una terza parte indipendente verifichi i risultati di un test di benchmark per garantirne la credibilità e l'affidabilità. La verifica di terze parti può creare fiducia nei risultati e fornire un mezzo prezioso per convalidare le prestazioni e le capacità dei sistemi di intelligenza artificiale.

## Benchmarking del Modello

Il benchmarking dei modelli di machine learning è importante per determinare l'efficacia e l'efficienza di vari algoritmi di apprendimento automatico nella risoluzione di compiti o problemi specifici. Analizzando i risultati ottenuti dal benchmarking, sviluppatori e ricercatori possono identificare i punti di forza e di debolezza dei loro modelli, portando a decisioni più informate sulla selezione del modello e su un'ulteriore ottimizzazione.

L'evoluzione e il progresso dei modelli di apprendimento automatico sono intrinsecamente collegati alla disponibilità e alla qualità dei set di dati. Nell'apprendimento automatico, i dati fungono da materia prima che alimenta gli algoritmi, consentendo loro di apprendere, adattarsi e, in definitiva, eseguire compiti che erano tradizionalmente di dominio degli esseri umani. Pertanto, è importante comprendere questa storia.

### Contesto Storico

I dataset di apprendimento automatico hanno una storia ricca e si sono evoluti in modo significativo nel corso degli anni, crescendo in dimensioni, complessità e diversità per soddisfare le richieste sempre crescenti del settore. Diamo un'occhiata più da vicino a questa evoluzione, partendo da uno dei primi e più iconici set di dati: MNIST.

#### MNIST (1998)

Il [dataset MNIST](https://www.tensorflow.org/datasets/catalog/mnist), creato da Yann LeCun, Corinna Cortes e Christopher J.C. Burges nel 1998, può essere considerato una pietra miliare nella storia dei dataset di machine learning. Comprende 70.000 immagini in scala di grigi da 28x28 pixel etichettate di cifre scritte a mano (0-9). MNIST è stato ampiamente utilizzato per il benchmarking degli algoritmi nell'elaborazione delle immagini e nell'apprendimento automatico come punto di partenza per molti ricercatori e professionisti. @fig-mnist mostra alcuni esempi di cifre scritte a mano.

![Cifre scritte a mano in MNIST. Fonte: [Suvanjanprasai](https://en.wikipedia.org/wiki/File:MnistExamplesModified.png)](images/png/mnist.png){#fig-mnist}

#### ImageNet (2009)

Facciamo un salto al 2009 e vediamo l'introduzione di [ImageNet](https://www.tensorflow.org/datasets/catalog/imagenet2012), che ha segnato un balzo significativo nella scala e nella complessità dei dataset. ImageNet è composto da oltre 14 milioni di immagini etichettate che abbracciano più di 20.000 categorie. Fei-Fei Li e il suo team lo hanno sviluppato per far progredire il riconoscimento degli oggetti e la ricerca sulla visione artificiale. Il dataset è diventato sinonimo della ImageNet [Large Scale Visual Recognition Challenge (LSVRC)](https://www.image-net.org/challenges/LSVRC/), una competizione annuale cruciale nello sviluppo di modelli di deep learning, tra cui il famoso AlexNet nel 2012.

#### COCO (2014)

Il [Common Objects in Context (COCO) dataset](https://cocodataset.org/) [@lin2014microsoft], rilasciato nel 2014, ha ulteriormente ampliato il panorama dei set di dati di apprendimento automatico introducendo un set più ricco di annotazioni. COCO è costituito da immagini contenenti scene complesse con più oggetti e ogni immagine è annotata con riquadri di delimitazione degli oggetti, maschere di segmentazione e didascalie, come mostrato in @fig-coco. Questo set di dati è stato determinante nel far progredire la ricerca nel rilevamento degli oggetti, nella segmentazione e nella didascalia delle immagini.

![Immagini di esempio dal set di dati COCO. Fonte: [Coco](https://cocodataset.org/)](images/png/coco.png){#fig-coco}

#### GPT-3 (2020)

Sebbene gli esempi sopra riportati si concentrino principalmente sui dataset di immagini, si sono verificati anche sviluppi significativi nei dataset di testo. Un esempio degno di nota è GPT-3 [@brown2020language], sviluppato da OpenAI. GPT-3 è un modello linguistico addestrato su testo Internet eterogeneo. Sebbene il dataset utilizzato per addestrare GPT-3 non sia disponibile al pubblico, il modello stesso, costituito da 175 miliardi di parametri, è una testimonianza della scala e della complessità dei moderni dataset e modelli di apprendimento automatico.

#### Presente e Futuro

Oggi disponiamo di una pletora di dataset che abbracciano vari domini, tra cui sanità, finanza, scienze sociali e altro ancora. Le seguenti caratteristiche ci aiutano a classificare lo spazio e la crescita dei dataset di apprendimento automatico che alimentano lo sviluppo del modello.

1. **Diversità dei Set di Dati:** La varietà di set di dati disponibili per ricercatori e ingegneri si è ampliata notevolmente, coprendo molti campi, tra cui l'elaborazione del linguaggio naturale, il riconoscimento delle immagini e altro ancora. Questa diversità ha alimentato lo sviluppo di modelli di apprendimento automatico specializzati, su misura per attività specifiche, come la traduzione, il riconoscimento vocale e il riconoscimento facciale.

2. **Volume di Dati:** L'enorme volume di dati che è diventato disponibile nell'era digitale ha anche svolto un ruolo cruciale nel progresso dei modelli di apprendimento automatico. I grandi set di dati consentono ai modelli di catturare la complessità e le sfumature dei fenomeni del mondo reale, portando a previsioni più accurate e affidabili.

3. **Qualità e Pulizia dei Dati:** La qualità dei dati è un altro fattore critico che influenza le prestazioni dei modelli di apprendimento automatico. Set di dati puliti, ben etichettati e imparziali sono essenziali per modelli di addestramento solidi ed equi.

4. **Accesso Aperto ai Dati:** La disponibilità di set di dati "open-access" ha contribuito in modo significativo anche al progresso dell'apprendimento automatico. I dati "aperti" consentono ai ricercatori di tutto il mondo di collaborare, condividere approfondimenti e basarsi sul lavoro degli altri, portando a un'innovazione più rapida e allo sviluppo di modelli più avanzati.

5. **Problemi di Etica e Privacy:** Man mano che i set di dati crescono in dimensioni e complessità, le considerazioni etiche e i problemi di privacy diventano sempre più importanti. È in corso un dibattito sull'equilibrio tra lo sfruttamento dei dati per i progressi dell'apprendimento automatico e la protezione dei diritti alla privacy degli individui.

Lo sviluppo di modelli di apprendimento automatico si basa in larga misura sulla disponibilità di set di dati diversificati, grandi, di alta qualità e ad accesso libero. Mentre andiamo avanti, affrontare le considerazioni etiche e le preoccupazioni sulla privacy associate all'uso di grandi set di dati è fondamentale per garantire che le tecnologie di apprendimento automatico siano vantaggiose per la società. C'è una crescente consapevolezza che i dati agiscono come carburante per l'apprendimento automatico, guidando e alimentando lo sviluppo di modelli di apprendimento automatico. Di conseguenza, si sta ponendo maggiore attenzione sullo sviluppo dei set di dati stessi. Esploreremo questo aspetto in modo più dettagliato nella sezione del benchmarking dei dati.

### Metriche del Modello

La valutazione del modello di machine learning si è evoluta da un focus ristretto sulla precisione a un approccio più completo che considera una serie di fattori, da considerazioni etiche e applicabilità nel mondo reale a vincoli pratici come dimensioni ed efficienza del modello. Questo cambiamento riflette la maturazione del campo poiché i modelli di apprendimento automatico vengono sempre più applicati in scenari reali diversi e complessi.

#### Precisione

La precisione è una delle metriche più intuitive e comunemente utilizzate per valutare i modelli di apprendimento automatico. Nelle prime fasi dell'apprendimento automatico, la precisione era spesso la metrica principale, se non l'unica, considerata quando si valutavano le prestazioni del modello. Tuttavia, con l'evoluzione del campo, è diventato chiaro che fare affidamento esclusivamente sull'accuratezza può essere fuorviante, soprattutto in applicazioni in cui determinati tipi di errori comportano conseguenze significative.

Si consideri l'esempio di un modello di diagnosi medica con una precisione del 95%. Sebbene a prima vista possa sembrare impressionante, dobbiamo guardare più a fondo per valutare appieno le prestazioni del modello. Supponiamo che il modello non riesca a diagnosticare accuratamente condizioni gravi che, sebbene rare, possono avere gravi conseguenze; la sua elevata precisione potrebbe non essere così significativa. Un esempio ben noto di questa limitazione è il [modello di retinopatia diabetica di Google](https://about.google/intl/ALL_us/stories/seeingpotential/). Sebbene abbia raggiunto un'elevata accuratezza in laboratorio, ha incontrato delle difficoltà quando è stato implementato in cliniche reali in Thailandia, dove le variazioni nelle popolazioni di pazienti, la qualità delle immagini e i fattori ambientali ne hanno ridotto l'efficacia. Questo esempio illustra che anche i modelli con elevata accuratezza devono essere testati per la loro capacità di generalizzare in condizioni diverse e imprevedibili per garantire affidabilità e impatto in contesti reali.

Allo stesso modo, se il modello funziona bene in media ma mostra significative disparità nelle prestazioni tra diversi gruppi demografici, anche questo sarebbe motivo di preoccupazione. L'evoluzione dell'apprendimento automatico ha quindi visto uno spostamento verso un approccio più olistico alla valutazione del modello, tenendo conto non solo dell'accuratezza, ma anche di altri fattori cruciali come la correttezza, trasparenza e applicabilità nel mondo reale. Un esempio lampante è il progetto [Gender Shades](http://gendershades.org/) del MIT Media Lab, guidato da Joy Buolamwini, che evidenzia i pregiudizi ottenendo risultati migliori sui volti maschili e dalla pelle più chiara rispetto ai volti femminili e dalla pelle più scura.

Sebbene l'accuratezza resti essenziale per valutare i modelli di apprendimento automatico, è necessario un approccio completo per valutare appieno le prestazioni. Ciò include metriche aggiuntive per l'equità, la trasparenza e l'applicabilità nel mondo reale, insieme a test rigorosi su diversi set di dati per identificare e affrontare i pregiudizi. Questo approccio di valutazione olistico riflette la crescente consapevolezza del settore delle implicazioni nel mondo reale nell'implementazione dei modelli.

#### Equità

Il "fairness" [equità] nell'apprendimento automatico implica la garanzia che i modelli funzionino in modo coerente su diversi gruppi, in particolare in applicazioni ad alto impatto come approvazioni di prestiti, assunzioni e giustizia penale. Affidarsi esclusivamente all'accuratezza può essere fuorviante se il modello mostra risultati distorti su gruppi demografici. Ad esempio, un modello di approvazione dei prestiti con elevata accuratezza potrebbe comunque negare sistematicamente i prestiti a determinati gruppi, sollevando dubbi sulla sua equità.

Il "bias" [distorsione] nei modelli può sorgere direttamente, quando attributi sensibili come razza o genere influenzano le decisioni, o indirettamente, quando caratteristiche neutre sono correlate a questi attributi, influenzando i risultati. Affidarsi semplicemente all'accuratezza può essere insufficiente quando si valutano i modelli. Ad esempio, si consideri un modello di approvazione dei prestiti con un tasso di accuratezza del 95%. Sebbene questa cifra possa sembrare impressionante a prima vista, non rivela come il modello si comporta nei diversi gruppi demografici. Un esempio ben noto è lo strumento COMPAS utilizzato nel sistema di giustizia penale degli Stati Uniti, che ha mostrato pregiudizi razziali nel prevedere la recidiva nonostante non utilizzasse esplicitamente la razza come variabile.

Per affrontare l'equità è necessario analizzare le prestazioni di un modello tra i gruppi, identificare i pregiudizi e applicare misure correttive come il ribilanciamento dei set di dati o l'utilizzo di algoritmi consapevoli dell'equità. Ricercatori e professionisti sviluppano continuamente metriche e metodologie su misura per casi d'uso specifici per valutare la correttezza e l'equità in scenari del mondo reale. Ad esempio, l'analisi di impatto disparato, la parità demografica e le pari opportunità sono alcune delle metriche impiegate per valutare l'equità/correttezza. Inoltre, la trasparenza e l'interpretabilità dei modelli sono fondamentali per raggiungere la correttezza. Strumenti come [AI Fairness 360](https://ai-fairness-360.org/) e [Fairness Indicators](https://www.tensorflow.org/tfx/guide/fairness_indicators) aiutano a spiegare come un modello prende decisioni, consentendo agli sviluppatori di rilevare e correggere problemi di equità nei modelli di apprendimento automatico.

Sebbene l'accuratezza sia una metrica preziosa, non sempre fornisce il quadro completo; la valutazione dell'equità garantisce che i modelli siano efficaci in scenari del mondo reale. Garantire l'equità/correttezza nei modelli di apprendimento automatico, in particolare nelle applicazioni che hanno un impatto significativo sulla vita delle persone, richiede una rigorosa valutazione delle prestazioni del modello in gruppi diversi, un'attenta identificazione e attenuazione dei pregiudizi e l'implementazione di misure di trasparenza e interpretabilità.

#### Complessità

##### Parametri

Nelle fasi iniziali del machine learning, il benchmarking dei modelli si basava spesso sui conteggi dei parametri come proxy [sostituto] per la complessità del modello. La logica era che più parametri in genere portano a un modello più complesso, che dovrebbe, a sua volta, fornire prestazioni migliori. Tuttavia, questo approccio trascura i costi pratici associati all'elaborazione di modelli di grandi dimensioni. Man mano che aumenta il numero dei parametri, aumentano anche le risorse computazionali richieste, rendendo tali modelli poco pratici per l'implementazione in scenari reali, in particolare su dispositivi con potenza di elaborazione limitata.

Affidarsi ai conteggi dei parametri come proxy per la complessità del modello non riesce a considerare anche l'efficienza del modello. Un modello ben ottimizzato con meno parametri può spesso ottenere prestazioni paragonabili o addirittura superiori a un modello più grande. Ad esempio, MobileNets, sviluppato da Google, è una famiglia di modelli progettati specificamente per dispositivi mobili ed edge. Hanno utilizzato convoluzioni separabili in profondità per ridurre il numero dei parametri e le richieste computazionali mantenendo comunque prestazioni elevate.

Alla luce di queste limitazioni, il settore si è spostato verso un approccio più olistico al benchmarking dei modelli che considera i conteggi dei parametri e altri fattori cruciali come le operazioni in virgola mobile al secondo (FLOP), il consumo di memoria e la latenza. Questo approccio completo bilancia le prestazioni con la distribuibilità, assicurando che i modelli non siano solo accurati, ma anche efficienti e adatti alle applicazioni del mondo reale.

##### FLOP

I "floating-point operation" (FLOP), o operazioni in virgola mobile al secondo, sono diventati una metrica critica per rappresentare il carico computazionale di un modello. Tradizionalmente, il numero dei parametri veniva utilizzato come indicatore per la complessità del modello, basandosi sul presupposto che più parametri avrebbero prodotto prestazioni migliori. Tuttavia, questo approccio trascura il costo computazionale dell'elaborazione di questi parametri, che può influire sull'usabilità di un modello in scenari del mondo reale con risorse limitate.

I FLOP misurano il numero di operazioni in virgola mobile eseguite da un modello per generare una previsione. Un modello con molti FLOP richiede risorse computazionali sostanziali per elaborare il vasto numero di operazioni, il che potrebbe renderlo poco pratico per alcune applicazioni. Al contrario, un modello con un numero di FLOP inferiore è più leggero e può essere facilmente distribuito in scenari in cui le risorse computazionali sono limitate. @fig-flops, da [@bianco2018benchmark], illustra il compromesso tra accuratezza di ImageNet, FLOP e numero dei parametri, dimostrando che alcune architetture raggiungono un'efficienza maggiore di altre.

![Un grafico che raffigura la top-1 Imagenet Accuracy rispetto al numero di FLOP di un modello insieme al conteggio dei parametri del modello. La figura mostra un compromesso complessivo tra complessità e accuratezza del modello, sebbene alcune architetture del modello siano più efficienti di altre. Fonte: @bianco2018benchmark.](images/png/model_FLOPS_VS_TOP_1.png){#fig-flops}

Consideriamo un esempio. BERT---Bidirectional Encoder Representations from Transformers [@devlin2018bert]---è un modello di elaborazione del linguaggio naturale molto diffuso, con oltre 340 milioni di parametri, il che lo rende un modello di grandi dimensioni con elevata accuratezza e prestazioni impressionanti in diverse attività. Tuttavia, le dimensioni di BERT, unite al suo elevato numero di FLOP, lo rendono un modello computazionalmente intensivo che potrebbe non essere adatto per applicazioni in tempo reale o per l'implementazione su dispositivi edge con capacità computazionali limitate. Alla luce di ciò, c'è stato un crescente interesse nello sviluppo di modelli più piccoli in grado di raggiungere livelli di prestazioni simili alle loro controparti più grandi, pur essendo più efficienti nel carico computazionale. DistilBERT, ad esempio, è una versione più piccola di BERT che mantiene il 97% delle sue prestazioni, pur essendo il 40% più piccola in termini di numero di parametri. La riduzione delle dimensioni si traduce anche in un numero di FLOP inferiore, rendendo DistilBERT una scelta più pratica per scenari con risorse limitate.

Sebbene il numero dei parametri indichi la dimensione del modello, non cattura completamente il costo computazionale. I FLOP forniscono una misura più accurata del carico computazionale, evidenziando i compromessi pratici nell'implementazione del modello. Questo passaggio dal conteggio dei parametri ai FLOP riflette la crescente consapevolezza del settore delle sfide di implementazione in contesti diversi.

##### Efficienza

Anche le metriche di efficienza, come il consumo di memoria e la latenza/capacità di elaborazione, hanno acquisito importanza. Queste metriche sono particolarmente cruciali quando si distribuiscono modelli su dispositivi edge o in applicazioni in tempo reale, poiché misurano la velocità con cui un modello può elaborare i dati e la quantità di memoria richiesta. In questo contesto, le curve di Pareto vengono spesso utilizzate per visualizzare il compromesso tra diverse metriche, aiutando le parti interessate a decidere quale modello si adatta meglio alle loro esigenze.

### Lezioni Apprese

Il benchmarking dei modelli ci ha offerto diverse preziose intuizioni che possono essere sfruttate per guidare l'innovazione nei benchmark di sistema. La progressione dei modelli di apprendimento automatico è stata profondamente influenzata dall'avvento delle classifiche e dalla disponibilità open source di modelli e set di dati. Questi elementi hanno svolto il ruolo di catalizzatori significativi, spingendo l'innovazione e accelerando l'integrazione di modelli all'avanguardia negli ambienti di produzione. Tuttavia, come approfondiremo ulteriormente, questi non sono gli unici fattori che contribuiscono allo sviluppo dei benchmark di apprendimento automatico.

Le classifiche svolgono un ruolo fondamentale nel fornire un metodo oggettivo e trasparente per ricercatori e professionisti per valutare l'efficacia di diversi modelli, classificandoli in base alle loro prestazioni nei benchmark. Questo sistema promuove un ambiente competitivo, incoraggiando lo sviluppo di modelli che non siano solo accurati ma anche efficienti. L'ImageNet Large Scale Visual Recognition Challenge (ILSVRC) ne è un ottimo esempio, con la sua classifica annuale che contribuisce in modo significativo allo sviluppo di modelli innovativi come AlexNet.

L'accesso open source a modelli e set di dati all'avanguardia diffonde ulteriormente l'apprendimento automatico, facilitando la collaborazione tra ricercatori e professionisti in tutto il mondo. Questo accesso aperto accelera il processo di test, convalida e distribuzione di nuovi modelli in ambienti di produzione, come dimostrato dall'adozione diffusa di modelli come BERT e GPT-3 in varie applicazioni, dall'elaborazione del linguaggio naturale a compiti multimodali più complessi.

Piattaforme di collaborazione della comunità come Kaggle hanno rivoluzionato il settore ospitando competizioni che uniscono data scientist da tutto il mondo per risolvere problemi intricati. Benchmark specifici fungono da paletti per l'innovazione e lo sviluppo di modelli.

Inoltre, la disponibilità di set di dati diversi e di alta qualità è fondamentale per l'addestramento e il test dei modelli di apprendimento automatico. Set di dati come ImageNet hanno svolto un ruolo fondamentale nell'evoluzione dei modelli di riconoscimento delle immagini, mentre ampi set di dati di testo hanno facilitato i progressi nei modelli di elaborazione del linguaggio naturale.

Infine, è necessario supportare i contributi di istituti accademici e di ricerca. Il loro ruolo nella pubblicazione di articoli di ricerca, nella condivisione di risultati in conferenze e nella promozione della collaborazione tra varie istituzioni ha contribuito in modo significativo al progresso dei modelli e dei benchmark di apprendimento automatico.

#### Tendenze Emergenti

Man mano che i modelli di apprendimento automatico diventano più sofisticati, lo diventano anche i benchmark necessari per valutarli in modo accurato. Ci sono diversi benchmark e dataset emergenti che stanno guadagnando popolarità grazie alla loro capacità di valutare i modelli in scenari più complessi e realistici:

**Dataset Multimodali:** Questi set di dati contengono più tipi di dati, come testo, immagini e audio, per rappresentare meglio le situazioni del mondo reale. Un esempio è VQA (Visual Question Answering) [@antol2015vqa], in cui viene testata la capacità dei modelli di rispondere a domande basate su testo sulle immagini.

**Valutazione di Correttezza e Bias:** C'è una crescente attenzione alla creazione di benchmark che valutino l'equità/Correttezza e i bias [pregiudizi] dei modelli di apprendimento automatico. Esempi includono il toolkit [AI Fairness 360](https://ai-fairness-360.org/), che offre un set completo di metriche e set di dati per valutare il bias nei modelli.

**Generalizzazione Out-of-Distribution:** Test di quanto bene i modelli funzionano su dati diversi dalla distribuzione di training originale. Questo valuta la capacità del modello di generalizzare a dati nuovi e inediti. Esempi di benchmark sono Wilds [@koh2021wilds], RxRx e ANC-Bench.

**Robustezza Avversaria:** Valutazione delle prestazioni del modello in caso di attacchi avversari o perturbazioni ai dati di input. Questo testa la robustezza del modello. Esempi di benchmark sono ImageNet-A [@hendrycks2021natural], ImageNet-C [@xie2020adversarial] e CIFAR-10.1.

**Prestazioni nel Mondo Reale:** Test di modelli su set di dati del mondo reale che corrispondono da vicino alle attività finali anziché solo su set di dati di benchmark predefiniti. Esempi sono set di dati di imaging medico per attività sanitarie o log di chat di assistenza clienti per sistemi di dialogo.

**Efficienza Energetica e di Calcolo:** Benchmark che misurano le risorse di calcolo necessarie per ottenere una particolare accuratezza. Questo valuta l'efficienza del modello. Esempi sono MLPerf e Greenbench, già discussi nella sezione Benchmarking dei sistemi.

**Interpretabilità e Spiegabilità:** Benchmark che valutano quanto sia facile comprendere e spiegare la logica interna e le previsioni di un modello. Esempi di parametri sono la fedeltà ai gradienti di input e la coerenza delle spiegazioni.

### Limitazioni e Sfide

Sebbene i benchmark dei modelli siano uno strumento essenziale per valutare i modelli di machine learning, è necessario affrontare diverse limitazioni e sfide per garantire che riflettano accuratamente le prestazioni in scenari reali.

**Il dataset non corrisponde a scenari reali:** Spesso, i dati utilizzati nei benchmark dei modelli vengono puliti e preelaborati a tal punto che potrebbe essere necessario rappresentare accuratamente i dati che un modello incontrerebbe in applicazioni reali. Questa versione idealizzata dei dati può portare a una sovrastima delle prestazioni di un modello. Nel caso del set di dati ImageNet, le immagini sono ben etichettate e categorizzate. Tuttavia, in uno scenario reale, un modello potrebbe dover gestire immagini sfocate che potrebbero essere meglio illuminate o scattate da angolazioni scomode. Questa discrepanza può influire in modo significativo sulle prestazioni del modello.

**Sim2Real Gap:** Il Sim2Real Gap si riferisce alla differenza nelle prestazioni di un modello quando si passa da un ambiente simulato a un ambiente reale. Questo gap è spesso osservato nella robotica, dove un robot addestrato in un ambiente simulato ha difficoltà a svolgere compiti nel mondo reale a causa della complessità e dell'imprevedibilità degli ambienti reali. Un robot addestrato a raccogliere oggetti in un ambiente simulato potrebbe aver bisogno di aiuto per svolgere lo stesso compito nel mondo reale perché l'ambiente simulato non rappresenta accuratamente le complessità della fisica, dell'illuminazione e della variabilità degli oggetti del mondo reale.

**Sfide nella Creazione di Dataset:** La creazione di un set di dati per il benchmarking del modello è un'attività impegnativa che richiede un'attenta considerazione di vari fattori come qualità dei dati, diversità e rappresentazione. Come discusso nella sezione di ingegneria dei dati, garantire che i dati siano puliti, imparziali e rappresentativi dello scenario del mondo reale è fondamentale per l'accuratezza e l'affidabilità del benchmark. Ad esempio, quando si crea un set di dati per un'attività correlata all'assistenza sanitaria, è importante assicurarsi che i dati siano rappresentativi dell'intera popolazione e non distorti verso un particolare gruppo demografico. Ciò garantisce che il modello funzioni bene in diverse popolazioni di pazienti.

I benchmark del modello sono essenziali per misurare la capacità di un'architettura di modello di risolvere un'attività fissa, ma è importante affrontare le limitazioni e le sfide ad essi associate. Ciò include il garantire che il set di dati rappresenti accuratamente scenari del mondo reale, affrontare il divario Sim2Real e superare le sfide della creazione di set di dati imparziali e rappresentativi. Affrontando queste sfide e molte altre, possiamo garantire che i benchmark del modello forniscano una valutazione più accurata e affidabile delle prestazioni di un modello in applicazioni del mondo reale.

Lo [Speech Commands dataset](https://arxiv.org/pdf/1804.03209.pdf) e il suo successore [MSWC](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/fe131d7f5a6b38b23cc967316c13dae2-Paper-round2.pdf) sono benchmark comuni per una delle applicazioni TinyML per eccellenza, l'individuazione delle parole chiave. I comandi vocali stabiliscono metriche di errore di streaming oltre la precisione di classificazione standard top-1 più pertinenti al caso d'uso di individuazione delle parole chiave. L'utilizzo di metriche pertinenti ai casi è ciò che eleva un dataset a un benchmark del modello.

## Benchmarking dei Dati

Negli ultimi anni, l'intelligenza artificiale si è concentrata sullo sviluppo di modelli di apprendimento automatico sempre più sofisticati, come i grandi modelli linguistici. L'obiettivo è stato quello di creare modelli in grado di prestazioni di livello umano o sovrumane su un'ampia gamma di attività, addestrandoli su enormi set di dati. Questo approccio incentrato sul modello ha prodotto rapidi progressi, con modelli che hanno ottenuto risultati all'avanguardia su molti benchmark consolidati. @fig-superhuman-perf mostra le prestazioni dei sistemi di intelligenza artificiale rispetto alle prestazioni umane (contrassegnate dalla linea orizzontale a 0) in cinque applicazioni: riconoscimento della scrittura a mano, riconoscimento vocale, riconoscimento delle immagini, comprensione della lettura e comprensione del linguaggio. Negli ultimi dieci anni, le prestazioni dell'intelligenza artificiale hanno superato quelle degli esseri umani.

![IA e prestazioni umane. Fonte: @kiela2021dynabench.](images/png/dynabench.png){#fig-superhuman-perf}

Tuttavia, le crescenti preoccupazioni su questioni come pregiudizi, sicurezza e robustezza persistono anche nei modelli che raggiungono un'elevata accuratezza sui benchmark standard. Inoltre, alcuni set di dati popolari utilizzati per la valutazione dei modelli stanno iniziando a saturarsi, con modelli che raggiungono prestazioni quasi perfette su divisioni di test esistenti [@kiela2021dynabench]. Come semplice esempio, ci sono immagini di test nel classico dataset di cifre scritte a mano MNIST che potrebbero sembrare indecifrabili per la maggior parte dei valutatori umani, ma a cui è stata assegnata un'etichetta quando è stato creato il set di dati: i modelli che concordano con quelle etichette potrebbero sembrare esibire prestazioni sovrumane, ma potrebbero invece catturare solo idiosincrasie del processo di etichettatura e acquisizione dalla creazione del set di dati nel 1994. Con lo stesso spirito, i ricercatori di visione artificiale ora chiedono: "Abbiamo finito con ImageNet?" [@beyer2020we]. Ciò evidenzia i limiti nell'approccio convenzionale incentrato sul modello di ottimizzazione dell'accuratezza su set di dati fissi tramite innovazioni architettoniche.

Sta emergendo un paradigma alternativo chiamato IA incentrata sui dati. Invece di trattare i dati come statici e concentrarsi strettamente sulle prestazioni del modello, questo approccio riconosce che i modelli sono validi solo quanto i loro dati di training. Quindi, l'enfasi si sposta sulla cura di dataset di alta qualità che riflettano meglio la complessità del mondo reale, sviluppando benchmark di valutazione più informativi e considerando attentamente come i dati vengono campionati, preelaborati e aumentati. L'obiettivo è ottimizzare il comportamento del modello migliorando i dati anziché semplicemente ottimizzando le metriche su set di dati imperfetti. L'intelligenza artificiale incentrata sui dati esamina e migliora criticamente i dati stessi per produrre un'intelligenza artificiale utile. Ciò riflette un'importante evoluzione nella mentalità, poiché il campo affronta le carenze di un benchmarking ristretto.

Questa sezione esplorerà le principali differenze tra gli approcci all'intelligenza artificiale incentrati sui modelli e sui dati. Questa distinzione ha importanti implicazioni sul modo in cui eseguiamo il benchmarking dei sistemi di intelligenza artificiale. In particolare, vedremo come concentrarsi sulla qualità dei dati e sull'efficienza può migliorare direttamente le prestazioni dell'apprendimento automatico come alternativa all'ottimizzazione delle sole architetture dei modelli. L'approccio incentrato sui dati riconosce che i modelli sono validi solo quanto i loro dati di addestramento. Quindi, migliorare la cura dei dati, i benchmark di valutazione e i processi di gestione dei dati può produrre sistemi di intelligenza artificiale più sicuri, più equi e più robusti. Ripensare il benchmarking per dare priorità ai dati insieme ai modelli rappresenta un'importante evoluzione, poiché il settore si sforza di fornire un impatto affidabile nel mondo reale.

### Limitazioni dell'IA Incentrata sul Modello

Nell'era dell'IA incentrata sul modello, una caratteristica importante era lo sviluppo di architetture di modelli complesse. Ricercatori e professionisti hanno dedicato notevoli sforzi alla progettazione di modelli sofisticati e intricati nella ricerca di prestazioni superiori. Ciò ha spesso comportato l'incorporazione di livelli aggiuntivi e la messa a punto di una moltitudine di iperparametri per ottenere miglioramenti nell'accuratezza. Contemporaneamente, c'era una notevole enfasi sullo sfruttamento di algoritmi avanzati. Questi algoritmi, spesso in prima linea nelle ultime ricerche, sono stati impiegati per migliorare le prestazioni dei modelli di IA. L'obiettivo principale di questi algoritmi era ottimizzare il processo di apprendimento dei modelli, estraendo così il massimo delle informazioni dai dati di addestramento.

Sebbene l'approccio incentrato sul modello sia stato centrale per molti progressi nell'IA, ha diverse aree di miglioramento. Innanzitutto, lo sviluppo di architetture di modelli complesse può spesso portare a un overfitting. Questo è quando il modello funziona bene sui dati di addestramento ma deve generalizzare a nuovi dati mai visti. I layer aggiuntivi e la complessità possono catturare il rumore nei dati di training come se fosse un pattern reale, danneggiando le prestazioni del modello su nuovi dati.

In secondo luogo, affidarsi ad algoritmi avanzati può a volte oscurare la reale comprensione del funzionamento di un modello. Questi algoritmi spesso agiscono come una scatola nera, rendendo difficile interpretare il modo in cui il modello prende decisioni. Questa mancanza di trasparenza può essere un ostacolo significativo, specialmente in applicazioni critiche come sanità e finanza, dove la comprensione del processo decisionale del modello è fondamentale.

In terzo luogo, l'enfasi sul raggiungimento di risultati all'avanguardia su set di dati di riferimento può a volte essere fuorviante. Questi dataset devono rappresentare in modo più completo le complessità e la variabilità dei dati del mondo reale. Un modello che funziona bene su un set di dati di riferimento potrebbe non essere necessariamente generalizzato bene a dati nuovi e mai visti in un'applicazione del mondo reale. Questa discrepanza può portare a una falsa fiducia nelle capacità del modello e ostacolarne l'applicabilità pratica.

Infine, l'approccio incentrato sul modello spesso si basa su grandi set di dati etichettati per l'addestramento. Tuttavia, ottenere tali set di dati richiede tempo e impegno in molti scenari del mondo reale. Questa dipendenza da grandi dataset limita anche l'applicabilità dell'IA in domini in cui i dati sono scarsi o costosi da etichettare.

Come risultato delle ragioni di cui sopra, e di molte altre, la comunità dell'IA sta passando a un approccio più incentrato sui dati. Invece di concentrarsi solo sull'architettura del modello, i ricercatori stanno ora dando priorità alla cura di set di dati di alta qualità, allo sviluppo di migliori benchmark di valutazione e alla considerazione di come i dati vengono campionati e preelaborati. L'idea chiave è che i modelli sono validi solo quanto i loro dati di training. Quindi, concentrandoci sull'ottenimento dei dati giusti, potremo sviluppare sistemi di intelligenza artificiale più equi, sicuri e allineati con i valori umani. Questo cambiamento incentrato sui dati rappresenta un importante cambiamento di mentalità man mano che l'intelligenza artificiale progredisce.

### Verso un'Intelligenza Artificiale Incentrata sui Dati

L'intelligenza artificiale incentrata sui dati è un paradigma che sottolinea l'importanza di dataset di alta qualità, ben etichettati e diversificati nello sviluppo di modelli di intelligenza artificiale. Contrariamente all'approccio incentrato sul modello, che si concentra sulla rifinitura e l'iterazione dell'architettura e dell'algoritmo del modello per migliorare le prestazioni, l'intelligenza artificiale incentrata sui dati dà priorità alla qualità dei dati di input come motore principale per migliorare le prestazioni del modello. I dati di alta qualità sono [puliti, ben etichettati](https://landing.ai/blog/tips-for-a-data-centric-ai-approach/) e rappresentativi degli scenari del mondo reale che il modello incontrerà. Al contrario, i dati di bassa qualità possono portare a scarse prestazioni del modello, indipendentemente dalla complessità o dalla sofisticatezza dell'architettura del modello.

L'intelligenza artificiale incentrata sui dati pone una forte enfasi sulla pulizia e l'etichettatura dei dati. La pulizia comporta la rimozione di valori anomali, la gestione dei valori mancanti e la risoluzione di altre incongruenze nei dati. L'etichettatura, d'altro canto, comporta l'assegnazione di etichette significative e accurate ai dati. Entrambi questi processi sono fondamentali per garantire che il modello di intelligenza artificiale venga addestrato su dati accurati e pertinenti. Un altro aspetto importante dell'approccio incentrato sui dati è il "data augmentation" [l'aumento dei dati]. Ciò comporta l'aumento artificiale delle dimensioni e della diversità del set di dati applicando varie trasformazioni ai dati, come rotazione, ridimensionamento e capovolgimento delle immagini di addestramento. L'aumento dei dati aiuta a migliorare la robustezza del modello e le capacità di generalizzazione.

Ci sono diversi vantaggi nell'adottare un approccio incentrato sui dati per lo sviluppo dell'intelligenza artificiale. Innanzitutto, porta a prestazioni del modello migliorate e capacità di generalizzazione. Assicurandosi che il modello venga addestrato su dati diversi e di alta qualità, il modello può generalizzare meglio a dati nuovi e mai visti [@gaviria2022dollar].

Inoltre, un approccio incentrato sui dati può spesso portare a modelli più semplici che sono più facili da interpretare e gestire. Questo perché l'enfasi è sui dati piuttosto che sull'architettura del modello, il che significa che i modelli più semplici possono raggiungere prestazioni elevate quando addestrati su dati di alta qualità.

Il passaggio all'IA incentrata sui dati rappresenta un significativo cambiamento di paradigma. Dando priorità alla qualità dei dati di input, questo approccio cerca di modellare le prestazioni e le capacità di generalizzazione, portando in ultima analisi a sistemi di intelligenza artificiale più solidi e affidabili. @fig-data-vs-model illustra questa differenza. Mentre continuiamo ad avanzare nella nostra comprensione e applicazione dell'IA, è probabile che l'approccio incentrato sui dati svolga un ruolo importante nel plasmare il futuro di questo campo.

![Sviluppo di machine learning incentrato sul modello e incentrato sui dati. Fonte: [NVIDIA](https://blogs.nvidia.com/blog/difference-deep-learning-training-inference-ai/)](images/png/datavsmodelai.png){#fig-data-vs-model}

### Benchmarking dei Dati

Il benchmarking dei dati mira a valutare problemi comuni nei set di dati, come l'identificazione di errori di etichetta, caratteristiche rumorose, squilibrio di rappresentazione (ad esempio, su 1000 classi in Imagenet-1K, ci sono oltre 100 categorie che sono solo tipi di cani), squilibrio di classe (dove alcune classi hanno molti più campioni di altre), se i modelli addestrati su un dato set di dati possono generalizzare a caratteristiche fuori distribuzione o quali tipi di bias potrebbero esistere in un dato set di dati [@gaviria2022dollar]. Nella sua forma più semplice, il benchmarking dei dati mira a migliorare l'accuratezza su un set di test rimuovendo campioni di addestramento rumorosi o etichettati in modo errato mantenendo fissa l'architettura del modello. Recenti competizioni nel benchmarking dei dati hanno invitato i partecipanti a presentare nuove strategie di "augmentation" e tecniche di apprendimento attivo.

Le tecniche incentrate sui dati continuano a guadagnare attenzione nel benchmarking, soprattutto perché i modelli di base sono sempre più addestrati su obiettivi auto-supervisionati. Rispetto ai set di dati più piccoli come Imagenet-1K, i set di dati più grandi comunemente usati nell'apprendimento auto-supervisionato, come Common Crawl, OpenImages e LAION-5B, contengono quantità maggiori di rumore, duplicati, bias e dati potenzialmente offensivi.

[DataComp](https://www.datacomp.ai/) è una competizione di dataset lanciata di recente che ha come obiettivo la valutazione di grandi corpora. DataComp si concentra sulle coppie linguaggio-immagine usate per addestrare i modelli CLIP. Il documento introduttivo rileva che quando il budget di elaborazione totale per l'addestramento è costante, i modelli CLIP più performanti nelle attività downstream, come la classificazione ImageNet, vengono addestrati solo sul 30% del pool di campioni disponibile. Ciò suggerisce che un corretto filtraggio di grandi corpora è fondamentale per migliorare l'accuratezza dei modelli di base. Analogamente, Demystifying CLIP Data [@xu2023demystifying] chiede se il successo di CLIP sia attribuibile all'architettura o al set di dati.

[DataPerf](https://www.dataperf.org/) è un altro recente lavoro incentrato sul benchmarking dei dati in varie modalità. DataPerf offre round di competizione online per stimolare il miglioramento dei dataset. L'offerta inaugurale è stata lanciata con sfide in termini di visione, parlato, acquisizione, debug e prompt di testo per la generazione di immagini.

### Efficienza dei Dati

Man mano che i modelli di apprendimento automatico diventano più grandi e complessi e le risorse di elaborazione diventano più scarse di fronte alla crescente domanda, diventa difficile soddisfare i requisiti di elaborazione anche con le flotte di machine learning più grandi. Per superare queste sfide e garantire la scalabilità del sistema di apprendimento automatico, è necessario esplorare nuove opportunità che aumentino gli approcci convenzionali alla scalabilità delle risorse.

Migliorare la qualità dei dati può essere un metodo utile per avere un impatto significativo sulle prestazioni del sistema di apprendimento automatico. Uno dei principali vantaggi del miglioramento della qualità dei dati è il potenziale di poter ridurre le dimensioni del set di dati di addestramento mantenendo o addirittura migliorando le prestazioni del modello. Questa riduzione delle dimensioni dei dati è direttamente correlata alla quantità di tempo di addestramento richiesto, consentendo così ai modelli di convergere in modo più rapido ed efficiente. Raggiungere questo equilibrio tra qualità dei dati e dimensioni del set di dati è un compito impegnativo che richiede lo sviluppo di metodi, algoritmi e tecniche sofisticati.

Possono essere adottati diversi approcci per migliorare la qualità dei dati. Questi metodi includono e non sono limitati a quanto segue:

* **Pulizia dei Dati:** Ciò comporta la gestione dei valori mancanti, la correzione degli errori e la rimozione dei valori anomali. I dati puliti assicurano che il modello non stia imparando da rumore o imprecisioni.
* **Interpretabilità e Spiegabilità dei Dati:** Le tecniche comuni includono LIME [@ribeiro2016should], che fornisce informazioni sui limiti decisionali dei classificatori, e valori Shapley [@lundberg2017unified], che stimano l'importanza dei singoli campioni nel contribuire alle previsioni di un modello.
* **Feature Engineering:** Trasformare o creare nuove funzionalità può migliorare significativamente le prestazioni del modello fornendo informazioni più pertinenti per l'apprendimento.
* **Data Augmentation:** Aumentare i dati creando nuovi campioni tramite varie trasformazioni può aiutare a migliorare la robustezza e la generalizzazione del modello.
* **Active Learning:** Questo è un approccio di apprendimento semi-supervisionato in cui il modello interroga attivamente un "oracolo" umano per etichettare i campioni più informativi [@coleman2022similarity]. Ciò garantisce che il modello venga addestrato sui dati più rilevanti.
* **Riduzione della Dimensionalità:** Tecniche come PCA possono ridurre il numero di feature in un set di dati, riducendo così la complessità e il tempo di training.

Esistono molti altri metodi in circolazione. Ma l'obiettivo è lo stesso. Affinare il set di dati e garantire che sia della massima qualità può ridurre il tempo di addestramento necessario per la convergenza dei modelli. Tuttavia, per raggiungere questo obiettivo è necessario sviluppare e implementare metodi, algoritmi e tecniche sofisticati in grado di pulire, preelaborare e aumentare i dati, mantenendo al contempo i campioni più informativi. Questa è una sfida continua che richiederà una continua ricerca e innovazione nel campo dell'apprendimento automatico.

## La Tripletta

Mentre i benchmark di sistema, modello e dati sono stati tradizionalmente studiati in modo isolato, si sta diffondendo la consapevolezza che per comprendere e far progredire completamente l'IA, dobbiamo adottare una visione più olistica. Iterando tra sistemi di benchmarking, modelli e dataset insieme, potrebbero emergere nuove intuizioni che non sono evidenti quando questi componenti vengono analizzati separatamente. Le prestazioni del sistema influiscono sulla precisione del modello, le capacità del modello determinano le esigenze dei dati e le caratteristiche dei dati determinano i requisiti del sistema.

Il benchmarking della triade di sistema, modello e dati in modo integrato porterà probabilmente a scoperte sulla progettazione congiunta dei sistemi di IA, sulle proprietà di generalizzazione dei modelli e sul ruolo della cura e della qualità dei dati nel consentire le prestazioni. Piuttosto che benchmark ristretti di singoli componenti, il futuro dell'IA richiede benchmark che valutino la relazione simbiotica tra piattaforme di elaborazione, algoritmi e dati di training. Questa prospettiva a livello di sistema sarà fondamentale per superare le attuali limitazioni e sbloccare il prossimo livello di capacità dell'IA.

@fig-benchmarking-trifecta illustra i molti modi potenziali per far interagire tra loro il benchmarking dei dati, quello dei modelli e quello dell'infrastruttura di sistema. L'esplorazione di queste complesse interazioni probabilmente porterà alla scoperta di nuove opportunità di ottimizzazione e capacità di miglioramento. La tripletta di benchmark di dati, modelli e sistemi offre un ricco spazio per la progettazione congiunta e la co-ottimizzazione.

![La tripletta del Benchmarking.](images/png/benchmarking_trifecta.png){#fig-benchmarking-trifecta}

Sebbene questa prospettiva integrata rappresenti una tendenza emergente, il settore ha ancora molto da scoprire sulle sinergie e i compromessi tra questi componenti. Mentre eseguiamo il benchmarking iterativo di combinazioni di dati, modelli e sistemi, emergeranno nuove intuizioni che rimangono nascoste quando questi elementi vengono studiati separatamente. Questo approccio di benchmarking multiforme che traccia le intersezioni di dati, algoritmi e hardware promette di essere una strada fruttuosa per importanti progressi nell'intelligenza artificiale, anche se è ancora nelle sue fasi iniziali.

## Benchmark per Tecnologie Emergenti

Date le loro significative differenze rispetto alle tecniche esistenti, le tecnologie emergenti possono essere particolarmente difficili da progettare per i benchmark. I benchmark standard utilizzati per le tecnologie esistenti potrebbero non evidenziare le feature chiave del nuovo approccio. Al contrario, i nuovi benchmark potrebbero essere visti come artificiosi per favorire la tecnologia emergente rispetto ad altre. Potrebbero essere così diversi dai benchmark esistenti da non poter essere compresi e perdere significato. Pertanto, i benchmark per le tecnologie emergenti devono bilanciare equità, applicabilità e facilità di confronto con quelli esistenti.

Un esempio di tecnologia emergente in cui il benchmarking si è dimostrato particolarmente difficile è nel [Neuromorphic Computing](@sec-neuromorphic). Utilizzando il cervello come fonte di ispirazione per un'intelligenza generale scalabile, robusta ed efficiente dal punto di vista energetico, il calcolo neuromorfico [@schuman2022opportunities] incorpora direttamente meccanismi biologicamente realistici sia negli algoritmi di calcolo che nell'hardware, come le reti neurali spiking [@maass1997networks] e le architetture non-von Neumann architectures per eseguirle [@davies2018loihi; @modha2023neural]. Da una prospettiva full-stack di modelli, tecniche di training e sistemi hardware, il calcolo neuromorfico differisce dall'hardware e dall'intelligenza artificiale convenzionali. Pertanto, esiste una sfida fondamentale nello sviluppo di benchmark equi e utili per guidare la tecnologia.

Un'iniziativa in corso per sviluppare benchmark neuromorfici standard è NeuroBench [@yik2023neurobench]. Per un benchmarking adeguato del neuromorfico, NeuroBench segue principi di alto livello di _inclusività_ attraverso l'applicabilità di attività e metriche sia alle soluzioni neuromorfiche che non neuromorfiche, _attuabilità_ dell'implementazione utilizzando strumenti comuni e aggiornamenti _iterativi_ per continuare a garantire la pertinenza man mano che il campo cresce rapidamente. NeuroBench e altri benchmark per le tecnologie emergenti forniscono una guida critica per le tecniche future, che potrebbero essere necessarie man mano che i limiti di scalabilità degli approcci esistenti si avvicinano.

## Conclusione

Ciò che viene misurato viene migliorato. Questo capitolo ha esplorato la natura multiforme del benchmarking che abbraccia sistemi, modelli e dati. Il benchmarking è importante per far progredire l'IA in quanto fornisce le misurazioni essenziali per monitorare i progressi.

I benchmark del sistema ML consentono l'ottimizzazione attraverso metriche di velocità, efficienza e scalabilità. I benchmark del modello guidano l'innovazione attraverso attività e metriche standardizzate oltre l'accuratezza. I benchmark dei dati evidenziano problemi di qualità, equilibrio e rappresentazione.

È importante notare che la valutazione di questi componenti in modo isolato presenta dei limiti. In futuro, sarà probabilmente utilizzato un benchmarking più integrato per esplorare l'interazione tra benchmark di sistema, modello e dati. Questa visione promette nuove intuizioni sulla progettazione congiunta di dati, algoritmi e infrastrutture.

Man mano che l'IA diventa più complessa, il benchmarking completo diventa ancora più critico. Gli standard devono evolversi continuamente per misurare nuove capacità e rivelare limitazioni. Una stretta collaborazione tra settore, mondo accademico, etichette nazionali, ecc. è essenziale per sviluppare benchmark rigorosi, trasparenti e socialmente utili.

Il benchmarking fornisce la bussola per guidare il progresso nell'IA. Misurando costantemente e condividendo apertamente i risultati, possiamo orientarci verso sistemi performanti, robusti e affidabili. Se l'IA deve soddisfare adeguatamente le esigenze sociali e umane, deve essere sottoposta a benchmarking tenendo a mente gli interessi dell'umanità. A tal fine, ci sono aree emergenti, come il benchmarking della sicurezza dei sistemi di IA, ma questo è per un altro giorno e qualcosa di cui possiamo discutere ulteriormente in "Generative AI"!

Il benchmarking è un argomento in continua evoluzione. L'articolo [The Olympics of AI: Benchmarking Machine Learning Systems](https://towardsdatascience.com/the-olympics-of-ai-benchmarking-machine-learning-systems-c4b2051fbd2b) copre diversi sottocampi emergenti nel benchmarking dell'IA, tra cui robotica, realtà estesa e calcolo neuromorfico che incoraggiamo il lettore ad approfondire.

## Risorse {#sec-benchmarking-ai-resource}

Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Lavoriamo continuamente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.

:::{.callout-note collapse="false"}

#### Slide

Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale secondo il proprio ritmo. Incoraggiamo studenti e docenti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.

* [Perché il benchmarking è importante?](https://docs.google.com/presentation/d/17udz3gxeYF3r3X1r4ePwu1I9H8ljb53W3ktFSmuDlGs/edit?usp=drive_link&resourcekey=0-Espn0a0x81kl2txL_jIWjw)

* [Benchmarking di inferenza embedded.](https://docs.google.com/presentation/d/18PI_0xmcW1xwwfcjmj25PikqBM_92vQfOXFV4hah-6I/edit?resourcekey=0-KO3HQcDAsR--jgbKd5cp4w#slide=id.g94db9f9f78_0_2)

:::

:::{.callout-important collapse="false"}

#### Video

* _Prossimamente._
:::

:::{.callout-caution collapse="false"}

#### Esercizi

Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.

* @exr-cuda

* @exr-perf
:::
