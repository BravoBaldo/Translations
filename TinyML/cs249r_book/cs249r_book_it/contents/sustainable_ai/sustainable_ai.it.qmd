---
bibliography: sustainable_ai.bib
---

# IA Sostenibile {#sec-sustainable_ai}

::: {.content-visible when-format="html"}
Risorse: [Slide](#sec-sustainable-ai-resource), [Video](#sec-sustainable-ai-resource), [Esercizi](#sec-sustainable-ai-resource), [Laboratori](#sec-sustainable-ai-resource)
:::

![_DALL·E 3 Prompt: Illustrazione 3D su uno sfondo chiaro di una rete IA sostenibile interconnessa con una miriade di fonti energetiche ecocompatibili. L'IA gestisce e ottimizza attivamente la sua energia da fonti come pannelli solari, turbine eoliche e dighe idroelettriche, enfatizzando l'efficienza energetica e le prestazioni. Reti neurali profonde si diffondono ovunque, ricevendo energia da queste risorse sostenibili._](images/png/cover_sustainable_ai.png)

::: {.callout-tip}

## Obiettivi dell'Apprendimento

* Comprendere l'impatto ambientale dell'IA, inclusi consumo energetico, emissioni di carbonio, rifiuti elettronici ed effetti sulla biodiversità.
* Informarsi su metodi e best practice per lo sviluppo di sistemi IA sostenibili
* Apprezzare l'importanza di adottare una prospettiva del ciclo di vita quando si valuta e si affronta la sostenibilità dei sistemi IA.
* Riconoscere i ruoli che vari stakeholder, come ricercatori, aziende, politici e utenti finali, svolgono nel promuovere un progresso IA responsabile e sostenibile.
* Scoprire framework, metriche e strumenti specifici per consentire uno sviluppo di IA più ecologico.
* Apprezzare i casi di studio del mondo reale come le pratiche di efficienza 4M di Google che mostrano come le organizzazioni stanno adottando misure tangibili per migliorare il record ambientale dell'IA

:::

## Introduzione

I rapidi progressi nell'intelligenza artificiale (IA) e nel machine learning (ML) [apprendimento automatico] hanno portato a molte applicazioni e ottimizzazioni utili per l'efficienza delle prestazioni. Tuttavia, la notevole crescita dell'IA ha un costo significativo ma spesso trascurato: il suo impatto ambientale. Il rapporto più recente pubblicato dall'IPCC, l'organismo internazionale che guida le valutazioni scientifiche del cambiamento climatico e dei suoi impatti, ha sottolineato l'importanza urgente di affrontare il cambiamento climatico. Senza sforzi immediati per ridurre le emissioni globali di $\textrm{CO}_2$ di almeno il 43 percento prima del 2030, supereremo il riscaldamento globale di 1,5 gradi Celsius [@lecocq2022mitigation]. Ciò potrebbe avviare cicli di feedback positivi, spingendo le temperature ancora più in alto. Accanto alle questioni ambientali, le Nazioni Unite hanno riconosciuto [17 Sustainable Development Goals (SDG)](https://sdgs.un.org/goals) [Obiettivi di sviluppo sostenibile], in cui l'IA può svolgere un ruolo importante e, viceversa, possono svolgere un ruolo importante nello sviluppo di sistemi di IA. Poiché il campo continua a espandersi, considerare la sostenibilità è fondamentale.

I sistemi di intelligenza artificiale, in particolare i grandi modelli linguistici come [GPT-3](https://openai.com/blog/gpt-3-apps/) e i modelli di visione artificiale come [DALL-E 2](https://openai.com/dall-e-2/), richiedono enormi quantità di risorse computazionali per l'addestramento. Ad esempio, si stima che GPT-3 consumi 1.300 megawattora di elettricità, pari a 1.450 famiglie medie statunitensi in un mese intero [@maslej2023artificial], o in altre parole, consuma abbastanza energia da rifornire una famiglia media statunitense per 120 anni! Questa immensa richiesta di energia deriva principalmente da data center affamati di energia con server che eseguono calcoli intensivi per addestrare queste complesse reti neurali per giorni o settimane.

Le stime attuali indicano che le emissioni di carbonio prodotte dallo sviluppo di un singolo modello di intelligenza artificiale sofisticato possono eguagliare le emissioni nell'arco di vita di cinque veicoli standard a benzina [@strubell2019energy]. Una parte significativa dell'elettricità attualmente consumata dai data center è generata da fonti non rinnovabili come carbone e gas naturale, con il risultato che i data center contribuiscono a circa l'[1% delle emissioni totali di carbonio a livello mondiale](https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks). Ciò è paragonabile alle emissioni dell'intero settore delle compagnie aeree. Questa immensa impronta di carbonio dimostra l'urgente necessità di passare a fonti di energia rinnovabili come l'energia solare ed eolica per gestire lo sviluppo dell'intelligenza artificiale.

Inoltre, anche i sistemi di intelligenza artificiale su piccola scala distribuiti su dispositivi edge come parte di TinyML hanno impatti ambientali che non dovrebbero essere ignorati [@prakash2023tinyml]. L'hardware specializzato richiesto per l'intelligenza artificiale ha un impatto ambientale dovuto all'estrazione e alla produzione di risorse naturali. GPU, CPU e chip come le TPU dipendono da metalli delle terre rare la cui estrazione e lavorazione generano un notevole inquinamento. Anche la produzione di questi componenti ha le sue richieste energetiche. Inoltre, la raccolta, l'archiviazione e la preelaborazione dei dati utilizzati per addestrare modelli sia su piccola che su larga scala comportano costi ambientali, esacerbando ulteriormente le implicazioni di sostenibilità dei sistemi ML.

Pertanto, mentre l'intelligenza artificiale promette innovazioni in molti campi, per sostenere il progresso è necessario affrontare le sfide della sostenibilità. L'intelligenza artificiale può continuare a progredire in modo responsabile ottimizzando l'efficienza dei modelli, esplorando hardware specializzato alternativo e fonti di energia rinnovabile per i data center e monitorando il suo impatto ambientale complessivo.

## Responsabilità Sociale ed Etica {#social-and-ethical-responsibility}

L'impatto ambientale dell'IA non è solo una questione tecnica, ma anche etica e sociale. Man mano che l'IA diventa sempre più integrata nelle nostre vite e nei nostri settori, la sua sostenibilità diventa sempre più critica.

### Considerazioni Etiche {#ethical-considerations}

La portata dell'impatto ambientale dell'IA solleva profonde questioni etiche sulle responsabilità degli sviluppatori e delle aziende di IA nel ridurre al minimo le emissioni di carbonio e l'uso di energia. In quanto creatori di sistemi e tecnologie di IA che possono avere impatti globali di vasta portata, gli sviluppatori hanno l'obbligo etico di integrare consapevolmente la tutela ambientale nel loro processo di progettazione, anche se la sostenibilità avviene a scapito di alcuni guadagni di efficienza.

C'è una chiara e attuale necessità per noi di avere conversazioni aperte e oneste sui compromessi ambientali dell'IA all'inizio del ciclo di vita dello sviluppo. I ricercatori dovrebbero sentirsi autorizzati a esprimere preoccupazioni se le priorità organizzative non sono allineate con gli obiettivi etici, come nel caso della [lettera aperta per sospendere i giganteschi esperimenti di IA](https://futureoflife.org/open-letter/pause-giant-ai-experiments/).

Inoltre, c'è una crescente necessità per le aziende di IA di esaminare attentamente i loro contributi al cambiamento climatico e al danno ambientale. Le grandi aziende tecnologiche sono responsabili dell'infrastruttura cloud, delle richieste di energia dei data center e dell'estrazione delle risorse necessarie per alimentare l'IA odierna. La leadership dovrebbe valutare se i valori e le politiche organizzative promuovano la sostenibilità, dalla produzione di hardware alle pipeline di training dei modelli.

Inoltre, potrebbe essere necessaria più di un'autoregolamentazione volontaria: i governi potrebbero dover introdurre nuove normative volte a standard e pratiche di intelligenza artificiale sostenibili se speriamo di frenare l'esplosione energetica prevista di modelli sempre più grandi. Le metriche segnalate come l'utilizzo del computer, l'impronta di carbonio e i parametri di riferimento dell'efficienza potrebbero responsabilizzare le organizzazioni.

Attraverso principi etici, politiche aziendali e regole pubbliche, i tecnici e le aziende di intelligenza artificiale hanno un profondo dovere nei confronti del nostro pianeta per garantire l'avanzamento responsabile e sostenibile della tecnologia in grado di trasformare radicalmente la società moderna. Dobbiamo alle generazioni future di fare le cose per bene.

### Sostenibilità a Lungo Termine {#long-term-sustainability}

La massiccia espansione prevista dell'IA solleva urgenti preoccupazioni sulla sua sostenibilità a lungo termine. Poiché il software e le applicazioni di IA aumentano rapidamente in complessità e utilizzo in tutti i settori, la domanda di potenza di calcolo e infrastrutture salirà alle stelle in modo esponenziale nei prossimi anni.

Per mettere in prospettiva la portata della crescita prevista, la capacità di calcolo totale richiesta per l'addestramento dei modelli di IA ha visto un sorprendente aumento di 350.000 volte dal 2012 al 2019 [@schwartz2020green]. I ricercatori prevedono una crescita di oltre un ordine di grandezza ogni anno, man mano che vengono sviluppati assistenti IA personalizzati, tecnologia autonoma, strumenti di medicina di precisione e altro ancora. Le tendenze sono simili per i sistemi ML embedded, con una stima di 2,5 miliardi di dispositivi edge abilitati all'IA distribuiti entro il 2030.

La gestione di questo livello di espansione richiede innovazioni incentrate su software e hardware in termini di efficienza e integrazione rinnovabile da parte di ingegneri e scienziati dell'IA. Dal lato software, nuove tecniche di ottimizzazione dei modelli, distillazione, potatura, numeri a bassa precisione, condivisione delle conoscenze tra sistemi e altre aree devono diventare best practice diffuse per frenare le esigenze energetiche. Ad esempio, realizzare anche una domanda di elaborazione ridotta del 50% per raddoppio della capacità avrebbe un impatto enorme sull'energia totale.

Dal lato dell'infrastruttura hardware, a causa dei crescenti costi di trasferimento dati, archiviazione, raffreddamento e spazio, continuare con l'attuale modello di server farm centralizzato nei data center è probabilmente irrealizzabile a lungo termine [@lannelongue2021green]. Esplorare opzioni di elaborazione decentralizzate alternative attorno a "edge AI" su dispositivi locali o all'interno di reti di telecomunicazioni può alleviare le pressioni di ridimensionamento sui data center iper-scalabili ad alto consumo energetico. Allo stesso modo, il passaggio a fonti di energia rinnovabile ibride e a zero emissioni di carbonio che alimentano i principali data center dei provider cloud in tutto il mondo sarà essenziale.

### IA per il Bene Ambientale {#ai-for-environmental-good}

Sebbene molta attenzione sia rivolta alle sfide di sostenibilità dell'IA, queste potenti tecnologie forniscono soluzioni uniche per combattere il cambiamento climatico e guidare il progresso ambientale. Ad esempio, l'apprendimento automatico può ottimizzare continuamente le reti elettriche intelligenti per migliorare l'integrazione delle energie rinnovabili e l'efficienza della distribuzione dell'elettricità attraverso le reti [@zhang2018review]. I modelli possono acquisire lo stato in tempo reale di una rete elettrica e le previsioni meteorologiche per allocare e spostare le fonti rispondendo alla domanda e all'offerta.

Le reti neurali ottimizzate si sono anche dimostrate notevolmente efficaci nelle [previsioni meteorologiche](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/) di prossima generazione [@lam2023learning] e nella modellazione climatica [@kurth2023fourcastnet]. Possono analizzare rapidamente enormi volumi di dati climatici per potenziare la preparazione agli eventi estremi e la pianificazione delle risorse per uragani, inondazioni, siccità e altro ancora. I ricercatori del clima hanno raggiunto un'accuratezza all'avanguardia del percorso delle tempeste combinando simulazioni di IA con modelli numerici tradizionali.

L'intelligenza artificiale consente inoltre un migliore monitoraggio della biodiversità [@silvestro2022improving], della fauna selvatica [@schwartz2021deployment], degli [ecosistemi](https://blogs.nvidia.com/blog/conservation-ai-detects-threats-to-endangered-species/#:~:text=The%20Conservation%20AI%20platform%20%E2%80%94%20built,of%20potential%20threats%20via%20email) e della deforestazione illegale tramite droni e satelliti. Gli algoritmi di visione artificiale possono automatizzare le stime della popolazione delle specie e le valutazioni della salute dell'habitat su vaste regioni non monitorate. Queste capacità forniscono agli ambientalisti potenti strumenti per combattere il bracconaggio [@bondi2018spot], ridurre i rischi di estinzione delle specie e comprendere i cambiamenti ecologici.

Investimenti mirati in applicazioni di intelligenza artificiale per la sostenibilità ambientale, la condivisione di dati intersettoriali e l'accessibilità dei modelli possono accelerare notevolmente le soluzioni a urgenti problemi ecologici. L'enfasi sull'intelligenza artificiale per il bene sociale indirizza l'innovazione in direzioni più pulite, guidando queste tecnologie che modellano il mondo verso uno sviluppo etico e responsabile.

### Caso di Studio

I data center di Google sono fondamentali per alimentare prodotti come Search, Gmail e YouTube, utilizzati quotidianamente da miliardi di persone. Tuttavia, mantenere attive e funzionanti le vaste server farm richiede molta energia, in particolare per i sistemi di raffreddamento essenziali. Google si impegna costantemente per migliorare l'efficienza in tutte le operazioni. Tuttavia, i progressi si stavano rivelando difficili solo con i metodi tradizionali, considerando le complesse dinamiche personalizzate coinvolte. Questa sfida ha spinto una svolta nell'apprendimento automatico, producendo potenziali risparmi.

Dopo oltre un decennio di ottimizzazione della progettazione dei data center, invenzione di hardware di elaborazione a basso consumo energetico e protezione di fonti di energia rinnovabili, [Google ha portato gli scienziati di DeepMind a sbloccare ulteriori progressi](https://blog.google/outreach-initiatives/environment/deepmind-ai-reduces-energy-used-for/). Gli esperti di intelligenza artificiale hanno affrontato fattori complessi che circondano il funzionamento degli apparati di raffreddamento industriali. Apparecchiature come pompe e refrigeratori interagiscono in modo non lineare, mentre cambiano anche le condizioni meteorologiche esterne e le variabili architettoniche interne. Catturare questa complessità ha confuso le rigide formule ingegneristiche e l'intuizione umana.

Il team DeepMind ha sfruttato i dati storici estesi dei sensori di Google che descrivono temperature, consumi energetici e altri attributi come input di training. Hanno creato un sistema flessibile basato su reti neurali per modellare le relazioni e prevedere configurazioni ottimali, riducendo al minimo la "power usage effectiveness (PUE)" [efficacia dell'utilizzo di energia] [@barroso2019datacenter]; PUE è la misura standard per valutare l'efficienza con cui un data center utilizza l'energia, che fornisce la percentuale di energia totale consumata dalla struttura divisa per l'energia utilizzata direttamente per le operazioni di elaborazione. Quando testato in tempo reale, il sistema AI ha prodotto notevoli guadagni rispetto alle innovazioni precedenti, riducendo l'energia di raffreddamento del 40% per un calo del 15% nel PUE totale, un nuovo record del sito. Il framework generalizzabile ha appreso rapidamente le dinamiche di raffreddamento in condizioni mutevoli che le regole statiche non potevano eguagliare. Questa svolta evidenzia il ruolo crescente dell'AI nella trasformazione della tecnologia moderna e nell'abilitazione di un futuro sostenibile.

## Consumo Energetico {#energy-consumption}

### Comprendere le Esigenze Energetiche {#understanding-energy-needs}

Comprendere le esigenze energetiche per il training e il funzionamento dei modelli di intelligenza artificiale è fondamentale nel campo in rapida evoluzione dell'intelligenza artificiale. Con l'intelligenza artificiale che sta entrando in uso diffuso in molti nuovi campi [@bohr2020rise; @sudhakar2023data], si prevede che la domanda di dispositivi e data center abilitati all'intelligenza artificiale esploderà. Questa comprensione ci aiuta a capire perché l'intelligenza artificiale, in particolare il deep learning, è spesso etichettata come ad alta intensità energetica.

#### Requisiti Energetici per il Training dell'Intelligenza Artificiale {#energy-requirements-for-ai-training}

Il training di sistemi di intelligenza artificiale complessi come i grandi modelli di deep learning può richiedere livelli sorprendentemente elevati di potenza di calcolo, con profonde implicazioni energetiche. Consideriamo il modello linguistico all'avanguardia di OpenAI GPT-3 come un esempio lampante. Questo sistema spinge i confini della generazione di testo attraverso algoritmi formati su enormi set di dati. Tuttavia, l'energia consumata da GPT-3 per un singolo ciclo di addestramento potrebbe rivaleggiare con l'utilizzo mensile di un'[intera cittadina](https://www.washington.edu/news/2023/07/27/how-much-energy-does-chatgpt-use/). Negli ultimi anni, questi modelli di intelligenza artificiale generativa hanno guadagnato sempre più popolarità, portando a un numero maggiore di modelli addestrati. Oltre all'aumento del numero di modelli, aumenterà anche il numero di parametri in questi modelli. La ricerca mostra che l'aumento delle dimensioni del modello (numero di parametri), delle dimensioni del set di dati e del calcolo utilizzato per l'addestramento migliora le prestazioni in modo fluido senza segni di saturazione [@kaplan2020scaling]. Notare come, in @fig-scaling-laws, il "test loss" diminuisce man mano che ciascuno dei 3 aumenta.

![Le prestazioni migliorano con il calcolo, il set di dati e le dimensioni del modello. Fonte: @kaplan2020scaling.](images/png/model_scaling.png){#fig-scaling-laws}

Cosa determina requisiti così immensi? Durante l'addestramento, modelli come GPT-3 apprendono le proprie capacità elaborando continuamente enormi volumi di dati per regolare i parametri interni. La capacità di elaborazione che consente i rapidi progressi dell'IA contribuisce anche all'aumento del consumo di energia, soprattutto quando i set di dati e i modelli aumentano a dismisura. GPT-3 evidenzia una traiettoria costante nel campo in cui ogni balzo nella sofisticazione dell'IA risale a una potenza di calcolo e risorse sempre più sostanziali. Il suo predecessore, GPT-2, richiedeva un addestramento 10 volte inferiore per calcolare solo 1,5 miliardi di parametri, una differenza ora ridotta da grandezze in quanto GPT-3 comprende 175 miliardi di parametri. Mantenere questa traiettoria verso un'intelligenza artificiale sempre più capace solleva sfide future in termini di fornitura di energia e infrastrutture.

#### Uso Operativo dell'Energia {#operational-energy-use}

Lo sviluppo e l'addestramento di modelli di intelligenza artificiale richiedono un'enorme quantità di dati, potenza di calcolo ed energia. Tuttavia, l'implementazione e il funzionamento di tali modelli comportano anche significativi costi ricorrenti di risorse nel tempo. I sistemi di intelligenza artificiale sono ora integrati in vari settori e applicazioni e stanno entrando nella vita quotidiana di una fascia demografica in crescita. Il loro impatto cumulativo sull'energia operativa e sulle infrastrutture potrebbe eclissare l'addestramento iniziale del modello.

Questo concetto si riflette nella domanda di hardware di addestramento e inferenza nei data center e nell'edge. L'inferenza si riferisce all'uso di un modello addestrato per fare previsioni o decisioni su dati del mondo reale. Secondo una [recente analisi McKinsey](https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%20intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificial-intelligence-hardware.ashx), la necessità di sistemi avanzati per addestrare modelli sempre più grandi sta crescendo rapidamente. Tuttavia, i calcoli di inferenza costituiscono già una parte dominante e crescente dei carichi di lavoro totali dell'intelligenza artificiale, come mostrato in @fig-mckinsey. L'esecuzione di inferenze in tempo reale con modelli addestrati, sia per la classificazione delle immagini, il riconoscimento vocale o l'analisi predittiva, richiede invariabilmente hardware di elaborazione come server e chip. Tuttavia, persino un modello che gestisce migliaia di richieste di riconoscimento facciale o query in linguaggio naturale ogni giorno è messo in ombra da piattaforme enormi come Meta. Dove l'inferenza su milioni di foto e video condivisi sui social media, i requisiti energetici dell'infrastruttura continuano a crescere!

![Dimensioni del mercato per l'hardware di inferenza e training. Fonte: [McKinsey.](https://www.mckinsey.com/~/media/McKinsey/Industries/Semiconductors/Our%20Insights/Artificial%20intelligence%20hardware%20New%20opportunities%20for%20semiconductor%20companies/Artificial-intelligence-hardware.ashx)](images/png/mckinsey_analysis.png){#fig-mckinsey}

Gli algoritmi che alimentano assistenti intelligenti abilitati all'intelligenza artificiale, magazzini automatizzati, veicoli a guida autonoma, assistenza sanitaria personalizzata e altro hanno un'impronta energetica individuale marginale. Tuttavia, la proliferazione prevista di queste tecnologie potrebbe aggiungere centinaia di milioni di endpoint che eseguono algoritmi di intelligenza artificiale ininterrottamente, causando un aumento della scala dei loro requisiti energetici collettivi. Gli attuali guadagni di efficienza hanno bisogno di aiuto per controbilanciare questa crescita netta.

Si prevede che l'intelligenza artificiale registrerà un [tasso di crescita annuale del 37,3% tra il 2023 e il 2030](https://www.forbes.com/advisor/business/ai-statistics/). Tuttavia, applicando lo stesso tasso di crescita al computing operativo, entro il 2030 il fabbisogno energetico annuale dell'IA potrebbe moltiplicarsi fino a 1.000 volte. Quindi, mentre l'ottimizzazione del modello affronta un aspetto, l'innovazione responsabile deve anche considerare i costi totali del ciclo di vita su scale di distribuzione globali che erano inimmaginabili solo anni fa, ma che ora pongono sfide infrastrutturali e di sostenibilità.

### Data Center e il Loro Impatto {#data-centers-and-their-impact}

Con l'aumento della domanda di servizi di IA, l'impatto dei data center sul consumo energetico dei sistemi di IA sta diventando sempre più importante. Sebbene queste strutture siano fondamentali per il progresso e la distribuzione dell'IA, contribuiscono in modo significativo al suo impatto energetico.

#### Scala {#scale}

I data center sono i cavalli da tiro essenziali che consentono le recenti richieste di elaborazione dei sistemi di IA avanzati. Ad esempio, i principali provider come Meta gestiscono enormi data center che si estendono fino alle [dimensioni di più campi da calcio](https://tech.facebook.com/engineering/2021/8/eagle-mountain-data-center/), ospitando centinaia di migliaia di server ad alta capacità ottimizzati per l'elaborazione parallela e la produttività dei dati.

Queste enormi strutture forniscono l'infrastruttura per addestrare reti neurali complesse su vasti set di dati. Ad esempio, sulla base di [informazioni trapelate](https://www.semianalysis.com/p/gpt-4-architecture-infrastructure), il modello linguistico GPT-4 di OpenAI è stato addestrato su data center Azure con oltre 25.000 GPU Nvidia A100, utilizzate ininterrottamente per oltre 90-100 giorni.

Inoltre, l'inferenza in tempo reale per applicazioni AI consumer su larga scala è resa possibile solo sfruttando le server farm all'interno dei data center. Servizi come Alexa, Siri e Google Assistant elaborano miliardi di richieste vocali al mese da parte di utenti in tutto il mondo, basandosi sul data center computing per una risposta a bassa latenza. In futuro, l'espansione di casi d'uso all'avanguardia come veicoli a guida autonoma, diagnosi di medicina di precisione e modelli di previsione climatica accurati richiederà risorse di calcolo significative da ottenere attingendo a vaste risorse di cloud computing on-demand dai data center. Alcune applicazioni emergenti, come le auto autonome, hanno rigidi vincoli di latenza e larghezza di banda. Sarà necessario collocare la potenza di calcolo a livello di data center sull'edge anziché sul cloud.

I prototipi di ricerca del MIT hanno mostrato camion e auto con hardware di bordo che eseguono l'elaborazione AI in tempo reale dei dati dei sensori equivalenti a piccoli data center [@sudhakar2023data]. Questi innovativi "data center su ruote" dimostrano come veicoli come i camion a guida autonoma potrebbero aver bisogno di un calcolo su scala di data center embedded a bordo per ottenere una latenza di sistema di millisecondi per la navigazione, sebbene probabilmente ancora integrato dalla connettività wireless 5G a data center cloud più potenti.

La larghezza di banda, lo storage e le capacità di elaborazione richieste per abilitare questa futura tecnologia su larga scala dipenderanno in larga misura dai progressi nell'infrastruttura dei data center e dalle innovazioni algoritmiche dell'intelligenza artificiale.

#### Domanda di Energia {#energy-demand}

La domanda di energia dei data center può essere approssimativamente suddivisa in 4 componenti: infrastruttura, rete, storage e server. In @fig-energydemand, vediamo che l'infrastruttura dati (che include raffreddamento, illuminazione e controlli) e i server utilizzano la maggior parte del budget energetico totale dei data center negli Stati Uniti [@shehabi2016united]. Questa sezione suddivide la domanda di energia per i server e l'infrastruttura. Per quest'ultima, l'attenzione è rivolta ai sistemi di raffreddamento, poiché il raffreddamento è il fattore dominante nel consumo energetico nell'infrastruttura.

![Consumo energetico dei data center negli Stati Uniti. Fonte: International Energy Agency (IEA).](images/png/energy_datacenter.png){#fig-energydemand}

##### Server {#servers}

L'aumento del consumo energetico dei data center deriva principalmente dalla crescita esponenziale dei requisiti di elaborazione AI. Le macchine NVIDIA DGX H100 ottimizzate per il deep learning possono assorbire fino a [10,2 kW al picco](https://docs.nvidia.com/dgx/dgxh100-user-guide/introduction-to-dgxh100.html). I principali provider gestiscono data center con centinaia o migliaia di questi nodi DGX ad alto consumo energetico collegati in rete per addestrare i più recenti modelli AI. Ad esempio, il supercomputer sviluppato per OpenAI è un singolo sistema con oltre 285.000 core CPU, 10.000 GPU e 400 gigabit al secondo di connettività di rete per ogni server GPU.

I calcoli intensivi necessari per l'intera flotta densamente popolata di una struttura e l'hardware di supporto comportano che i data center assorbano decine di megawatt 24 ore su 24. Nel complesso, gli algoritmi AI avanzati continuano ad aumentare il consumo energetico dei data center man mano che vengono distribuiti più nodi DGX per tenere il passo con la crescita prevista della domanda di risorse di elaborazione AI nei prossimi anni.

##### Sistemi di Raffreddamento {#cooling-systems}

Per mantenere i server robusti alimentati al massimo della capacità e freschi, i data center richiedono una capacità di raffreddamento enorme per contrastare il calore prodotto da server densamente stipati, apparecchiature di rete e altro hardware che eseguono carichi di lavoro intensivi di elaborazione senza sosta. Con grandi data center che contengono migliaia di rack di server che operano a pieno regime, sono necessarie torri di raffreddamento e refrigeratori su scala industriale, che utilizzano energia pari al 30-40% dell'impronta elettrica totale del data center [@dayarathna2015data]. Di conseguenza, le aziende sono alla ricerca di metodi di raffreddamento alternativi. Ad esempio, il data center di Microsoft in Irlanda sfrutta un fiordo vicino per scambiare calore [utilizzando oltre mezzo milione di galloni [1.9 milioni di litri] di acqua di mare al giorno](https://local.microsoft.com/communities/emea/dublin/).

Riconoscendo l'importanza del raffreddamento efficiente dal punto di vista energetico, sono state introdotte innovazioni volte a ridurre questa domanda di energia. Tecniche come il raffreddamento gratuito, che utilizza fonti di aria o acqua esterne quando le condizioni sono favorevoli, e l'uso dell'intelligenza artificiale per ottimizzare i sistemi di raffreddamento sono esempi di come il settore si adatta. Queste innovazioni riducono il consumo energetico, i costi operativi e diminuiscono l'impatto ambientale. Tuttavia, gli aumenti esponenziali della complessità del modello AI continuano a richiedere più server e hardware di accelerazione che operano a un utilizzo più elevato, il che si traduce in una maggiore generazione di calore e in un'energia sempre maggiore utilizzata esclusivamente per il raffreddamento.

#### L'impatto Ambientale {#the-environmental-impact}

L'impatto ambientale dei data center non è causato solo dal consumo energetico diretto del data center stesso [@siddik2021environmental]. Il funzionamento del data center comporta la fornitura di acqua trattata al data center e lo scarico delle acque reflue dal data center. Gli impianti idrici e di trattamento delle acque reflue sono i principali consumatori di elettricità.

Oltre al consumo di elettricità, ci sono molti altri aspetti dell'impatto ambientale di questi data center. Il consumo di acqua dei data center può portare a problemi di scarsità idrica, maggiori esigenze di trattamento delle acque e adeguate infrastrutture di scarico delle acque reflue. Inoltre, le materie prime necessarie per la costruzione e la trasmissione di rete hanno un impatto considerevole sull'ambiente e i componenti nei data center devono essere aggiornati e sottoposti a manutenzione. Laddove quasi il 50 percento dei server è stato aggiornato entro 3 anni di utilizzo, i cicli di aggiornamento hanno dimostrato di rallentare [@davis2022uptime]. Tuttavia, ciò genera notevoli rifiuti elettronici, che possono essere difficili da riciclare.

### Ottimizzazione Energetica {#energy-optimization}

In definitiva, misurare e comprendere il consumo energetico dell'IA facilita l'ottimizzazione del consumo energetico.

Un modo per ridurre il consumo energetico di una data quantità di lavoro computazionale è eseguirlo su hardware più efficiente dal punto di vista energetico.
Ad esempio, i chip TPU possono essere più efficienti dal punto di vista energetico rispetto alle CPU quando si tratta di eseguire grandi calcoli tensoriali per l'IA, poiché le TPU possono eseguire tali calcoli molto più velocemente senza consumare molta più energia delle CPU.
Un altro modo è quello di creare sistemi software consapevoli del consumo energetico e delle caratteristiche dell'applicazione.
Buoni esempi sono lavori di sistema come Zeus [@jie2023zeus] e Perseus [@jaewon2023perseus], entrambi caratterizzati dal compromesso tra tempo di calcolo e consumo energetico a vari livelli di un sistema di addestramento ML per ottenere una riduzione energetica senza rallentamento end-to-end.
In realtà, costruire sia hardware che software a basso consumo energetico e combinarne i vantaggi dovrebbe essere promettente, insieme a framework open source (ad esempio, [Zeus](https://ml.energy/zeus)) che facilitano gli sforzi della comunità.

## Impronta di Carbonio {#carbon-footprint}

Le enormi richieste di elettricità dei data center possono portare a significative esternalità ambientali in assenza di un'adeguata fornitura di energia rinnovabile. Molte strutture dipendono fortemente da fonti di energia non rinnovabili come carbone e gas naturale. Ad esempio, si stima che i data center producano fino al [2% delle emissioni globali totali di $\textrm{CO}_2$](https://www.independent.co.uk/climate-change/news/global-warming-data-centres-to-consume-three-times-as-much-energy-in-next-decade-experts-warn-a6830086.html), il che sta [colmando il divario con il settore aereo](https://www.computerworld.com/article/3431148/why-data-centres-are-the-new-frontier-in-the-fight-against-climate-change.html). Come accennato nelle sezioni precedenti, le richieste di elaborazione dell'intelligenza artificiale sono destinate ad aumentare. Le emissioni di questa ondata sono triplici. In primo luogo, si prevede che i data center aumenteranno di dimensioni [@liu2020energy]. In secondo luogo, le emissioni durante il training sono destinate ad aumentare in modo significativo [@patterson2022carbon]. In terzo luogo, le chiamate di inferenza a questi modelli sono destinate ad aumentare drasticamente.

Senza azioni, questa crescita esponenziale della domanda rischia di aumentare ulteriormente l'impronta di carbonio dei data center a livelli insostenibili. I principali fornitori hanno promesso la neutralità carbonica e impegnato fondi per garantire energia pulita, ma i progressi rimangono incrementali rispetto ai piani di espansione complessivi del settore. Politiche di decarbonizzazione della rete più radicali e investimenti in energia rinnovabile potrebbero rivelarsi essenziali per contrastare l'impatto climatico dell'ondata imminente di nuovi data center volti a supportare la prossima generazione di IA.

### Definizione e Significato {#definition-and-significance}

Il concetto di "impronta di carbonio" è emerso come una metrica chiave. Questo termine si riferisce alla quantità totale di gas serra, in particolare anidride carbonica, emessi direttamente o indirettamente da un individuo, un'organizzazione, un evento o un prodotto. Queste emissioni contribuiscono in modo significativo all'effetto serra, accelerando il riscaldamento globale e il cambiamento climatico. L'impronta di carbonio è misurata in termini di equivalenti di anidride carbonica ($\textrm{CO}_2$e), consentendo un resoconto completo che include vari gas serra e il loro relativo impatto ambientale. Esempi di ciò applicato ad attività di ML su larga scala sono mostrati in @fig-carbonfootprint.

![Impronta di carbonio delle attività di ML su larga scala. Fonte: @wu2022sustainable.](images/png/model_carbonfootprint.png){#fig-carbonfootprint}

Considerare l'impronta di carbonio è particolarmente importante nel rapido progresso dell'IA e nella sua integrazione in vari settori, mettendone in evidenza l'impatto ambientale. I sistemi di IA, in particolare quelli che comportano calcoli intensivi come il deep learning e l'elaborazione di dati su larga scala, sono noti per le loro notevoli richieste di energia. Questa energia, spesso ricavata dalle reti elettriche, potrebbe ancora basarsi prevalentemente sui combustibili fossili, il che comporta significative emissioni di gas serra.

Prendiamo ad esempio l'addestramento di grandi modelli di IA come GPT-3 o complesse reti neurali. Questi processi richiedono un'immensa potenza di calcolo, in genere fornita dai data center. Il consumo energetico associato al funzionamento di questi centri, in particolare per attività ad alta intensità, comporta notevoli emissioni di gas serra. Gli studi hanno evidenziato che l'addestramento di un singolo modello di intelligenza artificiale può generare emissioni di carbonio paragonabili a quelle delle emissioni di più auto nel corso della loro vita, facendo luce sul costo ambientale dello sviluppo di tecnologie di intelligenza artificiale avanzate [@dayarathna2015data]. @fig-carboncars mostra un confronto tra le impronte di carbonio più basse e più alte, a partire da un volo di andata e ritorno tra New York e San Francisco, la vita media umana all'anno, la vita media americana all'anno, un'auto statunitense incluso il carburante nel corso della vita e un modello Transformer con ricerca di architettura neurale, che ha l'impronta più alta.

![Impronta di carbonio del modello NLP in libbre di $\textrm{CO}_2$ equivalente. Fonte: @dayarathna2015data.](images/png/carbon_benchmarks.png){#fig-carboncars}

Inoltre, l'impronta di carbonio dell'IA si estende oltre la fase operativa. L'intero ciclo di vita dei sistemi di IA, inclusa la produzione di hardware di elaborazione, l'energia utilizzata nei data center per il raffreddamento e la manutenzione e lo smaltimento dei rifiuti elettronici, contribuisce alla loro impronta di carbonio complessiva. Abbiamo discusso alcuni di questi aspetti in precedenza e discuteremo degli aspetti relativi ai rifiuti più avanti in questo capitolo.

### La Necessità di Consapevolezza e Azione {#the-need-for-awareness-and-action}

Comprendere l'impronta di carbonio dei sistemi di IA è fondamentale per diversi motivi. In primo luogo, è un passo avanti verso la mitigazione degli impatti del cambiamento climatico. Man mano che l'intelligenza artificiale continua a crescere e a permeare diversi aspetti delle nostre vite, il suo contributo alle emissioni globali di carbonio diventa una preoccupazione significativa. La consapevolezza di queste emissioni può informare le decisioni prese da sviluppatori, aziende, decisori politici e persino ingegneri e scienziati ML come noi per garantire un equilibrio tra innovazione tecnologica e responsabilità ambientale.

Inoltre, questa comprensione stimola la spinta verso la 'Green AI' [@schwartz2020green]. Questo approccio si concentra sullo sviluppo di tecnologie di intelligenza artificiale efficienti, potenti e sostenibili dal punto di vista ambientale. Incoraggia l'esplorazione di algoritmi ad alta efficienza energetica, l'utilizzo di fonti di energia rinnovabili nei data center e l'adozione di pratiche che riducano l'impatto ambientale complessivo dell'intelligenza artificiale.

In sostanza, l'impronta di carbonio è una considerazione essenziale nello sviluppo e nell'applicazione delle tecnologie di intelligenza artificiale. Man mano che l'intelligenza artificiale si evolve e le sue applicazioni diventano più diffuse, la gestione della sua impronta di carbonio è fondamentale per garantire che questo progresso tecnologico sia in linea con gli obiettivi più ampi di sostenibilità ambientale.

### Stima dell'Impronta di Carbonio dell'IA {#estimating-the-ai-carbon-footprint}

Stimare l'impronta di carbonio dei sistemi di IA è fondamentale per comprendere il loro impatto ambientale. Ciò comporta l'analisi dei vari elementi che contribuiscono alle emissioni durante il ciclo di vita delle tecnologie di intelligenza artificiale e l'impiego di metodologie specifiche per quantificare accuratamente tali emissioni. Sono stati proposti molti metodi diversi per quantificare le emissioni di carbonio dell'apprendimento automatico.

L'impronta di carbonio dell'intelligenza artificiale comprende diversi elementi chiave, ognuno dei quali contribuisce all'impatto ambientale complessivo. Innanzitutto, l'energia viene consumata durante le fasi di addestramento e operative del modello di intelligenza artificiale. La fonte di questa energia influenza pesantemente le emissioni di carbonio. Una volta addestrati, questi modelli, a seconda della loro applicazione e scala, continuano a consumare elettricità durante il funzionamento. Oltre alle considerazioni energetiche, anche l'hardware utilizzato stressa l'ambiente.

L'impronta di carbonio varia in modo significativo in base alle fonti di energia utilizzate. La composizione delle fonti che forniscono l'energia utilizzata nella rete varia ampiamente a seconda della regione geografica e persino del momento in un singolo giorno! Ad esempio, negli Stati Uniti, [circa il 60 percento dell'approvvigionamento energetico totale è ancora coperto da combustibili fossili](https://www.eia.gov/tools/faqs/faq.php?id=427&t=3). Le fonti di energia nucleare e rinnovabili coprono il restante 40 percento. Queste frazioni non sono costanti durante il giorno. Poiché la produzione di energia rinnovabile solitamente si basa su fattori ambientali, come la radiazione solare e i campi di pressione, non forniscono una fonte di energia costante.

La variabilità della produzione di energia rinnovabile è stata una sfida continua nell'uso diffuso di queste fonti. Guardando @fig-energyprod, che mostra i dati per la rete europea, vediamo che dovrebbe essere in grado di produrre la quantità di energia richiesta durante il giorno. Mentre l'energia solare raggiunge il picco a metà giornata, quella eolica ha due picchi distinti, al mattino e alla sera. Attualmente, facciamo affidamento su metodi di produzione di energia basati su combustibili fossili e carbone per supplire alla mancanza di energia nei periodi in cui le energie rinnovabili non soddisfano il fabbisogno.

È necessaria l'innovazione nelle soluzioni di accumulo di energia per consentire un uso costante di fonti di energia rinnovabile. Il carico energetico di base è attualmente soddisfatto dall'energia nucleare.
 Questa fonte energetica costante non produce direttamente emissioni di carbonio, ma deve essere più rapida per adattarsi alla variabilità delle fonti energetiche rinnovabili. Le aziende tecnologiche come Microsoft hanno mostrato interesse per le fonti di energia nucleare [per alimentare i loro data center](https://www.bloomberg.com/news/newsletters/2023-09-29/microsoft-msft-sees-artificial-intelligence-and-nuclear-energy-as-dynamic-duo). Poiché la domanda dei data center è più costante rispetto alla domanda delle normali famiglie, l'energia nucleare potrebbe essere utilizzata come fonte energetica dominante.

![Fonti di energia e capacità di generazione. Fonte: [Energy Charts](https://www.energy-charts.info/?l=en&c=DE).](images/png/europe_energy_grid.png){#fig-energyprod}

Inoltre, la produzione e lo smaltimento dell'hardware AI aumentano l'impronta di carbonio. La produzione di dispositivi informatici specializzati, come GPU e CPU, richiede molta energia e risorse. Questa fase spesso si basa su fonti energetiche che contribuiscono alle emissioni di gas serra. Il processo di produzione dell'industria elettronica è stato identificato come una delle otto grandi catene di fornitura responsabili di oltre il 50 percento delle emissioni globali [@challenge2021supply]. Inoltre, lo smaltimento a fine vita di questo hardware, che può portare a rifiuti elettronici, ha anche implicazioni ambientali. Come accennato, i server hanno un ciclo di aggiornamento di circa 3-5 anni. Di questi rifiuti elettronici, attualmente [solo il 17,4 percento viene raccolto e riciclato correttamente.](https://www.genevaenvironmentnetwork.org/resources/updates/the-growing-environmental-risks-of-e-waste/). Le emissioni di carbonio di questi rifiuti elettronici hanno mostrato un aumento di oltre il 50 percento tra il 2014 e il 2020 [@singh2022disentangling].

Come è chiaro da quanto sopra, è necessaria un'adeguata analisi del ciclo di vita per descrivere tutti gli aspetti rilevanti delle emissioni causate dall'IA. Un altro metodo è la contabilità del carbonio, che valuta la quantità di emissioni di anidride carbonica direttamente e indirettamente associate alle operazioni di IA. Questa misura utilizza in genere equivalenti di $\textrm{CO}_2$, consentendo un modo standardizzato di segnalare e valutare le emissioni.

:::{#exr-cf .callout-caution collapse="true"}

### Impronta di Carbonio dell'IA

Sapevate che i modelli di IA all'avanguardia che potreste utilizzare hanno un impatto ambientale? Questo esercizio approfondirà l'"impronta di carbonio" di un sistema di IA. Imparerete come le richieste energetiche dei data center, il training dei grandi modelli di IA e persino la produzione di hardware contribuiscono alle emissioni di gas serra. Discuteremo perché è fondamentale essere consapevoli di questo impatto e impareremo metodi per stimare l'impronta di carbonio dei progetti di IA. Prepariamoci ad esplorare l'intersezione tra IA e sostenibilità ambientale!

[![](https://colab.research.google.com/assets/colab-badge.png)](https://colab.research.google.com/drive/1zH7JrUixOAzb0qEexrgnFzBoRvn65nMh#scrollTo=5EunUBwmc9Lm)
:::

## Oltre l'Impronta di Carbonio {#beyond-carbon-footprint}

L'attuale attenzione alla riduzione delle emissioni di carbonio e del consumo energetico dei sistemi di intelligenza artificiale affronta un aspetto cruciale della sostenibilità. Tuttavia, la produzione di semiconduttori e hardware che consentono l'intelligenza artificiale comporta anche gravi impatti ambientali che ricevono relativamente meno attenzione pubblica. Costruire e gestire un impianto di fabbricazione di semiconduttori all'avanguardia, o "fab", ha notevoli requisiti di risorse e sottoprodotti inquinanti che vanno oltre un'ampia impronta di carbonio.

Ad esempio, una fabbrica all'avanguardia che produce chip come quelli a 5 nm potrebbe richiedere fino a [quattro milioni di galloni di acqua pura al giorno](https://wccftech.com/tsmc-using-water-tankers-for-chip-production-as-5nm-plant-faces-rationing/). Questo consumo di acqua si avvicina a ciò che una città di mezzo milione di persone richiederebbe per tutte le esigenze. L'approvvigionamento di questa risorsa pone costantemente un'enorme pressione sulle falde acquifere e sui bacini idrici locali, soprattutto nelle regioni già sottoposte a stress idrico che ospitano molti centri di produzione ad alta tecnologia.

Inoltre, oltre 250 sostanze chimiche pericolose uniche vengono utilizzate in varie fasi della produzione di semiconduttori all'interno delle fab [@mills1997overview]. Tra queste, solventi volatili come acido solforico, acido nitrico e acido fluoridrico, insieme ad arsina, fosfina e altre sostanze altamente tossiche. Per impedire lo scarico di queste sostanze chimiche sono necessari ampi controlli di sicurezza e infrastrutture di trattamento delle acque reflue per evitare la contaminazione del suolo e rischi per le comunità circostanti. Qualsiasi manipolazione chimica impropria o fuoriuscita imprevista comporta conseguenze disastrose.

Oltre al consumo di acqua e ai rischi chimici, le operazioni di fabbricazione dipendono anche dall'approvvigionamento di metalli rari, generano tonnellate di rifiuti pericolosi e possono ostacolare la biodiversità locale. Questa sezione analizzerà questi impatti critici ma meno discussi. Con vigilanza e investimenti nella sicurezza, i danni derivanti dalla produzione di semiconduttori possono essere contenuti pur consentendo il progresso tecnologico. Tuttavia, ignorare questi problemi esternalizzati aggraverà i danni ecologici e i rischi per la salute nel lungo periodo.

### Utilizzo e Stress Idrico {#water-usage-and-stress}

La fabbricazione di semiconduttori è un processo che richiede un consumo di acqua incredibilmente elevato. In base a un articolo del 2009, un tipico wafer di silicio da 300 mm richiede 8.328 litri di acqua, di cui 5.678 litri sono acqua ultrapura [@cope2009pure]. Oggi, una tipica fabbrica può utilizzare fino a [quattro milioni di galloni di acqua pura](https://wccftech.com/tsmc-arizona-foundry-205-million-approved/). Per gestire una struttura, si prevede che l'ultima fabbrica di TSMC in Arizona utilizzerà 8,9 milioni di galloni al giorno, ovvero quasi il 3 percento dell'attuale produzione idrica della città. Per mettere le cose in prospettiva, Intel e [Quantis](https://quantis.com/) hanno scoperto che oltre il 97% del loro consumo diretto di acqua è attribuito alle operazioni di produzione di semiconduttori all'interno delle loro strutture di fabbricazione [@cooper2011semiconductor].

Quest'acqua viene ripetutamente utilizzata per rimuovere i contaminanti nelle fasi di pulizia e funge anche da refrigerante e fluido vettore nei processi di ossidazione termica, deposizione chimica e planarizzazione chimico-meccanica. Nei mesi estivi di punta, ciò equivale approssimativamente al consumo giornaliero di acqua di una città con una popolazione di mezzo milione di persone.

Nonostante si trovi in regioni con acqua a sufficienza, l'uso intensivo può depauperare gravemente le falde acquifere e i bacini di drenaggio locali. Ad esempio, la città di Hsinchu a Taiwan ha subito [affondamenti delle falde acquifere e intrusioni di acqua marina](https://wccftech.com/tsmc-using-water-tankers-for-chip-production-as-5nm-plant-faces-rationing/) nelle falde acquifere a causa dell'eccessivo pompaggio per soddisfare le richieste di approvvigionamento idrico della fabbrica della Taiwan Semiconductor Manufacturing Company (TSMC). Nelle aree interne con scarsità d'acqua come l'Arizona, [sono necessari massicci apporti di acqua](https://www.americanbar.org/groups/environment_energy_resources/publications/wr/a-tale-of-two-shortages/) per supportare le fabbriche nonostante i bacini già esistenti.

Lo scarico di acqua dalle fabbriche rischia di contaminare l'ambiente oltre all'esaurimento se non trattato correttamente. Sebbene gran parte dello scarico venga riciclato all'interno della fabbrica, i sistemi di purificazione filtrano comunque metalli, acidi e altri contaminanti che possono inquinare fiumi e laghi se non gestiti con cautela [@prakash2022cfu]. Questi fattori rendono essenziale la gestione dell'uso dell'acqua quando si mitigano impatti più ampi sulla sostenibilità.

### Uso di Sostanze Chimiche Pericolose {#hazardous-chemicals-usage}

La moderna fabbricazione di semiconduttori comporta la lavorazione di molte sostanze chimiche altamente pericolose in condizioni estreme di calore e pressione [@kim2018chemical]. Le principali sostanze chimiche utilizzate includono:

* **Acidi forti:** Gli acidi fluoridrico, solforico, nitrico e cloridrico corrodono rapidamente gli ossidi e altri contaminanti superficiali, ma presentano anche pericoli di tossicità. Le fab possono utilizzare migliaia di tonnellate di questi acidi all'anno e l'esposizione accidentale può essere fatale per i lavoratori.
* **Solventi:** Solventi chiave come xilene, metanolo e metilisobutilchetone (MIBK) gestiscono i fotoresist dissolvibili, ma hanno effetti negativi sulla salute come irritazione della pelle/degli occhi ed effetti narcotici se maneggiati in modo improprio. Creano anche rischi di esplosione e inquinamento atmosferico.
* **Gas tossici:** Le miscele di gas contenenti arsina (AsH3), fosfina (PH3), diborano (B2H6), germano (GeH4), ecc., sono alcune delle sostanze chimiche più letali utilizzate nelle fasi di doping e deposizione di vapore. Esposizioni minime possono causare avvelenamento, danni ai tessuti e persino la morte senza un trattamento rapido.
* **Composti clorurati:** Le vecchie formulazioni di planarizzazione chimico-meccanica incorporavano percloroetilene, tricloroetilene e altri solventi clorurati, che da allora sono stati vietati a causa dei loro effetti cancerogeni e dell'impatto sullo strato di ozono. Tuttavia, il loro rilascio precedente minaccia ancora le falde acquifere circostanti.

Protocolli di gestione rigorosi, dispositivi di protezione per i lavoratori, ventilazione, sistemi di filtraggio/lavaggio, serbatoi di contenimento secondari e meccanismi di smaltimento specializzati sono essenziali laddove queste sostanze chimiche vengono utilizzate per ridurre al minimo i pericoli per la salute, le esplosioni, l'aria e le fuoriuscite ambientali [@wald1987semiconductor]. Ma occasionalmente si verificano ancora errori umani e guasti alle apparecchiature, evidenziando perché la riduzione delle intensità chimiche di fabbricazione è uno sforzo di sostenibilità continuo.

### Esaurimento delle Risorse {#resource-depletion}

Sebbene il silicio costituisca la base, sulla Terra c'è una scorta pressoché infinita di silicio. Infatti, [il silicio è il secondo elemento più abbondante trovato nella crosta terrestre](https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust), rappresentando il 27,7% della massa totale della crosta. Solo l'ossigeno supera il silicio in abbondanza all'interno della crosta. Pertanto, il silicio non è necessario da considerare per l'esaurimento delle risorse. Tuttavia, i vari metalli e materiali speciali che consentono il processo di fabbricazione dei circuiti integrati e forniscono proprietà specifiche devono ancora essere scoperti. Mantenere le scorte di queste risorse è fondamentale, ma è minacciato dalla disponibilità finita e dalle influenze geopolitiche [@nakano2021geopolitics].

Gallio, indio e arsenico sono ingredienti vitali nella formazione di semiconduttori composti ultra-efficienti nei chip ad altissima velocità adatti per applicazioni 5G e AI [@chen2006gallium]. Tuttavia, questi elementi rari hanno depositi naturali relativamente scarsi che si stanno esaurendo. Lo United States Geological Survey ha inserito l'indio nella sua lista delle materie prime a rischio più critiche, stimando una fornitura globale sostenibile per meno di 15 anni alla crescita attuale della domanda [@davies2011endangered].

L'elio è richiesto in grandi volumi per le fabbriche di nuova generazione per consentire un raffreddamento preciso dei wafer durante il funzionamento. Ma la relativa rarità dell'elio e il fatto che una volta rilasciato nell'atmosfera, fuoriesce rapidamente dalla Terra rendono il mantenimento delle scorte di elio estremamente impegnativo a lungo termine [@davies2011endangered]. Secondo le US National Academies, in questo mercato scarsamente scambiato si stanno già verificando notevoli aumenti dei prezzi e shock dell'offerta.

Altri rischi includono il controllo della Cina sul 90% degli elementi delle terre rare fondamentali per la produzione di materiali semiconduttori [@jha2014rare]. Qualsiasi problema nella catena di fornitura o controversia commerciale può portare a catastrofiche carenze di materie prime, data la mancanza di alternative attuali. Insieme alle carenze di elio, risolvere la disponibilità limitata e lo squilibrio geografico nell'accesso agli ingredienti essenziali rimane una priorità del settore per la sostenibilità.

### Generazione di Rifiuti Pericolosi {#hazardous-waste-generation}

Le fabbriche di semiconduttori generano tonnellate di rifiuti pericolosi ogni anno come sottoprodotti dei vari processi chimici [@grossman2007high]. I principali flussi di rifiuti includono:

* **Rifiuti gassosi:** I sistemi di ventilazione delle fab catturano gas nocivi come arsina, fosfina e germano e li filtrano per evitare l'esposizione dei lavoratori. Tuttavia, ciò produce quantità significative di gas condensato pericoloso che necessita di un trattamento specializzato.
* **COV:** I composti organici volatili come xilene, acetone e metanolo sono ampiamente utilizzati come solventi fotoresistenti e vengono evaporati come emissioni durante la cottura, l'incisione e lo stripping. I COV pongono problemi di tossicità e richiedono sistemi di lavaggio per impedirne il rilascio.
* **Acidi esausti:** Acidi forti come acido solforico, acido fluoridrico e acido nitrico si esauriscono nelle fasi di pulizia e incisione, trasformandosi in una zuppa corrosiva e tossica che può reagire pericolosamente, rilasciando calore e fumi se mescolata.
* **Fanghi:** Il trattamento delle acque degli effluenti scaricati contiene metalli pesanti concentrati, residui acidi e contaminanti chimici. I sistemi di filtropressa separano questi fanghi pericolosi.
* **Torta di filtrazione:** I sistemi di filtrazione gassosa generano torte appiccicose di diverse tonnellate di composti assorbiti pericolosi che richiedono contenimento.

Senza adeguate procedure di movimentazione, serbatoi di stoccaggio, materiali di imballaggio e contenimento secondario, lo smaltimento improprio di uno qualsiasi di questi flussi di rifiuti può causare pericolose fuoriuscite, esplosioni e rilasci nell'ambiente. Gli enormi volumi significano che anche le fabbriche ben gestite producono tonnellate di rifiuti pericolosi anno dopo anno, che richiedono un trattamento esteso.

### Impatti sulla Biodiversità {#biodiversity-impacts}

#### Interruzione e Frammentazione dell'Habitat {#habitat-disruption-and-fragmentation}

Le fabbriche di semiconduttori necessitano di ampie aree contigue per ospitare camere bianche, strutture di supporto, stoccaggio di sostanze chimiche, trattamento dei rifiuti e infrastrutture ausiliarie. Lo sviluppo di questi vasti spazi edificati smantella inevitabilmente gli habitat esistenti, danneggiando biomi sensibili che potrebbero aver impiegato decenni per svilupparsi. Ad esempio, la costruzione di un nuovo modulo di fabbricazione potrebbe radere al suolo gli ecosistemi forestali locali da cui specie come gufi maculati e alci dipendono per sopravvivere. La rimozione totale di tali habitat minaccia gravemente le popolazioni di animali selvatici che dipendono da quei terreni.

Inoltre, condutture, canali idrici, sistemi di scarico dell'aria e dei rifiuti, strade di accesso, torri di trasmissione e altre infrastrutture di supporto frammentano gli habitat indisturbati rimanenti. Gli animali che si spostano quotidianamente per cibo, acqua e deposizione delle uova possono vedere i loro percorsi di migrazione bloccati da queste barriere umane fisiche che dividono in due i corridoi precedentemente naturali.

#### Disturbi della Vita Acquatica {#aquatic-life-disturbances}

Con le fabbriche di semiconduttori che consumano milioni di galloni di acqua ultra pura ogni giorno, accedere e scaricare tali volumi rischia di alterare l'idoneità degli ambienti acquatici circostanti che ospitano pesci, piante acquatiche, anfibi e altre specie. Se la fabbrica attinge alle falde acquifere come fonte di approvvigionamento primaria, un prelievo eccessivo a tassi insostenibili può impoverire i laghi o portare all'essiccazione dei corsi d'acqua man mano che i livelli dell'acqua scendono [@davies2011endangered].

Inoltre, lo scarico di acque reflue a temperature più elevate per raffreddare le apparecchiature di fabbricazione può modificare le condizioni del fiume a valle attraverso l'inquinamento termico. Le variazioni di temperatura oltre le soglie per cui si sono evolute le specie autoctone possono interrompere i cicli riproduttivi. L'acqua più calda contiene anche meno ossigeno disciolto, fondamentale per sostenere la vita di piante e animali acquatici [@poff2002aquatic]. In combinazione con tracce di contaminanti residui che sfuggono ai sistemi di filtrazione, l'acqua scaricata può trasformare cumulativamente gli ambienti rendendoli molto meno abitabili per gli organismi sensibili [@till2019fish].

#### Emissioni Chimiche e Aeree {#air-and-chemical-emissions}

Mentre le moderne fabbriche di semiconduttori mirano a contenere gli scarichi di aria e sostanze chimiche attraverso sistemi di filtraggio estesi, alcuni livelli di emissioni spesso persistono, aumentando i rischi per la flora e la fauna vicine. Gli inquinanti atmosferici possono essere trasportati sottovento, tra cui composti organici volatili (COV), composti di ossido di azoto (NOx), particolato proveniente da scarichi operativi delle fabbriche ed emissioni di carburante delle centrali elettriche.

Poiché i contaminanti permeano i terreni e le fonti d'acqua locali, la fauna selvatica che ingerisce cibo e acqua contaminati ingerisce sostanze tossiche, che la ricerca dimostra possono ostacolare la funzione cellulare, i tassi di riproduzione e la longevità, avvelenando lentamente gli ecosistemi [@hsu2016accumulation].

Allo stesso modo, le fuoriuscite accidentali di sostanze chimiche e la gestione impropria dei rifiuti, che rilasciano acidi e metalli pesanti nel terreno, possono influire notevolmente sulla capacità di ritenzione e lisciviazione. La flora, come le vulnerabili orchidee autoctone adattate a substrati poveri di nutrienti, può subire morie quando viene a contatto con sostanze chimiche di deflusso estranee che alterano il pH e la permeabilità del terreno. Un'analisi ha scoperto che una singola fuoriuscita di 500 galloni di acido nitrico ha portato all'estinzione regionale di una rara specie di muschio nell'anno successivo, quando l'effluente acido ha raggiunto gli habitat forestali vicini. Tali eventi di contaminazione innescano reazioni a catena attraverso la rete interconnessa della vita. Pertanto, protocolli rigorosi sono essenziali per evitare scarichi e deflussi pericolosi.

## Analisi del Ciclo di Vita {#life-cycle-analysis}

Per comprendere l'impatto ambientale olistico dei sistemi di intelligenza artificiale è necessario un approccio completo che consideri l'intero ciclo di vita di queste tecnologie. Il "Life Cycle Analysis (LCA)" [analisi del ciclo di vita] si riferisce a un quadro metodologico utilizzato per quantificare gli impatti ambientali in tutte le fasi del ciclo di vita di un prodotto o sistema, dall'estrazione delle materie prime allo smaltimento a fine vita. L'applicazione dell'LCA ai sistemi di intelligenza artificiale può aiutare a identificare le aree prioritarie da prendere di mira per ridurre l'impatto ambientale complessivo.

### Fasi del Ciclo di Vita di un Sistema di IA

Il ciclo di vita di un sistema di intelligenza artificiale può essere suddiviso in quattro fasi chiave:

* **Fase di Progettazione:** Include l'energia e le risorse utilizzate nella ricerca e nello sviluppo delle tecnologie di intelligenza artificiale. Comprende le risorse computazionali utilizzate per lo sviluppo e il test degli algoritmi che contribuiscono alle emissioni di carbonio.

* **Fase di Produzione:** Questa fase prevede la produzione di componenti hardware come schede grafiche, processori e altri dispositivi di elaborazione necessari per l'esecuzione degli algoritmi di intelligenza artificiale. La produzione di questi componenti spesso comporta un notevole consumo di energia per l'estrazione dei materiali, l'elaborazione e le emissioni di gas serra.

* **Fase di Utilizzo:** La fase successiva più dispendiosa in termini di energia riguarda l'uso operativo dei sistemi di intelligenza artificiale. Include l'elettricità consumata nei data center per l'addestramento e l'esecuzione delle reti neurali e l'alimentazione delle applicazioni per gli utenti finali. Questa è probabilmente una delle fasi con il più alto consumo di carbonio.

* **Fase di Smaltimento:** Questa fase finale riguarda gli aspetti di fine vita dei sistemi di intelligenza artificiale, tra cui il riciclaggio e lo smaltimento dei rifiuti elettronici generati da hardware obsoleto o non funzionante oltre la sua durata utile.

### Impatto Ambientale in Ogni Fase {#environmental-impact-at-each-stage}

**Progettazione e Produzione**

L'impatto ambientale durante queste fasi iniziali di vita include emissioni derivanti dall'uso di energia e dall'esaurimento delle risorse derivanti dall'estrazione di materiali per la produzione di hardware. Al centro dell'hardware AI ci sono semiconduttori, principalmente silicio, utilizzati per realizzare i circuiti integrati nei processori e nei chip di memoria. Questa produzione di hardware si basa su metalli come il rame per i cablaggi, l'alluminio per gli involucri e varie plastiche e compositi per altri componenti. Utilizza anche terre rare e leghe specializzate, elementi come neodimio, terbio e ittrio, utilizzati in piccole ma vitali quantità. Ad esempio, la creazione di GPU si basa su rame e alluminio. Allo stesso tempo, i chip utilizzano terre rare, che è il processo di estrazione che può generare notevoli emissioni di carbonio e danni all'ecosistema.

**Fase di Utilizzo**

L'AI calcola la maggior parte delle emissioni nel ciclo di vita a causa del continuo elevato consumo di energia, in particolare per il training e l'esecuzione di modelli. Ciò include emissioni dirette e indirette derivanti dall'uso di elettricità e dalla generazione di energia di rete non rinnovabile. Gli studi stimano che l'addestramento di modelli complessi può avere un'impronta di carbonio paragonabile alle emissioni fino a cinque auto nel corso della loro vita.

**Fase di Smaltimento**

Gli impatti della fase di smaltimento includono l'inquinamento dell'aria e dell'acqua dovuto a materiali tossici nei dispositivi, le sfide associate al riciclaggio di componenti elettronici complessi e la contaminazione in caso di gestione impropria. I composti nocivi derivanti dalla combustione dei rifiuti elettronici vengono rilasciati nell'atmosfera. Allo stesso tempo, la perdita di piombo, mercurio e altri materiali dalle discariche comporta rischi di contaminazione del suolo e delle falde acquifere se non adeguatamente controllata. L'implementazione di un efficace riciclaggio dei componenti elettronici è fondamentale.

:::{#exr-mle .callout-caution collapse="true"}

### Monitoraggio delle Emissioni ML

In questo esercizio, esploreremo l'impatto ambientale dell'addestramento di modelli di machine learning. Utilizzeremo CodeCarbon per monitorare le emissioni, apprenderemo l'analisi del "Life Cycle Analysis (LCA)" per comprendere l'impronta di carbonio dell'IA ed esploreremo strategie per rendere lo sviluppo del tuo modello ML più rispettoso dell'ambiente. Alla fine, si sarà in grado di monitorare le emissioni di carbonio dei modelli e iniziare a implementare pratiche più ecologiche nei progetti.

[![](https://colab.research.google.com/assets/colab-badge.png)](https://colab.research.google.com/drive/1elYSajW0_qxA_6k-B8w4TGR5ec8vaw5f?usp=drive_link#scrollTo=EFpgp_rIA_TY)
:::

## Sfide nell'LCA {#challenges-in-lca}

### Mancanza di Coerenza e Standard {#lack-of-consistency-and-standards}

Una delle principali sfide che l'analisi del "life cycle analysis (LCA)" [ciclo di vita ] deve affrontare per i sistemi di intelligenza artificiale è la necessità di standard e framework metodologici coerenti. A differenza di categorie di prodotti come i materiali da costruzione, che hanno sviluppato standard internazionali per LCA tramite ISO 14040, non esistono linee guida stabilite per analizzare l'impatto ambientale di tecnologie informatiche complesse come l'intelligenza artificiale.

Questa assenza di uniformità significa che i ricercatori fanno ipotesi diverse e scelte metodologiche variabili. Ad esempio, uno studio del 2021 dell'Università del Massachusetts Amherst [@strubell2019energy] ha analizzato le emissioni del ciclo di vita di diversi modelli di elaborazione del linguaggio naturale, ma ha preso in considerazione solo l'utilizzo delle risorse computazionali per il training e ha omesso gli impatti sulla produzione di hardware. Uno studio più completo del 2020 condotto dai ricercatori della Stanford University ha incluso stime delle emissioni derivanti dalla produzione di server, processori e altri componenti pertinenti, seguendo uno standard LCA allineato a ISO per l'hardware dei computer. Tuttavia, queste scelte divergenti nei confini del sistema e negli approcci contabili riducono la robustezza e impediscono confronti tra risultati simili.

Framework e protocolli standardizzati su misura per gli aspetti unici dei sistemi di intelligenza artificiale e rapidi cicli di aggiornamento fornirebbero maggiore coerenza. Ciò potrebbe consentire a ricercatori e sviluppatori di comprendere i punti critici ambientali, confrontare le opzioni tecnologiche e monitorare con precisione i progressi nelle iniziative di sostenibilità nel campo dell'intelligenza artificiale. Gruppi industriali e organismi di normazione internazionali come IEEE o ACM dovrebbero dare priorità all'affrontare questa lacuna metodologica.

### Lacune nei Dati {#data-gaps}

Un'altra sfida fondamentale per una valutazione completa del ciclo di vita dei sistemi di intelligenza artificiale sono le lacune sostanziali nei dati, in particolare per quanto riguarda gli impatti sulla catena di fornitura a monte e i flussi di rifiuti elettronici a valle. La maggior parte degli studi esistenti si concentra strettamente sulle emissioni della fase di apprendimento o di utilizzo derivanti dalle richieste di potenza di calcolo, che tralasciano una parte significativa delle emissioni nel corso della vita [@gupta2022].

Ad esempio, esistono pochi dati pubblici delle aziende che quantificano l'uso di energia e le emissioni derivanti dalla produzione di componenti hardware specializzati che abilitano l'intelligenza artificiale, tra cui GPU di fascia alta, chip ASIC, unità a stato solido e altro. Spesso i ricercatori si affidano a fonti secondarie o medie generiche del settore per approssimare gli impatti sulla produzione. Analogamente, in media, c'è una trasparenza limitata sul destino a valle una volta che i sistemi di intelligenza artificiale vengono scartati dopo 4-5 anni di durata utile.

Mentre i livelli di generazione di rifiuti elettronici possono essere stimati, i dettagli sulle perdite di materiali pericolosi, sui tassi di riciclaggio e sui metodi di smaltimento per i componenti complessi sono estremamente incerti senza una migliore documentazione aziendale o requisiti di reporting normativi.

La necessità di dati dettagliati sul consumo di risorse computazionali per l'addestramento di diversi tipi di modelli rende difficili calcoli affidabili delle emissioni per parametro o per query anche per la fase di utilizzo. Esistono tentativi di creare inventari del ciclo di vita che stimino il fabbisogno energetico medio per le attività chiave dell'intelligenza artificiale [@henderson2020towards; @anthony2020carbontracker], ma la variabilità tra configurazioni hardware, algoritmi e incertezza dei dati di input rimane estremamente elevata. Inoltre, i dati sull'intensità di carbonio in tempo reale, fondamentali per tracciare con precisione l'impronta di carbonio operativa, devono essere migliorati in molte posizioni geografiche, rendendo gli strumenti esistenti per le emissioni di carbonio operative mere approssimazioni basate sui valori di intensità di carbonio media annuale.

La sfida è che strumenti come [CodeCarbon](https://codecarbon.io/) e [ML $\textrm{CO}_2$](https://mlco2.github.io/impact/#compute) sono, nella migliore delle ipotesi, solo approcci ad hoc, nonostante le loro buone intenzioni. Colmare le lacune reali dei dati con divulgazioni più rigorose sulla sostenibilità aziendale e una rendicontazione obbligatoria dell'impatto ambientale sarà fondamentale per comprendere e gestire gli impatti climatici complessivi dell'IA.

### Rapido Ritmo di Evoluzione {#rapid-pace-of-evolution}

L'evoluzione estremamente rapida dei sistemi di intelligenza artificiale pone ulteriori sfide nel mantenere aggiornate le valutazioni del ciclo di vita e nel tenere conto degli ultimi progressi hardware e software. Gli algoritmi di base, i chip specializzati, i framework e l'infrastruttura tecnica alla base dell'intelligenza artificiale hanno tutti fatto progressi eccezionalmente rapidi, con nuovi sviluppi che hanno rapidamente reso obsoleti i sistemi precedenti.

Ad esempio, nel deep learning, le nuove architetture di reti neurali che raggiungono prestazioni significativamente migliori su benchmark chiave o nuovi hardware ottimizzati come i chip TPU di Google possono cambiare completamente un modello "medio" in meno di un anno. Questi rapidi cambiamenti rendono rapidamente obsoleti gli studi LCA una tantum per il monitoraggio accurato delle emissioni derivanti dalla progettazione, esecuzione o smaltimento dell'intelligenza artificiale più recente.

Tuttavia, le risorse e l'accesso necessari per aggiornare continuamente gli LCA devono essere migliorati. Rifare frequentemente il lavoro, inventari del ciclo di vita ad alta intensità di dati e modelli di impatto per rimanere aggiornati con lo stato dell'arte dell'intelligenza artificiale è probabilmente irrealizzabile per molti ricercatori e organizzazioni. Tuttavia, analisi aggiornate potrebbero rilevare hotspot ambientali man mano che algoritmi e chip di silicio continuano a evolversi rapidamente.

Ciò presenta difficoltà nel bilanciare la precisione dinamica attraverso una valutazione continua con vincoli pragmatici. Alcuni ricercatori hanno proposto metriche proxy semplificate come il monitoraggio delle generazioni hardware nel tempo o l'utilizzo di benchmark rappresentativi come un set oscillante di paletti per confronti relativi, sebbene la granularità possa essere sacrificata. Nel complesso, la sfida del cambiamento rapido richiederà soluzioni metodologiche innovative per evitare di sottostimare gli oneri ambientali in evoluzione dell'IA.

### Complessità della Catena di Fornitura {#supply-chain-complexity}

Infine, le complesse e spesso opache catene di fornitura associate alla produzione dell'ampia gamma di componenti hardware specializzati che abilitano l'intelligenza artificiale pongono sfide per la modellazione completa del ciclo di vita. Lo "stato-dell'arte" dellIA si basa su progressi all'avanguardia nell'elaborazione di chip, schede grafiche, archiviazione dati, apparecchiature di rete e altro ancora. Tuttavia, tracciare le emissioni e l'uso delle risorse attraverso le reti a livelli di fornitori globalizzati per tutti questi componenti è estremamente difficile.

Ad esempio, le unità di elaborazione grafica NVIDIA dominano gran parte dell'hardware di elaborazione dell'intelligenza artificiale, ma l'azienda si affida a diversi fornitori discreti in Asia e oltre per produrre GPU. Molte aziende a ogni livello di fornitore scelgono di mantenere privati i dati ambientali a livello di stabilimento, il che potrebbe abilitare completamente LCA robuste. Ottenere la trasparenza end-to-end su più livelli di fornitori in aree geografiche diverse con protocolli di divulgazione e normative variabili pone barriere nonostante sia fondamentale per la definizione completa dei confini. Ciò diventa ancora più complesso quando si tenta di modellare acceleratori hardware emergenti come le "tensor processing units (TPU)" [unità di elaborazione tensoriale], le cui reti di produzione devono ancora essere rese pubbliche.

Senza la volontà dei giganti della tecnologia di richiedere e consolidare la divulgazione dei dati sull'impatto ambientale da tutte le loro catene di fornitura di elettronica globali, rimarrà una notevole incertezza sulla quantificazione dell'impronta del ciclo di vita completo dell'abilitazione hardware AI. Una maggiore visibilità della catena di fornitura abbinata a quadri di reporting sulla sostenibilità standardizzati che affrontino specificamente gli input complessi dell'AI promettono di arricchire gli LCA e dare priorità alle riduzioni dell'impatto ambientale.

## Progettazione e Sviluppo Sostenibili {#sustainable-design-and-development}

### Principi di Sostenibilità {#sustainability-principles}

Man mano che l'impatto dell'IA sull'ambiente diventa sempre più evidente, l'attenzione alla progettazione e allo sviluppo sostenibili nell'IA sta acquisendo importanza. Ciò comporta l'incorporazione di principi di sostenibilità nella progettazione dell'IA, lo sviluppo di modelli a risparmio energetico e l'integrazione di queste considerazioni in tutta la pipeline di sviluppo dell'IA. C'è una crescente necessità di considerare le implicazioni di sostenibilità e sviluppare principi per guidare l'innovazione responsabile. Di seguito è riportato un set di principi fondamentali. I principi fluiscono dalle fondamenta concettuali all'esecuzione pratica ai fattori di supporto all'implementazione; i principi forniscono una prospettiva del ciclo completo sull'incorporamento della sostenibilità nella progettazione e nello sviluppo dell'IA.

**Lifecycle Thinking:** Incoraggiare i progettisti a considerare l'intero ciclo di vita dei sistemi di IA, dalla raccolta e preelaborazione dei dati allo sviluppo del modello, al training, all'implementazione e al monitoraggio. L'obiettivo è garantire che la sostenibilità sia presa in considerazione in ogni fase. Ciò include l'utilizzo di hardware a risparmio energetico, la priorità alle fonti di energia rinnovabili e la pianificazione del riutilizzo o del riciclaggio di modelli dismessi.

**A Prova di Futuro:** Progettare sistemi di intelligenza artificiale che anticipino esigenze e cambiamenti futuri può migliorare la sostenibilità. Ciò può comportare la creazione di modelli adattabili tramite apprendimento per trasferimento e architetture modulari. Include anche la capacità di pianificazione per aumenti previsti di scala operativa e volumi di dati.

**Efficienza e Minimalismo:** Questo principio si concentra sulla creazione di modelli di intelligenza artificiale che raggiungano i risultati desiderati con il minimo utilizzo di risorse possibile. Comporta la semplificazione di modelli e algoritmi per ridurre i requisiti computazionali. Tecniche specifiche includono la potatura di parametri ridondanti, la quantizzazione e la compressione di modelli e la progettazione di architetture di modelli efficienti, come quelle discusse nel capitolo [Ottimizzazioni](../optimizations/optimizations.qmd).

**Integrazione del Lifecycle Assessment (LCA):** [Valutazione del Ciclo di Vita ] L'analisi degli impatti ambientali durante lo sviluppo e l'implementazione dei cicli di vita evidenzia le pratiche non sostenibili in anticipo. I team possono quindi apportare modifiche anziché scoprire i problemi in ritardo, quando sono più difficili da affrontare. L'integrazione di questa analisi nel flusso di progettazione standard evita di creare problemi ereditati di sostenibilità.

**Allineamento degli Incentivi:** Gli incentivi economici e politici dovrebbero promuovere e premiare lo sviluppo sostenibile dell'IA. Questi possono includere sovvenzioni governative, iniziative aziendali, standard di settore e mandati accademici per la sostenibilità. Gli incentivi allineati consentono alla sostenibilità di essere inglobata nella cultura dell'IA.

**Metriche e Obiettivi di Sostenibilità:** È importante stabilire metriche chiaramente definite che misurino fattori di sostenibilità come l'uso del carbonio e l'efficienza energetica. Stabilire obiettivi chiari per queste metriche fornisce linee guida concrete per i team per sviluppare sistemi di IA responsabili. Il monitoraggio delle prestazioni sulle metriche nel tempo mostra i progressi verso gli obiettivi di sostenibilità prefissati.

**Equità, Trasparenza e Responsabilità:** I sistemi di IA sostenibili dovrebbero essere equi, trasparenti e responsabili. I modelli dovrebbero essere imparziali, con processi di sviluppo trasparenti e meccanismi per l'audit e la risoluzione dei problemi. Ciò crea fiducia nel pubblico e consente l'identificazione di pratiche non sostenibili.

**Collaborazione Interdisciplinare:** I ricercatori di intelligenza artificiale che collaborano con scienziati e ingegneri ambientali possono dare vita a sistemi innovativi ad alte prestazioni ma rispettosi dell'ambiente. L'unione di competenze provenienti da diversi campi fin dall'inizio dei progetti consente di incorporare il pensiero sostenibile nel processo di progettazione dell'intelligenza artificiale.

**Istruzione e Consapevolezza:** Workshop, programmi di formazione e programmi di studio che riguardano la sostenibilità dell'intelligenza artificiale accrescono la consapevolezza tra la prossima generazione di professionisti. Ciò fornisce agli studenti le conoscenze per sviluppare un'intelligenza artificiale che riduca al minimo gli impatti negativi sulla società e sull'ambiente. Inculcare questi valori fin dall'inizio plasma i professionisti e le culture aziendali di domani.

## Infrastruttura di IA Green {#green-ai-infrastructure}

Green AI rappresenta un approccio trasformativo all'IA che incorpora la sostenibilità ambientale come principio fondamentale nella progettazione e nel ciclo di vita del sistema di IA [@schwartz2020green]. Questo cambiamento è guidato dalla crescente consapevolezza dell'impatto ecologico e dell'impronta di carbonio significativa delle tecnologie di IA, in particolare il processo di elaborazione intensiva di modelli di ML complessi.

L'essenza di Green AI risiede nel suo impegno ad allineare il progresso dell'IA con gli obiettivi di sostenibilità in termini di efficienza energetica, utilizzo di energia rinnovabile e riduzione dei rifiuti. L'introduzione degli ideali di Green AI riflette la crescente responsabilità nel settore tecnologico verso la tutela ambientale e le pratiche tecnologiche etiche. Va oltre le ottimizzazioni tecniche verso una valutazione olistica del ciclo di vita su come i sistemi di IA influenzano le metriche di sostenibilità. Stabilire nuovi standard per un'IA ecologicamente consapevole apre la strada alla coesistenza armoniosa di progresso tecnologico e salute planetaria.

### Sistemi di IA a Risparmio Energetico {#energy-efficient-ai-systems}

L'efficienza energetica nei sistemi di intelligenza artificiale è un pilastro della Green AI, che mira a ridurre le richieste di energia tradizionalmente associate allo sviluppo e alle operazioni di intelligenza artificiale. Questo passaggio verso pratiche di intelligenza artificiale attente al risparmio energetico è fondamentale per affrontare le preoccupazioni ambientali sollevate dal campo in rapida espansione dell'intelligenza artificiale. Concentrandosi sull'efficienza energetica, i sistemi di intelligenza artificiale possono diventare più sostenibili, riducendo il loro impatto ambientale e aprendo la strada a un loro utilizzo più responsabile.

Come abbiamo discusso in precedenza, l'addestramento e il funzionamento dei modelli di intelligenza artificiale, in particolare quelli su larga scala, sono noti per il loro elevato consumo energetico, che deriva dall'architettura del modello ad alta intensità di calcolo e dall'affidamento a grandi quantità di dati di addestramento. Ad esempio, si stima che l'addestramento di un grande modello di rete neurale all'avanguardia possa avere un'impronta di carbonio di 284 tonnellate, equivalente alle emissioni di 5 auto nel corso della loro vita [@strubell2019energy].

Per affrontare le enormi richieste di energia, ricercatori e sviluppatori stanno esplorando attivamente metodi per ottimizzare i sistemi di intelligenza artificiale per una migliore efficienza energetica mantenendo al contempo l'accuratezza e le prestazioni del modello. Ciò include tecniche come quelle che abbiamo discusso nei capitoli sulle ottimizzazioni del modello, sull'intelligenza artificiale efficiente e sull'accelerazione hardware:

* Distillazione della conoscenza per trasferire la conoscenza da grandi modelli di intelligenza artificiale a versioni in miniatura
* Approcci di quantizzazione e potatura che riducono le complessità computazionali e spaziali
* Numeri a bassa precisione: riduzione della precisione matematica senza influire sulla qualità del modello
* Hardware specializzato come TPU, chip neuromorfici ottimizzati esplicitamente per un'elaborazione efficiente dell'intelligenza artificiale

Un esempio è il lavoro di Intel su Q8BERT: quantizzazione del modello di linguaggio BERT con interi a 8 bit, che porta a una riduzione di 4 volte delle dimensioni del modello con una perdita di accuratezza minima [@zafrir2019q8bert]. La spinta verso un'intelligenza artificiale efficiente dal punto di vista energetico non è solo uno sforzo tecnico: ha implicazioni tangibili nel mondo reale. Sistemi più performanti riducono i costi operativi e l'impatto ambientale dell'intelligenza artificiale, rendendola accessibile per un'ampia distribuzione su dispositivi mobili ed edge. Apre inoltre la strada alla democratizzazione dell'IA e mitiga i pregiudizi ingiusti che possono emergere da un accesso non uniforme alle risorse informatiche tra regioni e comunità. Perseguire un'IA efficiente dal punto di vista energetico è quindi fondamentale per creare un futuro equo e sostenibile con l'IA.

### Infrastruttura di IA Sostenibile {#sustainable-ai-infrastructure}

L'infrastruttura AI sostenibile include i framework fisici e tecnologici che supportano i sistemi AI, concentrandosi sulla sostenibilità ambientale. Ciò implica la progettazione e la gestione dell'infrastruttura AI per ridurre al minimo l'impatto ecologico, conservare le risorse e ridurre le emissioni di carbonio. L'obiettivo è creare un ecosistema sostenibile per l'AI che si allinei con obiettivi ambientali più ampi..

I data center green sono fondamentali per l'infrastruttura AI sostenibile, ottimizzati per l'efficienza energetica e spesso alimentati da fonti di energia rinnovabili. Questi data center impiegano tecnologie di raffreddamento avanzate [@ebrahimi2014review], design di server a risparmio energetico [@uddin2012energy] e sistemi di gestione intelligenti [@buyya2010energyefficient] per ridurre il consumo di energia. Il passaggio a un'infrastruttura informatica verde implica anche l'adozione di hardware a risparmio energetico, come processori ottimizzati per l'AI che offrono prestazioni elevate con requisiti energetici inferiori, di cui abbiamo discusso nel capitolo [ Accelerazione IA](../hw_acceleration/hw_acceleration.qmd). Questi sforzi riducono collettivamente l'impronta di carbonio delle operazioni di intelligenza artificiale su larga scala.

L'integrazione di fonti di energia rinnovabili, come energia solare, eolica e idroelettrica, nell'infrastruttura di intelligenza artificiale è importante per la sostenibilità ambientale [@chua1971memristor]. Molte aziende tecnologiche e istituti di ricerca stanno [investendo in progetti di energia rinnovabile per alimentare i loro data center](https://www.forbes.com/sites/siemens-smart-infrastructure/2023/03/13/how-data-centers-are-driving-the-renewable-energy-transition/?sh=3208c5b54214). Ciò non solo aiuta a rendere le operazioni di intelligenza artificiale carbon neutral, ma promuove anche un'adozione più ampia di energia pulita. L'utilizzo di fonti di energia rinnovabili mostra chiaramente l'impegno per la responsabilità ambientale nel settore dell'intelligenza artificiale.

La sostenibilità si estende anche ai materiali e all'hardware utilizzati nella creazione di sistemi di intelligenza artificiale. Ciò implica la scelta di materiali ecocompatibili, l'adozione di pratiche di riciclaggio e la garanzia di uno smaltimento responsabile dei rifiuti elettronici. Sono in corso sforzi per sviluppare componenti hardware più sostenibili, tra cui chip a risparmio energetico progettati per attività specifiche del dominio (come gli acceleratori di IA) e materiali ecocompatibili nella produzione di dispositivi [@cenci2021ecofriendly;@irimiavladu2014textquotedblleftgreentextquotedblright]. Anche il ciclo di vita di questi componenti è un punto focale, con iniziative volte a estendere la durata di vita dell'hardware e a promuovere il riciclaggio e il riutilizzo.

Sebbene si stiano facendo progressi nell'infrastruttura di IA sostenibile, permangono delle sfide, come gli elevati costi della tecnologia verde e la necessità di standard globali nelle pratiche sostenibili. Le direzioni future includono un'adozione più diffusa di energia verde, ulteriori innovazioni nell'hardware a risparmio energetico e la collaborazione internazionale su politiche di IA sostenibile. Perseguire un'infrastruttura di IA sostenibile non è solo uno sforzo tecnico, ma un approccio olistico che comprende aspetti ambientali, economici e sociali, assicurando che l'IA avanzi in armonia con la salute del nostro pianeta.

### Framework e Strumenti {#frameworks-and-tools}

L'accesso ai framework e agli strumenti giusti è essenziale per implementare in modo efficace le pratiche di intelligenza artificiale verde. Queste risorse sono progettate per aiutare sviluppatori e ricercatori a creare sistemi di IA più efficienti dal punto di vista energetico e rispettosi dell'ambiente. Vanno da librerie software ottimizzate per un basso consumo energetico a piattaforme che facilitano lo sviluppo di applicazioni di IA sostenibili.

Diverse librerie software e ambienti di sviluppo sono specificamente pensati per l'intelligenza artificiale verde. Questi strumenti spesso includono funzionalità per ottimizzare i modelli di IA per ridurre il loro carico computazionale e, di conseguenza, il loro consumo energetico. Ad esempio, le librerie in PyTorch e TensorFlow che supportano la potatura del modello, la quantizzazione e le architetture di reti neurali efficienti consentono agli sviluppatori di creare sistemi di intelligenza artificiale che richiedono meno potenza di elaborazione ed energia. Inoltre, comunità open source come la [Green Carbon Foundation](https://github.com/Green-Software-Foundation) stanno creando una metrica centralizzata dell'intensità di carbonio e sviluppando software per l'elaborazione consapevole delle emissioni di carbonio.

Gli strumenti di monitoraggio dell'energia sono fondamentali per l'intelligenza artificiale verde, poiché consentono agli sviluppatori di misurare e analizzare il consumo energetico dei loro sistemi. Fornendo informazioni dettagliate su dove e come viene utilizzata l'energia, questi strumenti consentono agli sviluppatori di prendere decisioni informate sull'ottimizzazione dei loro modelli per una migliore efficienza energetica. Ciò può comportare modifiche nella progettazione dell'algoritmo, nella selezione dell'hardware, nella selezione del software di cloud computing o nei parametri operativi. @fig-azuredashboard è uno screenshot di una dashboard del consumo energetico fornita dalla piattaforma di servizi cloud di Microsoft.

![Dashboard del consumo energetico di Microsoft Azure. Fonte: [Will Buchanan.](https://techcommunity.microsoft.com/t5/green-tech-blog/charting-the-path-towards-sustainable-ai-with-azure-machine/ba-p/2866923)](images/png/azure_dashboard.png){#fig-azuredashboard}

Con la crescente integrazione di fonti di energia rinnovabile nelle operazioni di IA, i framework che facilitano questo processo stanno diventando sempre più importanti. Questi framework aiutano a gestire l'approvvigionamento energetico da fonti rinnovabili come l'energia solare o eolica, assicurando che i sistemi di IA possano funzionare in modo efficiente con input energetici fluttuanti.

Oltre all'efficienza energetica, gli strumenti di valutazione della sostenibilità aiutano a valutare l'impatto ambientale più ampio dei sistemi di IA. Questi strumenti possono analizzare fattori come l'impronta di carbonio delle operazioni di IA, l'impatto del ciclo di vita dei componenti hardware [@gupta2022] e la sostenibilità complessiva dei progetti di IA [@prakash2022cfu].

La disponibilità e lo sviluppo continuo di framework e strumenti di IA Green sono fondamentali per promuovere pratiche di sostenibili. Fornendo le risorse necessarie a sviluppatori e ricercatori, questi strumenti facilitano la creazione di sistemi più rispettosi dell'ambiente e incoraggiano un più ampio cambiamento verso la sostenibilità nella comunità tecnologica. Man mano che l'IA Green continua a evolversi, questi framework e strumenti svolgeranno un ruolo fondamentale nel dare forma a un futuro più sostenibile per l'IA.
As Green AI continues to evolve, these frameworks and tools will play a vital role in shaping a more sustainable future for AI.

### Benchmark e Classifiche

Benchmark e classifiche sono importanti per guidare i progressi nell'IA Green, poiché forniscono modi standardizzati per misurare e confrontare diversi metodi. Benchmark ben progettati che catturano metriche rilevanti su efficienza energetica, emissioni di carbonio e altri fattori di sostenibilità consentono alla comunità di monitorare i progressi in modo equo e significativo.

Esistono ampi benchmark per tracciare le prestazioni del modello di IA, come quelli discussi nel capitolo [Benchmarking](../benchmarking/benchmarking.qmd). Tuttavia, esiste una chiara e urgente necessità di ulteriori benchmark standardizzati incentrati su parametri di sostenibilità come efficienza energetica, emissioni di carbonio e impatto ecologico complessivo. La comprensione dei costi ambientali dell'IA deve attualmente essere migliorata da una mancanza di trasparenza e misura standardizzata attorno a questi fattori.

Sforzi emergenti come [ML.ENERGY Leaderboard](https://ml.energy/leaderboard), che fornisce risultati di benchmarking delle prestazioni e del consumo energetico per la generazione di testo di modelli linguistici di grandi dimensioni (LLM), aiutano a migliorare la comprensione del costo energetico dell'implementazione GenAI.

Come con qualsiasi benchmark, quelli di IA Green devono rappresentare scenari di utilizzo e carichi di lavoro realistici. I benchmark che si concentrano strettamente su metriche facilmente manipolabili possono portare a guadagni a breve termine, ma non riescono a riflettere gli ambienti di produzione effettivi in cui sono necessarie misure di efficienza e sostenibilità più olistiche. La comunità dovrebbe continuare ad espandere i benchmark per coprire diversi casi d'uso.

Un'adozione più ampia di suite di benchmark comuni da parte degli operatori del settore accelererà l'innovazione nell'IA Green consentendo un confronto più semplice delle tecniche tra le organizzazioni. I benchmark condivisi abbassano la barriera per dimostrare i vantaggi di sostenibilità di nuovi strumenti e best practice. uttavia, quando si progettano benchmark per l'intero settore, è necessario prestare attenzione a questioni come proprietà intellettuale, privacy e sensibilità commerciale. Le iniziative per sviluppare set di dati di riferimento aperti per la valutazione dell'IA Green possono aiutare a promuovere una partecipazione più ampia.

Man mano che i metodi e l'infrastruttura per l'IA Green continuano a maturare, la comunità deve rivedere la progettazione dei benchmark per garantire che le suite esistenti catturino bene nuove tecniche e scenari. Monitorare il panorama in evoluzione attraverso aggiornamenti e revisioni regolari dei benchmark sarà importante per mantenere confronti rappresentativi nel tempo. Gli sforzi della comunità per la cura dei benchmark possono consentire suite di benchmark sostenibili che resistano alla prova del tempo. Suite di benchmark complete di proprietà di comunità di ricerca o terze parti neutrali come [MLCommons](https://mlcommons.org) possono incoraggiare una più ampia partecipazione e standardizzazione.

## Caso di Studio: 4M di Google {#case-study-google-4ms}

Negli ultimi dieci anni, l'intelligenza artificiale è passata rapidamente dalla ricerca accademica ai sistemi di produzione su larga scala che alimentano numerosi prodotti e servizi Google. Poiché i modelli e i carichi di lavoro dell'IA sono cresciuti esponenzialmente in termini di dimensioni e richieste di elaborazione, sono emerse preoccupazioni circa il loro consumo energetico e l'impatto ambientale. Alcuni ricercatori hanno previsto una crescita incontrollata dell'appetito energetico del ML che potrebbe superare le efficienze ottenute da algoritmi e hardware migliorati [@thompson2021deep].

Tuttavia, i dati di produzione di Google rivelano una storia diversa: l'IA rappresenta un costante 10-15% del consumo energetico totale dell'azienda dal 2019 al 2021. Questo caso di studio analizza come Google ha applicato un approccio sistematico sfruttando quattro best practice, quelle che definiscono le "4 M": "Model efficiency", "Machine optimization", "Mechanization through cloud computing" e "Mapping to green locations" [efficienza del modello, ottimizzazione delle macchine, meccanizzazione tramite cloud computing e mappatura di luoghi Green], per piegare la curva delle emissioni dai carichi di lavoro dell'IA.

La portata dell'utilizzo dell'IA da parte di Google lo rende un caso di studio ideale. Solo nel 2021, l'azienda ha addestrato modelli come il GLam da 1,2 trilioni di parametri. Analizzare come l'applicazione dell'IA è stata abbinata a rapidi guadagni di efficienza in questo ambiente ci aiuta a fornire un modello logico che il più ampio campo dell'IA seguirà.

Pubblicando in modo trasparente statistiche dettagliate sull'uso dell'energia, adottando tassi di acquisto di cloud senza emissioni di carbonio e fonti rinnovabili e altro ancora, insieme alle sue innovazioni tecniche, Google ha consentito ai ricercatori esterni di misurare i progressi in modo accurato. Il loro studio nell'ACM CACM [@patterson2022carbon] evidenzia come l'approccio multiforme dell'azienda dimostri che le previsioni di consumo energetico dell'IA incontrollabili possono essere superate concentrando gli sforzi ingegneristici su modelli di sviluppo sostenibile. Il ritmo dei miglioramenti suggerisce anche che i guadagni di efficienza dell'ML sono appena iniziati.

### Le 4M Best Practice di Google {#google-4m-best-practices}

Per ridurre le emissioni derivanti dai carichi di lavoro IA in rapida espansione, gli ingegneri di Google hanno sistematicamente identificato quattro aree di best practice, denominate "4 M", in cui le ottimizzazioni potrebbero sommarsi per ridurre l'impatto ambientale del ML:

* **Modello:** La selezione di architetture di modelli di intelligenza artificiale efficienti può ridurre i calcoli di 5-10 volte senza alcuna perdita di qualità. Google ha svolto ricerche approfondite sullo sviluppo di modelli "sparsi" e sulla ricerca di architetture neurali per creare modelli più efficienti come Evolved Transformer e Primer.
* **Macchina:** L'utilizzo di hardware ottimizzato per l'IA rispetto ai sistemi generici migliora le prestazioni per watt di 2-5 volte. Le Tensor Processing Unit (TPU) di Google hanno portato a un'efficienza di carbonio 5-13 volte migliore rispetto alle GPU non ottimizzate per il ML.
* **Meccanizzazione:** Sfruttando i sistemi di cloud computing progettati per un utilizzo elevato rispetto ai tradizionali data center on-premise, i costi energetici si riducono di 1,4-2 volte. Google cita l'efficacia dell'utilizzo energetico del suo data center come superiore alle medie del settore.
* **Mappa:** La scelta di ubicazioni per data center dotate di elettricità a basse emissioni di carbonio riduce le emissioni lorde di altre 5-10 volte. Google fornisce mappe in tempo reale che evidenziano la percentuale di energia rinnovabile utilizzata dalle sue strutture.

Insieme, queste pratiche hanno creato drastici guadagni di efficienza composti. Ad esempio, l'ottimizzazione del modello Transformer AI su TPU in una sede di data center sostenibile ha ridotto il consumo di energia dell'83%. Ha ridotto le emissioni di $\textrm{CO}_2$ di un fattore di 747.

### Risultati Significativi {#significant-results}

Nonostante la crescita esponenziale nell'adozione dell'IA nei prodotti e nei servizi, gli sforzi di Google per migliorare l'efficienza del carbonio del ML hanno prodotto guadagni misurabili, contribuendo a limitare l'appetito energetico complessivo. Un punto dati chiave che evidenzia questo progresso è che i carichi di lavoro dell'intelligenza artificiale sono rimasti stabili al 10%-15% del consumo energetico totale dell'azienda dal 2019 al 2021. Man mano che l'IA è diventata parte integrante di più offerte Google, i cicli di elaborazione complessivi dedicati ad essa sono cresciuti in modo sostanziale. Tuttavia, l'efficienza negli algoritmi, nell'hardware specializzato, nella progettazione dei data center e nella geografia flessibile ha consentito alla sostenibilità di tenere il passo, con l'IA che rappresenta solo una frazione dell'elettricità totale del data center in anni di espansione.

Altri casi di studio sottolineano come un focus ingegneristico sui modelli di sviluppo dell'intelligenza artificiale sostenibile abbia consentito rapidi miglioramenti della qualità di pari passo con i guadagni ambientali. Ad esempio, il modello di elaborazione del linguaggio naturale GPT-3 è stato considerato all'avanguardia a metà del 2020. Tuttavia, il suo successore GLaM ha migliorato la precisione riducendo al contempo le esigenze di elaborazione del training e utilizzando energia più pulita nei data center, riducendo le emissioni di CO~2~ di un fattore 14 in soli 18 mesi di evoluzione del modello.

Analogamente, Google ha scoperto che le precedenti speculazioni pubblicate non hanno colto nel segno sull'appetito energetico del ML per fattori da 100 a 100.000X a causa della mancanza di metriche del mondo reale. Tracciando in modo trasparente l'impatto dell'ottimizzazione, Google sperava di motivare l'efficienza evitando al contempo estrapolazioni sovrastimate sul pedaggio ambientale del ML.

Questi casi di studio basati sui dati mostrano come aziende come Google stiano indirizzando i progressi dell'IA verso traiettorie sostenibili e migliorando l'efficienza per superare la crescita dell'adozione. Con ulteriori sforzi in termini di analisi del ciclo di vita, ottimizzazione dell'inferenza ed espansione delle energie rinnovabili, le aziende possono puntare ad accelerare i progressi, dimostrando che il potenziale pulito del ML è stato appena sbloccato dagli attuali guadagni.

### Ulteriori Miglioramenti {#further-improvements}

Sebbene Google abbia compiuto progressi misurabili nel limitare l'impatto ambientale delle sue operazioni di intelligenza artificiale, l'azienda riconosce che ulteriori guadagni in termini di efficienza saranno essenziali per un'innovazione responsabile, data la continua espansione della tecnologia.

Un'area di attenzione è mostrare come i progressi siano spesso erroneamente considerati come un aumento dell'insostenibilità informatica, come la ricerca di architettura neurale (NAS) per trovare modelli ottimizzati, che stimolano risparmi a valle, superando i costi iniziali. Nonostante spenda più energia nella scoperta di modelli piuttosto che nell'ingegneria manuale, la NAS riduce le emissioni nel corso del ciclo di vita producendo progetti efficienti richiamabili su innumerevoli applicazioni.

Inoltre, l'analisi rivela che concentrare gli sforzi di sostenibilità sull'ottimizzazione lato server e data center ha senso, dato il consumo energetico dominante rispetto ai dispositivi consumer. Sebbene Google riduca gli impatti dell'inferenza su processori come i telefoni cellulari, la priorità è il miglioramento dei cicli di training e dell'approvvigionamento di energie rinnovabili per data center per ottenere il massimo effetto.

A tal fine, i progressi di Google nel mettere in comune strutture cloud progettate in modo inefficiente evidenziano il valore della scala e della centralizzazione. Man mano che sempre più carichi di lavoro si allontanano dai server inefficienti in sede, la priorità data dai giganti di Internet alle energie rinnovabili, con Google e Facebook abbinate al 100% dalle energie rinnovabili rispettivamente dal 2017 e dal 2020, sblocca tagli alle emissioni composte.

Insieme, questi sforzi sottolineano che, sebbene non sia possibile adagiarsi sugli allori, l'approccio multiforme di Google dimostra che i miglioramenti dell'efficienza dell'IA stanno solo accelerando. Le iniziative intersettoriali relative alla valutazione del ciclo di vita, ai modelli di sviluppo attenti alle emissioni di carbonio, alla trasparenza e all'abbinamento della crescente domanda di IA con la fornitura di energia elettrica pulita aprono la strada a un'ulteriore flessione della curva man mano che l'adozione aumenta. I risultati dell'azienda spingono il settore più ampio a replicare queste attività di sostenibilità integrate.

## IA Embedded - Internet of Trash {#embedded-ai-internet-of-trash}

Sebbene molta attenzione sia stata rivolta a rendere più sostenibili gli immensi data center che alimentano l'IA, una preoccupazione altrettanto urgente è lo spostamento delle capacità dell'IA in dispositivi edge e endpoint intelligenti. L'IA edge/embedded consente una reattività quasi in tempo reale senza dipendenze dalla connettività. Riduce inoltre le esigenze di larghezza di banda di trasmissione. Tuttavia, l'aumento di dispositivi minuscoli comporta altri rischi.

I minuscoli computer, microcontrollori e ASIC personalizzati che alimentano l'intelligenza edge affrontano limitazioni di dimensioni, costi e potenza che escludono le GPU di fascia alta utilizzate nei data center. Invece, richiedono algoritmi ottimizzati e circuiti estremamente compatti ed efficienti dal punto di vista energetico per funzionare senza problemi. Tuttavia, l'ingegneria per questi fattori di forma microscopici apre rischi in termini di obsolescenza programmata, smaltibilità e spreco. @fig-iot-devices mostra che si prevede che il numero di dispositivi IoT raggiungerà [i 30 miliardi di dispositivi connessi entro il 2030](https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/).

![Numero di dispositivi connessi all'Internet of Things (IoT) in tutto il mondo dal 2019 al 2023. Fonte: [Statista.](https://www.statista.com/statistics/1183457/iot-connected-devices-worldwide/)](images/png/statista_chip_growth.png){#fig-iot-devices}

La gestione del fine vita dei gadget connessi a Internet dotati di sensori e intelligenza artificiale rimane un problema spesso trascurato durante la progettazione. Tuttavia, questi prodotti permeano beni di consumo, veicoli, infrastrutture pubbliche, apparecchiature industriali e altro ancora.

### Rifiuti Elettronici {#e-waste}

I rifiuti elettronici, o "e-waste", si riferiscono ad apparecchiature elettriche e componenti scartati che entrano nel flusso dei rifiuti. Ciò include dispositivi che devono essere collegati, hanno una batteria o circuiti elettrici. Con la crescente adozione di dispositivi intelligenti e sensori connessi a Internet, i volumi di e-waste aumentano rapidamente ogni anno. Questi gadget in proliferazione contengono metalli pesanti tossici come piombo, mercurio e cadmio che diventano pericoli per l'ambiente e la salute se smaltiti in modo improprio.

La quantità di rifiuti elettronici prodotti sta crescendo a un ritmo allarmante. Oggi, [ne produciamo già 50 milioni di tonnellate all'anno](https://www.unep.org/news-and-stories/press-release/un-report-time-seize-opportunity-tackle-challenge-e-waste). Entro il 2030, si prevede che tale cifra salirà a ben 75 milioni di tonnellate, poiché il consumo di elettronica di consumo continua ad accelerare. La produzione globale di e-waste raggiungerà i 120 milioni di tonnellate all'anno entro il 2050 [@un2019circular]. La produzione in forte crescita e i brevi cicli di vita dei nostri gadget alimentano questa crisi, dagli smartphone e tablet ai dispositivi connessi a Internet e agli elettrodomestici.

I paesi in via di sviluppo sono i più colpiti, in quanto necessitano di più infrastrutture per elaborare in modo sicuro i dispositivi elettronici obsoleti. Nel 2019, i tassi di riciclaggio formali dei rifiuti elettronici nei paesi più poveri variavano dal 13% al 23%. Il resto finisce per essere scaricato illegalmente, bruciato o smantellato in modo grossolano, rilasciando materiali tossici nell'ambiente e danneggiando i lavoratori e le comunità locali. Chiaramente, c'è ancora molto da fare per costruire una capacità globale per una gestione etica e sostenibile dei rifiuti elettronici, altrimenti rischiamo danni irreversibili.

Il pericolo è che la manipolazione grossolana dei dispositivi elettronici per spogliarli delle parti di valore esponga i lavoratori e le comunità emarginati a nocive plastiche/metalli bruciati. L'avvelenamento da piombo presenta rischi particolarmente elevati per lo sviluppo infantile se ingerito o inalato. Nel complesso, solo circa il 20% dei rifiuti elettronici prodotti è stato raccolto utilizzando metodi ecologicamente corretti, secondo le stime delle Nazioni Unite [@un2019circular]. Quindi sono urgentemente necessarie soluzioni per una gestione responsabile del ciclo di vita per contenere lo smaltimento non sicuro, dato che il volume aumenta vertiginosamente.

### Elettronica Monouso {#disposable-electronics}

I costi in rapida diminuzione dei microcontrollori, delle piccole batterie ricaricabili e dell'hardware compatto di comunicazione hanno consentito l'integrazione di sistemi di sensori intelligenti nei beni di consumo di uso quotidiano. Questi dispositivi Internet-of-Things (IoT) monitorano le condizioni del prodotto, le interazioni degli utenti e i fattori ambientali per consentire reattività in tempo reale, personalizzazione e decisioni aziendali basate sui dati nel mercato connesso in evoluzione.

Tuttavia, questi dispositivi elettronici integrati affrontano poca supervisione o pianificazione per gestire in modo sostenibile il loro eventuale smaltimento una volta che i prodotti spesso rivestiti in plastica vengono scartati dopo breve tempo. I sensori IoT ora risiedono comunemente in articoli monouso come bottiglie d'acqua, imballaggi per alimenti, flaconi di farmaci e contenitori per cosmetici che finiscono prevalentemente nei flussi di rifiuti delle discariche dopo poche settimane o mesi di utilizzo da parte dei consumatori.

Il problema si accelera poiché sempre più produttori si affrettano a integrare chip mobili, fonti di alimentazione, moduli Bluetooth e altri moderni circuiti integrati in silicio, che costano meno di 1 dollaro USA, in vari prodotti senza protocolli per il riciclaggio, la sostituzione delle batterie o la riutilizzabilità dei componenti. Nonostante le loro piccole dimensioni individuali, i volumi di questi dispositivi e il peso dei rifiuti nel corso della loro vita incombono. A differenza della regolamentazione di dispositivi elettronici più grandi, esistono pochi vincoli normativi sui requisiti dei materiali o sulla tossicità di piccoli gadget monouso.

Pur offrendo praticità durante il lavoro, la combinazione insostenibile di difficile recupero e limitati meccanismi di guasto sicuri fa sì che i dispositivi connessi monouso contribuiscano a quote sproporzionate di futuri volumi di rifiuti elettronici che necessitano di urgente attenzione.

### Obsolescenza Programmata {#planned-obsolescence}

L'obsolescenza programmata si riferisce alla strategia di progettazione intenzionale di produzione di prodotti con durate di vita artificialmente limitate che diventano rapidamente non funzionali o obsoleti. Ciò stimola cicli di acquisto di sostituzione più rapidi poiché i consumatori scoprono che i dispositivi non soddisfano più le loro esigenze nel giro di pochi anni. Tuttavia, l'elettronica progettata per l'obsolescenza prematura contribuisce a volumi di rifiuti elettronici insostenibili.

Ad esempio, incollare batterie e componenti di smartphone insieme ostacola la riparabilità rispetto ad assemblaggi modulari e accessibili. L'implementazione di aggiornamenti software che rallentano deliberatamente le prestazioni del sistema crea la percezione che valga la pena aggiornare i dispositivi prodotti solo diversi anni prima.

Allo stesso modo, le introduzioni alla moda di nuove generazioni di prodotti con aggiunte di funzionalità minori ma esclusive fanno sembrare rapidamente datate le versioni precedenti. Queste tattiche costringono ad acquistare nuovi gadget ([ad esempio, iPhone](https://www.cnbc.com/2020/12/08/the-psychology-of-new-iphone-releases-apple-marketing.html)) molto prima della fine della loro operatività. Se moltiplicati per categorie di elettronica in rapida evoluzione, miliardi di articoli appena indossati vengono scartati ogni anno.

L'obsolescenza programmata intensifica quindi l'utilizzo delle risorse e la creazione di rifiuti nella produzione di prodotti senza alcuna intenzione di lunga durata. Ciò contraddice i principi di sostenibilità in materia di durata, riutilizzo e conservazione dei materiali. Mentre stimola vendite e guadagni continui per i produttori nel breve termine, la strategia esternalizza costi ambientali e tossine su comunità prive di un'adeguata infrastruttura di elaborazione dei rifiuti elettronici.

Le politiche e l'azione dei consumatori sono fondamentali per contrastare i design dei gadget che sono inutilmente monouso per default. Le aziende dovrebbero anche investire in programmi di gestione dei prodotti che supportino il riutilizzo e il recupero responsabili.

Consideriamo l'esempio del mondo reale. [Apple è stata attenzionata](https://undergradlawreview.blog.fordham.edu/consumer-protection/the-product-ecosystem-and-planned-obsolescence-apples-threats-to-consumer-rights/) nel corso degli anni per aver presumibilmente coinvolto nell'obsolescenza programmata per incoraggiare i clienti ad acquistare nuovi modelli di iPhone. L'azienda avrebbe progettato i suoi telefoni in modo che le prestazioni si degradino nel tempo o che le funzionalità esistenti diventino incompatibili con i nuovi sistemi operativi, il che, secondo i critici, è finalizzato a stimolare cicli di aggiornamento più rapidi. Nel 2020, Apple ha pagato una multa di 25 milioni di euro per risolvere un caso in Francia in cui le autorità di regolamentazione hanno ritenuto l'azienda colpevole di aver rallentato intenzionalmente i vecchi iPhone senza informare chiaramente i clienti tramite aggiornamenti di iOS.

Non essendo trasparente sulle modifiche alla gestione dell'alimentazione che hanno ridotto le prestazioni del dispositivo, Apple ha partecipato ad attività ingannevoli che hanno ridotto la durata del prodotto per aumentare le vendite. L'azienda ha affermato che è stato fatto per "smussare" i picchi che potrebbero causare improvvisamente lo spegnimento delle vecchie batterie. Tuttavia, questo esempio evidenzia i rischi legali legati all'impiego dell'obsolescenza programmata e alla mancata comunicazione corretta di quando le modifiche alle funzionalità influiscono sull'usabilità del dispositivo nel tempo: persino marchi leader come Apple possono avere problemi se percepiti come coloro che accorciano intenzionalmente i cicli di vita del prodotto.

## Considerazioni Normative e Politiche {#policy-and-regulatory-considerations}

### Mandati di Misura e Rendicontazione {#measurement-and-reporting-mandates}

Un meccanismo politico sempre più rilevante per i sistemi di IA è rappresentato dai requisiti di misurazione e rendicontazione relativi al consumo energetico e alle emissioni di carbonio. Misurazioni obbligatorie, audit, divulgazioni e metodologie più rigorose allineate alle metriche di sostenibilità possono aiutare a colmare le lacune informative che ostacolano le ottimizzazioni dell'efficienza.

Allo stesso tempo, le politiche nazionali o regionali richiedono alle aziende di una certa dimensione di utilizzare l'IA nei loro prodotti o sistemi back-end per segnalare il consumo energetico o le emissioni associate ai principali carichi di lavoro di IA. Organizzazioni come la Partnership on AI, IEEE e NIST potrebbero contribuire a definire metodologie standardizzate. Proposte più complesse implicano la definizione di modalità coerenti per misurare la complessità computazionale, il PUE del data center, l'intensità di carbonio dell'approvvigionamento energetico e le efficienze ottenute tramite hardware specifico per l'IA.

Anche gli obblighi di rendicontazione per gli utenti del settore pubblico che acquistano servizi di IA, ad esempio tramite una proposta di legge in Europa, potrebbero aumentare la trasparenza. Tuttavia, gli enti regolatori devono bilanciare l'ulteriore onere di misurazione che tali mandati impongono alle organizzazioni con le continue riduzioni di carbonio derivanti dall'incorporazione di modelli di sviluppo consapevoli della sostenibilità.

Per essere più costruttivi, qualsiasi politica di misurazione e rendicontazione dovrebbe concentrarsi sull'abilitazione di un continuo perfezionamento piuttosto che su restrizioni o limiti semplicistici. Man mano che i progressi dell'IA si sviluppano rapidamente, agili barriere di sicurezza di governance che incorporano considerazioni sulla sostenibilità in normali metriche di valutazione possono motivare un cambiamento positivo. Tuttavia, una prescrizione eccessiva rischia di limitare l'innovazione se i requisiti diventano obsoleti. La politica di efficienza dell'IA accelera i progressi in tutto il settore combinando flessibilità con appropriate barriere di sicurezza di trasparenza.

### Meccanismi di Restrizione {#restriction-mechanisms}

Oltre agli obblighi di segnalazione, i politici dispongono di diversi meccanismi di restrizione che potrebbero modellare direttamente il modo in cui i sistemi di IA vengono sviluppati e implementati per ridurre le emissioni:

Limiti sulle Emissioni delle Elaborazioni: La [proposta di legge sull'intelligenza artificiale della Commissione europea](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence) adotta un approccio orizzontale che potrebbe consentire di stabilire limiti per l'intera economia sul volume di potenza di elaborazione disponibile per l'addestramento dei modelli di intelligenza artificiale. Come i sistemi di scambio delle emissioni, i limiti mirano a disincentivare indirettamente l'elaborazione estensiva rispetto alla sostenibilità. Tuttavia, la qualità del modello potrebbe essere migliorata per fornire più percorsi per l'acquisizione di capacità aggiuntiva.

Condizionamento dell'Accesso alle Risorse Pubbliche: Alcuni esperti hanno proposto incentivi come consentire l'accesso solo a set di dati pubblici o potenza di elaborazione per lo sviluppo di modelli fondamentalmente efficienti piuttosto che architetture stravaganti. Ad esempio, il [consorzio di benchmarking MLCommons](https://mlcommons.org/) fondato da importanti aziende tecnologiche potrebbe integrare formalmente l'efficienza nelle sue metriche di classifica standardizzate, tuttavia, l'accesso condizionato rischia di limitare l'innovazione.

Meccanismi Finanziari: Analogamente alle tasse sul carbonio sulle industrie inquinanti, le tariffe applicate per unità di consumo di elaborazione correlato all'IA potrebbero scoraggiare un inutile ridimensionamento del modello, finanziando al contempo innovazioni di efficienza. I crediti d'imposta potrebbero in alternativa premiare le organizzazioni pioniere di tecniche di IA più accurate ma compatte. Tuttavia, gli strumenti finanziari richiedono un'attenta calibrazione tra generazione di entrate ed equità e non penalizzare eccessivamente gli usi produttivi dell'IA.

Divieti Tecnologici: Se la misurazione fissasse costantemente le emissioni estreme su applicazioni specifiche dell'IA senza percorsi di bonifica, i divieti assoluti rappresentano uno strumento di ultima istanza per i decisori politici. Tuttavia, dato il duplice uso dell'IA, definire implementazioni dannose e benefiche risulta complesso, rendendo necessaria una valutazione di impatto olistica prima di concludere che non esiste alcun valore redentivo. Vietare tecnologie promettenti rischia di avere conseguenze indesiderate e richiede cautela.

### Incentivi Governativi {#government-incentives}

È una pratica comune per i governi fornire incentivi fiscali o di altro tipo a consumatori o aziende quando contribuiscono a pratiche tecnologiche più sostenibili. Tali incentivi esistono già negli Stati Uniti per [l'adozione di pannelli solari](https://www.irs.gov/credits-deductions/residential-clean-energy-credit) o [edifici a risparmio energetico](https://www.energy.gov/eere/buildings/179d-commercial-buildings-energy-efficiency-tax-deduction). Per quanto ne sappiamo, non esistono ancora incentivi fiscali per pratiche di sviluppo specifiche per l'IA.

Un altro potenziale programma di incentivi che sta iniziando a essere esplorato è l'utilizzo di sovvenzioni governative per finanziare progetti di IA Green. Ad esempio, in Spagna, [sono stati stanziati 300 milioni di euro](https://www.state.gov/artificial-intelligence-for-accelerating-progress-on-the-sustainable-development-goals-addressing-societys-greatest-challenges/) per finanziare specificamente progetti di IA e sostenibilità. Gli incentivi governativi sono una strada promettente per incoraggiare pratiche di comportamento aziendale e dei consumatori sostenibili, ma è necessaria un'attenta riflessione per determinare come tali incentivi si adatteranno alle richieste del mercato [@maxime2016impact].

### Autoregolamentazione {#self-regulation}

Complementari alle potenziali azioni governative, i meccanismi di autogoverno volontario consentono alla comunità dell'IA di perseguire obiettivi di sostenibilità senza interventi dall'alto:

Impegni per le Energie Rinnovabili: Grandi professionisti dell'IA come Google, Microsoft, Amazon e Facebook si sono impegnati ad acquistare abbastanza elettricità rinnovabile per soddisfare il 100% delle loro richieste energetiche. Questi impegni sbloccano tagli alle emissioni composti man mano che aumenta la potenza di calcolo. La formalizzazione di tali programmi incentiva le regioni dei data center verdi. Tuttavia, ci sono critiche sul fatto che questi impegni siano sufficienti [@monyei2018electrons].

Prezzi Interni del Carbonio: Alcune organizzazioni utilizzano prezzi ombra sulle emissioni di carbonio per rappresentare i costi ambientali nelle decisioni di allocazione del capitale tra progetti di IA. Se modellati in modo efficace, gli oneri teorici sulle impronte di carbonio dello sviluppo indirizzano i finanziamenti verso innovazioni efficienti piuttosto che solo verso guadagni di accuratezza.

Checklist per lo Sviluppo dell'Efficienza: Gruppi come AI Sustainability Coalition suggeriscono modelli di checklist volontari che evidenziano le scelte di progettazione del modello, le configurazioni hardware e altri fattori che gli architetti possono regolare per applicazione per limitare le emissioni. Le organizzazioni possono guidare il cambiamento radicando la sostenibilità come metrica di successo primaria insieme a precisione e costi.

Auditing Indipendente: Anche in assenza di mandati di divulgazione pubblica, le aziende specializzate in audit di sostenibilità tecnologica aiutano gli sviluppatori di IA a identificare gli sprechi, creare roadmap di efficienza e confrontare i progressi tramite revisioni imparziali. Strutturare tali audit in procedure di governance interna o nel processo di approvvigionamento espande la responsabilità.

### Considerazioni Globali {#global-considerations}

Mentre misurazione, restrizioni, incentivi e autoregolamentazione rappresentano potenziali meccanismi politici per promuovere la sostenibilità dell'IA, la frammentazione tra i regimi nazionali rischia di avere conseguenze indesiderate. Come per altri domini di politica tecnologica, la divergenza tra regioni deve essere gestita attentamente.

Ad esempio, a causa di preoccupazioni sulla privacy dei dati regionali, OpenAI ha impedito agli utenti europei di accedere al suo chatbot virale ChatGPT. Ciò è avvenuto dopo che la proposta di legge sull'IA dell'UE ha segnalato un approccio precauzionale, consentendo alla CE di vietare determinati usi dell'IA ad alto rischio e di imporre regole di trasparenza che creano incertezza per il rilascio di nuovi modelli. Tuttavia, sarebbe saggio mettere in guardia contro l'azione del regolatore in quanto potrebbe inavvertitamente limitare l'innovazione europea se i regimi con una regolamentazione più leggera attraggono più spesa e talenti per la ricerca sull'IA nel settore privato. Trovare un terreno comune è fondamentale.

I principi dell'OCSE sull'IA e i quadri delle Nazioni Unite sottolineano principi universalmente concordati che tutte le politiche nazionali dovrebbero sostenere: trasparenza, responsabilità, mitigazione dei "bias" [pregiudizi] e altro ancora. Incorporare in modo costruttivo la sostenibilità come principio fondamentale per un'IA responsabile all'interno di linee guida internazionali può motivare un'azione unitaria senza sacrificare la flessibilità tra sistemi legali divergenti. Evitare dinamiche di corsa al ribasso dipende da una cooperazione multilaterale illuminata.

## Percezione e Coinvolgimento del Pubblico {#public-perception-and-engagement}

Mentre l'attenzione della società e gli sforzi politici volti alla sostenibilità ambientale aumentano in tutto il mondo, cresce l'entusiasmo per l'utilizzo dell'intelligenza artificiale per aiutare ad affrontare le sfide ecologiche. Tuttavia, la comprensione e gli atteggiamenti del pubblico nei confronti del ruolo dei sistemi di IA nei contesti di sostenibilità devono ancora essere chiariti e sono offuscati da idee sbagliate. Da un lato, le persone sperano che algoritmi avanzati possano fornire nuove soluzioni per l'energia verde, il consumo responsabile, i percorsi di decarbonizzazione e la conservazione dell'ecosistema. Dall'altro, i timori sui rischi dell'IA incontrollata si insinuano anche nel dominio ambientale e minano il discorso costruttivo. Inoltre, una mancanza di consapevolezza pubblica su questioni chiave come la trasparenza nello sviluppo di strumenti di IA incentrati sulla sostenibilità e potenziali pregiudizi nei dati o nella modellazione minacciano anche di limitare la partecipazione inclusiva e degradare la fiducia del pubblico.

Affrontare priorità complesse e interdisciplinari come la sostenibilità ambientale richiede un coinvolgimento pubblico informato e sfumato e progressi responsabili nell'innovazione dell'IA. Il percorso da seguire richiede sforzi collaborativi attenti ed equi tra esperti in ML, climatologia, politica ambientale, scienze sociali e comunicazione. Mappare il panorama delle percezioni pubbliche, identificare le insidie e tracciare strategie per coltivare sistemi di IA comprensibili, accessibili e affidabili che puntino a priorità ecologiche condivise si rivelerà essenziale per realizzare obiettivi di sostenibilità. Questo terreno complesso giustifica un esame approfondito delle dinamiche socio-tecniche coinvolte.

### Consapevolezza dell'IA {#ai-awareness}

A maggio 2022, il [Pew Research Center ha intervistato 5.101 adulti statunitensi](https://www.pewresearch.org/internet/2023/08/17/what-americans-know-about-ai-cybersecurity-and-big-tech/), scoprendo che il 60% aveva sentito o letto "un po'" sull'IA mentre il 27% ne aveva sentito "molto", il che indica un discreto riconoscimento generale, ma probabilmente una comprensione limitata di dettagli o applicazioni. Tuttavia, tra coloro che hanno una certa familiarità con l'IA, emergono preoccupazioni riguardo ai rischi di uso improprio dei dati personali secondo i termini concordati. Ciononostante, il 62% ritiene che l'IA potrebbe semplificare la vita moderna se applicata in modo responsabile. Tuttavia, una comprensione specifica dei contesti di sostenibilità deve ancora essere migliorata.

Gli studi che tentano di categorizzare i "sentiment" del discorso online rilevano una divisione quasi equa tra ottimismo e cautela riguardo all'implementazione dell'IA per obiettivi di sostenibilità. I fattori che guidano la positività includono le speranze di una migliore previsione dei cambiamenti ecologici utilizzando modelli di ML. La negatività nasce da una mancanza di fiducia negli algoritmi auto-supervisionati che evitano conseguenze indesiderate dovute a impatti umani imprevedibili su sistemi naturali complessi durante l'addestramento.

La convinzione pubblica più diffusa rimane che, mentre l'IA ha il potenziale per accelerare le soluzioni su questioni come la riduzione delle emissioni e la protezione della fauna selvatica, una salvaguardia inadeguata intorno a pregiudizi dei dati, punti ciechi etici e considerazioni sulla privacy potrebbero essere rischi più apprezzati se perseguiti con noncuranza, soprattutto su larga scala. Ciò porta a esitazione intorno al supporto incondizionato senza prove di uno sviluppo deliberato e guidato democraticamente.

### Messaggistica {#messaging}

[Gli sforzi ottimistici](https://www.climatechange.ai/) stanno evidenziando la promessa di sostenibilità dell'IA e sottolineano il potenziale del ML avanzato per accelerare radicalmente gli effetti di decarbonizzazione da reti intelligenti, app personalizzate di tracciamento del carbonio, ottimizzazioni automatizzate dell'efficienza degli edifici e analisi predittive che guidano gli sforzi di conservazione mirati. Una modellazione in tempo reale più completa di complessi cambiamenti climatici ed ecologici utilizzando algoritmi auto-miglioranti offre speranza per mitigare le perdite di biodiversità ed evitare gli scenari peggiori.

Tuttavia, [prospettive cautelative](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/), come i [Principi di IA di Asilomar](https://futureoflife.org/open-letter/ai-principles/), mettono in dubbio se l'IA stessa potrebbe esacerbare le sfide della sostenibilità se vincolata in modo improprio. Le crescenti richieste di energia dei sistemi di elaborazione su larga scala e il training sempre più massiccio del modello di rete neurale sono in conflitto con le ambizioni di energia pulita. La mancanza di diversità negli input di dati o nelle priorità degli sviluppatori potrebbe sminuire le urgenti considerazioni di giustizia ambientale. L'impegno pubblico scettico a breve termine probabilmente dipende dalla necessità di salvaguardie percepibili contro i sistemi di intelligenza artificiale incontrollati che impazziscono nei processi ecologici fondamentali.

In sostanza, i "framing" polarizzati promuovono l'intelligenza artificiale come uno strumento indispensabile per la risoluzione dei problemi di sostenibilità, se indirizzata compassionevolmente verso le persone e il pianeta, oppure presentano l'IA come un amplificatore dei danni esistenti che dominano insidiosamente aspetti nascosti dei sistemi naturali centrali per tutta la vita. Superare tali impasse richiede di bilanciare discussioni oneste sui compromessi con visioni condivise per un progresso tecnologico equo e democraticamente governato che mira al ripristino.

### Partecipazione Equa {#equitable-participation}

Garantire una partecipazione e un accesso equi dovrebbe costituire la pietra angolare di qualsiasi iniziativa di sostenibilità con il potenziale per importanti impatti sociali. Questo principio si applica ugualmente ai sistemi di IA che mirano a obiettivi ambientali. Tuttavia, voci comunemente escluse come le comunità in prima linea, rurali o indigene e le generazioni future non presenti per il consenso potrebbero subire conseguenze sproporzionate dalle trasformazioni tecnologiche. Ad esempio, la [Partnership on AI](https://partnershiponai.org) ha lanciato eventi espressamente mirati al contributo delle comunità emarginate sull'implementazione responsabile dell'intelligenza artificiale.

Garantire un accesso e una partecipazione equi dovrebbe costituire la pietra angolare di qualsiasi iniziativa di sostenibilità con il potenziale per importanti impatti sociali, che si tratti di intelligenza artificiale o altro. Tuttavia, l'impegno inclusivo nell'intelligenza artificiale ambientale si basa in parte sulla disponibilità e sulla comprensione delle risorse informatiche fondamentali. Come sottolinea il recente rapporto [OCSE](https://www.oecd.org/) sulla [capacità di calcolo IA nazionale](https://www.oecd.org/economy/a-blueprint-for-building-national-compute-capacity-for-artificial-intelligence-876367e3-en.htm) [@oecd2023blueprint], molti paesi attualmente non dispongono di dati o piani strategici che mappino le esigenze per l'infrastruttura richiesta per alimentare i sistemi di IA. Questo punto cieco politico potrebbe limitare gli obiettivi economici ed esacerbare le barriere all'ingresso per le popolazioni emarginate. Il loro progetto sollecita lo sviluppo di strategie nazionali per la capacità di calcolo AI lungo dimensioni di capacità, accessibilità, pipeline di innovazione e resilienza per ancorare l'innovazione. L'archiviazione dei dati di base deve essere migliorata e le piattaforme di sviluppo dei modelli o l'hardware specializzato potrebbero inavvertitamente concentrare i progressi dell'AI nelle mani di gruppi selezionati. Pertanto, la pianificazione di un'espansione equilibrata delle risorse di calcolo AI fondamentali tramite iniziative politiche si collega direttamente alle speranze di una risoluzione dei problemi di sostenibilità democratizzata utilizzando strumenti ML equi e trasparenti.

L'idea chiave è che la partecipazione equa nei sistemi di intelligenza artificiale che affrontano le sfide ambientali si basa in parte sulla garanzia che la capacità di elaborazione e l'infrastruttura di base siano corrette, il che richiede una pianificazione politica proattiva da una prospettiva nazionale.

### Trasparenza {#transparency}

Mentre le agenzie del settore pubblico e le aziende private si affrettano ad adottare strumenti di IA per aiutare ad affrontare le urgenti sfide ambientali, le richieste di trasparenza sullo sviluppo e la funzionalità di questi sistemi hanno iniziato ad amplificarsi. Le funzionalità di ML spiegabili e interpretabili diventano sempre più cruciali per creare fiducia nei modelli emergenti che mirano a guidare le conseguenti politiche di sostenibilità. Iniziative come il [Montreal Carbon Pledge](https://unfccc.int/news/montreal-carbon-pledge) hanno riunito i leader della tecnologia per impegnarsi a pubblicare valutazioni di impatto prima di lanciare sistemi ambientali, come promesso di seguito:

> _"Come investitori istituzionali, dobbiamo agire nel migliore interesse a lungo termine dei nostri beneficiari. In questo ruolo fiduciario, i rischi di investimento a lungo termine sono associati alle emissioni di gas serra, ai cambiamenti climatici e alla regolamentazione del carbonio. Misurare la nostra impronta di carbonio è fondamentale per comprendere meglio, quantificare e gestire gli impatti, i rischi e le opportunità correlati al carbonio e ai cambiamenti climatici nei nostri investimenti. Pertanto, come primo passo, ci impegniamo a misurare e divulgare annualmente l'impronta di carbonio dei nostri investimenti per utilizzare queste informazioni per sviluppare una strategia di coinvolgimento e identificare e stabilire obiettivi di riduzione dell'impronta di carbonio." -- Montréal Carbon Pledge_

Abbiamo bisogno di un impegno simile per la sostenibilità e la responsabilità dell'IA. L'accettazione diffusa e l'impatto delle soluzioni di sostenibilità dell'IA dipenderanno in parte dalla comunicazione deliberata di schemi di convalida, metriche e livelli di giudizio umano applicati prima dell'implementazione in tempo reale. Lavori come i [Principi per l'IA spiegabile del NIST](https://oecd.ai/en/dashboards/policy-initiatives/http:%2F%2Faipo.oecd.org%2F2021-data-policyInitiatives-26746) possono aiutare a promuovere la trasparenza nei sistemi di IA. Il National Institute of Standards and Technology (NIST) ha pubblicato un influente set di linee guida denominato "Principles for Explainable AI" [Principi per l'IA spiegabile]  [@phillips2020four]. Questo framework articola le best practice per la progettazione, la valutazione e l'implementazione di sistemi di IA responsabili con funzionalità trasparenti e interpretabili che creano comprensione e fiducia fondamentali per l'utente.

Delinea quattro principi fondamentali: in primo luogo, i sistemi di IA dovrebbero fornire spiegazioni contestualmente rilevanti che giustifichino il ragionamento alla base dei loro output alle parti interessate appropriate. In secondo luogo, queste spiegazioni di IA devono comunicare informazioni in modo significativo per il livello di comprensione appropriato del loro pubblico target. Il successivo è il principio di accuratezza, che stabilisce che le spiegazioni dovrebbero riflettere fedelmente il processo effettivo e la logica che informano i meccanismi interni di un modello di IA per generare output o raccomandazioni dati in base agli input. Infine, un principio di limiti di conoscenza obbliga le spiegazioni a chiarire i confini di un modello di IA nel catturare l'intera ampiezza della complessità, della varianza e delle incertezze del mondo reale all'interno di uno spazio problematico.

Nel complesso, questi principi NIST offrono ai professionisti e agli adottanti dell'IA una guida su considerazioni chiave sulla trasparenza, essenziali per sviluppare soluzioni accessibili che diano priorità all'autonomia e alla fiducia dell'utente piuttosto che semplicemente massimizzare le sole metriche di accuratezza predittiva. Man mano che l'IA avanza rapidamente in contesti sociali sensibili come sanità, finanza, occupazione e oltre, tali linee guida di progettazione incentrate sull'uomo continueranno a crescere in importanza per ancorare l'innovazione agli interessi pubblici.

Ciò si applica anche al dominio della capacità ambientale. Un'innovazione dell'IA responsabile e guidata democraticamente che mira a priorità ecologiche condivise dipende dal mantenimento della vigilanza pubblica, della comprensione e della supervisione su sistemi altrimenti opachi che assumono ruoli di primo piano nelle decisioni della società. Dare priorità a progetti di algoritmi spiegabili e pratiche di trasparenza radicale secondo standard globali può aiutare a sostenere la fiducia collettiva che questi strumenti migliorino piuttosto che mettere a repentaglio le speranze per un futuro guidato.

## Direzioni e Sfide Future {#future-directions-and-challenges}

Guardando al futuro, il ruolo dell'IA nella sostenibilità ambientale è destinato a crescere in modo ancora più significativo. Il potenziale dell'IA per guidare i progressi nell'energia rinnovabile, nella modellazione climatica, negli sforzi di conservazione e altro è immenso. Tuttavia, è una moneta a due facce, poiché dobbiamo superare diverse sfide e indirizzare i nostri sforzi verso uno sviluppo dell'IA sostenibile e responsabile.

### Direzioni Future {#future-directions}

Una delle direzioni chiave del futuro è lo sviluppo di modelli e algoritmi di intelligenza artificiale più efficienti dal punto di vista energetico. Ciò implica una ricerca e innovazione continue in aree come il "pruning" [potatura] dei modelli, la quantizzazione e l'uso di numeri a bassa precisione, nonché lo sviluppo dell'hardware per consentire la piena redditività di queste innovazioni. Inoltre, esaminiamo paradigmi di elaborazione alternativi che non si basano su architetture von-Neumann. Ulteriori informazioni su questo argomento sono disponibili nel capitolo sull'accelerazione hardware. L'obiettivo è creare sistemi di IA che offrano prestazioni elevate riducendo al minimo il consumo di energia e le emissioni di carbonio.

Un'altra direzione importante è l'integrazione di fonti di energia rinnovabili nell'infrastruttura di IA. Poiché i data center continuano a contribuire in modo significativo all'impronta di carbonio dell'IA, la transizione verso fonti di energia rinnovabili come l'energia solare ed eolica è fondamentale. Gli sviluppi nell'accumulo di energia sostenibile a lungo termine, come [Ambri](https://ambri.com/), uno spin-off del MIT, potrebbero consentire questa transizione. Ciò richiede investimenti e collaborazioni significativi tra aziende tecnologiche, fornitori di energia e politici.

### Sfide

Nonostante queste promettenti direzioni, devono essere affrontate diverse sfide. Una delle sfide principali è la necessità di standard e metodologie coerenti per misurare e segnalare l'impatto ambientale dell'IA. Questi metodi devono catturare la complessità dei cicli di vita dei modelli di IA e dell'hardware di sistema. Inoltre, sono necessarie infrastrutture IA e hardware di sistema efficienti e sostenibili dal punto di vista ambientale. Ciò è costituito da tre componenti:

1. Massimizzare l'utilizzo delle risorse di acceleratore e sistema.
2. Prolungare la durata di vita delle infrastrutture IA.
3. Progettare hardware di sistema tenendo presente l'impatto ambientale.

Dal lato software, dovremmo bilanciare la sperimentazione e il conseguente costo di training. Tecniche come la ricerca dell'architettura neurale e l'ottimizzazione degli iperparametri possono essere utilizzate per l'esplorazione dello spazio di progettazione. Tuttavia, queste sono spesso molto dispendiose in termini di risorse. Una sperimentazione efficiente può ridurre significativamente l'impatto ambientale. Successivamente, dovrebbero essere esplorati metodi per ridurre gli sforzi di training sprecati.

Per migliorare la qualità del modello, spesso ridimensioniamo il set di dati. Tuttavia, le maggiori risorse di sistema richieste per l'archiviazione e l'ingestione dei dati causate da questa scalabilità hanno un impatto ambientale significativo [@wu2022sustainable]. È importante comprendere a fondo la velocità con cui i dati perdono il loro valore predittivo e ideare strategie di campionamento dei dati.

Anche le lacune nei dati rappresentano una sfida significativa. Senza aziende e governi che condividono apertamente dati dettagliati e accurati sul consumo di energia, sulle emissioni di carbonio e su altri impatti ambientali, non è facile sviluppare strategie efficaci per un'IA sostenibile.

Infine, il ritmo rapido dello sviluppo dell'IA richiede un approccio agile alla politica imposta a questi sistemi. La politica dovrebbe garantire uno sviluppo sostenibile senza limitare l'innovazione. Ciò richiede che esperti in tutti i settori dell'IA, delle scienze ambientali, dell'energia e della politica lavorino insieme per raggiungere un futuro sostenibile.

## Conclusione

Dobbiamo affrontare le considerazioni sulla sostenibilità man mano che l'intelligenza artificiale si espande rapidamente nei settori e nella società. L'intelligenza artificiale promette innovazioni rivoluzionarie, ma il suo impatto ambientale minaccia la sua crescita diffusa. Questo capitolo analizza molteplici aspetti, dall'energia e dalle emissioni agli impatti sui rifiuti e sulla biodiversità, che gli sviluppatori di intelligenza artificiale/apprendimento automatico devono valutare quando creano sistemi di IA responsabili.

Fondamentalmente, abbiamo bisogno di elevare la sostenibilità a priorità di progettazione primaria piuttosto che a un ripensamento. Tecniche come modelli ad alta efficienza energetica, data center alimentati da fonti rinnovabili e programmi di riciclaggio dell'hardware offrono soluzioni, ma l'impegno olistico rimane fondamentale. Abbiamo bisogno di standard in materia di trasparenza, contabilità del carbonio e divulgazioni della catena di fornitura per integrare i guadagni tecnici. Tuttavia, esempi come le pratiche di efficienza 4M di Google contenenti l'uso di energia ML evidenziano che possiamo far progredire l'intelligenza artificiale di pari passo con gli obiettivi ambientali con uno sforzo concertato. Raggiungiamo questo equilibrio armonioso facendo collaborare ricercatori, aziende, regolatori e utenti in tutti i domini. L'obiettivo non è soluzioni perfette, ma un miglioramento continuo mentre integriamo l'IA in nuovi settori.

## Risorse {#sec-sustainable-ai-resource}

Ecco un elenco curato di risorse per supportare studenti e insegnanti nei loro percorsi di apprendimento e insegnamento. Lavoriamo continuamente per espandere questa raccolta e presto aggiungeremo nuovi esercizi.

:::{.callout-note collapse="false"}

#### Slide

Queste slide sono uno strumento prezioso per gli insegnanti per tenere lezioni e per gli studenti per rivedere il materiale secondo il proprio ritmo. Incoraggiamo studenti e docenti a sfruttare queste slide per migliorare la loro comprensione e facilitare un trasferimento efficace delle conoscenze.

* [Transparency and Sustainability.](https://docs.google.com/presentation/d/1wGKWV-speisH6V-g-u_w8xFwEjZjqp7u2YXs27flmiM/edit#slide=id.ge93ee14fb9_0_0)

* [Sustainability of TinyML.](https://docs.google.com/presentation/d/1rdJ82YlvD66JDATtj-KUQkJ6tkuAfFAs1w6-njvp6zM/edit#slide=id.ge93ee14fb9_0_0)

* [Model Cards for Transparency.](https://docs.google.com/presentation/d/1ndDzSwnSMNwUShW-RyIN29T9KeEoM_I14qsExPehW70/edit#slide=id.ge947b43ef5_0_0)

:::

:::{.callout-important collapse="false"}

#### Video

* _Prossimamente._
:::

:::{.callout-caution collapse="false"}

#### Esercizi

Per rafforzare i concetti trattati in questo capitolo, abbiamo curato una serie di esercizi che sfidano gli studenti ad applicare le proprie conoscenze e ad approfondire la propria comprensione.

* @exr-cf

* @exr-mle
:::

:::{.callout-warning collapse="false"}

#### Laboratori

Oltre agli esercizi, offriamo laboratori pratici che consentono agli studenti di acquisire esperienza pratica con le tecnologie di IA embedded. Questi laboratori forniscono una guida passo dopo passo, consentendo agli studenti di sviluppare le proprie competenze in un ambiente strutturato e di supporto. Siamo lieti di annunciare che presto saranno disponibili nuovi laboratori, che arricchiranno ulteriormente l'esperienza di apprendimento.

* _Prossimamente._
:::
